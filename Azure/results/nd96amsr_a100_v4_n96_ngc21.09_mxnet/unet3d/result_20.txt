+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019052430792557079
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019052430792557079
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019052430792557079
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019052430792557079
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07381/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019052430792557079_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C0436
Clearing cache on ip-0A0C046E
Clearing cache on ip-0A0C0486
Clearing cache on ip-0A0C048A
Clearing cache on ip-0A0C0441
Clearing cache on ip-0A0C0497
Clearing cache on ip-0A0C0495
Clearing cache on ip-0A0C04A0
Clearing cache on ip-0A0C0493
Clearing cache on ip-0A0C042D
Clearing cache on ip-0A0C0491
Clearing cache on ip-0A0C0489
Clearing cache on ip-0A0C046C
Clearing cache on ip-0A0C0472
Clearing cache on ip-0A0C0437
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C048C
Clearing cache on ip-0A0C0483
Clearing cache on ip-0A0C0435
Clearing cache on ip-0A0C045F
Clearing cache on ip-0A0C0473
Clearing cache on ip-0A0C0449
Clearing cache on ip-0A0C0466
Clearing cache on ip-0A0C0487
Clearing cache on ip-0A0C0438
Clearing cache on ip-0A0C047E
Clearing cache on ip-0A0C0496
Clearing cache on ip-0A0C0464
Clearing cache on ip-0A0C044D
Clearing cache on ip-0A0C0460
Clearing cache on ip-0A0C0484
Clearing cache on ip-0A0C0429
Clearing cache on ip-0A0C049F
Clearing cache on ip-0A0C04A4
Clearing cache on ip-0A0C0443
Clearing cache on ip-0A0C0498
Clearing cache on ip-0A0C0482
Clearing cache on ip-0A0C04AA
Clearing cache on ip-0A0C04C8
Clearing cache on ip-0A0C04B7
Clearing cache on ip-0A0C048D
Clearing cache on ip-0A0C04BA
Clearing cache on ip-0A0C04A8
Clearing cache on ip-0A0C048B
Clearing cache on ip-0A0C04A2
Clearing cache on ip-0A0C04B1
Clearing cache on ip-0A0C04B4
Clearing cache on ip-0A0C0490
Clearing cache on ip-0A0C049C
Clearing cache on ip-0A0C04A7
Clearing cache on ip-0A0C0492
Clearing cache on ip-0A0C04B3
Clearing cache on ip-0A0C04A9
Clearing cache on ip-0A0C04C7
Clearing cache on ip-0A0C04C2
Clearing cache on ip-0A0C04BB
Clearing cache on ip-0A0C04C3
Clearing cache on ip-0A0C04B0
Clearing cache on ip-0A0C048F
Clearing cache on ip-0A0C04BE
Clearing cache on ip-0A0C04C5
Clearing cache on ip-0A0C04CD
Clearing cache on ip-0A0C04DB
Clearing cache on ip-0A0C04D4
Clearing cache on ip-0A0C04C4
Clearing cache on ip-0A0C04C6
Clearing cache on ip-0A0C049B
Clearing cache on ip-0A0C04B2
Clearing cache on ip-0A0C04CF
Clearing cache on ip-0A0C04AF
Clearing cache on ip-0A0C04BD
Clearing cache on ip-0A0C04B9
Clearing cache on ip-0A0C0485
Clearing cache on ip-0A0C04C0
Clearing cache on ip-0A0C04A1
Clearing cache on ip-0A0C04BC
Clearing cache on ip-0A0C04AD
Clearing cache on ip-0A0C04DA
Clearing cache on ip-0A0C04D3
Clearing cache on ip-0A0C04A5
Clearing cache on ip-0A0C0499
Clearing cache on ip-0A0C0494
Clearing cache on ip-0A0C0488
Clearing cache on ip-0A0C04D9
Clearing cache on ip-0A0C04AC
Clearing cache on ip-0A0C04AE
Clearing cache on ip-0A0C04B6
Clearing cache on ip-0A0C04D8
Clearing cache on ip-0A0C04C9
Clearing cache on ip-0A0C04A6
Clearing cache on ip-0A0C046B
Clearing cache on ip-0A0C0461
Clearing cache on ip-0A0C04B5
Clearing cache on ip-0A0C04AB
Clearing cache on ip-0A0C049D
Clearing cache on ip-0A0C04CC
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:24:33 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634621078.255213] [ip-0A0C04BE:46830:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.262693] [ip-0A0C049C:556  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.274588] [ip-0A0C04AB:4532 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.280554] [ip-0A0C048D:14969:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.292948] [ip-0A0C04D3:36198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.299450] [ip-0A0C046E:30889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.308488] [ip-0A0C0466:31580:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.314986] [ip-0A0C046E:30885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.317433] [ip-0A0C0488:27071:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.319732] [ip-0A0C04B3:21631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.323753] [ip-0A0C04AE:19407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.325748] [ip-0A0C049C:569  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.326079] [ip-0A0C049C:577  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.326468] [ip-0A0C04AB:4529 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.328957] [ip-0A0C0466:31579:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.329405] [ip-0A0C04BD:44434:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.333947] [ip-0A0C04AB:4536 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.338222] [ip-0A0C0497:61351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.344227] [ip-0A0C04BE:46831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.345494] [ip-0A0C0464:28928:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.346375] [ip-0A0C04AE:19411:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.347451] [ip-0A0C0464:28927:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.347488] [ip-0A0C04A9:13023:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.350760] [ip-0A0C048F:18770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.351359] [ip-0A0C0482:16697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.352890] [ip-0A0C04CC:38332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.353030] [ip-0A0C0483:27898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.353063] [ip-0A0C0483:27897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.354500] [ip-0A0C046E:30884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.355385] [ip-0A0C048D:14970:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.356466] [ip-0A0C04B9:46910:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.356840] [ip-0A0C0499:15624:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.357760] [ip-0A0C04BE:46832:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.357780] [ip-0A0C04A4:14367:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.358695] [ip-0A0C04C8:38941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.360796] [ip-0A0C04B0:97891:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.363188] [ip-0A0C04C8:38947:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.365908] [ip-0A0C04D4:34993:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.365934] [ip-0A0C0460:28600:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.365936] [ip-0A0C0460:28603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.367737] [ip-0A0C04AD:88651:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.368212] [ip-0A0C0495:13509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.370033] [ip-0A0C0492:8777 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.369686] [ip-0A0C0489:29234:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.370401] [ip-0A0C04CC:38330:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.371800] [ip-0A0C0492:8773 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.374933] [ip-0A0C0438:29827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.375353] [ip-0A0C04B2:87499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.378960] [ip-0A0C0482:16700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.381063] [ip-0A0C04A1:31917:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.380896] [ip-0A0C04D3:36197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.380983] [ip-0A0C04D3:36196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.381906] [ip-0A0C04CC:38326:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.382168] [ip-0A0C046C:24754:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.383700] [ip-0A0C04D4:34987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.384052] [ip-0A0C0495:13511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.384045] [ip-0A0C04CF:69727:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.386005] [ip-0A0C04BD:44431:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.385835] [ip-0A0C04BC:42314:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.387875] [ip-0A0C049C:553  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.388480] [ip-0A0C04A5:16036:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.389972] [ip-0A0C04A9:13024:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.390945] [ip-0A0C04B3:21632:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.391336] [ip-0A0C044D:26525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.392508] [ip-0A0C04C4:46608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.394496] [ip-0A0C04C9:37808:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.395039] [ip-0A0C0489:29238:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.395230] [ip-0A0C0482:16701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.395549] [ip-0A0C0466:31575:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.395745] [ip-0A0C0499:15622:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.396118] [ip-0A0C0494:10982:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.396959] [ip-0A0C0488:27068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.401736] [ip-0A0C04BE:46836:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.402162] [ip-0A0C04B0:97888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.401988] [ip-0A0C04DA:32011:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.403380] [ip-0A0C0485:91366:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.404120] [ip-0A0C04DA:32010:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.404077] [ip-0A0C04C5:48446:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.405400] [ip-0A0C04D3:36200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.406426] [ip-0A0C0497:61357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.406197] [ip-0A0C04DB:30710:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.406193] [ip-0A0C04DB:30715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.410398] [ip-0A0C042D:97691:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.410559] [ip-0A0C04B2:87501:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.411059] [ip-0A0C048D:14968:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.411645] [ip-0A0C0437:25710:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.411837] [ip-0A0C04A0:3209 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.412452] [ip-0A0C04A4:14368:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.412584] [ip-0A0C04A1:31912:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.412903] [ip-0A0C0495:13512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.413274] [ip-0A0C04AE:19406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.414661] [ip-0A0C04BC:42315:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.416203] [ip-0A0C048D:14965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.417057] [ip-0A0C04B3:21637:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.417196] [ip-0A0C0488:27074:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.420447] [ip-0A0C0488:27075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.420969] [ip-0A0C0484:30930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.424313] [ip-0A0C048F:18773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.424580] [ip-0A0C04BE:46850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.425842] [ip-0A0C04BB:86401:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.426006] [ip-0A0C0436:29247:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.426474] [ip-0A0C04A6:13640:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.429099] [ip-0A0C0461:90548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.431345] [ip-0A0C04D8:38256:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.431929] [ip-0A0C04AE:19405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.432691] [ip-0A0C048C:10319:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.434085] [ip-0A0C04A0:3216 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.434374] [ip-0A0C04B6:80852:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.435186] [ip-0A0C0492:8774 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.434350] [ip-0A0C04B6:80851:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.435839] [ip-0A0C04CF:69728:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.438699] [ip-0A0C04AD:88653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.439108] [ip-0A0C04C2:68819:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.439491] [ip-0A0C0443:90192:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.440646] [ip-0A0C0441:22347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.440701] [ip-0A0C0494:10987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.441342] [ip-0A0C04AD:88648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.443715] [ip-0A0C04B3:21634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.445456] [ip-0A0C0496:93244:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.445904] [ip-0A0C048D:14972:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.445901] [ip-0A0C04C5:48450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.446255] [ip-0A0C04B4:23394:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.446282] [ip-0A0C04C0:45640:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.447171] [ip-0A0C0485:91392:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.447762] [ip-0A0C04AB:4530 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.448338] [ip-0A0C047E:26028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.448134] [ip-0A0C0473:27552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.449410] [ip-0A0C04B9:46909:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.450619] [ip-0A0C04B5:14618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.451566] [ip-0A0C048F:18775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.452244] [ip-0A0C0438:29834:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.452937] [ip-0A0C0435:57047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.452947] [ip-0A0C0435:57046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.453492] [ip-0A0C04AB:4535 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.453943] [ip-0A0C04BD:44436:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.453966] [ip-0A0C04BD:44432:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.453889] [ip-0A0C0449:26488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.454639] [ip-0A0C04C9:37809:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.454560] [ip-0A0C04C0:45643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.454957] [ip-0A0C04C7:39789:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.454615] [ip-0A0C046C:24751:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.456549] [ip-0A0C04D9:67544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.457930] [ip-0A0C0443:90190:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.457661] [ip-0A0C04C5:48453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.458016] [ip-0A0C04BE:46829:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.458136] [ip-0A0C04B9:46908:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.459270] [ip-0A0C04BE:46835:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.459253] [ip-0A0C045F:27022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.460287] [ip-0A0C0435:57049:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.460197] [ip-0A0C04BA:79114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.460853] [ip-0A0C04BE:46833:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.463566] [ip-0A0C0487:28815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.464040] [ip-0A0C04A6:13643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.464101] [ip-0A0C04A6:13641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.465181] [ip-0A0C049C:570  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.465442] [ip-0A0C04A4:14363:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.465581] [ip-0A0C04B0:97890:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.466393] [ip-0A0C0437:25714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.466646] [ip-0A0C0473:27545:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.466803] [ip-0A0C049C:571  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.466557] [ip-0A0C0497:61353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.467512] [ip-0A0C048A:25740:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.467203] [ip-0A0C0497:61358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.467544] [ip-0A0C049D:8103 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.470038] [ip-0A0C04B4:23392:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.470020] [ip-0A0C046E:30886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.472311] [ip-0A0C04B5:14615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.472200] [ip-0A0C04AD:88650:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.473124] [ip-0A0C0437:25709:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.473098] [ip-0A0C046C:24749:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.472954] [ip-0A0C04A9:13025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.473576] [ip-0A0C04B9:46911:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.473817] [ip-0A0C0484:30924:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.474720] [ip-0A0C0484:30927:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.475516] [ip-0A0C04D9:67542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.475543] [ip-0A0C0498:23814:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.476309] [ip-0A0C042D:97682:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.477813] [ip-0A0C047E:26031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.478867] [ip-0A0C049C:554  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.479005] [ip-0A0C04A9:13020:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.480917] [ip-0A0C049C:555  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.481735] [ip-0A0C0482:16724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.481683] [ip-0A0C0497:61354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.482579] [ip-0A0C04BB:86394:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.482631] [ip-0A0C0499:15620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.483730] [ip-0A0C048D:14971:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.483873] [ip-0A0C04AB:4533 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.485055] [ip-0A0C04C4:46607:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.486743] [ip-0A0C0491:11351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.486743] [ip-0A0C0491:11348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.486755] [ip-0A0C0491:11346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.486836] [ip-0A0C048B:11773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.487838] [ip-0A0C048D:14967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.487862] [ip-0A0C0490:15148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.488234] [ip-0A0C048C:10318:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.489036] [ip-0A0C0466:31577:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.489037] [ip-0A0C04AB:4534 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.489020] [ip-0A0C04B7:82201:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.489406] [ip-0A0C046E:30887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.489310] [ip-0A0C048D:14964:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.490718] [ip-0A0C04A4:14365:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.491077] [ip-0A0C044D:26502:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.491563] [ip-0A0C04B3:21636:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.490991] [ip-0A0C04A8:19468:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.491563] [ip-0A0C048C:10316:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.491922] [ip-0A0C04B2:87497:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.493217] [ip-0A0C046E:30890:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.493197] [ip-0A0C04AB:4531 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.493381] [ip-0A0C045F:27020:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.493731] [ip-0A0C04B4:23391:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.494405] [ip-0A0C04C4:46610:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.494746] [ip-0A0C046C:24761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.495073] [ip-0A0C04C2:68821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.495610] [ip-0A0C046E:30883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.495388] [ip-0A0C048F:18772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.495832] [ip-0A0C049B:2441 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.498399] [ip-0A0C0496:93241:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.498328] [ip-0A0C04BC:42311:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.498399] [ip-0A0C04D3:36199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.498480] [ip-0A0C04D3:36201:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.499104] [ip-0A0C04C5:48447:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.499348] [ip-0A0C04BB:86398:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.499567] [ip-0A0C0466:31578:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.499793] [ip-0A0C04DA:32014:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.499818] [ip-0A0C04D3:36195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.500662] [ip-0A0C04C9:37807:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.500352] [ip-0A0C049D:8105 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.500719] [ip-0A0C0487:28817:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.501528] [ip-0A0C0438:29838:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.502059] [ip-0A0C0483:27896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.502121] [ip-0A0C0499:15623:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.503214] [ip-0A0C0438:29828:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.502720] [ip-0A0C04A8:19465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.503478] [ip-0A0C0464:28929:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.504042] [ip-0A0C04D3:36202:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.508022] [ip-0A0C0460:28602:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.508211] [ip-0A0C0460:28605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.508230] [ip-0A0C04A9:13019:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.508363] [ip-0A0C0489:29233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.508932] [ip-0A0C04A5:16039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.509945] [ip-0A0C0472:30947:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.511438] [ip-0A0C04A1:31913:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.512165] [ip-0A0C04A7:88275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.514832] [ip-0A0C04A2:5414 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.511921] [ip-0A0C0488:27073:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.512148] [ip-0A0C0464:28924:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.512282] [ip-0A0C0441:22346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.512349] [ip-0A0C0441:22341:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.512551] [ip-0A0C04AE:19404:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.512720] [ip-0A0C04AE:19409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.513554] [ip-0A0C0494:10986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.513529] [ip-0A0C04BC:42310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.514082] [ip-0A0C04B3:21635:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.513858] [ip-0A0C0449:26484:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.514119] [ip-0A0C049F:1812 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.514653] [ip-0A0C04CC:38333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.515438] [ip-0A0C04BA:79113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.515598] [ip-0A0C04BA:79112:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.516769] [ip-0A0C040F:96441:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.516773] [ip-0A0C0483:27899:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.517155] [ip-0A0C046E:30888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.517355] [ip-0A0C0464:28953:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.519366] [ip-0A0C04AE:19410:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.520013] [ip-0A0C04B2:87505:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.520678] [ip-0A0C04AC:7382 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.521012] [ip-0A0C04BD:44435:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.521915] [ip-0A0C0435:57042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.522241] [ip-0A0C04CC:38329:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.522384] [ip-0A0C04CC:38327:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.522501] [ip-0A0C04C8:38945:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.522204] [ip-0A0C044D:26501:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.522753] [ip-0A0C04C8:38942:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.523143] [ip-0A0C04C8:38948:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.523208] [ip-0A0C044D:26500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.523732] [ip-0A0C0488:27070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.524440] [ip-0A0C04B0:97893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.524521] [ip-0A0C04AE:19408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.524880] [ip-0A0C0473:27546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.525581] [ip-0A0C048A:25739:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.525702] [ip-0A0C048A:25742:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.526669] [ip-0A0C04B3:21638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.528240] [ip-0A0C04AD:88649:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.528787] [ip-0A0C0466:31574:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.528901] [ip-0A0C0466:31576:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.528970] [ip-0A0C04A1:31911:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.528769] [ip-0A0C0489:29232:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.528729] [ip-0A0C0497:61356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.529023] [ip-0A0C0498:23817:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.529611] [ip-0A0C0437:25715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.530026] [ip-0A0C04B3:21633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.530459] [ip-0A0C0488:27069:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.530331] [ip-0A0C04C6:42009:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.530706] [ip-0A0C0488:27072:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.531666] [ip-0A0C04C9:37813:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.533100] [ip-0A0C04D8:38255:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.533188] [ip-0A0C04D8:38250:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.533510] [ip-0A0C04BD:44438:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.533313] [ip-0A0C0449:26485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.533651] [ip-0A0C04BD:44433:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.534680] [ip-0A0C0492:8770 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.534749] [ip-0A0C0460:28611:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.535059] [ip-0A0C042D:97685:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.536096] [ip-0A0C045F:27025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.536230] [ip-0A0C04B7:82200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.537092] [ip-0A0C04C7:39784:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.537241] [ip-0A0C0497:61352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.537823] [ip-0A0C04C8:38944:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.537749] [ip-0A0C04BD:44437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.537643] [ip-0A0C04B6:80845:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.537671] [ip-0A0C0497:61359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.538327] [ip-0A0C04D4:34990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.538306] [ip-0A0C04C8:38946:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.538442] [ip-0A0C04D4:34988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.538571] [ip-0A0C04C8:38943:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.538862] [ip-0A0C0460:28599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.540467] [ip-0A0C0466:31581:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.540686] [ip-0A0C04B0:97892:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.540200] [ip-0A0C04CF:69732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.540705] [ip-0A0C04B2:87496:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.540821] [ip-0A0C048B:11777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.540917] [ip-0A0C0482:16699:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.541980] [ip-0A0C0483:27902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.542187] [ip-0A0C0482:16698:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.542749] [ip-0A0C0472:30952:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.544073] [ip-0A0C04A5:16044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.544504] [ip-0A0C0494:10981:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.545459] [ip-0A0C04A7:88273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.545059] [ip-0A0C0438:29831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.545423] [ip-0A0C04D4:34991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.545535] [ip-0A0C04A5:16040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.545694] [ip-0A0C04CC:38328:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.545657] [ip-0A0C0464:28923:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.545172] [ip-0A0C049B:2436 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.545753] [ip-0A0C04CC:38325:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.545384] [ip-0A0C04DB:30709:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.546126] [ip-0A0C0489:29236:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.546708] [ip-0A0C0483:27903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.546321] [ip-0A0C04CF:69726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.547223] [ip-0A0C04C7:39781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.548881] [ip-0A0C04C9:37806:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.549229] [ip-0A0C0464:28930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.548961] [ip-0A0C04B9:46913:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.549053] [ip-0A0C04B9:46912:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.549410] [ip-0A0C0464:28925:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.549004] [ip-0A0C049B:2430 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.549961] [ip-0A0C048F:18799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.549973] [ip-0A0C04B6:80853:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.550002] [ip-0A0C048F:18769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.550145] [ip-0A0C0482:16702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.551303] [ip-0A0C0443:90191:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.551806] [ip-0A0C04B0:97887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.551814] [ip-0A0C0482:16704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.553315] [ip-0A0C0437:25713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.553548] [ip-0A0C046B:14128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.553486] [ip-0A0C0494:10988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.554709] [ip-0A0C0484:30926:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.554988] [ip-0A0C04A9:13018:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.555413] [ip-0A0C04B9:46936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.556334] [ip-0A0C042D:97680:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.556697] [ip-0A0C0485:91369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.556725] [ip-0A0C0483:27901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.556050] [ip-0A0C04DB:30711:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.556951] [ip-0A0C04A9:13022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.557952] [ip-0A0C0435:57043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.557479] [ip-0A0C0489:29235:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.558288] [ip-0A0C0483:27900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.558532] [ip-0A0C04D9:67538:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.558576] [ip-0A0C048F:18774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.558667] [ip-0A0C0429:19455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.559597] [ip-0A0C0485:91363:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.560178] [ip-0A0C048F:18771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.560491] [ip-0A0C0436:29243:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.560688] [ip-0A0C04A4:14362:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.560738] [ip-0A0C0436:29249:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.560819] [ip-0A0C04DA:32012:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.560841] [ip-0A0C0486:28900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.561464] [ip-0A0C04B9:46922:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.561583] [ip-0A0C0473:27547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.562433] [ip-0A0C0492:8778 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.562425] [ip-0A0C04A4:14364:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.562642] [ip-0A0C0495:13510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.562968] [ip-0A0C04A4:14366:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.562693] [ip-0A0C044D:26499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.562703] [ip-0A0C04AD:88652:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.562970] [ip-0A0C04A4:14369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.563375] [ip-0A0C0495:13513:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.563232] [ip-0A0C04BB:86393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.563249] [ip-0A0C04BC:42313:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.563696] [ip-0A0C0495:13508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.564313] [ip-0A0C0499:15621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.564823] [ip-0A0C0499:15627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.564698] [ip-0A0C04A9:13017:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.565959] [ip-0A0C047E:26029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.566426] [ip-0A0C04D8:38252:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.566587] [ip-0A0C0460:28598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.566968] [ip-0A0C0437:25712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.567099] [ip-0A0C04B7:82202:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.567428] [ip-0A0C04D4:34989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.567766] [ip-0A0C04D4:34992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.567811] [ip-0A0C04C4:46612:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.568204] [ip-0A0C04AC:7388 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.568790] [ip-0A0C04BB:86406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.568716] [ip-0A0C046C:24750:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.569208] [ip-0A0C0492:8771 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.568765] [ip-0A0C04AD:88654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.569201] [ip-0A0C04C4:46606:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.569322] [ip-0A0C04A6:13637:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.569551] [ip-0A0C0461:90550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.570199] [ip-0A0C0461:90553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.570658] [ip-0A0C04A0:3213 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.570949] [ip-0A0C04D4:34994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.571124] [ip-0A0C0490:15147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.571312] [ip-0A0C0490:15149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.571706] [ip-0A0C04B0:97886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.572515] [ip-0A0C04AD:88647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.572459] [ip-0A0C04DB:30708:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.573435] [ip-0A0C042D:97681:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.573457] [ip-0A0C04B2:87498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.574001] [ip-0A0C0496:93245:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.573723] [ip-0A0C046C:24752:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.573650] [ip-0A0C04C6:42010:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.574652] [ip-0A0C04B0:97889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.574434] [ip-0A0C0498:23813:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.575344] [ip-0A0C04AF:5827 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.575979] [ip-0A0C04A0:3212 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.575217] [ip-0A0C04DB:30712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.575894] [ip-0A0C04C2:68820:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.576198] [ip-0A0C0460:28597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.576284] [ip-0A0C04C2:68817:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.576372] [ip-0A0C0499:15625:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.576458] [ip-0A0C04CD:35141:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.577706] [ip-0A0C0495:13514:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.578203] [ip-0A0C0492:8775 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.578096] [ip-0A0C0499:15626:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.578684] [ip-0A0C04A1:31910:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.578706] [ip-0A0C04B2:87502:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.578373] [ip-0A0C04BC:42316:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.578570] [ip-0A0C04BC:42309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.579829] [ip-0A0C0435:57045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.579686] [ip-0A0C046C:24753:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.580015] [ip-0A0C04BA:79111:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.579900] [ip-0A0C0489:29231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.579757] [ip-0A0C04CF:69730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.580465] [ip-0A0C04A1:31915:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.580443] [ip-0A0C04C5:48452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.580678] [ip-0A0C04BC:42312:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.581381] [ip-0A0C04C5:48451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.581798] [ip-0A0C04B2:87500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.582435] [ip-0A0C0495:13515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.582332] [ip-0A0C049F:1808 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.582640] [ip-0A0C04C0:45644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.582631] [ip-0A0C048C:10321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.582765] [ip-0A0C0461:90549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.583049] [ip-0A0C04C0:45637:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.583409] [ip-0A0C0492:8772 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.583109] [ip-0A0C04C5:48448:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.583228] [ip-0A0C04B1:17558:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.584029] [ip-0A0C0435:57048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.583466] [ip-0A0C04CF:69729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.584738] [ip-0A0C0491:11347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.583768] [ip-0A0C04CF:69733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.584686] [ip-0A0C04DA:32009:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.584794] [ip-0A0C0437:25738:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.585166] [ip-0A0C04C5:48449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.585397] [ip-0A0C0487:28813:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.585921] [ip-0A0C04A5:16038:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.586443] [ip-0A0C04B4:23397:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.586362] [ip-0A0C044D:26498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.586790] [ip-0A0C04BB:86395:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.587611] [ip-0A0C0496:93248:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.588073] [ip-0A0C0435:57044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.588284] [ip-0A0C0438:29829:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.588346] [ip-0A0C0438:29833:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.588332] [ip-0A0C046C:24748:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.588751] [ip-0A0C0489:29237:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.590500] [ip-0A0C04A1:31909:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.589717] [ip-0A0C04DB:30714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.590581] [ip-0A0C04A1:31916:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.590495] [ip-0A0C0436:29244:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.590920] [ip-0A0C04B6:80849:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.591041] [ip-0A0C049D:8102 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.592890] [ip-0A0C0485:91362:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.592756] [ip-0A0C0490:15150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.592912] [ip-0A0C04C4:46605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.593133] [ip-0A0C0496:93247:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.593213] [ip-0A0C042D:97683:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.593464] [ip-0A0C0437:25711:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.594264] [ip-0A0C0485:91364:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.594103] [ip-0A0C040F:96436:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.594366] [ip-0A0C047E:26030:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.594235] [ip-0A0C0438:29830:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.594673] [ip-0A0C04A0:3211 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.594602] [ip-0A0C04CF:69731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.595535] [ip-0A0C04DA:32015:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.595718] [ip-0A0C044D:26503:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.596718] [ip-0A0C04A7:88274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.596431] [ip-0A0C04C7:39790:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.596707] [ip-0A0C044D:26504:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.597860] [ip-0A0C04C4:46611:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.599192] [ip-0A0C04C9:37826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.599681] [ip-0A0C04C9:37810:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.600669] [ip-0A0C04A6:13638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.600665] [ip-0A0C04A5:16042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.600019] [ip-0A0C04DB:30713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.600674] [ip-0A0C049F:1809 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.601384] [ip-0A0C04B6:80850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.601376] [ip-0A0C0498:23815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.603053] [ip-0A0C04C4:46609:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.604180] [ip-0A0C04C9:37811:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.604262] [ip-0A0C048B:11778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.606199] [ip-0A0C04DA:32007:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.606254] [ip-0A0C04DA:32008:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.607314] [ip-0A0C0491:11352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.606885] [ip-0A0C0484:30925:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.607616] [ip-0A0C04C3:45105:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.607880] [ip-0A0C04C2:68815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.607980] [ip-0A0C04C0:45638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.608174] [ip-0A0C0461:90552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.608760] [ip-0A0C04CD:35139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.608875] [ip-0A0C0493:10799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.608835] [ip-0A0C0494:10984:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.608904] [ip-0A0C0494:10985:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.609598] [ip-0A0C04A0:3215 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.609592] [ip-0A0C04A0:3214 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.610206] [ip-0A0C04A0:3210 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.610407] [ip-0A0C04C7:39783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.610205] [ip-0A0C045F:27021:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.610447] [ip-0A0C0494:10983:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.610552] [ip-0A0C04A8:19472:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.611580] [ip-0A0C0436:29250:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.612139] [ip-0A0C0443:90188:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.612253] [ip-0A0C0443:90189:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.612369] [ip-0A0C04D9:67541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.612377] [ip-0A0C04A5:16037:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.612504] [ip-0A0C04A5:16041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.613419] [ip-0A0C040F:96442:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.614623] [ip-0A0C0436:29246:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.614715] [ip-0A0C042D:97684:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.614557] [ip-0A0C04C2:68822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.615106] [ip-0A0C04C0:45642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.616243] [ip-0A0C0486:28901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.617080] [ip-0A0C0485:91367:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.617362] [ip-0A0C0472:30951:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.618517] [ip-0A0C0449:26482:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.618855] [ip-0A0C04B6:80846:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.619567] [ip-0A0C0485:91365:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.619249] [ip-0A0C04BB:86400:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.620139] [ip-0A0C0491:11345:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.619528] [ip-0A0C048A:25736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.620009] [ip-0A0C04A6:13639:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.619919] [ip-0A0C048C:10322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.620050] [ip-0A0C04BB:86396:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.620776] [ip-0A0C046B:14126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.621725] [ip-0A0C048C:10317:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.622942] [ip-0A0C047E:26033:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.622691] [ip-0A0C04B5:14616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.623189] [ip-0A0C0496:93249:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.622723] [ip-0A0C04B6:80848:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.623067] [ip-0A0C04A6:13644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.623073] [ip-0A0C04AC:7385 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.623117] [ip-0A0C042D:97679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.623239] [ip-0A0C04B4:23398:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.623178] [ip-0A0C04A6:13642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.624890] [ip-0A0C0491:11344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.624375] [ip-0A0C0441:22345:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.625091] [ip-0A0C048C:10320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.625281] [ip-0A0C04B7:82203:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.625336] [ip-0A0C0484:30931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.625744] [ip-0A0C048C:10323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.626067] [ip-0A0C0449:26487:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.627505] [ip-0A0C048B:11774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.627493] [ip-0A0C0484:30928:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.628163] [ip-0A0C0429:19453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.628278] [ip-0A0C04AA:86483:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.629029] [ip-0A0C0436:29245:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.628867] [ip-0A0C0484:30929:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.629807] [ip-0A0C0441:22344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.629902] [ip-0A0C049B:2431 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.630766] [ip-0A0C0461:90547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.630688] [ip-0A0C049D:8104 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.630819] [ip-0A0C04C2:68823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.630942] [ip-0A0C04C2:68816:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.634388] [ip-0A0C04A2:5415 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.631770] [ip-0A0C04D8:38251:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.632149] [ip-0A0C0461:90546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.633391] [ip-0A0C04B4:23393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.633274] [ip-0A0C049F:1810 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.633779] [ip-0A0C0436:29248:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.634608] [ip-0A0C04C7:39782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.634503] [ip-0A0C04B4:23395:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.635145] [ip-0A0C04D8:38253:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.638150] [ip-0A0C04A2:5413 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.635083] [ip-0A0C0461:90551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.637559] [ip-0A0C04A7:88277:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.637448] [ip-0A0C0496:93240:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.637384] [ip-0A0C0487:28816:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.637585] [ip-0A0C0496:93242:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.637468] [ip-0A0C04D9:67539:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.637703] [ip-0A0C04B4:23396:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.637529] [ip-0A0C04B5:14622:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.637793] [ip-0A0C04B1:17559:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.637623] [ip-0A0C04B5:14617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.639797] [ip-0A0C0443:90193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.640074] [ip-0A0C04D9:67545:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.640537] [ip-0A0C0487:28811:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.640649] [ip-0A0C04C6:42006:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.642121] [ip-0A0C04AC:7387 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.642665] [ip-0A0C0443:90194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.644788] [ip-0A0C04B1:17560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.645669] [ip-0A0C0491:11343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.645783] [ip-0A0C047E:26027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.645922] [ip-0A0C047E:26032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.648718] [ip-0A0C0443:90195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.648918] [ip-0A0C0429:19459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.649363] [ip-0A0C04D8:38249:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.649491] [ip-0A0C04D8:38254:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.650376] [ip-0A0C04C7:39785:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.650825] [ip-0A0C04C0:45636:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.651187] [ip-0A0C04C7:39786:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.650892] [ip-0A0C045F:27024:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.651019] [ip-0A0C04C0:45641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.652675] [ip-0A0C045F:27023:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.654000] [ip-0A0C0487:28814:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.655147] [ip-0A0C047E:26034:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.654812] [ip-0A0C048A:25738:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.655861] [ip-0A0C0473:27551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.656094] [ip-0A0C048B:11775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.656328] [ip-0A0C04B5:14620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.656341] [ip-0A0C0498:23811:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.657225] [ip-0A0C0473:27548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.656943] [ip-0A0C0498:23810:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.657657] [ip-0A0C04BA:79116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.657593] [ip-0A0C04C6:42004:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.658020] [ip-0A0C04B5:14621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.658479] [ip-0A0C04B5:14619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.658963] [ip-0A0C04BA:79130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.660091] [ip-0A0C048B:11779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.660100] [ip-0A0C04BA:79110:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.660460] [ip-0A0C048A:25737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.661196] [ip-0A0C0490:15144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.661775] [ip-0A0C0498:23812:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.662425] [ip-0A0C04D9:67543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.662932] [ip-0A0C0441:22340:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.663320] [ip-0A0C04D9:67540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.663217] [ip-0A0C04BA:79117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.663419] [ip-0A0C0441:22343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.663528] [ip-0A0C0473:27544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.663144] [ip-0A0C0498:23816:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.663896] [ip-0A0C04AF:5821 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.665895] [ip-0A0C048A:25741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.666280] [ip-0A0C0441:22342:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.666222] [ip-0A0C049D:8101 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.666817] [ip-0A0C048B:11776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.669053] [ip-0A0C04C3:45103:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.669316] [ip-0A0C0473:27549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.669625] [ip-0A0C04C3:45100:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.669914] [ip-0A0C0449:26511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.671090] [ip-0A0C040F:96439:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.671247] [ip-0A0C049D:8109 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.671554] [ip-0A0C048B:11780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.671505] [ip-0A0C0487:28812:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.672372] [ip-0A0C0472:30948:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.673039] [ip-0A0C0487:28822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.674854] [ip-0A0C04CD:35140:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.675100] [ip-0A0C045F:27026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.674850] [ip-0A0C04A8:19488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.675921] [ip-0A0C045F:27019:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.675626] [ip-0A0C04A8:19466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.676419] [ip-0A0C0449:26486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.677377] [ip-0A0C0490:15151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.678133] [ip-0A0C04AC:7383 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.678014] [ip-0A0C0449:26483:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.678561] [ip-0A0C048A:25735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.681701] [ip-0A0C04B7:82198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.683001] [ip-0A0C0486:28903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.683511] [ip-0A0C049F:1811 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.687702] [ip-0A0C04A2:5416 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.685275] [ip-0A0C04A8:19470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.686553] [ip-0A0C049D:8106 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.688362] [ip-0A0C04A8:19469:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.688951] [ip-0A0C0490:15145:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.689022] [ip-0A0C0490:15146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.689312] [ip-0A0C046B:14129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.689223] [ip-0A0C0493:10793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.689245] [ip-0A0C0493:10794:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.689655] [ip-0A0C0472:30949:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.690759] [ip-0A0C049D:8107 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.691016] [ip-0A0C049B:2442 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.691112] [ip-0A0C049B:2438 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.691865] [ip-0A0C04B7:82199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.695203] [ip-0A0C04A2:5412 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.692403] [ip-0A0C04B7:82197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.692253] [ip-0A0C04A8:19467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.693578] [ip-0A0C04AC:7412 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.697053] [ip-0A0C04B7:82204:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.697242] [ip-0A0C04C6:42003:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.697127] [ip-0A0C049B:2435 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.699956] [ip-0A0C04AF:5826 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.701295] [ip-0A0C0486:28898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.705072] [ip-0A0C0472:30946:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.706844] [ip-0A0C049B:2432 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.711121] [ip-0A0C04A2:5419 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.708105] [ip-0A0C04AF:5851 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.710650] [ip-0A0C0472:30945:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.712617] [ip-0A0C04A7:88279:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.713809] [ip-0A0C04CD:35136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.714112] [ip-0A0C040F:96432:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.715698] [ip-0A0C046B:14132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.715803] [ip-0A0C046B:14133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.716895] [ip-0A0C04AC:7386 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.721504] [ip-0A0C04A2:5420 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.720609] [ip-0A0C04AC:7384 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.724244] [ip-0A0C04A2:5421 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.721106] [ip-0A0C04C6:42007:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.722311] [ip-0A0C046B:14130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.721993] [ip-0A0C0429:19454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.723645] [ip-0A0C04A7:88276:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.724128] [ip-0A0C0472:30950:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.725428] [ip-0A0C04C3:45106:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.728007] [ip-0A0C04A7:88278:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.727365] [ip-0A0C049F:1817 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.728080] [ip-0A0C04A7:88280:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.727459] [ip-0A0C049F:1813 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.727730] [ip-0A0C049F:1816 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.727909] [ip-0A0C04C6:42008:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.729380] [ip-0A0C04AA:86481:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.731382] [ip-0A0C0429:19460:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.732815] [ip-0A0C04C6:42005:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.734923] [ip-0A0C0429:19458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.735544] [ip-0A0C0486:28896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.739255] [ip-0A0C04AF:5822 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.739728] [ip-0A0C040F:96433:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.739927] [ip-0A0C040F:96434:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.740316] [ip-0A0C040F:96437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.744788] [ip-0A0C0429:19456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.745054] [ip-0A0C04AA:86478:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.745781] [ip-0A0C0486:28899:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.746848] [ip-0A0C0486:28902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.746863] [ip-0A0C04CD:35137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.747257] [ip-0A0C046B:14131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.748171] [ip-0A0C046B:14127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.748334] [ip-0A0C0493:10798:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.750017] [ip-0A0C0486:28904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.750727] [ip-0A0C0429:19452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.751034] [ip-0A0C04B1:17562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.759688] [ip-0A0C04CD:35134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.760558] [ip-0A0C04C3:45101:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.761091] [ip-0A0C04C3:45104:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.764439] [ip-0A0C04AA:86479:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.767384] [ip-0A0C04B1:17564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.768317] [ip-0A0C04AF:5824 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.769049] [ip-0A0C0493:10800:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.778121] [ip-0A0C04AF:5823 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.778678] [ip-0A0C04AF:5825 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.779643] [ip-0A0C04CD:35138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.779956] [ip-0A0C04CD:35135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.784734] [ip-0A0C04B1:17561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.785628] [ip-0A0C04AA:86485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.788924] [ip-0A0C0493:10795:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.797271] [ip-0A0C04B1:17557:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.798149] [ip-0A0C04B1:17556:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.805196] [ip-0A0C04C3:45099:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.807853] [ip-0A0C04C3:45102:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.808216] [ip-0A0C04AA:86484:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.812869] [ip-0A0C0493:10797:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.814877] [ip-0A0C0493:10796:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.851692] [ip-0A0C04AA:86480:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621078.852042] [ip-0A0C04AA:86482:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634621079742, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634621079783, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634621079784, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634621079784, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634621079785, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634621079785, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634621079785, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:50] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:52] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0435:0:57043 - context.c:584] INFO job (ID: 867564279316149300) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:57043 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:57043 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:57042 - context.c:584] INFO job (ID: 867565144801900068) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:57042 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:57042 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:57045 - context.c:584] INFO job (ID: 867564694075591912) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:57045 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:57045 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:57047 - context.c:584] INFO job (ID: 867564727141069069) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:57047 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:57047 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:57046 - context.c:584] INFO job (ID: 867564217470047883) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:57046 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:57046 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:57044 - context.c:584] INFO job (ID: 867565208765806036) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:57044 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:57044 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:57049 - context.c:584] INFO job (ID: 867564587574859778) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:57049 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:57049 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:57048 - context.c:584] INFO job (ID: 867564172449163708) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:57048 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:57048 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172044, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3263568447, "metadata": {"file": "main.py", "lineno": 72}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172044, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172045, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172045, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172045, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172045, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172045, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172045, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172045, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172045, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172045, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621172045, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:26:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621196035, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634621196072, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621196079, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634621196079, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621198741, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1634621198742, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1634621198742, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621198742, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621200172, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2350.7072607594328, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621200172, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621200172, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2350.7072607594328, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634621200173, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621200173, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621200839, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5041.283066194812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621200840, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621200840, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5041.283066194812, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621200840, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621200840, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621201491, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5164.410925953207, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621201491, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621201491, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5164.410925953207, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634621201491, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621201491, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621202124, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5310.023748959594, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621202124, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621202125, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5310.023748959594, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634621202125, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621202125, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621202750, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5373.019817041787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621202751, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621202751, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5373.019817041787, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634621202751, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621202751, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621203371, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5418.978662633827, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621203372, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621203372, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5418.978662633827, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634621203372, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621203372, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621203993, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5412.788810054298, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621203993, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621203993, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5412.788810054298, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634621203993, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621203993, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621204615, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5403.706611850695, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621204616, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621204616, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5403.706611850695, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634621204616, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621204616, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621205234, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.105561948245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621205234, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621205234, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.105561948245, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634621205234, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621205235, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621205842, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5528.79999968615, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621205843, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621205843, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5528.79999968615, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634621205843, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621205843, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621206454, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5500.741586725647, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621206454, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621206454, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5500.741586725647, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634621206454, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621206454, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621207073, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5431.35488450983, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621207073, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621207074, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5431.35488450983, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634621207074, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621207074, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621207693, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5431.260690743835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621207693, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621207693, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5431.260690743835, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634621207693, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621207693, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621208305, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5487.88080359907, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621208306, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621208306, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5487.88080359907, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634621208306, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621208306, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621208922, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5454.850033693988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621208922, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621208923, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5454.850033693988, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634621208923, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621208923, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621209535, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5484.647250002044, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621209536, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621209536, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5484.647250002044, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634621209536, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621209536, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621210153, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5444.820450132249, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621210153, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621210154, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5444.820450132249, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634621210154, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621210154, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621210768, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5469.451202142317, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621210768, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621210769, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5469.451202142317, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634621210769, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621210769, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621211382, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5482.839915684896, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621211382, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621211382, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5482.839915684896, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634621211382, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621211382, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621211996, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5476.1735497401, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621211996, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621211996, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5476.1735497401, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634621211996, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621211996, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621212608, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5498.129860604477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621212608, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621212608, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5498.129860604477, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634621212608, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621212608, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621213239, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5326.364018777952, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621213240, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621213240, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5326.364018777952, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634621213240, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621213240, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621213855, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5461.453970918721, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621213856, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621213856, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5461.453970918721, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634621213856, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621213856, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621214476, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5424.169966437787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621214476, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621214476, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5424.169966437787, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634621214476, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621214476, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621215094, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5442.427579047858, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621215094, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621215094, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5442.427579047858, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634621215094, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621215094, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621215718, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5387.578987126722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621215719, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621215719, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5387.578987126722, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634621215719, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621215719, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621216337, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5441.357986032951, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621216337, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621216337, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5441.357986032951, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634621216337, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621216337, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621216961, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5388.944864582931, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621216961, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621216961, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5388.944864582931, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634621216962, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621216962, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621217577, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5460.063787251848, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621217578, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621217578, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5460.063787251848, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634621217578, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621217578, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621218191, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5480.466798964484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621218192, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621218192, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5480.466798964484, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634621218192, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621218192, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621218804, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5493.990950205077, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621218804, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621218804, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5493.990950205077, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634621218804, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621218804, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621219417, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5483.95575591429, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621219418, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621219418, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5483.95575591429, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634621219418, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621219418, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621220031, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5484.421001262056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621220031, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621220031, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5484.421001262056, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634621220031, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621220032, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621220647, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5459.757068833596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621220648, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621220648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5459.757068833596, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634621220648, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621220648, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621221259, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5499.784166569429, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621221259, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621221259, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5499.784166569429, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634621221260, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621221260, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621221868, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5521.619053514743, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621221869, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621221869, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5521.619053514743, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634621221869, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621221869, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621222478, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5521.854872488291, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621222478, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621222478, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5521.854872488291, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634621222478, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621222478, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621223087, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5525.281928194545, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621223087, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621223087, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5525.281928194545, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634621223087, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621223087, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621223697, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5516.60671918579, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621223697, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621223697, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5516.60671918579, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634621223697, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621223698, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621224306, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5522.529988616258, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621224307, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621224307, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5522.529988616258, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634621224307, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621224307, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621224918, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5496.369365268984, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621224919, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621224919, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5496.369365268984, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634621224919, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621224919, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621225533, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5476.086306424488, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621225533, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621225533, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5476.086306424488, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634621225533, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621225534, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621226152, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5435.5173222418325, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621226152, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621226152, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5435.5173222418325, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634621226152, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621226153, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621226767, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5468.279723514105, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621226768, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621226768, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5468.279723514105, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634621226768, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621226768, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621227375, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5538.836868193802, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621227375, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621227375, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5538.836868193802, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634621227376, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621227376, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621227988, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5484.762515971273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621227989, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621227989, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5484.762515971273, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634621227989, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621227989, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621228595, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5548.73983347711, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621228595, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621228595, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5548.73983347711, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634621228595, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621228595, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621229207, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5492.5948585875785, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621229208, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621229208, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5492.5948585875785, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634621229208, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621229208, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621229819, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5501.836803133185, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621229819, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621229819, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5501.836803133185, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634621229820, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621229820, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621230425, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5554.828680745764, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621230425, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621230425, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5554.828680745764, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634621230494, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621230494, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621230509, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621230939, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8787534832954407, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621230939, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621231092, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5623.264110868731, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621231092, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621231092, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5623.264110868731, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621231256, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621231256, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621231262, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621231673, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8950755596160889, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621231673, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621231909, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5150.594679700983, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621231909, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621231909, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5150.594679700983, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621231935, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621231935, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621231950, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621232394, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.883651614189148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621232394, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621232579, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5218.940440612814, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621232579, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621232579, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5218.940440612814, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621232604, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621232604, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621232620, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621233054, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8880786895751953, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621233055, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621233248, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5217.906648425597, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621233249, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621233249, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5217.906648425597, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621233273, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621233274, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621233288, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621233721, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8653421401977539, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621233722, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621233913, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5252.985352402259, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621233914, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621233914, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5252.985352402259, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621233939, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621233939, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621233954, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621234391, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8919248580932617, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621234391, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621234577, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5263.491425126817, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621234578, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621234578, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5263.491425126817, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621234672, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621234672, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621234687, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621235109, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8839026689529419, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621235109, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621235305, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5307.559963438374, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621235305, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621235306, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5307.559963438374, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621235331, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621235331, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621235348, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621235782, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8810086250305176, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621235782, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621235977, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5201.949482309949, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621235977, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621235978, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5201.949482309949, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621236002, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621236003, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621236018, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621236454, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8848589658737183, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621236454, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621236647, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5215.116489225885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621236647, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621236647, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5215.116489225885, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621236672, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621236673, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621236687, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621237123, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8788780570030212, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621237123, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621237315, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5229.339745302342, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621237315, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621237316, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5229.339745302342, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621237350, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621237350, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621237366, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621237795, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.893017053604126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621237795, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621237978, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5355.806217706371, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621237978, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621237978, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5355.806217706371, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621238004, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621238005, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621238019, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621238447, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8914609551429749, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621238448, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621238634, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5339.50963019374, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621238634, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621238634, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5339.50963019374, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621238662, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621238662, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621238678, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621239105, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.896099328994751, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621239105, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621239283, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5407.195996187723, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621239284, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621239284, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5407.195996187723, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621239309, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621239309, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621239325, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621239761, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.889021098613739, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621239762, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621239950, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5242.133074044881, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621239950, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621239950, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5242.133074044881, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621239987, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621239987, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621240003, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621240441, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.886527955532074, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621240442, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621240629, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5236.167264734273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621240630, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621240630, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5236.167264734273, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621240655, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621240655, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621240670, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621241107, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8896852135658264, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621241107, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621241289, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5297.948707923882, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621241289, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621241289, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5297.948707923882, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621241315, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621241315, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621241332, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621241769, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8906300067901611, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621241769, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621241953, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5273.317320770743, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621241953, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621241953, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5273.317320770743, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621241978, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621241978, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621241995, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621242427, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8878157138824463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621242428, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621242612, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5302.162436708646, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621242612, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621242612, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5302.162436708646, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621242637, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621242637, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621242653, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621243088, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9015867710113525, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621243089, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621243274, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5277.632266037524, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621243274, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621243274, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5277.632266037524, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621243300, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621243300, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621243316, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621243751, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8760441541671753, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621243751, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621243937, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5275.433427927467, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621243937, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621243937, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5275.433427927467, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621243964, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621243964, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621243979, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621244410, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8942574262619019, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621244410, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621244599, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5288.03882861265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621244599, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621244600, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5288.03882861265, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621244629, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621244629, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621244645, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621245067, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8930277824401855, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621245068, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621245258, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5344.326774305113, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621245258, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621245258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5344.326774305113, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621245285, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621245285, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621245301, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621245731, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8859103918075562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621245731, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621245918, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5305.270214565713, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621245919, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621245919, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5305.270214565713, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621245944, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621245944, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621245961, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621246394, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8997248411178589, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621246394, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621246598, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5142.700650498, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621246598, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621246598, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5142.700650498, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621246623, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621246623, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621246638, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621247075, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.892508864402771, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621247075, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621247263, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5246.799484138449, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621247263, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621247264, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5246.799484138449, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621247288, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621247288, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621247304, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621247742, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8869678974151611, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621247742, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621247927, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5263.070768513733, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621247927, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621247927, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5263.070768513733, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621247962, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621247962, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621247978, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621248399, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.870125412940979, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621248399, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621248583, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5410.937103812842, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621248583, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621248584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5410.937103812842, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621248611, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621248611, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621248627, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621249056, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8898674249649048, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621249057, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621249255, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5220.514136608192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621249255, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621249255, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5220.514136608192, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621249288, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621249288, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621249304, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621249723, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8915989995002747, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621249723, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621249941, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5146.289431507082, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621249941, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621249941, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5146.289431507082, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621249970, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621249970, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621249987, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621250404, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9027447700500488, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621250405, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621250615, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5214.367805799982, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621250615, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621250615, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5214.367805799982, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621250644, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621250645, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621250661, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621251080, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8980661630630493, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621251080, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621251265, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5417.855779743717, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621251265, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621251265, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5417.855779743717, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621251291, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621251292, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621251308, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621251737, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9043744802474976, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621251738, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621251926, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5293.932574477532, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621251927, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621251927, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5293.932574477532, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621251953, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621251953, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621251969, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621252404, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9024443030357361, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621252404, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621252594, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5243.100413075401, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621252594, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621252594, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5243.100413075401, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621252623, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621252623, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621252639, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621253061, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8994600772857666, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621253061, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621253238, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5462.232952398302, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621253238, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621253238, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5462.232952398302, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621253267, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621253267, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621253282, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621253713, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9044970273971558, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621253713, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621253896, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5342.136822669108, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621253896, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621253896, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5342.136822669108, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621253922, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621253923, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621253938, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621254377, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8910950422286987, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621254377, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621254557, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5296.085165103593, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621254557, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621254557, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5296.085165103593, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621254583, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621254583, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621254598, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621255034, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9027743339538574, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621255035, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621255223, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5248.472122082457, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621255223, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621255224, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5248.472122082457, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621255249, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621255249, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621255265, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621255702, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8931256532669067, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621255702, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621255884, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5293.79933850335, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621255884, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621255884, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5293.79933850335, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621255913, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621255913, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621255929, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621256350, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8920903205871582, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621256350, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621256531, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5439.99691191349, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621256531, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621256531, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5439.99691191349, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621256558, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621256558, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621256573, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621257004, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8941541910171509, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621257004, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621257187, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5340.096375041919, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621257188, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621257188, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5340.096375041919, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621257212, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621257213, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621257228, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621257666, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9042392373085022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621257667, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621257854, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5240.281303951575, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621257854, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621257854, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5240.281303951575, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621257881, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621257881, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621257896, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621258334, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8858959078788757, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621258335, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621258521, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5254.646263340419, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621258521, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621258521, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5254.646263340419, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621258546, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621258546, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621258561, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621259002, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8983384370803833, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621259002, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621259185, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5261.532209980993, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621259185, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621259185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5261.532209980993, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621259210, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621259210, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621259225, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621259663, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8976377248764038, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621259663, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621259854, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5222.380988908492, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621259854, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621259854, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5222.380988908492, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621259879, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621259879, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621259896, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621260332, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.900904655456543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621260333, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621260521, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5233.705438977507, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621260522, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621260522, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5233.705438977507, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621260553, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621260553, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621260569, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621260990, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.893288254737854, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621260990, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621261174, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5411.01189566585, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621261174, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621261174, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5411.01189566585, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621261201, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621261202, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621261217, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621261648, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8810514211654663, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621261648, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621261831, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5340.3068252998055, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621261831, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621261831, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5340.3068252998055, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621261860, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621261861, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621261877, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621262296, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.892040491104126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621262297, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621262473, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5487.936366882648, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621262473, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621262473, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5487.936366882648, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621262501, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621262501, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621262517, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621262947, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8988479971885681, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621262947, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621263129, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5352.7772158523985, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621263129, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621263129, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5352.7772158523985, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621263158, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621263159, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621263174, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621263595, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8923431634902954, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621263595, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621263778, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5428.214761130011, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621263778, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621263778, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5428.214761130011, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621263807, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621263807, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621263823, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621264241, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8934104442596436, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621264241, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621264424, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5448.019836198278, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621264424, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621264424, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5448.019836198278, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621264451, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621264451, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621264465, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621264897, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9019303321838379, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621264898, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621265085, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5302.361927666238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621265085, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621265085, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5302.361927666238, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621265111, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621265112, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621265126, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621265560, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8795658946037292, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621265560, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621265741, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5342.487175326891, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621265741, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621265741, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5342.487175326891, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621265768, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621265768, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621265784, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621266217, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9060136675834656, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621266217, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621266396, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5348.563881487138, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621266396, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621266396, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5348.563881487138, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621266424, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621266424, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621266439, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621266878, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.902400016784668, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621266879, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621267072, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5191.40627969994, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621267072, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621267072, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5191.40627969994, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621267098, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621267099, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621267114, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621267552, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9082604646682739, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621267552, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621267552, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634621267744, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5209.215830287232, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621267744, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621267744, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5209.215830287232, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
ENDING TIMING RUN AT 2021-10-19 05:27:53 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:53 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:53 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:53 AM
RESULT,image_segmentation,,200,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:54 AM
RESULT,image_segmentation,,201,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:54 AM
RESULT,image_segmentation,,201,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:54 AM
RESULT,image_segmentation,,201,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:54 AM
RESULT,image_segmentation,,201,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:54 AM
RESULT,image_segmentation,,201,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:54 AM
RESULT,image_segmentation,,201,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:54 AM
RESULT,image_segmentation,,201,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:54 AM
RESULT,image_segmentation,,201,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:57 AM
RESULT,image_segmentation,,204,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:58 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:58 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:58 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:58 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:58 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:58 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:58 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:58 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:59 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:00 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:01 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:02 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:03 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:04 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:05 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:06 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
ENDING TIMING RUN AT 2021-10-19 05:28:07 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:24:33 AM
