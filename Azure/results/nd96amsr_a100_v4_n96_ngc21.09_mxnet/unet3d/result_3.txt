+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019052351006903182
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019052351006903182
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019052351006903182
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019052351006903182
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07357/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019052351006903182_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C0409
Clearing cache on ip-0A0C040B
Clearing cache on ip-0A0C040E
Clearing cache on ip-0A0C0412
Clearing cache on ip-0A0C0414
Clearing cache on ip-0A0C0431
Clearing cache on ip-0A0C0442
Clearing cache on ip-0A0C0433
Clearing cache on ip-0A0C042B
Clearing cache on ip-0A0C041D
Clearing cache on ip-0A0C0424
Clearing cache on ip-0A0C042A
Clearing cache on ip-0A0C041C
Clearing cache on ip-0A0C0427
Clearing cache on ip-0A0C0425
Clearing cache on ip-0A0C0407
Clearing cache on ip-0A0C0416
Clearing cache on ip-0A0C0408
Clearing cache on ip-0A0C041F
Clearing cache on ip-0A0C0423
Clearing cache on ip-0A0C040A
Clearing cache on ip-0A0C0413
Clearing cache on ip-0A0C040C
Clearing cache on ip-0A0C0418
Clearing cache on ip-0A0C0411
Clearing cache on ip-0A0C0420
Clearing cache on ip-0A0C0419
Clearing cache on ip-0A0C041A
Clearing cache on ip-0A0C0518
Clearing cache on ip-0A0C042F
Clearing cache on ip-0A0C0417
Clearing cache on ip-0A0C0410
Clearing cache on ip-0A0C041E
Clearing cache on ip-0A0C0434
Clearing cache on ip-0A0C0475
Clearing cache on ip-0A0C0454
Clearing cache on ip-0A0C0446
Clearing cache on ip-0A0C042E
Clearing cache on ip-0A0C047A
Clearing cache on ip-0A0C041B
Clearing cache on ip-0A0C043F
Clearing cache on ip-0A0C0465
Clearing cache on ip-0A0C045A
Clearing cache on ip-0A0C0450
Clearing cache on ip-0A0C0469
Clearing cache on ip-0A0C0452
Clearing cache on ip-0A0C0421
Clearing cache on ip-0A0C0426
Clearing cache on ip-0A0C0428
Clearing cache on ip-0A0C0457
Clearing cache on ip-0A0C0440
Clearing cache on ip-0A0C0453
Clearing cache on ip-0A0C043D
Clearing cache on ip-0A0C0445
Clearing cache on ip-0A0C0476
Clearing cache on ip-0A0C044C
Clearing cache on ip-0A0C0467
Clearing cache on ip-0A0C0439
Clearing cache on ip-0A0C0463
Clearing cache on ip-0A0C044F
Clearing cache on ip-0A0C0480
Clearing cache on ip-0A0C043B
Clearing cache on ip-0A0C044B
Clearing cache on ip-0A0C043E
Clearing cache on ip-0A0C0471
Clearing cache on ip-0A0C044E
Clearing cache on ip-0A0C0430
Clearing cache on ip-0A0C0477
Clearing cache on ip-0A0C0481
Clearing cache on ip-0A0C047C
Clearing cache on ip-0A0C042C
Clearing cache on ip-0A0C0432
Clearing cache on ip-0A0C0447
Clearing cache on ip-0A0C044A
Clearing cache on ip-0A0C045D
Clearing cache on ip-0A0C043A
Clearing cache on ip-0A0C043C
Clearing cache on ip-0A0C045E
Clearing cache on ip-0A0C045C
Clearing cache on ip-0A0C0458
Clearing cache on ip-0A0C046D
Clearing cache on ip-0A0C0455
Clearing cache on ip-0A0C047D
Clearing cache on ip-0A0C045B
Clearing cache on ip-0A0C0474
Clearing cache on ip-0A0C0459
Clearing cache on ip-0A0C046A
Clearing cache on ip-0A0C047B
Clearing cache on ip-0A0C0479
Clearing cache on ip-0A0C0456
Clearing cache on ip-0A0C047F
Clearing cache on ip-0A0C0462
Clearing cache on ip-0A0C0422
Clearing cache on ip-0A0C0451
Clearing cache on ip-0A0C0470
Clearing cache on ip-0A0C0448
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:23:53 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634621038.415781] [ip-0A0C040E:32536:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.445717] [ip-0A0C0410:61254:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.478120] [ip-0A0C040B:88269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.492800] [ip-0A0C0430:69090:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.521870] [ip-0A0C0425:47874:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.527346] [ip-0A0C0410:61241:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.531853] [ip-0A0C040E:32529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.535263] [ip-0A0C0409:4238 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.540406] [ip-0A0C040E:32531:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.541417] [ip-0A0C0410:61242:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.554344] [ip-0A0C040E:32535:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.554862] [ip-0A0C043B:29405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.555513] [ip-0A0C0425:47873:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.559067] [ip-0A0C040B:88264:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.565988] [ip-0A0C0430:69096:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.566038] [ip-0A0C0430:69092:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.567903] [ip-0A0C0409:4254 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.581596] [ip-0A0C040B:88268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.582004] [ip-0A0C042C:37775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.584525] [ip-0A0C0410:61246:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.587639] [ip-0A0C0408:68742:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.587916] [ip-0A0C043B:29402:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.589888] [ip-0A0C042C:37773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.593052] [ip-0A0C040A:46209:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.593784] [ip-0A0C047F:10543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.595841] [ip-0A0C040E:32533:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.597624] [ip-0A0C0417:75155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.599574] [ip-0A0C040E:32534:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.607510] [ip-0A0C040C:56880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.608892] [ip-0A0C0463:19146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.610026] [ip-0A0C0407:49372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.610366] [ip-0A0C040E:32532:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.610570] [ip-0A0C043F:25742:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.611794] [ip-0A0C044E:21656:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.613804] [ip-0A0C0410:61245:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.615335] [ip-0A0C0411:44168:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.615148] [ip-0A0C0417:75179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.615880] [ip-0A0C040B:88262:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.615612] [ip-0A0C0422:65568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.616876] [ip-0A0C047F:10549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.617694] [ip-0A0C0407:49374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.622585] [ip-0A0C045E:25979:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.622881] [ip-0A0C040E:32537:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.622896] [ip-0A0C0465:16672:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.624136] [ip-0A0C0410:61243:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.625505] [ip-0A0C0409:4236 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.629614] [ip-0A0C0423:38563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.631867] [ip-0A0C042B:42352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.631873] [ip-0A0C043C:30668:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.631905] [ip-0A0C042B:42357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.639185] [ip-0A0C046D:13561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.640541] [ip-0A0C043B:29399:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.642430] [ip-0A0C045E:25982:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.642888] [ip-0A0C0423:38564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.643836] [ip-0A0C040B:88266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.645511] [ip-0A0C0465:16679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.646083] [ip-0A0C045D:16208:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.647539] [ip-0A0C0410:61239:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.648772] [ip-0A0C041F:48304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.650563] [ip-0A0C040A:46205:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.651824] [ip-0A0C0425:47879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.653212] [ip-0A0C041C:50352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.654100] [ip-0A0C047F:10547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.654073] [ip-0A0C0410:61240:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.655536] [ip-0A0C045A:28579:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.657825] [ip-0A0C0453:30226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.658523] [ip-0A0C042B:42353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.658811] [ip-0A0C041A:67902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.660523] [ip-0A0C040B:88265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.661464] [ip-0A0C042C:37774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.661707] [ip-0A0C0440:24077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.661858] [ip-0A0C040C:56881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.663546] [ip-0A0C0411:44138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.663457] [ip-0A0C046D:13566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.663664] [ip-0A0C0463:19151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.663717] [ip-0A0C0463:19150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.664376] [ip-0A0C0480:6484 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.665216] [ip-0A0C0424:33551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.671370] [ip-0A0C040B:88267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.671541] [ip-0A0C044E:21655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.673049] [ip-0A0C0411:44145:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.673567] [ip-0A0C044E:21654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.674590] [ip-0A0C045E:25976:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.676018] [ip-0A0C0447:31823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.676731] [ip-0A0C0430:69095:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.676957] [ip-0A0C040B:88263:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.677251] [ip-0A0C040A:46210:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.677759] [ip-0A0C0475:10900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.677837] [ip-0A0C045C:25546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.678953] [ip-0A0C042B:42355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.679070] [ip-0A0C0414:61269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.681516] [ip-0A0C0481:5387 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.681618] [ip-0A0C0413:76462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.682489] [ip-0A0C041C:50346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.683663] [ip-0A0C047B:13892:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.684171] [ip-0A0C0409:4235 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.684415] [ip-0A0C043F:25741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.685067] [ip-0A0C0445:35183:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.685735] [ip-0A0C0453:30227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.686061] [ip-0A0C0430:69091:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.688160] [ip-0A0C0480:6488 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.689106] [ip-0A0C0409:4240 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.689055] [ip-0A0C0408:68743:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.689938] [ip-0A0C0432:61125:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.690421] [ip-0A0C0408:68739:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.691474] [ip-0A0C041A:67906:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.691708] [ip-0A0C043F:25740:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.691395] [ip-0A0C042F:39653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.691417] [ip-0A0C042F:39651:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.692706] [ip-0A0C043E:18358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.692817] [ip-0A0C0479:7855 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.693001] [ip-0A0C0419:48271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.692838] [ip-0A0C0413:76465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.693001] [ip-0A0C0419:48274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.694477] [ip-0A0C0425:47878:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.694521] [ip-0A0C0476:4996 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.696768] [ip-0A0C0430:69094:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.697505] [ip-0A0C0480:6481 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.698768] [ip-0A0C0474:10862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.698938] [ip-0A0C0430:69089:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.699430] [ip-0A0C044C:26880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.699737] [ip-0A0C043C:30666:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.700903] [ip-0A0C0420:45750:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.701576] [ip-0A0C0479:7856 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.703856] [ip-0A0C045D:16203:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.704271] [ip-0A0C0417:75159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.705023] [ip-0A0C0407:49373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.705630] [ip-0A0C0412:24038:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.707410] [ip-0A0C045D:16204:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.707399] [ip-0A0C043E:18349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.707196] [ip-0A0C0418:41084:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.712261] [ip-0A0C0518:43163:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.712487] [ip-0A0C042A:35256:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.712990] [ip-0A0C044C:26903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.712822] [ip-0A0C043F:25743:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.712528] [ip-0A0C042A:35252:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.712847] [ip-0A0C043A:29899:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.714857] [ip-0A0C0477:12062:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.715261] [ip-0A0C0426:43033:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.716875] [ip-0A0C0425:47875:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.717310] [ip-0A0C0463:19145:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.718173] [ip-0A0C0430:69093:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.718220] [ip-0A0C045B:32528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.718528] [ip-0A0C0445:35178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.719014] [ip-0A0C042C:37776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.719208] [ip-0A0C0409:4263 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.721513] [ip-0A0C0409:4237 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.722419] [ip-0A0C0518:43164:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.722382] [ip-0A0C043B:29400:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.722701] [ip-0A0C041B:62585:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.724443] [ip-0A0C0409:4239 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.725241] [ip-0A0C0408:68735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.725921] [ip-0A0C0425:47876:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.726174] [ip-0A0C0407:49371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.727395] [ip-0A0C045C:25541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.728080] [ip-0A0C0411:44142:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.728215] [ip-0A0C040C:56879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.728709] [ip-0A0C0412:24040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.730260] [ip-0A0C0440:24074:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.730611] [ip-0A0C0481:5402 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.730767] [ip-0A0C0425:47880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.731584] [ip-0A0C0425:47877:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.732081] [ip-0A0C0422:65564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.733307] [ip-0A0C0422:65562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.733746] [ip-0A0C045B:32526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.734706] [ip-0A0C0475:10903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.734787] [ip-0A0C0475:10902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.735839] [ip-0A0C0471:14047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.736453] [ip-0A0C042C:37777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.736805] [ip-0A0C043B:29398:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.736985] [ip-0A0C041A:67907:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.736984] [ip-0A0C041C:50351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.739113] [ip-0A0C042E:43637:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.741646] [ip-0A0C045A:28584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.744113] [ip-0A0C0418:41086:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.744211] [ip-0A0C047F:10541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.744974] [ip-0A0C0467:14791:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.746769] [ip-0A0C041F:48300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.748256] [ip-0A0C0426:43031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.748041] [ip-0A0C041D:41392:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.748050] [ip-0A0C041D:41388:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.749123] [ip-0A0C042B:42358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.749367] [ip-0A0C042B:42356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.750387] [ip-0A0C0423:38565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.750202] [ip-0A0C041B:62583:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.750992] [ip-0A0C043C:30673:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.751984] [ip-0A0C040A:46207:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.752348] [ip-0A0C041F:48299:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.752998] [ip-0A0C0481:5388 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.752768] [ip-0A0C0469:14374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.753396] [ip-0A0C0408:68741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.754042] [ip-0A0C0476:4997 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.754097] [ip-0A0C0476:5001 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.754494] [ip-0A0C040C:56876:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.756358] [ip-0A0C042E:43639:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.757071] [ip-0A0C042B:42354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.757762] [ip-0A0C0428:33526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.757741] [ip-0A0C0433:38508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.757874] [ip-0A0C043A:29898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.759515] [ip-0A0C045E:25980:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.760001] [ip-0A0C043B:29403:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.760471] [ip-0A0C0456:32211:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.760333] [ip-0A0C0432:61124:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.762292] [ip-0A0C0458:32644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.762900] [ip-0A0C042C:37779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.762272] [ip-0A0C0458:32643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.763430] [ip-0A0C046D:13564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.764278] [ip-0A0C0452:28324:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.764318] [ip-0A0C042B:42351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.764779] [ip-0A0C044F:22662:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.766143] [ip-0A0C0459:25033:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.766282] [ip-0A0C0413:76460:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.766639] [ip-0A0C047B:13887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.766511] [ip-0A0C0476:5002 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.767791] [ip-0A0C0446:32536:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.767955] [ip-0A0C047B:13889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.767650] [ip-0A0C0417:75163:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.768124] [ip-0A0C041F:48325:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.767965] [ip-0A0C040A:46203:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.768037] [ip-0A0C0422:65563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.768699] [ip-0A0C0414:61276:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.768730] [ip-0A0C041D:41391:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.768953] [ip-0A0C0440:24080:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.768871] [ip-0A0C0414:61274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.769935] [ip-0A0C045D:16210:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.769997] [ip-0A0C0408:68744:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.771021] [ip-0A0C0452:28327:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.771078] [ip-0A0C0469:14372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.771240] [ip-0A0C0418:41081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.772335] [ip-0A0C0462:55958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.772957] [ip-0A0C0432:61117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.773232] [ip-0A0C044E:21661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.775327] [ip-0A0C046A:19706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.778771] [ip-0A0C0442:24516:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.778673] [ip-0A0C046A:19703:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.779076] [ip-0A0C0448:36319:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.779308] [ip-0A0C047F:10544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.779490] [ip-0A0C0417:75160:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.779813] [ip-0A0C047A:12267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.780436] [ip-0A0C043C:30671:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.781184] [ip-0A0C0426:43032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.781868] [ip-0A0C045E:25978:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.782025] [ip-0A0C041A:67908:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.782392] [ip-0A0C043B:29401:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.782578] [ip-0A0C043B:29406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.782593] [ip-0A0C0412:24043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.782984] [ip-0A0C0432:61123:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.783561] [ip-0A0C0414:61270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.784112] [ip-0A0C0424:33547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.784099] [ip-0A0C043A:29897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.785733] [ip-0A0C0459:25034:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.786468] [ip-0A0C040A:46206:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.786864] [ip-0A0C043F:25739:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.786640] [ip-0A0C040A:46208:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.787576] [ip-0A0C040C:56877:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.788536] [ip-0A0C0420:45745:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.788759] [ip-0A0C0474:10866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.788868] [ip-0A0C0474:10864:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.789157] [ip-0A0C042C:37778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.789964] [ip-0A0C0408:68736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.789814] [ip-0A0C0433:38509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.790686] [ip-0A0C0423:38568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.790192] [ip-0A0C0417:75157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.790694] [ip-0A0C0428:33550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.791036] [ip-0A0C0447:31824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.791284] [ip-0A0C0408:68737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.792204] [ip-0A0C042C:37780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.792377] [ip-0A0C044A:23977:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.792564] [ip-0A0C0518:43166:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.792641] [ip-0A0C047F:10542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.792806] [ip-0A0C047F:10550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.792971] [ip-0A0C047F:10548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.793639] [ip-0A0C0407:49370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.793687] [ip-0A0C0407:49375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.793913] [ip-0A0C0417:75158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.795869] [ip-0A0C043F:25745:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.795665] [ip-0A0C040A:46232:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.796014] [ip-0A0C043F:25747:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.796976] [ip-0A0C041E:44357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.797390] [ip-0A0C041A:67909:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.798021] [ip-0A0C0424:33553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.798132] [ip-0A0C043F:25744:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.798797] [ip-0A0C0422:65566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.798584] [ip-0A0C045C:25547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.799266] [ip-0A0C045A:28582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.799248] [ip-0A0C0465:16670:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.799783] [ip-0A0C045A:28585:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.799745] [ip-0A0C0465:16673:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.799503] [ip-0A0C0417:75161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.800337] [ip-0A0C0423:38561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.800281] [ip-0A0C045B:32531:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.800341] [ip-0A0C0463:19148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.801698] [ip-0A0C0467:14788:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.803753] [ip-0A0C0477:12055:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.805480] [ip-0A0C0439:21988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.805508] [ip-0A0C043C:30667:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.805787] [ip-0A0C0465:16674:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.806091] [ip-0A0C040C:56882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.806917] [ip-0A0C0440:24078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.808655] [ip-0A0C0414:61293:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.808512] [ip-0A0C044B:28091:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.811389] [ip-0A0C0456:32207:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.811841] [ip-0A0C0477:12061:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.812014] [ip-0A0C045D:16206:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.812780] [ip-0A0C0445:35179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.813504] [ip-0A0C0456:32205:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.813601] [ip-0A0C0411:44141:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.813632] [ip-0A0C0446:32534:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.813455] [ip-0A0C040C:56878:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.813448] [ip-0A0C046D:13565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.814026] [ip-0A0C0465:16677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.814643] [ip-0A0C045E:25975:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.814453] [ip-0A0C0411:44139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.814273] [ip-0A0C044E:21653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.814733] [ip-0A0C044B:28088:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.814764] [ip-0A0C043C:30669:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.814834] [ip-0A0C0463:19147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.814652] [ip-0A0C045C:25543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.816219] [ip-0A0C0480:6486 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.817897] [ip-0A0C0423:38567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.817525] [ip-0A0C040C:56883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.817964] [ip-0A0C0411:44140:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.818089] [ip-0A0C0411:44143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.817766] [ip-0A0C0422:65565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.818154] [ip-0A0C0450:97945:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.818581] [ip-0A0C0479:7859 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.818482] [ip-0A0C041F:48298:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.818313] [ip-0A0C046A:19702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.818950] [ip-0A0C0463:19143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.818994] [ip-0A0C0471:14050:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.819564] [ip-0A0C0422:65567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.820172] [ip-0A0C0422:65561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.820138] [ip-0A0C044E:21660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.820258] [ip-0A0C0442:24513:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.820909] [ip-0A0C0424:33550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.820972] [ip-0A0C0407:49377:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.821170] [ip-0A0C044F:22664:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.820709] [ip-0A0C045C:25544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.821127] [ip-0A0C0432:61118:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.822051] [ip-0A0C0407:49376:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.822205] [ip-0A0C0469:14392:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.822938] [ip-0A0C0419:48273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.823272] [ip-0A0C0447:31825:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.823495] [ip-0A0C045D:16205:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.823301] [ip-0A0C041C:50347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.824701] [ip-0A0C0453:30220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.825327] [ip-0A0C0453:30223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.825535] [ip-0A0C0465:16671:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.825568] [ip-0A0C047B:13891:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.825574] [ip-0A0C0421:46467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.826935] [ip-0A0C0423:38566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.826576] [ip-0A0C042F:39650:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.827535] [ip-0A0C0475:10899:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.828116] [ip-0A0C0423:38562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.828699] [ip-0A0C0463:19144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.829172] [ip-0A0C0447:31821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.830238] [ip-0A0C044E:21659:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.831064] [ip-0A0C045E:25977:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.831109] [ip-0A0C0453:30225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.831381] [ip-0A0C0477:12057:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.831366] [ip-0A0C0458:32642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.832200] [ip-0A0C045E:25994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.831601] [ip-0A0C044E:21657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.832172] [ip-0A0C0467:14810:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.832282] [ip-0A0C0465:16678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.832346] [ip-0A0C0462:55956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.832272] [ip-0A0C0434:33278:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.832561] [ip-0A0C045A:28581:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.832245] [ip-0A0C0434:33281:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.832752] [ip-0A0C0474:10867:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.832446] [ip-0A0C043A:29900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.833377] [ip-0A0C042F:39652:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.834216] [ip-0A0C043E:18344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.834201] [ip-0A0C0413:76466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.835652] [ip-0A0C044C:26877:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.836196] [ip-0A0C045A:28598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.836076] [ip-0A0C0481:5390 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.836175] [ip-0A0C042E:43633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.837034] [ip-0A0C0418:41078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.838464] [ip-0A0C0480:6485 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.839319] [ip-0A0C0420:45747:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.839502] [ip-0A0C045D:16209:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.839454] [ip-0A0C043C:30672:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.840139] [ip-0A0C043C:30670:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.840726] [ip-0A0C043E:18345:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.842676] [ip-0A0C046D:13567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.843493] [ip-0A0C046D:13563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.846147] [ip-0A0C041D:41389:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.846198] [ip-0A0C046D:13568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.847817] [ip-0A0C0446:32535:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.847777] [ip-0A0C046D:13562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.848585] [ip-0A0C045D:16207:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.849595] [ip-0A0C041F:48303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.849935] [ip-0A0C0419:48272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.849877] [ip-0A0C0445:35181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.850142] [ip-0A0C0451:27112:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.850298] [ip-0A0C041F:48302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.851294] [ip-0A0C0518:43165:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.850824] [ip-0A0C042F:39654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.852078] [ip-0A0C042A:35254:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.852252] [ip-0A0C047A:12272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.852398] [ip-0A0C042A:35253:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.852526] [ip-0A0C0413:76463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.852868] [ip-0A0C041C:50350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.853112] [ip-0A0C0480:6487 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.853152] [ip-0A0C041C:50349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.853922] [ip-0A0C0474:10889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.854157] [ip-0A0C0440:24079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.853871] [ip-0A0C047D:8020 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.856307] [ip-0A0C041A:67901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.857309] [ip-0A0C0424:33554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.857395] [ip-0A0C0440:24076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.857573] [ip-0A0C0439:21995:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.857603] [ip-0A0C0457:25072:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.857780] [ip-0A0C042A:35255:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.858288] [ip-0A0C0457:25065:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.858639] [ip-0A0C041F:48301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.859233] [ip-0A0C041A:67903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.859734] [ip-0A0C0480:6483 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.859972] [ip-0A0C0454:29179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.861305] [ip-0A0C041A:67904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.861472] [ip-0A0C041C:50348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.861866] [ip-0A0C043E:18348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.862439] [ip-0A0C0470:9830 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.863324] [ip-0A0C0424:33552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.863755] [ip-0A0C0475:10898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.864638] [ip-0A0C0471:14048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.864651] [ip-0A0C045C:25540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.866035] [ip-0A0C0479:7853 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.866407] [ip-0A0C044C:26874:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.866844] [ip-0A0C044F:22659:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.867174] [ip-0A0C0474:10865:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.867402] [ip-0A0C0450:97944:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.867542] [ip-0A0C0453:30221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.867338] [ip-0A0C0455:23721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.867622] [ip-0A0C0453:30222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.868507] [ip-0A0C047B:13893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.869196] [ip-0A0C044C:26876:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.869354] [ip-0A0C045C:25545:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.869923] [ip-0A0C0413:76464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.870566] [ip-0A0C0420:45749:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.870630] [ip-0A0C0447:31826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.870687] [ip-0A0C0434:33282:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.871412] [ip-0A0C0447:31822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.871365] [ip-0A0C041C:50353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.871691] [ip-0A0C0424:33548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.871731] [ip-0A0C0476:5003 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.872320] [ip-0A0C0440:24075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.872508] [ip-0A0C0427:41403:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.872512] [ip-0A0C0427:41406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.873275] [ip-0A0C0445:35180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.873138] [ip-0A0C047C:17215:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.873738] [ip-0A0C0476:4999 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.874177] [ip-0A0C0453:30224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.874244] [ip-0A0C045A:28580:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.874633] [ip-0A0C0479:7854 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.874342] [ip-0A0C045A:28586:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.875084] [ip-0A0C0428:33525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.875121] [ip-0A0C047B:13894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.875301] [ip-0A0C0480:6482 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.875702] [ip-0A0C0424:33549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.875708] [ip-0A0C0481:5394 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.876286] [ip-0A0C0459:25035:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.876565] [ip-0A0C0455:23718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.876769] [ip-0A0C0475:10905:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.876722] [ip-0A0C0412:24066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.876998] [ip-0A0C0481:5392 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.876785] [ip-0A0C0412:24039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.877186] [ip-0A0C0445:35182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.877552] [ip-0A0C042A:35257:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.877451] [ip-0A0C0481:5389 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.878436] [ip-0A0C0419:48276:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.879183] [ip-0A0C0419:48277:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.879097] [ip-0A0C0440:24081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.879821] [ip-0A0C0476:5000 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.880106] [ip-0A0C0476:4998 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.880380] [ip-0A0C0451:27119:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.881053] [ip-0A0C0447:31827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.881196] [ip-0A0C0474:10870:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.881311] [ip-0A0C044C:26875:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.881559] [ip-0A0C0420:45751:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.881623] [ip-0A0C045B:32530:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.881336] [ip-0A0C042F:39655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.882258] [ip-0A0C0442:24515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.882547] [ip-0A0C0413:76461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.883426] [ip-0A0C0447:31828:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.883930] [ip-0A0C0432:61120:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.884263] [ip-0A0C0432:61121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.884490] [ip-0A0C0414:61273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.884559] [ip-0A0C0462:55954:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.884577] [ip-0A0C0414:61272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.884801] [ip-0A0C047B:13890:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.886019] [ip-0A0C043E:18347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.886254] [ip-0A0C0420:45746:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.886285] [ip-0A0C0448:36324:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.885992] [ip-0A0C042F:39648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.886251] [ip-0A0C042F:39649:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.887204] [ip-0A0C0474:10863:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.886894] [ip-0A0C0413:76467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.887391] [ip-0A0C0475:10904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.888326] [ip-0A0C045B:32533:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.888357] [ip-0A0C0414:61271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.888293] [ip-0A0C0445:35177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.888303] [ip-0A0C0481:5391 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.888473] [ip-0A0C0432:61122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.889611] [ip-0A0C0518:43161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.889840] [ip-0A0C0467:14790:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.891005] [ip-0A0C044C:26878:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.891312] [ip-0A0C0454:29174:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.891345] [ip-0A0C045C:25542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.892316] [ip-0A0C044A:23976:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.893144] [ip-0A0C0419:48275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.893349] [ip-0A0C0420:45752:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.893436] [ip-0A0C0420:45748:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.893486] [ip-0A0C0458:32647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.894051] [ip-0A0C043E:18346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.894125] [ip-0A0C0475:10901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.894277] [ip-0A0C0412:24041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.894678] [ip-0A0C044F:22663:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.894832] [ip-0A0C041B:62584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.895153] [ip-0A0C043E:18343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.895385] [ip-0A0C041B:62581:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.895948] [ip-0A0C0419:48278:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.896557] [ip-0A0C047B:13888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.896910] [ip-0A0C0416:31652:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.897617] [ip-0A0C0426:43026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.897833] [ip-0A0C042E:43638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.899412] [ip-0A0C0479:7857 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.899395] [ip-0A0C0445:35176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.899949] [ip-0A0C0470:9831 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.900401] [ip-0A0C0448:36323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.900519] [ip-0A0C0416:31651:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.901119] [ip-0A0C0418:41079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.901132] [ip-0A0C0433:38512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.903076] [ip-0A0C0479:7860 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.902941] [ip-0A0C0477:12059:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.904020] [ip-0A0C047A:12271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.904213] [ip-0A0C041E:44354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.905429] [ip-0A0C0479:7858 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.905380] [ip-0A0C0452:28325:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.905152] [ip-0A0C0458:32648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.905472] [ip-0A0C042A:35251:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.905562] [ip-0A0C042A:35250:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.906619] [ip-0A0C043A:29895:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.906613] [ip-0A0C043A:29894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.907531] [ip-0A0C041D:41393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.907561] [ip-0A0C043A:29893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.908361] [ip-0A0C0418:41091:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.908067] [ip-0A0C043A:29896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.908613] [ip-0A0C0451:27115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.909178] [ip-0A0C0418:41080:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.909268] [ip-0A0C0418:41083:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.909727] [ip-0A0C0446:32532:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.910681] [ip-0A0C0412:24042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.910888] [ip-0A0C0412:24037:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.912505] [ip-0A0C0469:14396:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.912673] [ip-0A0C0469:14375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.913471] [ip-0A0C044C:26879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.913302] [ip-0A0C047D:8022 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.914842] [ip-0A0C041B:62580:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.914944] [ip-0A0C0471:14049:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.915109] [ip-0A0C0452:28330:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.915616] [ip-0A0C042E:43635:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.916704] [ip-0A0C0458:32649:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.917539] [ip-0A0C0477:12054:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.918065] [ip-0A0C0518:43159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.918370] [ip-0A0C0450:97949:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.919302] [ip-0A0C0439:21993:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.919728] [ip-0A0C041D:41394:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.919856] [ip-0A0C041D:41387:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.920807] [ip-0A0C0518:43160:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.921917] [ip-0A0C0471:14051:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.922856] [ip-0A0C0518:43162:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.923667] [ip-0A0C0454:29172:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.924845] [ip-0A0C0462:55952:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.924768] [ip-0A0C0448:36317:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.925718] [ip-0A0C0426:43027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.925829] [ip-0A0C0426:43030:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.925543] [ip-0A0C0433:38515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.925491] [ip-0A0C0459:25038:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.926403] [ip-0A0C041B:62582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.926398] [ip-0A0C041B:62578:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.926477] [ip-0A0C044B:28090:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.926971] [ip-0A0C041D:41390:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.927034] [ip-0A0C0477:12058:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.926873] [ip-0A0C042E:43661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.927905] [ip-0A0C0477:12053:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.927764] [ip-0A0C0442:24517:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.928871] [ip-0A0C043D:21029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.928983] [ip-0A0C044A:23975:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.928987] [ip-0A0C043D:21025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.929084] [ip-0A0C042E:43634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.929464] [ip-0A0C041E:44359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.929634] [ip-0A0C047A:12268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.930083] [ip-0A0C0433:38530:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.931428] [ip-0A0C0452:28326:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.931354] [ip-0A0C041B:62579:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.931039] [ip-0A0C042E:43636:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.933261] [ip-0A0C0426:43029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.934387] [ip-0A0C044A:23974:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.935410] [ip-0A0C045B:32525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.936044] [ip-0A0C045B:32529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.936164] [ip-0A0C045B:32527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.940253] [ip-0A0C0451:27114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.940258] [ip-0A0C0433:38520:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.940131] [ip-0A0C047D:8018 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.942751] [ip-0A0C044F:22665:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.943350] [ip-0A0C0462:55955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.943338] [ip-0A0C0421:46463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.943520] [ip-0A0C0421:46462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.944562] [ip-0A0C0426:43028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.945364] [ip-0A0C0428:33520:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.945569] [ip-0A0C0448:36321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.946019] [ip-0A0C0434:33285:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.945900] [ip-0A0C046A:19701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.947764] [ip-0A0C0428:33527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.947803] [ip-0A0C041E:44352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.948545] [ip-0A0C0458:32641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.948751] [ip-0A0C0458:32645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.949371] [ip-0A0C0431:35191:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.949115] [ip-0A0C0459:25036:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.950888] [ip-0A0C0471:14052:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.951371] [ip-0A0C0456:32204:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.951051] [ip-0A0C047C:17220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.951474] [ip-0A0C0467:14789:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.951898] [ip-0A0C0456:32208:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.952880] [ip-0A0C0428:33521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.953804] [ip-0A0C0471:14046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.953913] [ip-0A0C0471:14045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.953997] [ip-0A0C044B:28113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.954094] [ip-0A0C0421:46464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.955239] [ip-0A0C0452:28329:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.955552] [ip-0A0C0452:28331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.956143] [ip-0A0C0455:23715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.956118] [ip-0A0C0459:25037:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.956515] [ip-0A0C0467:14787:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.957357] [ip-0A0C0467:14786:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.958035] [ip-0A0C046A:19705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.959002] [ip-0A0C0433:38510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.959307] [ip-0A0C046A:19699:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.961390] [ip-0A0C0431:35197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.962493] [ip-0A0C0467:14793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.963104] [ip-0A0C0446:32537:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.963085] [ip-0A0C044F:22660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.964253] [ip-0A0C044F:22661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.965052] [ip-0A0C0428:33524:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.965029] [ip-0A0C0433:38511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.966581] [ip-0A0C0439:21994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.966669] [ip-0A0C0428:33523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.967935] [ip-0A0C0450:97946:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.969609] [ip-0A0C0452:28328:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.969585] [ip-0A0C047A:12265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.970048] [ip-0A0C0456:32206:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.970537] [ip-0A0C043D:21027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.970943] [ip-0A0C0456:32209:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.970333] [ip-0A0C046A:19700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.970884] [ip-0A0C0469:14370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.971942] [ip-0A0C0459:25032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.972575] [ip-0A0C0462:55953:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.972839] [ip-0A0C0462:55951:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.972672] [ip-0A0C0469:14373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.972918] [ip-0A0C0462:55957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.972732] [ip-0A0C0469:14371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.973710] [ip-0A0C044A:23972:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.974705] [ip-0A0C0446:32531:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.974936] [ip-0A0C0446:32530:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.975435] [ip-0A0C0448:36318:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.976702] [ip-0A0C0456:32210:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.976512] [ip-0A0C044F:22666:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.976622] [ip-0A0C0448:36320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.977525] [ip-0A0C044A:23978:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.977586] [ip-0A0C0439:21990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.978213] [ip-0A0C0446:32533:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.980859] [ip-0A0C0442:24519:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.981080] [ip-0A0C044B:28093:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.981208] [ip-0A0C0459:25031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.981642] [ip-0A0C0448:36322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.982161] [ip-0A0C044A:23973:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.982360] [ip-0A0C047C:17221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.982699] [ip-0A0C041E:44355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.984339] [ip-0A0C0439:21992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.987238] [ip-0A0C046A:19704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.989587] [ip-0A0C047A:12266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.990268] [ip-0A0C041E:44358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.990852] [ip-0A0C047A:12269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.990928] [ip-0A0C041E:44353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.991199] [ip-0A0C044A:23971:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.992103] [ip-0A0C047A:12270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.993249] [ip-0A0C0421:46468:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.994812] [ip-0A0C0454:29178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.998539] [ip-0A0C0431:35196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621038.999893] [ip-0A0C0442:24518:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.000616] [ip-0A0C0434:33284:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.000920] [ip-0A0C041E:44356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.001240] [ip-0A0C044B:28094:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.003153] [ip-0A0C0442:24514:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.007364] [ip-0A0C0454:29176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.009175] [ip-0A0C0450:97947:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.010026] [ip-0A0C0470:9827 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.010747] [ip-0A0C0427:41404:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.010934] [ip-0A0C0427:41401:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.010919] [ip-0A0C0442:24512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.013849] [ip-0A0C0455:23714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.014546] [ip-0A0C0457:25070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.014527] [ip-0A0C044B:28089:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.014600] [ip-0A0C0457:25066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.014994] [ip-0A0C0434:33286:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.015922] [ip-0A0C0450:97951:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.016587] [ip-0A0C0450:97950:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.016318] [ip-0A0C0451:27113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.016586] [ip-0A0C044B:28092:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.018477] [ip-0A0C0439:21991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.019856] [ip-0A0C043D:21028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.020390] [ip-0A0C0439:21989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.022147] [ip-0A0C0450:97948:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.023137] [ip-0A0C0434:33279:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.023728] [ip-0A0C0431:35192:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.025449] [ip-0A0C0434:33280:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.026435] [ip-0A0C0421:46461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.026868] [ip-0A0C0421:46466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.028530] [ip-0A0C043D:21024:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.030128] [ip-0A0C0421:46465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.031391] [ip-0A0C0455:23719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.032956] [ip-0A0C047D:8015 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.034794] [ip-0A0C0457:25068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.034849] [ip-0A0C0457:25069:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.036665] [ip-0A0C047D:8021 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.039376] [ip-0A0C0451:27116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.039808] [ip-0A0C0451:27117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.041722] [ip-0A0C0470:9833 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.041851] [ip-0A0C0427:41402:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.042486] [ip-0A0C0454:29173:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.043137] [ip-0A0C0416:31653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.046147] [ip-0A0C0470:9832 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.047869] [ip-0A0C0454:29177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.048230] [ip-0A0C0416:31654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.048226] [ip-0A0C0427:41408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.048427] [ip-0A0C0454:29175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.051734] [ip-0A0C047C:17216:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.051850] [ip-0A0C047C:17218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.053420] [ip-0A0C0455:23720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.055075] [ip-0A0C0451:27118:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.056268] [ip-0A0C0431:35190:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.057435] [ip-0A0C043D:21026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.058765] [ip-0A0C0457:25071:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.059522] [ip-0A0C0457:25067:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.060275] [ip-0A0C047D:8017 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.060693] [ip-0A0C0427:41405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.064291] [ip-0A0C0470:9828 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.065328] [ip-0A0C047D:8016 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.066592] [ip-0A0C0455:23716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.066488] [ip-0A0C047C:17219:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.066392] [ip-0A0C047D:8019 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.067636] [ip-0A0C0455:23717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.068698] [ip-0A0C0431:35193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.068841] [ip-0A0C0470:9829 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.068927] [ip-0A0C0427:41407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.071200] [ip-0A0C0416:31676:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.073823] [ip-0A0C0416:31666:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.074629] [ip-0A0C0431:35194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.075203] [ip-0A0C0416:31650:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.076973] [ip-0A0C047C:17217:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.079571] [ip-0A0C0431:35195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.080044] [ip-0A0C047C:17222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.082705] [ip-0A0C0470:9826 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.085033] [ip-0A0C0416:31649:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.087052] [ip-0A0C043D:21023:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621039.088136] [ip-0A0C043D:21022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634621039975, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634621040015, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634621040015, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634621040016, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634621040016, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634621040016, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634621040016, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:10] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:11] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:12] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:24:13] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0409:0:4239 - context.c:584] INFO job (ID: 867538485579572097) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:4239 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:4239 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:4235 - context.c:584] INFO job (ID: 867538852642995775) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:4235 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:4235 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:4263 - context.c:584] INFO job (ID: 867538821885039039) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:4263 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:4263 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:4236 - context.c:584] INFO job (ID: 867538725201706852) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:4236 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:4236 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:4238 - context.c:584] INFO job (ID: 867538477659284093) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:4238 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:4238 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:4254 - context.c:584] INFO job (ID: 867538402331304984) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:4254 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:4254 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:4240 - context.c:584] INFO job (ID: 867538683848391646) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:4240 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:4240 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:4237 - context.c:584] INFO job (ID: 867538402210916428) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:4237 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:4237 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134361, "event_type": "POINT_IN_TIME", "key": "seed", "value": 2947547653, "metadata": {"file": "main.py", "lineno": 72}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134361, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134361, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134361, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134361, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134361, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134362, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134362, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134362, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134362, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134362, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621134362, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:34] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:25:36] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621158277, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634621158323, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621158327, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634621158327, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621160808, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621160809, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1634621160809, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634621160810, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621162358, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2169.9810192159075, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621162359, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621162359, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2169.9810192159075, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634621162359, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621162359, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621163028, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5023.6575281280175, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621163028, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621163028, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5023.6575281280175, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621163028, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621163029, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621163699, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5008.780980874891, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621163700, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621163700, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5008.780980874891, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634621163700, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621163700, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621164343, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5230.871180782511, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621164343, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621164343, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5230.871180782511, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634621164343, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621164343, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621164990, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5199.552331593983, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621164990, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621164990, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5199.552331593983, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634621164990, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621164990, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621165627, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5276.5336057054365, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621165627, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621165628, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5276.5336057054365, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634621165628, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621165628, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621166252, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5383.999679088612, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621166252, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621166252, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5383.999679088612, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634621166253, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621166253, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621166885, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5315.509476206138, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621166885, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621166886, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5315.509476206138, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634621166886, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621166886, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621167506, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5414.192461777953, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621167507, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621167507, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5414.192461777953, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634621167507, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621167507, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621168133, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5374.605830396778, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621168133, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621168133, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5374.605830396778, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634621168133, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621168133, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621168759, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5369.633719787179, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621168760, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621168760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5369.633719787179, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634621168760, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621168760, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621169380, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5420.306306278587, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621169380, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621169381, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5420.306306278587, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634621169381, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621169381, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621170004, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5389.635277236416, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621170005, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621170005, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5389.635277236416, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634621170005, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621170005, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621170629, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5382.375227004948, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621170630, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621170630, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5382.375227004948, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634621170630, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621170630, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621171269, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5258.210578983442, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621171270, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621171270, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5258.210578983442, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634621171270, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621171270, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621171893, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5393.554399925294, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621171894, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621171894, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5393.554399925294, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634621171894, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621171894, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621172515, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5408.607127012368, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621172516, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621172516, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5408.607127012368, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634621172516, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621172516, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621173139, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5397.869955749517, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621173139, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621173139, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5397.869955749517, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634621173139, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621173140, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621173756, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5453.220535081002, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621173756, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621173756, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5453.220535081002, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634621173756, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621173757, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621174378, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5410.7189727173145, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621174378, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621174378, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5410.7189727173145, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634621174378, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621174378, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621175000, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5404.1168938887595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621175001, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621175001, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5404.1168938887595, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634621175001, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621175001, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621175620, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5431.81752798803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621175620, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621175620, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5431.81752798803, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634621175620, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621175621, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621176243, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5398.025022752135, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621176244, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621176244, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5398.025022752135, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634621176244, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621176244, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621176867, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5394.698207057696, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621176867, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621176867, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5394.698207057696, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634621176868, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621176868, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621177493, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5375.477101646073, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621177493, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621177493, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5375.477101646073, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634621177493, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621177494, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621178118, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5380.5997329717975, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621178119, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621178119, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5380.5997329717975, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634621178119, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621178119, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621178744, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5379.739122268972, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621178744, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621178744, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5379.739122268972, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634621178744, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621178744, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621179367, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5395.072010927301, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621179368, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621179368, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5395.072010927301, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634621179368, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621179368, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621180010, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5231.572174726502, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621180011, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621180011, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5231.572174726502, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634621180011, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621180011, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621180634, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5392.297597452016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621180635, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621180635, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5392.297597452016, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634621180635, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621180635, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621181252, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5445.575755608596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621181253, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621181253, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5445.575755608596, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634621181253, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621181253, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621181881, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5351.153260237271, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621181881, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621181882, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5351.153260237271, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634621181882, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621181882, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621182500, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5439.467789179857, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621182500, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621182500, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5439.467789179857, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634621182500, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621182500, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621183123, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5397.874090753967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621183124, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621183124, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5397.874090753967, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634621183124, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621183124, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621183744, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5417.941177488239, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621183745, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621183745, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5417.941177488239, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634621183745, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621183745, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621184369, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5381.084589587558, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621184370, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621184370, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5381.084589587558, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634621184370, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621184370, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621184990, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5420.093672815884, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621184991, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621184991, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5420.093672815884, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634621184991, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621184991, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621185613, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5405.364699817697, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621185613, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621185613, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5405.364699817697, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634621185613, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621185614, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621186231, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.842213363868, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621186232, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621186232, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.842213363868, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634621186232, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621186232, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621186847, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5462.184259545642, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621186848, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621186848, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5462.184259545642, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634621186848, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621186848, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621187465, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5449.629368969019, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621187465, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621187465, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5449.629368969019, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634621187465, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621187465, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621188080, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5463.8678423422325, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621188081, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621188081, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5463.8678423422325, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634621188081, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621188081, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621188702, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5410.394924705589, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621188702, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621188703, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5410.394924705589, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634621188703, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621188703, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621189327, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5387.344200128444, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621189327, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621189327, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5387.344200128444, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634621189327, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621189327, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621189946, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5433.199647472745, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621189946, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621189946, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5433.199647472745, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634621189946, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621189946, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621190564, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5442.513753170132, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621190564, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621190565, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5442.513753170132, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634621190565, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621190565, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621191184, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5425.262051626151, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621191185, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621191185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5425.262051626151, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634621191185, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621191185, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621191804, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5432.223714377784, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621191804, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621191804, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5432.223714377784, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634621191804, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621191804, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621192423, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5430.932084742333, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621192423, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621192423, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5430.932084742333, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634621192424, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621192424, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621193043, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5427.658662270989, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621193043, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621193043, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5427.658662270989, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634621193115, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621193115, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621193132, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621193560, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8705637454986572, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621193561, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621193738, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5392.526626172895, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621193739, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621193739, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5392.526626172895, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621193817, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621193817, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621193832, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621194265, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8886539936065674, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621194265, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621194489, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5003.778324724369, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621194489, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621194489, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5003.778324724369, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621194566, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621194566, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621194581, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621195001, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8931266069412231, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621195002, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621195216, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5172.265491441621, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621195216, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621195216, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5172.265491441621, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621195241, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621195241, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621195258, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621195702, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8634201288223267, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621195702, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621195899, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5101.767169897794, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621195900, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621195900, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5101.767169897794, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621195936, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621195936, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621195952, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621196390, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8927710056304932, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621196390, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621196589, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5142.824512388443, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621196590, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621196590, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5142.824512388443, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621196614, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621196614, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621196631, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621197066, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8946252465248108, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621197066, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621197258, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5225.238986680014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621197258, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621197258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5225.238986680014, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621197283, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621197283, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621197299, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621197736, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8933815956115723, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621197736, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621197937, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5136.614379089732, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621197937, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621197937, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5136.614379089732, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621197963, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621197963, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621197980, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621198416, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8785170316696167, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621198417, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621198618, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5131.5886707041045, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621198618, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621198618, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5131.5886707041045, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621198643, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621198643, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621198660, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621199101, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8920538425445557, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621199102, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621199298, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5134.076915370506, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621199298, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621199298, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5134.076915370506, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621199324, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621199324, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621199341, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621199778, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8928595781326294, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621199779, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621199976, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5155.095701069547, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621199976, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621199976, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5155.095701069547, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621200047, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621200047, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621200062, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621200501, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8914016485214233, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621200501, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621200710, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5070.022049578273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621200710, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621200710, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5070.022049578273, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621200784, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621200784, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621200799, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621201207, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9023876190185547, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621201207, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621201408, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.080564032, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621201408, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621201408, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.080564032, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621201434, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621201434, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621201451, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621201889, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8568128347396851, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621201889, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621202085, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5160.972600030762, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621202085, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621202085, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5160.972600030762, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621202114, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621202114, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621202131, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621202565, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9002622365951538, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621202565, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621202764, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5171.310828082039, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621202764, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621202764, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5171.310828082039, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621202791, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621202792, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621202810, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621203248, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.900538444519043, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621203248, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621203443, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5160.940470073905, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621203443, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621203443, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5160.940470073905, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621203472, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621203473, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621203490, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621203925, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8926370739936829, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621203926, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621204117, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5214.682303836953, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621204117, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621204117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5214.682303836953, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621204146, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621204146, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621204163, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621204587, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8794986605644226, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621204587, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621204785, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5258.932657162209, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621204785, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621204785, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5258.932657162209, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621204811, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621204811, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621204828, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621205264, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8901584148406982, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621205264, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621205450, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5258.218426593347, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621205450, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621205451, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5258.218426593347, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621205475, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621205475, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621205491, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621205930, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8669204711914062, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621205930, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621206123, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5189.681899163117, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621206123, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621206123, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5189.681899163117, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621206149, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621206149, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621206166, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621206601, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8520075082778931, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621206601, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621206802, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5153.176765610242, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621206802, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621206802, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5153.176765610242, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621206826, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621206827, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621206844, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621207284, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8903586864471436, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621207285, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621207473, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5198.505111686146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621207473, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621207473, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5198.505111686146, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621207498, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621207498, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621207515, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621207958, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9004334807395935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621207958, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621208156, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5106.645785245551, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621208156, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621208156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5106.645785245551, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621208180, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621208180, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621208197, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621208643, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8923704028129578, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621208643, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621208846, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5046.791136067382, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621208846, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621208847, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5046.791136067382, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621208871, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621208871, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621208888, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621209332, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9001961350440979, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621209332, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621209524, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5144.157343481826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621209525, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621209525, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5144.157343481826, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621209582, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621209583, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621209598, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621210011, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9032939672470093, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621210011, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621210214, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5320.399889007809, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621210214, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621210215, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5320.399889007809, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621210239, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621210239, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621210257, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621210708, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9001990556716919, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621210708, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621210903, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5061.322018960481, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621210903, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621210904, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5061.322018960481, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621210931, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621210931, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621210947, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621211385, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8966635465621948, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621211385, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621211575, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5215.512143310493, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621211575, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621211576, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5215.512143310493, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621211600, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621211601, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621211617, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621212060, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.902313232421875, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621212061, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621212289, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4883.880278085533, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621212289, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621212289, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4883.880278085533, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621212314, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621212314, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621212331, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621212774, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.894134521484375, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621212774, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621212981, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5038.033699711221, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621212981, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621212981, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5038.033699711221, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621213006, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621213006, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621213023, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621213467, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8994519710540771, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621213467, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621213670, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5059.9754413025585, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621213670, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621213670, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5059.9754413025585, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621213695, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621213695, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621213712, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621214155, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8701696991920471, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621214155, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621214353, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5105.099295574137, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621214353, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621214353, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5105.099295574137, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621214379, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621214379, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621214396, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621214840, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9057902097702026, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621214840, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621215039, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5096.672985884829, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621215039, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621215039, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5096.672985884829, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621215063, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621215064, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621215081, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621215520, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8988207578659058, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621215520, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621215711, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5190.543946214932, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621215711, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621215711, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5190.543946214932, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621215736, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621215736, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621215754, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621216195, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9043256044387817, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621216195, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621216394, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5112.516534308758, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621216394, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621216394, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5112.516534308758, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621216420, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621216420, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621216436, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621216876, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9064664244651794, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621216876, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621217069, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5175.506002221086, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621217069, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621217069, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5175.506002221086, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621217094, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621217094, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621217111, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621217553, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8996862173080444, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621217553, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621217744, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5170.098553106565, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621217745, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621217745, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5170.098553106565, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621217769, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621217769, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621217787, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621218232, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8983041644096375, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621218232, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621218429, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5092.518098437286, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621218430, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621218430, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5092.518098437286, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621218454, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621218454, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621218472, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621218913, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8964149951934814, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621218913, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621219108, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5137.606842529873, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621219109, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621219109, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5137.606842529873, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621219134, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621219135, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621219151, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621219594, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8941196203231812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621219594, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621219796, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5083.6949118181465, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621219796, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621219796, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5083.6949118181465, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621219820, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621219821, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621219837, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621220282, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8841676712036133, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621220282, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621220475, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5138.361745973641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621220475, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621220475, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5138.361745973641, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621220501, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621220501, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621220518, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621220964, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.891261875629425, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621220964, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621221165, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5067.595491654728, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621221165, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621221165, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5067.595491654728, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621221190, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621221190, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621221207, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621221649, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8996286392211914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621221649, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621221854, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5063.768043870851, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621221854, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621221854, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5063.768043870851, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621221881, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621221881, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621221898, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621222339, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8793818950653076, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621222339, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621222542, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5084.190094949347, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621222542, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621222542, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5084.190094949347, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621222567, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621222567, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621222583, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621223029, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8957076072692871, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621223029, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621223231, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5060.698615251695, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621223231, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621223231, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5060.698615251695, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621223257, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621223257, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621223275, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621223716, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.894534707069397, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621223716, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621223913, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5127.8617555922, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621223913, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621223913, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5127.8617555922, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621223964, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621223964, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621223980, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621224409, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8939206600189209, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621224409, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621224608, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5225.678807259437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621224608, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621224608, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5225.678807259437, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621224634, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621224634, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621224652, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621225086, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8948479294776917, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621225086, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621225275, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5242.546489788038, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621225275, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621225275, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5242.546489788038, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621225300, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621225300, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621225317, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621225756, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8989402651786804, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621225757, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621225950, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5172.487600845781, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621225950, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621225950, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5172.487600845781, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621225975, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621225976, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621225993, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621226433, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9036446809768677, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621226433, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621226622, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5203.311218520174, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621226622, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621226622, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5203.311218520174, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621226649, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621226650, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621226667, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621227108, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9030660390853882, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621227108, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621227301, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5162.384823252609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621227301, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621227301, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5162.384823252609, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621227327, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621227327, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621227343, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621227787, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9029253125190735, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621227787, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621227979, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5156.572632903889, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621227979, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621227979, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5156.572632903889, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634621228003, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621228003, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621228021, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621228463, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8933519124984741, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621228463, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621228663, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5098.100028361241, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621228663, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621228663, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5098.100028361241, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634621228691, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621228691, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621228707, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621229133, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8965089321136475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621229133, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621229327, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5279.937777571302, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621229328, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621229328, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5279.937777571302, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634621229354, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621229354, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621229371, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621229801, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9067903757095337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621229801, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621229991, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5275.360362350035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621229992, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621229992, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5275.360362350035, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634621230016, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621230016, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621230033, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621230477, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.90418541431427, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621230477, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621230674, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5107.982144177503, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621230675, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621230675, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5107.982144177503, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634621230699, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621230699, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621230716, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621231162, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9050828218460083, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621231162, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621231362, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5076.247638889489, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621231362, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621231362, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5076.247638889489, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634621231386, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621231387, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621231403, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634621231845, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8735707998275757, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634621231845, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634621232046, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5098.352701813436, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621232046, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621232046, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5098.352701813436, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634621232071, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621232072, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621232088, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634621232531, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8958032727241516, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634621232531, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634621232732, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5089.645321221787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621232732, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621232732, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5089.645321221787, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634621232757, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621232757, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621232775, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634621233210, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9044407606124878, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634621233210, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634621233407, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5169.15037742908, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621233408, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621233408, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5169.15037742908, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634621233433, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621233433, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621233449, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634621233889, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9043300151824951, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634621233890, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634621234081, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5187.191027282251, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621234082, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621234082, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5187.191027282251, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634621234107, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621234107, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621234124, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634621234565, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9046217203140259, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634621234565, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634621234760, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5151.758275502058, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621234760, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621234760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5151.758275502058, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634621234784, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621234785, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621234802, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634621235239, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8976155519485474, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634621235239, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634621235438, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5144.887877724749, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621235438, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621235438, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5144.887877724749, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634621235472, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621235472, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621235488, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634621235925, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.908566951751709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634621235925, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634621235925, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634621236118, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5200.243037092824, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621236119, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621236119, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5200.243037092824, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2240}}
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:22 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:23 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:25 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:26 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:27 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:29 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:30 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:31 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:32 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:33 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:34 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
ENDING TIMING RUN AT 2021-10-19 05:27:35 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:23:53 AM
