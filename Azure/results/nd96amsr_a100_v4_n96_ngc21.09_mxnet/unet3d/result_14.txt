+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019062717788481022
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019062717788481022
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019062717788481022
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019062717788481022
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07373/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347/unet3d_96x8x1_211019062717788481022_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C0409
Clearing cache on ip-0A0C040B
Clearing cache on ip-0A0C041B
Clearing cache on ip-0A0C043F
Clearing cache on ip-0A0C041C
Clearing cache on ip-0A0C041D
Clearing cache on ip-0A0C0418
Clearing cache on ip-0A0C0410
Clearing cache on ip-0A0C044B
Clearing cache on ip-0A0C0416
Clearing cache on ip-0A0C041E
Clearing cache on ip-0A0C0518
Clearing cache on ip-0A0C0413
Clearing cache on ip-0A0C0423
Clearing cache on ip-0A0C0411
Clearing cache on ip-0A0C043D
Clearing cache on ip-0A0C040C
Clearing cache on ip-0A0C0445
Clearing cache on ip-0A0C040A
Clearing cache on ip-0A0C041F
Clearing cache on ip-0A0C0412
Clearing cache on ip-0A0C040E
Clearing cache on ip-0A0C0408
Clearing cache on ip-0A0C0426
Clearing cache on ip-0A0C0424
Clearing cache on ip-0A0C045A
Clearing cache on ip-0A0C0421
Clearing cache on ip-0A0C0414
Clearing cache on ip-0A0C0448
Clearing cache on ip-0A0C044E
Clearing cache on ip-0A0C041A
Clearing cache on ip-0A0C0453
Clearing cache on ip-0A0C043B
Clearing cache on ip-0A0C0451
Clearing cache on ip-0A0C0467
Clearing cache on ip-0A0C0457
Clearing cache on ip-0A0C0432
Clearing cache on ip-0A0C044C
Clearing cache on ip-0A0C042F
Clearing cache on ip-0A0C0470
Clearing cache on ip-0A0C0474
Clearing cache on ip-0A0C0422
Clearing cache on ip-0A0C0480
Clearing cache on ip-0A0C0462
Clearing cache on ip-0A0C0479
Clearing cache on ip-0A0C0476
Clearing cache on ip-0A0C0481
Clearing cache on ip-0A0C0446
Clearing cache on ip-0A0C0454
Clearing cache on ip-0A0C047C
Clearing cache on ip-0A0C0450
Clearing cache on ip-0A0C0458
Clearing cache on ip-0A0C0452
Clearing cache on ip-0A0C043A
Clearing cache on ip-0A0C047A
Clearing cache on ip-0A0C0471
Clearing cache on ip-0A0C042E
Clearing cache on ip-0A0C043E
Clearing cache on ip-0A0C045C
Clearing cache on ip-0A0C0434
Clearing cache on ip-0A0C0456
Clearing cache on ip-0A0C0440
Clearing cache on ip-0A0C047D
Clearing cache on ip-0A0C045D
Clearing cache on ip-0A0C0463
Clearing cache on ip-0A0C042B
Clearing cache on ip-0A0C046A
Clearing cache on ip-0A0C0428
Clearing cache on ip-0A0C044F
Clearing cache on ip-0A0C044A
Clearing cache on ip-0A0C0433
Clearing cache on ip-0A0C0419
Clearing cache on ip-0A0C047B
Clearing cache on ip-0A0C0477
Clearing cache on ip-0A0C043C
Clearing cache on ip-0A0C0465
Clearing cache on ip-0A0C0417
Clearing cache on ip-0A0C0475
Clearing cache on ip-0A0C0442
Clearing cache on ip-0A0C042A
Clearing cache on ip-0A0C046D
Clearing cache on ip-0A0C0469
Clearing cache on ip-0A0C0427
Clearing cache on ip-0A0C042C
Clearing cache on ip-0A0C0439
Clearing cache on ip-0A0C0431
Clearing cache on ip-0A0C0420
Clearing cache on ip-0A0C0407
Clearing cache on ip-0A0C0425
Clearing cache on ip-0A0C047F
Clearing cache on ip-0A0C0447
Clearing cache on ip-0A0C045B
Clearing cache on ip-0A0C045E
Clearing cache on ip-0A0C0430
Clearing cache on ip-0A0C0455
Clearing cache on ip-0A0C0459
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051347:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:27:20 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634624845.761140] [ip-0A0C040E:69080:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.793784] [ip-0A0C0409:49196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.801462] [ip-0A0C0409:49203:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.853306] [ip-0A0C043C:67155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.859537] [ip-0A0C040E:69076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.873781] [ip-0A0C0474:46853:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.874786] [ip-0A0C0481:50808:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.875369] [ip-0A0C0410:97404:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.883174] [ip-0A0C040E:69079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.891612] [ip-0A0C040A:82342:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.894019] [ip-0A0C0445:71436:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.896070] [ip-0A0C0453:66761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.901463] [ip-0A0C0410:97413:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.909095] [ip-0A0C0463:55638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.913735] [ip-0A0C043C:67157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.918098] [ip-0A0C040E:69077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.920855] [ip-0A0C040A:82340:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.926961] [ip-0A0C0408:7889 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.934020] [ip-0A0C0463:55640:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.936343] [ip-0A0C043C:67156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.936234] [ip-0A0C0409:49198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.937308] [ip-0A0C040E:69082:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.939366] [ip-0A0C0453:66757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.943367] [ip-0A0C040E:69078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.942056] [ip-0A0C042E:80047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.946139] [ip-0A0C042A:71355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.947661] [ip-0A0C0409:49200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.948693] [ip-0A0C040E:69075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.951753] [ip-0A0C0445:71432:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.954444] [ip-0A0C0445:71459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.965603] [ip-0A0C0442:60509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.968001] [ip-0A0C0474:46854:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.969241] [ip-0A0C042A:71354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.968683] [ip-0A0C0409:49201:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.969021] [ip-0A0C0409:49199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.970642] [ip-0A0C0463:55639:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.971348] [ip-0A0C040E:69081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.972424] [ip-0A0C043B:66523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.973008] [ip-0A0C0459:61045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.974260] [ip-0A0C0451:63594:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.974487] [ip-0A0C0434:69630:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.975070] [ip-0A0C047D:53107:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.976276] [ip-0A0C0467:51225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.977160] [ip-0A0C047D:53110:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.980574] [ip-0A0C0474:46880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.983913] [ip-0A0C043C:67159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.984006] [ip-0A0C0445:71435:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.984051] [ip-0A0C0409:49197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.985040] [ip-0A0C0409:49195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.988207] [ip-0A0C047C:62737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.990899] [ip-0A0C0469:50472:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.991462] [ip-0A0C0459:61048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.993008] [ip-0A0C0481:50806:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.993372] [ip-0A0C0481:50805:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.995433] [ip-0A0C0407:85562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.995964] [ip-0A0C040A:82336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624845.997580] [ip-0A0C046D:49629:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.000006] [ip-0A0C0440:60128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.000631] [ip-0A0C042E:80042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.003224] [ip-0A0C0442:60504:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.004342] [ip-0A0C040B:27038:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.004381] [ip-0A0C040B:27042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.005353] [ip-0A0C0457:61118:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.005705] [ip-0A0C043A:66338:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.007710] [ip-0A0C047C:62730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.009982] [ip-0A0C041D:77425:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.010855] [ip-0A0C0474:46856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.011357] [ip-0A0C0451:63598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.014409] [ip-0A0C043F:61790:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.015909] [ip-0A0C040A:82337:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.016588] [ip-0A0C0416:68071:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.017508] [ip-0A0C0426:79529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.014393] [ip-0A0C042E:80046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.020195] [ip-0A0C042A:71353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.020877] [ip-0A0C0481:50810:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.021722] [ip-0A0C041F:84877:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.024560] [ip-0A0C0419:85436:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.024936] [ip-0A0C047B:59270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.024969] [ip-0A0C047B:59266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.025279] [ip-0A0C0453:66754:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.025848] [ip-0A0C041D:77423:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.026073] [ip-0A0C0414:97424:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.026079] [ip-0A0C043C:67153:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.026879] [ip-0A0C0425:83985:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.026877] [ip-0A0C0425:83979:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.028938] [ip-0A0C0469:50474:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.032318] [ip-0A0C046D:49622:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.033530] [ip-0A0C0471:50552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.035132] [ip-0A0C041B:969  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.034455] [ip-0A0C043A:66339:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.038060] [ip-0A0C041F:84881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.039903] [ip-0A0C0440:60126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.041287] [ip-0A0C043E:54764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.041260] [ip-0A0C0474:46855:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.041852] [ip-0A0C0469:50475:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.042849] [ip-0A0C0410:97405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.043428] [ip-0A0C0410:97406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.044442] [ip-0A0C0463:55643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.045213] [ip-0A0C0414:97435:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.046501] [ip-0A0C0457:61121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.047076] [ip-0A0C0432:9183 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.047590] [ip-0A0C0434:69627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.048786] [ip-0A0C045E:62495:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.048927] [ip-0A0C0407:85566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.050676] [ip-0A0C047F:56084:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.050525] [ip-0A0C0434:69628:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.051542] [ip-0A0C0465:53074:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.052276] [ip-0A0C047C:62733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.053565] [ip-0A0C0467:51227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.054040] [ip-0A0C0481:50807:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.054772] [ip-0A0C0451:63595:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.055083] [ip-0A0C0467:51222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.054638] [ip-0A0C0410:97401:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.055913] [ip-0A0C0481:50809:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.058624] [ip-0A0C0474:46857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.058731] [ip-0A0C0410:97400:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.059017] [ip-0A0C0477:57596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.061003] [ip-0A0C0453:66760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.065117] [ip-0A0C0426:79500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.065629] [ip-0A0C0518:79661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.065795] [ip-0A0C043C:67154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.066437] [ip-0A0C0465:53072:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.066506] [ip-0A0C0447:67765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.067269] [ip-0A0C042A:71350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.067811] [ip-0A0C0408:7893 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.067310] [ip-0A0C043B:66524:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.068055] [ip-0A0C0408:7895 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.069141] [ip-0A0C043C:67158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.069173] [ip-0A0C043D:57134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.070017] [ip-0A0C043E:54760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.071910] [ip-0A0C040C:93542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.071488] [ip-0A0C0421:82872:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.072081] [ip-0A0C041E:80823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.071791] [ip-0A0C0427:77806:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.072432] [ip-0A0C043C:67152:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.072482] [ip-0A0C047D:53109:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.073850] [ip-0A0C0413:15471:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.075785] [ip-0A0C0481:50811:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.075579] [ip-0A0C0457:61117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.077145] [ip-0A0C0421:82874:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.078002] [ip-0A0C0412:60366:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.078867] [ip-0A0C044A:60027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.078932] [ip-0A0C0412:60364:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.080081] [ip-0A0C0450:36625:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.079126] [ip-0A0C0442:60507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.080729] [ip-0A0C0410:97403:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.081265] [ip-0A0C0459:61043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.081551] [ip-0A0C040A:82338:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.081621] [ip-0A0C040A:82339:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.082170] [ip-0A0C040A:82341:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.082440] [ip-0A0C0410:97402:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.083627] [ip-0A0C045E:62471:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.083605] [ip-0A0C0481:50812:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.083330] [ip-0A0C0474:46851:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.083708] [ip-0A0C043F:61793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.084249] [ip-0A0C0407:85560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.084213] [ip-0A0C044C:62935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.084294] [ip-0A0C0445:71430:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.084406] [ip-0A0C0477:57597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.084354] [ip-0A0C0420:82028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.084800] [ip-0A0C0445:71429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.084363] [ip-0A0C0420:82043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.084083] [ip-0A0C0442:60532:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.085667] [ip-0A0C044A:60028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.085547] [ip-0A0C0408:7892 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.086446] [ip-0A0C0457:61122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.086993] [ip-0A0C0420:82031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.087442] [ip-0A0C040A:82357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.088880] [ip-0A0C0474:46852:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.090434] [ip-0A0C043D:57135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.092486] [ip-0A0C0445:71431:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.092568] [ip-0A0C0452:64704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.094301] [ip-0A0C0418:77711:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.096032] [ip-0A0C0518:79657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.096980] [ip-0A0C0446:68852:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.096206] [ip-0A0C0427:77807:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.097400] [ip-0A0C0467:51226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.097351] [ip-0A0C042F:76079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.098719] [ip-0A0C0463:55641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.098683] [ip-0A0C0453:66755:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.099813] [ip-0A0C0418:77709:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.099898] [ip-0A0C043B:66521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.100753] [ip-0A0C045C:61734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.101561] [ip-0A0C0447:67760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.101153] [ip-0A0C0413:15470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.102775] [ip-0A0C0445:71433:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.102993] [ip-0A0C0459:61049:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.103406] [ip-0A0C0440:60122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.104280] [ip-0A0C046D:49630:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.105444] [ip-0A0C046D:49627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.105430] [ip-0A0C044F:58779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.102568] [ip-0A0C042E:80045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.106434] [ip-0A0C041F:84878:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.107141] [ip-0A0C041E:80824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.106408] [ip-0A0C043B:66522:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.108076] [ip-0A0C044A:60025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.108086] [ip-0A0C0453:66759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.108674] [ip-0A0C0426:79499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.109006] [ip-0A0C0470:45865:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.109607] [ip-0A0C041E:80827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.109465] [ip-0A0C0453:66756:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.110222] [ip-0A0C045B:68950:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.109688] [ip-0A0C041A:6984 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.111546] [ip-0A0C0426:79504:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.110810] [ip-0A0C0442:60510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.112685] [ip-0A0C0411:80780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.113030] [ip-0A0C0453:66758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.113821] [ip-0A0C0463:55644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.115161] [ip-0A0C043A:66342:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.116019] [ip-0A0C044F:58776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.116301] [ip-0A0C0463:55642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.116398] [ip-0A0C0471:50547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.118063] [ip-0A0C0417:14165:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.119270] [ip-0A0C0411:80777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.118877] [ip-0A0C042F:76085:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.120388] [ip-0A0C0408:7890 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.121171] [ip-0A0C0480:52006:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.119916] [ip-0A0C042E:80048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.123438] [ip-0A0C0463:55637:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.125548] [ip-0A0C0439:58073:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.126213] [ip-0A0C047A:57677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.126324] [ip-0A0C0416:68074:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.126398] [ip-0A0C0419:85441:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.126587] [ip-0A0C0419:85438:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.127283] [ip-0A0C0451:63599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.127600] [ip-0A0C041B:965  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.127568] [ip-0A0C044E:58156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.127438] [ip-0A0C0462:92563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.129568] [ip-0A0C042B:78861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.129990] [ip-0A0C042A:71357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.129820] [ip-0A0C0467:51249:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.130530] [ip-0A0C0518:79658:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.131261] [ip-0A0C0433:74986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.132090] [ip-0A0C0417:14166:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.133699] [ip-0A0C0428:69646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.134706] [ip-0A0C0416:68069:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.135273] [ip-0A0C047F:56085:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.136078] [ip-0A0C041D:77426:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.136764] [ip-0A0C0479:53449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.136718] [ip-0A0C0479:53447:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.137338] [ip-0A0C0423:74557:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.138397] [ip-0A0C045B:68944:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.138502] [ip-0A0C0408:7894 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.138846] [ip-0A0C043A:66340:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.140688] [ip-0A0C042A:71352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.140959] [ip-0A0C045A:65085:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.139151] [ip-0A0C042E:80041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.142369] [ip-0A0C0455:59754:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.143875] [ip-0A0C042A:71351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.143186] [ip-0A0C047D:53104:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.142022] [ip-0A0C042E:80043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.144724] [ip-0A0C040B:27040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.146508] [ip-0A0C0431:71324:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.146037] [ip-0A0C0434:69631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.146322] [ip-0A0C0475:47391:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.146299] [ip-0A0C0475:47395:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.147083] [ip-0A0C043F:61788:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.146550] [ip-0A0C0442:60511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.148332] [ip-0A0C0428:69653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.149062] [ip-0A0C0452:64700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.149270] [ip-0A0C0408:7891 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.149323] [ip-0A0C041B:964  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.150100] [ip-0A0C040B:27037:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.151372] [ip-0A0C042A:71356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.150961] [ip-0A0C0469:50477:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.152306] [ip-0A0C042C:74199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.151735] [ip-0A0C043B:66525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.152293] [ip-0A0C042C:74202:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.153500] [ip-0A0C0423:74553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.152969] [ip-0A0C0459:61047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.153982] [ip-0A0C0452:64706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.153860] [ip-0A0C045C:61741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.154810] [ip-0A0C045E:62473:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.154591] [ip-0A0C043F:61789:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.154892] [ip-0A0C047C:62732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.154738] [ip-0A0C041F:84874:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.155224] [ip-0A0C0456:68734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.154783] [ip-0A0C047D:53106:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.155279] [ip-0A0C0456:68735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.154822] [ip-0A0C047D:53126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.155839] [ip-0A0C044B:64302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.154846] [ip-0A0C0442:60506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.156708] [ip-0A0C0450:36623:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.156568] [ip-0A0C041A:6988 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.157709] [ip-0A0C0425:83978:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.155886] [ip-0A0C042E:80044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.159359] [ip-0A0C0432:9180 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.159401] [ip-0A0C0442:60505:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.160920] [ip-0A0C0419:85440:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.160736] [ip-0A0C043E:54762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.161600] [ip-0A0C0408:7896 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.162389] [ip-0A0C047C:62731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.162701] [ip-0A0C0407:85563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.162966] [ip-0A0C0475:47389:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.163266] [ip-0A0C0451:63593:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.163694] [ip-0A0C047B:59273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.164025] [ip-0A0C047B:59271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.164487] [ip-0A0C0423:74558:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.164789] [ip-0A0C045D:52369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.164780] [ip-0A0C045D:52367:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.164951] [ip-0A0C0440:60125:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.165313] [ip-0A0C0416:68072:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.164991] [ip-0A0C0434:69633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.166092] [ip-0A0C0471:50549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.166115] [ip-0A0C043A:66337:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.166371] [ip-0A0C047D:53103:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.167901] [ip-0A0C0426:79498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.167474] [ip-0A0C0420:82029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.168518] [ip-0A0C0454:65553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.168948] [ip-0A0C0476:41073:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.169865] [ip-0A0C041D:77421:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.170318] [ip-0A0C045E:62472:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.170036] [ip-0A0C0448:73186:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.170619] [ip-0A0C046D:49623:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.170203] [ip-0A0C042F:76082:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.170603] [ip-0A0C0457:61116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.171036] [ip-0A0C0430:16937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.171527] [ip-0A0C0414:97422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.172188] [ip-0A0C0459:61046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.172664] [ip-0A0C047B:59272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.172958] [ip-0A0C0459:61044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.173030] [ip-0A0C0459:61042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.173211] [ip-0A0C044E:58157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.173912] [ip-0A0C047D:53105:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.176509] [ip-0A0C0454:65549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.176894] [ip-0A0C041F:84879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.176732] [ip-0A0C040B:27044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.177335] [ip-0A0C0420:82027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.178029] [ip-0A0C0451:63592:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.178036] [ip-0A0C0451:63596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.178689] [ip-0A0C041D:77427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.178673] [ip-0A0C0440:60121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.179362] [ip-0A0C041B:961  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.180467] [ip-0A0C0447:67761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.180749] [ip-0A0C047C:62736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.181561] [ip-0A0C0432:9194 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.180949] [ip-0A0C043B:66526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.181207] [ip-0A0C043B:66528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.183035] [ip-0A0C0432:9208 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.183123] [ip-0A0C0434:69629:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.183222] [ip-0A0C0413:15466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.185008] [ip-0A0C0452:64703:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.185219] [ip-0A0C047C:62735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.185178] [ip-0A0C0467:51221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.185110] [ip-0A0C043F:61786:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.185273] [ip-0A0C047C:62734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.185357] [ip-0A0C0467:51223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.185437] [ip-0A0C0467:51224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.185760] [ip-0A0C043E:54766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.185829] [ip-0A0C0455:59756:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.186726] [ip-0A0C0427:77812:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.187533] [ip-0A0C045C:61736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.187154] [ip-0A0C040B:27041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.187333] [ip-0A0C043B:66527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.188952] [ip-0A0C042B:78866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.189756] [ip-0A0C0425:83984:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.190591] [ip-0A0C0451:63597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.190024] [ip-0A0C043A:66336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.191361] [ip-0A0C0469:50476:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.192612] [ip-0A0C0469:50478:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.192517] [ip-0A0C040B:27043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.193873] [ip-0A0C0470:45866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.194440] [ip-0A0C0419:85434:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.194087] [ip-0A0C0462:92560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.194666] [ip-0A0C043F:61787:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.195751] [ip-0A0C047F:56090:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.195731] [ip-0A0C044B:64326:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.195444] [ip-0A0C0422:13640:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.196210] [ip-0A0C041C:86939:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.196603] [ip-0A0C041D:77424:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.196891] [ip-0A0C040C:93541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.196408] [ip-0A0C0457:61115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.196515] [ip-0A0C0457:61119:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.197287] [ip-0A0C0425:83981:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.197298] [ip-0A0C046D:49626:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.197343] [ip-0A0C046D:49624:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.197563] [ip-0A0C046D:49625:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.198193] [ip-0A0C0425:83982:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.198330] [ip-0A0C045E:62479:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.198071] [ip-0A0C0434:69634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.198346] [ip-0A0C0457:61120:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.199001] [ip-0A0C0418:77706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.199552] [ip-0A0C0471:50551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.199827] [ip-0A0C045C:61738:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.200300] [ip-0A0C044F:58777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.201200] [ip-0A0C0450:36626:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.200961] [ip-0A0C047B:59267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.201979] [ip-0A0C0518:79662:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.202414] [ip-0A0C0477:57601:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.203287] [ip-0A0C047F:56088:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.202898] [ip-0A0C0469:50473:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.203252] [ip-0A0C0416:68070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.202943] [ip-0A0C0477:57603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.202719] [ip-0A0C040B:27039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.203340] [ip-0A0C0434:69632:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.203999] [ip-0A0C0426:79503:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.204033] [ip-0A0C0426:79502:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.204290] [ip-0A0C041F:84880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.204491] [ip-0A0C0440:60129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.204046] [ip-0A0C043A:66341:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.204575] [ip-0A0C041A:6998 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.204117] [ip-0A0C043A:66343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.204782] [ip-0A0C0469:50479:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.205720] [ip-0A0C0470:45864:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.205928] [ip-0A0C0470:45861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.206331] [ip-0A0C0440:60123:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.207755] [ip-0A0C0446:68855:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.206860] [ip-0A0C0424:69572:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.207442] [ip-0A0C044A:60029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.208038] [ip-0A0C0416:68067:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.207916] [ip-0A0C043F:61792:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.209689] [ip-0A0C043F:61791:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.209593] [ip-0A0C0440:60130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.210769] [ip-0A0C0419:85439:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.210828] [ip-0A0C0419:85435:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.211125] [ip-0A0C0414:97421:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.211741] [ip-0A0C0407:85564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.212715] [ip-0A0C0407:85561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.212765] [ip-0A0C0430:16942:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.212704] [ip-0A0C044C:62941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.213705] [ip-0A0C0480:52007:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.214624] [ip-0A0C0446:68857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.214166] [ip-0A0C0425:83980:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.214185] [ip-0A0C0439:58077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.214374] [ip-0A0C0419:85437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.214875] [ip-0A0C040C:93539:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.215226] [ip-0A0C044C:62939:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.214957] [ip-0A0C0412:60361:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.216153] [ip-0A0C047B:59269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.216283] [ip-0A0C047B:59268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.216850] [ip-0A0C0431:71325:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.216855] [ip-0A0C0471:50553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.217859] [ip-0A0C041E:80825:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.217895] [ip-0A0C0414:97423:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.217854] [ip-0A0C043E:54763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.218296] [ip-0A0C041B:962  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.219740] [ip-0A0C0439:58071:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.219893] [ip-0A0C044B:64298:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.221074] [ip-0A0C0465:53078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.221454] [ip-0A0C0426:79506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.222139] [ip-0A0C0425:83983:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.222556] [ip-0A0C0412:60362:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.223548] [ip-0A0C0427:77811:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.224608] [ip-0A0C0416:68068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.224581] [ip-0A0C0413:15465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.225701] [ip-0A0C041F:84876:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.226174] [ip-0A0C0407:85567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.225907] [ip-0A0C041A:6987 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.226498] [ip-0A0C041F:84875:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.228633] [ip-0A0C0432:9181 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.228642] [ip-0A0C0407:85565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.228816] [ip-0A0C0416:68073:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.228452] [ip-0A0C0477:57610:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.228789] [ip-0A0C045C:61740:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.229660] [ip-0A0C041B:983  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.229749] [ip-0A0C041D:77428:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.229146] [ip-0A0C0417:14168:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.229719] [ip-0A0C0476:41076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.230805] [ip-0A0C0465:53071:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.232106] [ip-0A0C045A:65081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.232253] [ip-0A0C045A:65084:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.232450] [ip-0A0C041B:967  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.232564] [ip-0A0C041D:77422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.233139] [ip-0A0C0432:9182 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.232828] [ip-0A0C0447:67767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.233389] [ip-0A0C041B:963  :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.234663] [ip-0A0C040C:93537:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.234670] [ip-0A0C0414:97425:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.235327] [ip-0A0C044E:58149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.236200] [ip-0A0C0420:82030:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.236946] [ip-0A0C0456:68736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.237526] [ip-0A0C044A:60044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.238176] [ip-0A0C044F:58783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.238365] [ip-0A0C0450:36627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.237958] [ip-0A0C0421:82877:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.238084] [ip-0A0C0421:82876:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.239477] [ip-0A0C0454:65550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.239087] [ip-0A0C0448:73182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.239481] [ip-0A0C0431:71322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.239817] [ip-0A0C041E:80822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.239553] [ip-0A0C0424:69571:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.240215] [ip-0A0C0433:74983:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.241758] [ip-0A0C047F:56087:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.241627] [ip-0A0C0411:80781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.241292] [ip-0A0C0476:41078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.242275] [ip-0A0C047F:56098:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.241984] [ip-0A0C0447:67766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.241877] [ip-0A0C043D:57138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.244110] [ip-0A0C0421:82875:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.244532] [ip-0A0C044C:62937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.245410] [ip-0A0C047A:57672:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.244949] [ip-0A0C042B:78865:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.245928] [ip-0A0C0456:68730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.245658] [ip-0A0C0471:50554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.246660] [ip-0A0C0412:60363:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.247253] [ip-0A0C0432:9186 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.247741] [ip-0A0C043E:54765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.248519] [ip-0A0C045E:62474:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.248761] [ip-0A0C0414:97428:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.248664] [ip-0A0C0458:69026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.248381] [ip-0A0C0420:82032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.248479] [ip-0A0C0420:82034:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.250077] [ip-0A0C0447:67763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.250269] [ip-0A0C043E:54767:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.250618] [ip-0A0C044A:60026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.250788] [ip-0A0C044A:60030:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.250676] [ip-0A0C0465:53076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.251431] [ip-0A0C0414:97429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.250393] [ip-0A0C046A:56148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.251338] [ip-0A0C0418:77707:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.252556] [ip-0A0C043E:54761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.252698] [ip-0A0C0418:77712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.254141] [ip-0A0C0417:14164:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.255303] [ip-0A0C041E:80820:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.255293] [ip-0A0C045E:62476:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.255381] [ip-0A0C044A:60031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.255593] [ip-0A0C043D:57137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.256447] [ip-0A0C041E:80826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.256704] [ip-0A0C047F:56086:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.256427] [ip-0A0C0447:67762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.256855] [ip-0A0C047F:56089:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.257220] [ip-0A0C0465:53070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.257579] [ip-0A0C0433:74981:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.257247] [ip-0A0C0477:57598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.258262] [ip-0A0C040C:93540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.258518] [ip-0A0C0439:58078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.258202] [ip-0A0C0462:92566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.259710] [ip-0A0C0432:9184 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.259597] [ip-0A0C0413:15469:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.261064] [ip-0A0C045E:62470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.262093] [ip-0A0C041E:80821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.262555] [ip-0A0C045B:68949:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.262977] [ip-0A0C0430:16939:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.262800] [ip-0A0C041C:86941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.263387] [ip-0A0C0518:79655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.263308] [ip-0A0C0475:47388:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.263530] [ip-0A0C0412:60365:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.263684] [ip-0A0C0477:57600:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.264324] [ip-0A0C0450:36621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.265011] [ip-0A0C0428:69648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.264824] [ip-0A0C0475:47390:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.265107] [ip-0A0C0447:67764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.265312] [ip-0A0C0411:80776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.265043] [ip-0A0C0422:13643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.266319] [ip-0A0C047A:57673:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.265688] [ip-0A0C0471:50548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.266194] [ip-0A0C0470:45867:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.265763] [ip-0A0C0427:77810:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.266250] [ip-0A0C0471:50550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.267292] [ip-0A0C042B:78862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.267700] [ip-0A0C0518:79656:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.269144] [ip-0A0C0446:68851:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.268393] [ip-0A0C0413:15468:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.269039] [ip-0A0C0427:77809:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.269922] [ip-0A0C0477:57599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.270966] [ip-0A0C0465:53075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.271173] [ip-0A0C0479:53470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.271435] [ip-0A0C0479:53461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.271565] [ip-0A0C0465:53077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.272766] [ip-0A0C0431:71326:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.273443] [ip-0A0C045B:68946:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.273329] [ip-0A0C0518:79660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.274239] [ip-0A0C044E:58155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.274604] [ip-0A0C043D:57139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.275237] [ip-0A0C044C:62934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.275758] [ip-0A0C047A:57671:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.275380] [ip-0A0C0455:59755:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.275113] [ip-0A0C0421:82871:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.275754] [ip-0A0C0518:79654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.275581] [ip-0A0C0433:75009:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.276318] [ip-0A0C0421:82873:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.276784] [ip-0A0C0421:82878:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.277482] [ip-0A0C0427:77808:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.277647] [ip-0A0C041C:86937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.278204] [ip-0A0C0428:69644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.278375] [ip-0A0C0412:60368:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.279967] [ip-0A0C040C:93544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.279027] [ip-0A0C0413:15467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.279340] [ip-0A0C042F:76080:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.279781] [ip-0A0C0427:77805:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.280522] [ip-0A0C0413:15472:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.281837] [ip-0A0C040C:93538:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.281316] [ip-0A0C041A:6989 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.281924] [ip-0A0C042C:74204:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.282110] [ip-0A0C040C:93543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.281777] [ip-0A0C041C:86938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.281852] [ip-0A0C0418:77713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.283444] [ip-0A0C0480:52005:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.284911] [ip-0A0C0452:64699:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.284670] [ip-0A0C0418:77708:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.284789] [ip-0A0C0418:77710:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.284969] [ip-0A0C0452:64705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.287781] [ip-0A0C0479:53446:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.287716] [ip-0A0C044C:62940:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.288728] [ip-0A0C0412:60367:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.289204] [ip-0A0C0480:52003:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.288549] [ip-0A0C042F:76078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.289261] [ip-0A0C043D:57132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.292545] [ip-0A0C0450:36620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.293130] [ip-0A0C0450:36622:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.293273] [ip-0A0C0450:36624:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.293131] [ip-0A0C0452:64701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.294382] [ip-0A0C0431:71327:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.294574] [ip-0A0C0411:80775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.295320] [ip-0A0C0423:74554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.294788] [ip-0A0C042F:76086:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.295339] [ip-0A0C042B:78864:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.295714] [ip-0A0C043D:57133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.295930] [ip-0A0C044C:62938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.297488] [ip-0A0C0446:68850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.296880] [ip-0A0C0448:73181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.297470] [ip-0A0C045A:65082:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.297932] [ip-0A0C0439:58076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.298679] [ip-0A0C0428:69652:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.297929] [ip-0A0C0462:92564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.299486] [ip-0A0C0446:68856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.299474] [ip-0A0C0446:68853:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.298240] [ip-0A0C044E:58152:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.298854] [ip-0A0C044F:58782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.299299] [ip-0A0C0452:64702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.299701] [ip-0A0C043D:57136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.300122] [ip-0A0C044F:58781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.300110] [ip-0A0C0458:69031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.300515] [ip-0A0C0480:52008:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.300852] [ip-0A0C0424:69577:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.300706] [ip-0A0C0417:14169:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.301114] [ip-0A0C044E:58148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.301902] [ip-0A0C042C:74201:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.301559] [ip-0A0C0475:47394:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.301550] [ip-0A0C0475:47392:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.301481] [ip-0A0C044E:58161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.302349] [ip-0A0C044F:58778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.302544] [ip-0A0C045A:65086:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.302531] [ip-0A0C0417:14171:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.303644] [ip-0A0C044F:58780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.303764] [ip-0A0C0455:59751:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.303966] [ip-0A0C045C:61764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.305071] [ip-0A0C0470:45863:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.304774] [ip-0A0C0475:47393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.305353] [ip-0A0C045C:61735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.306045] [ip-0A0C045B:68947:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.305739] [ip-0A0C042B:78859:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.307624] [ip-0A0C0446:68854:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.306807] [ip-0A0C041A:6986 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.307682] [ip-0A0C045C:61737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.307405] [ip-0A0C044E:58150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.308126] [ip-0A0C042F:76084:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.308699] [ip-0A0C045D:52374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.308392] [ip-0A0C042F:76081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.309058] [ip-0A0C045D:52372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.309759] [ip-0A0C0430:16938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.310603] [ip-0A0C045D:52371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.310482] [ip-0A0C0424:69573:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.310826] [ip-0A0C044C:62936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.310489] [ip-0A0C041A:6990 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.312135] [ip-0A0C0454:65552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.312623] [ip-0A0C0423:74559:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.312610] [ip-0A0C0458:69027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.313012] [ip-0A0C0470:45862:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.312904] [ip-0A0C0439:58072:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.313363] [ip-0A0C0470:45886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.313467] [ip-0A0C041A:6985 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.314305] [ip-0A0C0454:65554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.314463] [ip-0A0C0411:80774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.315367] [ip-0A0C042C:74200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.315401] [ip-0A0C0411:80779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.316599] [ip-0A0C041C:86942:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.317524] [ip-0A0C0456:68733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.317620] [ip-0A0C045A:65088:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.317702] [ip-0A0C0411:80778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.318040] [ip-0A0C045B:68945:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.318253] [ip-0A0C045B:68951:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.318453] [ip-0A0C0455:59753:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.318987] [ip-0A0C047A:57676:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.318954] [ip-0A0C0480:52004:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.319085] [ip-0A0C0456:68731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.320031] [ip-0A0C0428:69647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.320178] [ip-0A0C0433:74984:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.320018] [ip-0A0C0476:41077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.322706] [ip-0A0C0448:73185:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.323277] [ip-0A0C0479:53448:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.324541] [ip-0A0C0479:53444:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.324781] [ip-0A0C0479:53445:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.325370] [ip-0A0C0423:74556:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.325028] [ip-0A0C0422:13644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.325957] [ip-0A0C042C:74203:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.325684] [ip-0A0C0417:14167:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.325851] [ip-0A0C0417:14178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.326714] [ip-0A0C042C:74197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.326937] [ip-0A0C044B:64297:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.327391] [ip-0A0C045A:65087:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.327229] [ip-0A0C0462:92565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.328092] [ip-0A0C0433:74982:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.330264] [ip-0A0C044B:64299:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.330781] [ip-0A0C0480:52010:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.331160] [ip-0A0C045B:68948:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.331386] [ip-0A0C0423:74560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.332376] [ip-0A0C0433:74985:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.332653] [ip-0A0C0433:74980:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.332727] [ip-0A0C0430:16940:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.332169] [ip-0A0C046A:56144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.334814] [ip-0A0C0448:73183:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.335003] [ip-0A0C0455:59758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.335215] [ip-0A0C0455:59752:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.335919] [ip-0A0C0428:69649:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.336561] [ip-0A0C0428:69645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.336966] [ip-0A0C042C:74198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.337836] [ip-0A0C0448:73187:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.338889] [ip-0A0C047A:57674:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.338970] [ip-0A0C047A:57700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.342439] [ip-0A0C0431:71321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.342612] [ip-0A0C0431:71320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.342034] [ip-0A0C0462:92562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.342077] [ip-0A0C0462:92561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.342535] [ip-0A0C0462:92567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.343173] [ip-0A0C042B:78871:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.343470] [ip-0A0C042B:78863:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.344043] [ip-0A0C0480:52009:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.344867] [ip-0A0C0439:58075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.344936] [ip-0A0C0439:58074:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.346202] [ip-0A0C0431:71323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.346476] [ip-0A0C0423:74555:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.347219] [ip-0A0C045A:65083:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.350306] [ip-0A0C044B:64301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.351300] [ip-0A0C047A:57675:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.351403] [ip-0A0C0476:41080:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.352928] [ip-0A0C0455:59757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.353599] [ip-0A0C0456:68737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.353885] [ip-0A0C0456:68732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.356427] [ip-0A0C045D:52373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.357308] [ip-0A0C0476:41075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.357622] [ip-0A0C044B:64300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.359101] [ip-0A0C044B:64303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.360911] [ip-0A0C045D:52370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.361047] [ip-0A0C0476:41079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.363199] [ip-0A0C0454:65555:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.362955] [ip-0A0C041C:86943:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.363350] [ip-0A0C0454:65551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.364169] [ip-0A0C045D:52368:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.364081] [ip-0A0C0476:41074:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.363352] [ip-0A0C046A:56145:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.364485] [ip-0A0C0422:13646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.364981] [ip-0A0C041C:86940:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.365110] [ip-0A0C0448:73180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.367597] [ip-0A0C0454:65548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.372292] [ip-0A0C0448:73184:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.373515] [ip-0A0C041C:86952:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.374730] [ip-0A0C0424:69574:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.377498] [ip-0A0C046A:56151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.380428] [ip-0A0C0430:16946:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.384616] [ip-0A0C0424:69599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.388376] [ip-0A0C0424:69580:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.389678] [ip-0A0C0430:16941:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.390059] [ip-0A0C0430:16943:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.393701] [ip-0A0C0422:13662:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.395903] [ip-0A0C0424:69575:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.399882] [ip-0A0C0458:69025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.400589] [ip-0A0C0422:13639:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.402740] [ip-0A0C0422:13642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.405198] [ip-0A0C0458:69032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.407922] [ip-0A0C0422:13641:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.427615] [ip-0A0C046A:56149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.427780] [ip-0A0C046A:56147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.428353] [ip-0A0C046A:56146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.429592] [ip-0A0C0458:69030:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.445851] [ip-0A0C0458:69029:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.445811] [ip-0A0C046A:56150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634624846.456053] [ip-0A0C0458:69028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634624847367, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634624847408, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634624847409, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634624847409, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634624847409, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634624847409, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634624847409, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:27:39] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0409:0:49198 - context.c:584] INFO job (ID: 867538643521833107) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:49198 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:49198 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:49195 - context.c:584] INFO job (ID: 867538301766782044) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:49195 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:49195 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:49196 - context.c:584] INFO job (ID: 867538608434056284) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:49196 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:49196 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:49199 - context.c:584] INFO job (ID: 867538381716159466) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:49199 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:49199 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:49201 - context.c:584] INFO job (ID: 867538175862588245) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:49201 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:49201 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:49203 - context.c:584] INFO job (ID: 867538126936794284) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:49203 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:49203 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:49200 - context.c:584] INFO job (ID: 867537885427997540) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:49200 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:49200 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0409:0:49197 - context.c:584] INFO job (ID: 867538091286173998) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0409:0:49197 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0409:0:49197 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940672, "event_type": "POINT_IN_TIME", "key": "seed", "value": 4149151259, "metadata": {"file": "main.py", "lineno": 72}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940672, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940672, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940672, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940672, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940672, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940673, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940673, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940673, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940673, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940673, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624940673, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:00] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:29:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634624964552, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634624964584, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624964589, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634624964590, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634624967143, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1634624967143, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1634624967143, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634624967144, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634624968631, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2259.6942993026837, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624968631, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624968631, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2259.6942993026837, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634624968631, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624968632, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624969289, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5109.22473377788, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624969290, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624969290, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5109.22473377788, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624969290, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624969290, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624969934, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5216.964032468174, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624969935, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624969935, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5216.964032468174, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634624969935, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624969935, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624970574, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5258.308675790909, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624970575, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624970575, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5258.308675790909, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634624970575, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624970575, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624971213, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5265.847558323581, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624971214, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624971214, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5265.847558323581, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634624971214, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624971214, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624971837, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5396.79920286045, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624971837, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624971837, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5396.79920286045, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634624971837, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624971838, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624972462, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5383.4690540120855, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624972462, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624972462, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5383.4690540120855, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634624972463, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624972463, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624973087, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5386.866451184794, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624973087, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624973087, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5386.866451184794, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634624973087, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624973087, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624973716, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5348.533433121991, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624973716, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624973716, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5348.533433121991, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634624973716, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624973717, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624974336, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5422.811216360097, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624974337, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624974337, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5422.811216360097, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634624974337, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624974337, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624974960, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5398.202843880738, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624974960, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624974960, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5398.202843880738, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634624974960, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624974960, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624975578, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5441.433621231878, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624975578, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624975578, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5441.433621231878, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634624975579, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624975579, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624976196, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5440.4295252268475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624976197, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624976197, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5440.4295252268475, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634624976197, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624976197, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624976820, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5399.7292790583615, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624976820, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624976820, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5399.7292790583615, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634624976820, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624976820, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624977449, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5345.401134709377, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624977450, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624977450, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5345.401134709377, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634624977450, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624977450, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624978078, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5351.139037195585, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624978078, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624978078, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5351.139037195585, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634624978079, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624978079, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624978700, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5407.21881744462, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624978701, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624978701, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5407.21881744462, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634624978701, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624978701, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624979325, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5383.442319857469, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624979326, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624979326, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5383.442319857469, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634624979326, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624979326, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624979950, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5389.476569715303, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624979950, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624979950, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5389.476569715303, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634624979950, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624979951, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624980571, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5417.734977776035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624980571, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624980572, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5417.734977776035, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634624980572, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624980572, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624981195, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5390.125886857112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624981196, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624981196, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5390.125886857112, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634624981196, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624981196, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624981822, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5370.642551318475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624981823, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624981823, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5370.642551318475, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634624981823, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624981823, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624982439, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5453.148791980043, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624982440, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624982440, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5453.148791980043, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634624982440, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624982440, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624983056, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5461.333333333333, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624983056, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624983056, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5461.333333333333, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634624983056, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624983056, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624983683, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5363.941852821854, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624983683, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624983683, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5363.941852821854, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634624983683, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624983684, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624984307, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5387.461591069563, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624984308, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624984308, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5387.461591069563, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634624984308, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624984308, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624984933, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5378.022831158265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624984933, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624984934, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5378.022831158265, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634624984934, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624984934, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624985553, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5424.08228459527, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624985554, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624985554, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5424.08228459527, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634624985554, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624985554, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624986178, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5389.44565375349, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624986178, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624986178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5389.44565375349, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634624986178, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624986178, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624986794, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5462.207547323384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624986794, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624986794, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5462.207547323384, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634624986794, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624986795, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624987415, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5416.421083702266, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624987415, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624987415, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5416.421083702266, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634624987416, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624987416, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624988029, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5478.790012510409, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624988030, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624988030, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5478.790012510409, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634624988030, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624988030, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624988646, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5458.6743111323885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624988646, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624988646, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5458.6743111323885, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634624988646, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624988646, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624989269, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5398.934928651988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624989269, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624989269, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5398.934928651988, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634624989269, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624989270, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624989882, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5483.998435685059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624989883, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624989883, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5483.998435685059, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634624989883, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624989883, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624990504, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5414.598096707601, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624990504, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624990504, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5414.598096707601, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634624990504, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624990505, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624991123, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5434.542652112196, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624991123, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624991123, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5434.542652112196, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634624991124, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624991124, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624991742, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5435.179816244147, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624991742, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624991742, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5435.179816244147, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634624991742, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624991742, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624992372, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5342.4608466517075, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624992372, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624992372, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5342.4608466517075, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634624992372, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624992372, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624992996, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5383.699390034958, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624992997, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624992997, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5383.699390034958, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634624992997, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624992997, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624993619, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5399.077646265566, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624993620, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624993620, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5399.077646265566, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634624993620, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624993620, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624994239, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5426.920857364114, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624994240, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624994240, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5426.920857364114, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634624994240, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624994240, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624994860, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5420.656562470671, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624994860, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624994860, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5420.656562470671, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634624994861, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624994861, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624995486, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5370.35398270556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624995487, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624995487, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5370.35398270556, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634624995487, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624995487, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624996108, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5409.398097307173, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624996109, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624996109, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5409.398097307173, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634624996109, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624996109, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624996729, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5425.023968809944, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624996729, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624996729, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5425.023968809944, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634624996729, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624996729, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624997345, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5460.90585356894, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624997345, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624997345, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5460.90585356894, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634624997345, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624997345, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624997961, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5456.480506432035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624997961, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624997962, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5456.480506432035, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634624997962, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624997962, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624998584, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5400.337611596451, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624998584, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624998584, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5400.337611596451, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634624998585, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624998585, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624999205, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5413.8201632114, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624999206, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624999206, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5413.8201632114, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634624999287, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624999287, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634624999304, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634624999731, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.889785885810852, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634624999731, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634624999911, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5386.798502399486, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634624999912, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634624999912, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5386.798502399486, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625000059, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625000059, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625000074, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625000498, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8750719428062439, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625000498, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625000717, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5106.717952973379, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625000717, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625000717, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5106.717952973379, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625000793, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625000794, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625000809, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625001206, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8726530075073242, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625001206, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625001401, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5536.649950085979, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625001401, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625001401, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5536.649950085979, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625001477, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625001477, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625001492, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625001892, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8516949415206909, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625001892, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625002092, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5463.662368476145, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625002092, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625002092, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5463.662368476145, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625002170, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625002170, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625002186, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625002598, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8778963088989258, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625002598, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625002800, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5334.283180434385, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625002801, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625002801, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5334.283180434385, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625002838, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625002838, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625002854, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625003252, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8943567276000977, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625003253, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625003440, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5576.291620800528, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625003441, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625003441, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5576.291620800528, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625003495, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625003495, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625003511, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625003920, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8896269798278809, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625003920, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625004104, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5524.415561811891, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625004104, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625004104, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5524.415561811891, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625004172, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625004172, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625004188, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625004603, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8675628900527954, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625004603, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625004802, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5341.203448299386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625004802, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625004802, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5341.203448299386, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625004859, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625004859, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625004875, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625005297, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.891382098197937, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625005298, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625005493, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5302.098602772483, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625005494, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625005494, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5302.098602772483, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625005532, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625005532, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625005547, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625005945, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8941150903701782, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625005945, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625006143, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5493.982383062166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625006144, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625006144, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5493.982383062166, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625006179, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625006179, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625006195, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625006594, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8942020535469055, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625006594, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625006789, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5515.876918765555, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625006789, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625006789, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5515.876918765555, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625006824, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625006825, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625006841, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625007239, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8710801601409912, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625007240, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625007431, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5543.939859088996, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625007431, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625007431, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5543.939859088996, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625007486, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625007487, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625007502, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625007902, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8655664920806885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625007902, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625008093, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5545.984125728574, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625008093, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625008093, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5545.984125728574, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625008198, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625008198, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625008213, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625008614, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.896714985370636, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625008614, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625008823, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5377.946896211435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625008823, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625008824, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5377.946896211435, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625008904, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625008904, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625008919, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625009317, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.4713174104690552, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625009318, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625009513, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5520.686792254744, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625009513, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625009513, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5520.686792254744, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625009549, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625009549, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625009565, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625009963, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6399949193000793, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625009963, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625010158, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5519.300879070784, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625010158, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625010158, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5519.300879070784, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625010237, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625010237, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625010252, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625010651, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6347954273223877, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625010651, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625010845, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5531.0957705716755, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625010845, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625010846, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5531.0957705716755, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625010951, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625010951, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625010967, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625011365, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7907954454421997, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625011366, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625011572, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5412.364738517575, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625011572, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625011572, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5412.364738517575, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625011608, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625011609, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625011625, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625012023, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8187801837921143, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625012023, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625012214, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5556.0703967703275, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625012214, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625012214, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5556.0703967703275, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625012250, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625012250, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625012266, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625012665, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8396888971328735, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625012665, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625012860, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5510.543153377054, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625012860, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625012860, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5510.543153377054, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625012951, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625012951, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625012966, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625013365, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8575809001922607, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625013365, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625013567, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5453.25640733939, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625013567, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625013567, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5453.25640733939, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625013654, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625013655, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625013670, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625014069, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.824856162071228, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625014069, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625014259, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5562.480512575798, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625014259, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625014259, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5562.480512575798, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625014298, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625014299, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625014314, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625014713, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8834659457206726, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625014713, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625014911, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5490.991941686519, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625014911, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625014911, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5490.991941686519, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625014948, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625014948, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625014964, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625015363, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8828275799751282, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625015363, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625015555, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5531.6428705163635, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625015555, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625015556, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5531.6428705163635, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625015679, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625015680, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625015695, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625016094, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.48748907446861267, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625016095, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625016305, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5376.246105015794, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625016305, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625016305, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5376.246105015794, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625016341, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625016341, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625016358, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625016755, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.751355767250061, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625016755, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625016947, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5551.39768732163, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625016947, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625016947, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5551.39768732163, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625017001, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625017001, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625017016, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625017415, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8307759165763855, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625017415, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625017604, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5568.753599296322, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625017605, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625017605, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5568.753599296322, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625017697, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625017697, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625017711, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625018110, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8538509607315063, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625018110, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625018345, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5186.232755321342, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625018346, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625018346, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5186.232755321342, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625018383, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625018383, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625018398, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625018797, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8485517501831055, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625018798, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625019012, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5340.76218310585, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625019012, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625019012, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5340.76218310585, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625019044, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625019044, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625019061, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625019461, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8749123811721802, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625019461, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625019683, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5260.721046525344, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625019683, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625019683, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5260.721046525344, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625019719, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625019719, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625019735, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625020134, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8776628971099854, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625020134, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625020325, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5546.134723638974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625020325, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625020325, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5546.134723638974, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625020378, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625020378, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625020394, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625020793, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8739080429077148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625020793, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625020983, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5556.962059057449, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625020983, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625020983, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5556.962059057449, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625021049, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625021049, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625021064, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625021464, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8944740891456604, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625021464, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625021655, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5549.390947075703, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625021655, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625021655, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5549.390947075703, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625021690, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625021690, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625021706, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625022105, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8907418251037598, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625022106, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625022303, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5480.162046092454, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625022304, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625022304, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5480.162046092454, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625022413, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625022413, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625022429, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625022827, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8821256160736084, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625022827, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625023034, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5410.98904238029, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625023035, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625023035, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5410.98904238029, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625023070, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625023070, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625023086, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625023486, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8904316425323486, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625023486, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625023673, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5576.104079858604, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625023673, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625023673, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5576.104079858604, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625023710, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625023710, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625023727, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625024126, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8771365880966187, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625024126, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625024315, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5556.944529768568, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625024315, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625024316, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5556.944529768568, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625024402, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625024402, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625024417, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625024816, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8926420211791992, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625024816, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625025018, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5454.07948877516, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625025019, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625025019, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5454.07948877516, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625025097, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625025097, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625025112, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625025512, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8890979290008545, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625025512, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625025710, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5487.594456824827, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625025710, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625025710, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5487.594456824827, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625025772, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625025773, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625025788, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625026186, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8863965272903442, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625026186, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625026380, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5530.066994793218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625026381, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625026381, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5530.066994793218, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625026468, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625026468, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625026483, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625026883, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8972184658050537, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625026884, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625027091, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5396.933540435466, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625027091, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625027091, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5396.933540435466, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625027127, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625027127, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625027143, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625027543, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8865582942962646, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625027543, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625027729, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5579.894854789856, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625027730, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625027730, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5579.894854789856, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625027765, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625027765, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625027782, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625028183, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8928039073944092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625028183, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625028368, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5574.683591171082, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625028369, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625028369, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5574.683591171082, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625028428, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625028429, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625028443, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625028842, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8970109224319458, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625028842, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625029030, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5591.8283986572815, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625029030, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625029030, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5591.8283986572815, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625029122, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625029122, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625029137, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625029536, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8873351812362671, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625029536, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625029733, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5497.54433323724, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625029734, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625029734, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5497.54433323724, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625029769, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625029770, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625029786, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625030185, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8848544359207153, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625030185, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625030374, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5564.641745766065, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625030374, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625030374, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5564.641745766065, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625030455, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625030456, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625030471, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625030870, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9016910791397095, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625030870, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625031074, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.577751432981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625031074, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625031074, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.577751432981, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625031136, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625031136, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625031151, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625031550, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9007364511489868, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625031550, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625031750, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5475.705447434381, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625031750, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625031750, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5475.705447434381, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625031821, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625031821, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625031836, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625032236, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.89920973777771, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625032237, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625032427, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5549.404058314796, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625032427, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625032427, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5549.404058314796, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625032530, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625032530, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625032545, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625032945, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8979262113571167, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625032945, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625033152, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5404.487859053191, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625033152, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625033152, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5404.487859053191, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625033233, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625033233, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625033248, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625033647, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9009302854537964, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625033647, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625033846, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5481.146754450923, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625033846, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625033846, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5481.146754450923, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625033908, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625033909, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625033924, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625034324, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.89349764585495, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625034324, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625034510, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5585.795475354164, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625034511, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625034511, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5585.795475354164, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625034546, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625034547, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625034563, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625034966, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8976160287857056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625034966, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625035155, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5527.225743092273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625035155, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625035155, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5527.225743092273, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625035190, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625035191, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625035207, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625035606, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9008920192718506, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625035606, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625035798, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5532.941580623796, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625035798, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625035798, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5532.941580623796, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625035835, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625035835, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625035851, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625036251, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9031025767326355, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625036251, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625036435, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5599.673798807897, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625036435, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625036436, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5599.673798807897, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625036526, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625036526, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625036541, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625036940, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8916440010070801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625036941, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625037140, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5476.105457158078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625037140, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625037140, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5476.105457158078, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625037175, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625037176, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625037191, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625037590, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9020771980285645, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625037591, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625037780, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5558.829561604294, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625037780, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625037780, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5558.829561604294, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625037855, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625037855, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625037870, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625038270, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.895797073841095, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625038270, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625038467, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5488.188552849404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625038467, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625038468, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5488.188552849404, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625038504, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625038504, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625038520, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625038920, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9025896787643433, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625038920, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625039113, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5517.258952763609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625039113, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625039113, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5517.258952763609, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625039149, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625039149, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625039166, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625039565, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8976994752883911, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625039565, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625039754, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5563.701490840312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625039754, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625039754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5563.701490840312, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625039789, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625039790, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625039806, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625040206, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8927491903305054, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625040206, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625040391, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5586.590402133018, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625040392, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625040392, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5586.590402133018, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625040427, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625040428, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625040443, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625040843, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9045093059539795, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625040843, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625041033, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5554.073410809209, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625041033, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625041033, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5554.073410809209, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625041069, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625041069, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625041085, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625041486, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8997197151184082, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625041486, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625041667, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5626.678953147146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625041667, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625041667, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5626.678953147146, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625041703, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625041703, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625041720, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625042119, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9039992094039917, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625042119, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625042312, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5517.900538209086, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625042313, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625042313, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5517.900538209086, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625042348, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625042349, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625042365, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625042765, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.891872227191925, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625042765, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625042947, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5613.762133959632, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625042947, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625042948, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5613.762133959632, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625043035, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625043035, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625043050, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625043449, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9057111144065857, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625043449, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625043649, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5472.620103310166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625043650, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625043650, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5472.620103310166, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625043686, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625043686, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625043702, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625044102, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8904470801353455, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625044102, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625044285, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5605.070122729691, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625044286, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625044286, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5605.070122729691, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625044321, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625044321, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625044338, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625044737, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8910828232765198, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625044738, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625044926, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5557.575653848718, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625044926, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625044927, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5557.575653848718, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625044963, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625044963, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625044979, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625045380, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8928309082984924, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625045380, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625045577, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5479.156389016542, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625045577, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625045577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5479.156389016542, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625045644, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625045645, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625045659, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625046060, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8977665901184082, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625046060, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625046248, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5567.569994322943, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625046249, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625046249, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5567.569994322943, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625046324, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625046325, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625046339, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625046740, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8848216533660889, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625046740, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625046933, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5524.584481931338, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625046933, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625046933, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5524.584481931338, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625046969, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625046969, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625046986, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625047386, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8982818126678467, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625047386, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625047569, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5602.0689021896105, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625047570, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625047570, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5602.0689021896105, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625047607, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625047607, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625047623, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625048025, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9027888774871826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625048025, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625048209, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5588.790361789795, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625048209, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625048209, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5588.790361789795, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625048245, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625048245, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625048261, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625048660, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8990474343299866, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625048660, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625048847, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5583.670876747564, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625048847, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625048847, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5583.670876747564, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625048918, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625048919, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625048934, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625049333, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8899152278900146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625049333, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625049524, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5554.677610326055, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625049524, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625049524, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5554.677610326055, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625049559, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625049560, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625049576, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634625049976, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8952102661132812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634625049977, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634625050169, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5515.114936861038, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625050169, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625050169, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5515.114936861038, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2500}}
:::MLLOG {"namespace": "", "time_ms": 1634625050248, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625050248, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625050263, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634625050663, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8950068950653076, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634625050664, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634625050864, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5458.462885147281, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625050864, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625050864, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5458.462885147281, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2520}}
:::MLLOG {"namespace": "", "time_ms": 1634625050900, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625050900, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625050916, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634625051317, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9040759801864624, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634625051317, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634625051501, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5597.5386316578415, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625051501, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625051501, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5597.5386316578415, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2540}}
:::MLLOG {"namespace": "", "time_ms": 1634625051538, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625051538, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625051554, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634625051954, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9034520387649536, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634625051954, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634625052148, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5501.8905014253605, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625052149, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625052149, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5501.8905014253605, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2560}}
:::MLLOG {"namespace": "", "time_ms": 1634625052184, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625052185, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625052201, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634625052600, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8962581753730774, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634625052600, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634625052791, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5544.954168002786, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625052791, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625052791, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5544.954168002786, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2580}}
:::MLLOG {"namespace": "", "time_ms": 1634625052828, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625052829, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625052845, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634625053245, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985496759414673, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634625053245, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634625053432, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5571.818348949576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625053432, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625053432, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5571.818348949576, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2600}}
:::MLLOG {"namespace": "", "time_ms": 1634625053495, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625053495, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625053510, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634625053918, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9073398113250732, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634625053918, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634625054104, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5519.79376064861, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625054104, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625054104, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5519.79376064861, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2620}}
:::MLLOG {"namespace": "", "time_ms": 1634625054167, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625054167, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625054182, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634625054583, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9026340246200562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634625054583, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634625054781, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5473.028164255373, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625054782, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625054782, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5473.028164255373, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2640}}
:::MLLOG {"namespace": "", "time_ms": 1634625054905, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625054905, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625054920, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634625055321, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8914160132408142, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634625055321, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634625055534, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5345.3261181657535, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625055534, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625055534, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5345.3261181657535, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2660}}
:::MLLOG {"namespace": "", "time_ms": 1634625055654, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625055654, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625055669, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634625056070, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8898335695266724, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634625056070, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634625056286, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5318.938043745327, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625056287, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625056287, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5318.938043745327, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2680}}
:::MLLOG {"namespace": "", "time_ms": 1634625056323, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625056323, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625056339, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2700}}
:::MLLOG {"namespace": "", "time_ms": 1634625056740, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8939439058303833, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2700}}
:::MLLOG {"namespace": "", "time_ms": 1634625056740, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2700}}
:::MLLOG {"namespace": "", "time_ms": 1634625056926, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5569.779210405982, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625056927, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625056927, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5569.779210405982, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2700}}
:::MLLOG {"namespace": "", "time_ms": 1634625057000, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625057001, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625057016, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2720}}
:::MLLOG {"namespace": "", "time_ms": 1634625057416, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9096295833587646, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2720}}
:::MLLOG {"namespace": "", "time_ms": 1634625057417, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2720}}
:::MLLOG {"namespace": "", "time_ms": 1634625057417, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634625057606, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5555.969637212471, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625057606, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625057606, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5555.969637212471, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2720}}
ENDING TIMING RUN AT 2021-10-19 06:31:03 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:03 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:03 AM
ENDING TIMING RUN AT 2021-10-19 06:31:03 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:03 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:03 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:04 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:04 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:04 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:04 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:04 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:04 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:04 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:05 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:05 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:06 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:06 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:06 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:06 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:06 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:07 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:08 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:08 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:08 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:08 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:08 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:08 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:08 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:08 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:08 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:08 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:09 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:10 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:11 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:12 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:13 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:13 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:13 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:13 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:13 AM
RESULT,image_segmentation,,233,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:14 AM
RESULT,image_segmentation,,234,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:15 AM
RESULT,image_segmentation,,235,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:16 AM
RESULT,image_segmentation,,236,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:17 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:17 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:17 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:17 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:27:20 AM
ENDING TIMING RUN AT 2021-10-19 06:31:17 AM
RESULT,image_segmentation,,237,nvidia,2021-10-19 06:27:20 AM
