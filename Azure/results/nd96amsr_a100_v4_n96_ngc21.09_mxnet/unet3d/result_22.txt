+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019053644250130448
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019053644250130448
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019053644250130448
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019053644250130448
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07384/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019053644250130448_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C04A1
Clearing cache on ip-0A0C04A2
Clearing cache on ip-0A0C0436
Clearing cache on ip-0A0C0489
Clearing cache on ip-0A0C0487
Clearing cache on ip-0A0C0472
Clearing cache on ip-0A0C048B
Clearing cache on ip-0A0C0464
Clearing cache on ip-0A0C04AB
Clearing cache on ip-0A0C0493
Clearing cache on ip-0A0C042D
Clearing cache on ip-0A0C045F
Clearing cache on ip-0A0C0441
Clearing cache on ip-0A0C0449
Clearing cache on ip-0A0C0435
Clearing cache on ip-0A0C04AC
Clearing cache on ip-0A0C046E
Clearing cache on ip-0A0C0486
Clearing cache on ip-0A0C0497
Clearing cache on ip-0A0C0499
Clearing cache on ip-0A0C048A
Clearing cache on ip-0A0C0437
Clearing cache on ip-0A0C0488
Clearing cache on ip-0A0C0473
Clearing cache on ip-0A0C0466
Clearing cache on ip-0A0C047E
Clearing cache on ip-0A0C0498
Clearing cache on ip-0A0C044D
Clearing cache on ip-0A0C0438
Clearing cache on ip-0A0C0460
Clearing cache on ip-0A0C0492
Clearing cache on ip-0A0C0494
Clearing cache on ip-0A0C048C
Clearing cache on ip-0A0C0483
Clearing cache on ip-0A0C04B5
Clearing cache on ip-0A0C04C3
Clearing cache on ip-0A0C04A5
Clearing cache on ip-0A0C04D8
Clearing cache on ip-0A0C04C5
Clearing cache on ip-0A0C049C
Clearing cache on ip-0A0C04A7
Clearing cache on ip-0A0C049F
Clearing cache on ip-0A0C04BC
Clearing cache on ip-0A0C04A9
Clearing cache on ip-0A0C04AD
Clearing cache on ip-0A0C0461
Clearing cache on ip-0A0C0484
Clearing cache on ip-0A0C04A6
Clearing cache on ip-0A0C0429
Clearing cache on ip-0A0C04B2
Clearing cache on ip-0A0C0491
Clearing cache on ip-0A0C04A0
Clearing cache on ip-0A0C04B4
Clearing cache on ip-0A0C04C0
Clearing cache on ip-0A0C04DB
Clearing cache on ip-0A0C0443
Clearing cache on ip-0A0C049B
Clearing cache on ip-0A0C04D4
Clearing cache on ip-0A0C04C6
Clearing cache on ip-0A0C04C8
Clearing cache on ip-0A0C046B
Clearing cache on ip-0A0C0490
Clearing cache on ip-0A0C04B3
Clearing cache on ip-0A0C04C9
Clearing cache on ip-0A0C04BB
Clearing cache on ip-0A0C04C2
Clearing cache on ip-0A0C04B6
Clearing cache on ip-0A0C048F
Clearing cache on ip-0A0C04B0
Clearing cache on ip-0A0C04AE
Clearing cache on ip-0A0C0482
Clearing cache on ip-0A0C04A8
Clearing cache on ip-0A0C04AF
Clearing cache on ip-0A0C04A4
Clearing cache on ip-0A0C0496
Clearing cache on ip-0A0C04BA
Clearing cache on ip-0A0C048D
Clearing cache on ip-0A0C046C
Clearing cache on ip-0A0C04C7
Clearing cache on ip-0A0C04CC
Clearing cache on ip-0A0C0495
Clearing cache on ip-0A0C04D3
Clearing cache on ip-0A0C04DA
Clearing cache on ip-0A0C04D9
Clearing cache on ip-0A0C04B9
Clearing cache on ip-0A0C0485
Clearing cache on ip-0A0C04B7
Clearing cache on ip-0A0C04C4
Clearing cache on ip-0A0C04B1
Clearing cache on ip-0A0C04BD
Clearing cache on ip-0A0C04AA
Clearing cache on ip-0A0C049D
Clearing cache on ip-0A0C04CF
Clearing cache on ip-0A0C04BE
Clearing cache on ip-0A0C04CD
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:36:46 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634621811.793403] [ip-0A0C048A:32428:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.828413] [ip-0A0C04CF:76500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.834777] [ip-0A0C04AD:95308:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.836674] [ip-0A0C04AF:12514:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.838942] [ip-0A0C04BB:93119:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.843139] [ip-0A0C048A:32426:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.847932] [ip-0A0C04AD:95306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.857664] [ip-0A0C0497:68155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.858450] [ip-0A0C048B:18487:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.862014] [ip-0A0C04AF:12511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.871331] [ip-0A0C04C4:53251:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.873481] [ip-0A0C046E:37631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.874788] [ip-0A0C0437:32328:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.876187] [ip-0A0C04A4:20987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.876775] [ip-0A0C04C9:46133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.877282] [ip-0A0C04AB:11251:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.879346] [ip-0A0C049C:7590 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.889415] [ip-0A0C04BB:93139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.890744] [ip-0A0C04BB:93118:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.890949] [ip-0A0C04AC:14112:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.894323] [ip-0A0C04CF:76501:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.898627] [ip-0A0C04A4:20993:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.898920] [ip-0A0C04B3:28357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.900750] [ip-0A0C046E:37632:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.900368] [ip-0A0C0482:23363:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.902653] [ip-0A0C04BE:53571:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.903296] [ip-0A0C04AD:95311:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.906822] [ip-0A0C04AF:12515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.909516] [ip-0A0C04C7:48132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.909605] [ip-0A0C04AC:14115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.910814] [ip-0A0C0437:32326:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.910975] [ip-0A0C0499:22268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.913316] [ip-0A0C04AB:11255:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.914862] [ip-0A0C0486:35619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.914666] [ip-0A0C048A:32425:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.914782] [ip-0A0C04CF:76497:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.918034] [ip-0A0C04AB:11257:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.917992] [ip-0A0C0466:38315:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.921033] [ip-0A0C04C2:75555:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.923500] [ip-0A0C0482:23365:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.924067] [ip-0A0C0466:38311:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.924901] [ip-0A0C04C3:51824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.928519] [ip-0A0C045F:33744:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.929186] [ip-0A0C04CF:76499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.932229] [ip-0A0C0497:68160:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.933349] [ip-0A0C0497:68157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.935642] [ip-0A0C04B0:7148 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.936891] [ip-0A0C0487:35539:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.936363] [ip-0A0C04A9:19725:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.936938] [ip-0A0C0487:35544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.937593] [ip-0A0C04C2:75552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.939193] [ip-0A0C049D:16487:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.939899] [ip-0A0C04AC:14117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.940444] [ip-0A0C04C7:48129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.940492] [ip-0A0C04C7:48128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.941683] [ip-0A0C04C8:47247:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.943696] [ip-0A0C048A:32422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.943721] [ip-0A0C048B:18485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.943998] [ip-0A0C048B:18484:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.945729] [ip-0A0C04A7:95019:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.945043] [ip-0A0C04BC:48956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.947906] [ip-0A0C0482:23364:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.948991] [ip-0A0C04A0:10114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.949544] [ip-0A0C0491:17979:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.952218] [ip-0A0C0449:33177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.954853] [ip-0A0C0486:35617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.957560] [ip-0A0C046E:37628:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.957941] [ip-0A0C047E:32635:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.963599] [ip-0A0C04A2:12174:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.959824] [ip-0A0C0492:15435:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.959976] [ip-0A0C04CC:46719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.960013] [ip-0A0C04CC:46717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.961355] [ip-0A0C04BD:51069:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.962712] [ip-0A0C0499:22263:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.966456] [ip-0A0C04A0:10109:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.966770] [ip-0A0C0461:97198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.967791] [ip-0A0C04A6:20351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.967382] [ip-0A0C048A:32427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.967479] [ip-0A0C04B3:28358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.969034] [ip-0A0C045F:33742:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.969109] [ip-0A0C045F:33743:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.971315] [ip-0A0C049D:16486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.973402] [ip-0A0C049B:9398 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.974492] [ip-0A0C04DA:40428:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.974530] [ip-0A0C049C:7591 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.975341] [ip-0A0C04BB:93124:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.975978] [ip-0A0C049F:8782 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.976010] [ip-0A0C049F:8778 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.975930] [ip-0A0C04BC:48961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.979055] [ip-0A0C04BA:85763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.980775] [ip-0A0C0495:20157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.980678] [ip-0A0C0490:21857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.980681] [ip-0A0C0490:21851:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.981264] [ip-0A0C04AD:95305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.981558] [ip-0A0C04B6:87508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.981557] [ip-0A0C04B6:87507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.982380] [ip-0A0C04AE:26070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.984214] [ip-0A0C04DA:40431:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.984834] [ip-0A0C048B:18512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.986043] [ip-0A0C046E:37630:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.985926] [ip-0A0C04BE:53575:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.986774] [ip-0A0C048A:32423:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.986870] [ip-0A0C048A:32424:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.989875] [ip-0A0C0460:35322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.990434] [ip-0A0C0497:68161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.991508] [ip-0A0C04A9:19727:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.993750] [ip-0A0C04C8:47248:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.994281] [ip-0A0C0437:32320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.994065] [ip-0A0C04CF:76494:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.994456] [ip-0A0C04C4:53253:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.994675] [ip-0A0C0438:36561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.994362] [ip-0A0C04B7:88916:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.994778] [ip-0A0C048B:18486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.996188] [ip-0A0C0490:21852:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.996378] [ip-0A0C04C2:75551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.996884] [ip-0A0C04AF:12512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.997511] [ip-0A0C048A:32429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621811.999623] [ip-0A0C04BE:53573:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.002452] [ip-0A0C0492:15434:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.002614] [ip-0A0C04AD:95312:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.001885] [ip-0A0C0484:37714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.003208] [ip-0A0C04B0:7152 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.001929] [ip-0A0C0484:37712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.003493] [ip-0A0C0441:28961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.003444] [ip-0A0C049C:7587 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.004086] [ip-0A0C0483:34536:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.004324] [ip-0A0C04AF:12510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.003969] [ip-0A0C04BC:48955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.005250] [ip-0A0C04C9:46134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.006223] [ip-0A0C04C3:51823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.007337] [ip-0A0C0429:26162:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.007370] [ip-0A0C049C:7588 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.010399] [ip-0A0C0486:35614:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.009608] [ip-0A0C04B7:88912:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.010249] [ip-0A0C0461:97199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.010449] [ip-0A0C04C5:55113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.010638] [ip-0A0C04CF:76498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.011699] [ip-0A0C047E:32633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.011681] [ip-0A0C042D:6976 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.011443] [ip-0A0C04C6:48704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.011440] [ip-0A0C04C6:48706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.014452] [ip-0A0C04BB:93122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.015400] [ip-0A0C04A4:20988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.014907] [ip-0A0C04CF:76495:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.015409] [ip-0A0C04C4:53252:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.015444] [ip-0A0C04D3:44596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.015745] [ip-0A0C0429:26163:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.015457] [ip-0A0C049B:9400 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.016007] [ip-0A0C04BA:85761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.016353] [ip-0A0C04CF:76496:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.016746] [ip-0A0C04A9:19728:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.017027] [ip-0A0C0489:35978:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.017087] [ip-0A0C04DB:39109:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.018008] [ip-0A0C04BE:53569:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.017077] [ip-0A0C04DB:39112:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.018888] [ip-0A0C0491:17974:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.020628] [ip-0A0C04B3:28362:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.020324] [ip-0A0C04AD:95307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.022104] [ip-0A0C0496:2150 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.022577] [ip-0A0C0488:33831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.023321] [ip-0A0C0497:68159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.025345] [ip-0A0C0499:22262:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.026013] [ip-0A0C04BA:85764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.025768] [ip-0A0C049C:7589 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.027520] [ip-0A0C04C9:46137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.027460] [ip-0A0C048D:21668:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.027649] [ip-0A0C04AB:11254:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.027396] [ip-0A0C04B2:94219:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.028539] [ip-0A0C0495:20160:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.028537] [ip-0A0C04AF:12513:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.028537] [ip-0A0C04C2:75548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.029019] [ip-0A0C0464:35681:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.029027] [ip-0A0C0464:35682:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.030021] [ip-0A0C04C4:53255:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.031551] [ip-0A0C04BB:93117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.031706] [ip-0A0C04AE:26068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.033727] [ip-0A0C04A4:21016:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.033711] [ip-0A0C04AA:93111:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.033892] [ip-0A0C0473:34182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.033890] [ip-0A0C048F:25457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.034475] [ip-0A0C04AD:95310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.039147] [ip-0A0C04A2:12177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.035993] [ip-0A0C04A0:10111:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.036737] [ip-0A0C0490:21854:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.037696] [ip-0A0C04BB:93120:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.038034] [ip-0A0C0437:32321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.039413] [ip-0A0C04A7:95022:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.038897] [ip-0A0C0487:35545:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.039245] [ip-0A0C046E:37626:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.038772] [ip-0A0C0498:30556:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.039923] [ip-0A0C04AF:12517:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.039508] [ip-0A0C0489:35982:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.041732] [ip-0A0C04C9:46139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.041777] [ip-0A0C04A9:19724:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.042835] [ip-0A0C04AF:12516:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.043282] [ip-0A0C04D3:44619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.043801] [ip-0A0C04AD:95309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.044152] [ip-0A0C044D:33151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.044416] [ip-0A0C04B5:21345:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.045108] [ip-0A0C0443:96853:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.045238] [ip-0A0C04BE:53572:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.046015] [ip-0A0C04BB:93121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.045917] [ip-0A0C04CD:43544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.050883] [ip-0A0C04A2:12178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.046835] [ip-0A0C0485:98086:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.048557] [ip-0A0C04AE:26064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.048098] [ip-0A0C0482:23368:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.048728] [ip-0A0C046E:37633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.049912] [ip-0A0C04A6:20349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.049694] [ip-0A0C0487:35540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.050297] [ip-0A0C04AB:11253:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.051653] [ip-0A0C0435:65349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.051557] [ip-0A0C04CD:43541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.051552] [ip-0A0C0472:37656:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.052109] [ip-0A0C0461:97197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.052407] [ip-0A0C04C8:47246:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.052631] [ip-0A0C04BD:51066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.053584] [ip-0A0C04C9:46136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.054399] [ip-0A0C046C:31419:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.055402] [ip-0A0C0437:32323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.056228] [ip-0A0C04A4:20992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.056711] [ip-0A0C04B3:28355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.056701] [ip-0A0C04AC:14119:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.057837] [ip-0A0C0483:34530:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.058072] [ip-0A0C046B:22543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.058425] [ip-0A0C0483:34535:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.059702] [ip-0A0C0449:33175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.060174] [ip-0A0C0460:35317:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.060237] [ip-0A0C0499:22267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.059999] [ip-0A0C04A8:26134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.060830] [ip-0A0C040F:5710 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.061567] [ip-0A0C04AC:14113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.061400] [ip-0A0C04BE:53574:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.062160] [ip-0A0C0482:23366:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.062995] [ip-0A0C04C4:53254:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.064087] [ip-0A0C0486:35620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.063763] [ip-0A0C049D:16490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.064139] [ip-0A0C0497:68158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.064999] [ip-0A0C0466:38314:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.066099] [ip-0A0C04C7:48130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.067429] [ip-0A0C04AB:11256:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.068208] [ip-0A0C04C7:48131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.067349] [ip-0A0C0497:68154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.068093] [ip-0A0C04D9:74260:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.067836] [ip-0A0C0494:17609:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.068074] [ip-0A0C049B:9397 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.071193] [ip-0A0C04AC:14118:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.071255] [ip-0A0C0461:97194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.071126] [ip-0A0C049C:7592 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.071603] [ip-0A0C048C:16942:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.072014] [ip-0A0C04B1:24194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.071645] [ip-0A0C04B5:21343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.072278] [ip-0A0C0488:33830:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.072493] [ip-0A0C04C3:51818:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.072270] [ip-0A0C049C:7586 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.073405] [ip-0A0C04C9:46135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.073245] [ip-0A0C04D3:44591:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.073809] [ip-0A0C0485:98085:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.073708] [ip-0A0C04C9:46138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.073254] [ip-0A0C0497:68156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.074563] [ip-0A0C04B0:7149 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.074548] [ip-0A0C0436:35966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.075068] [ip-0A0C042D:6998 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.076425] [ip-0A0C04C9:46132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.076491] [ip-0A0C046E:37627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.076280] [ip-0A0C048B:18489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.076886] [ip-0A0C046E:37629:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.077355] [ip-0A0C044D:33156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.078082] [ip-0A0C048D:21675:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.079173] [ip-0A0C04B2:94220:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.079729] [ip-0A0C0437:32322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.079565] [ip-0A0C0489:35976:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.079925] [ip-0A0C044D:33153:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.080654] [ip-0A0C0491:17977:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.080565] [ip-0A0C04C3:51822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.080484] [ip-0A0C0449:33180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.081466] [ip-0A0C047E:32631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.081500] [ip-0A0C04C4:53257:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.081829] [ip-0A0C0437:32327:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.081830] [ip-0A0C049F:8779 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.082127] [ip-0A0C048B:18488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.082232] [ip-0A0C048B:18483:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.082437] [ip-0A0C0473:34175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.082730] [ip-0A0C049C:7593 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.083209] [ip-0A0C04BC:48962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.085019] [ip-0A0C0466:38312:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.084991] [ip-0A0C04C4:53256:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.085502] [ip-0A0C04AC:14116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.085340] [ip-0A0C04C4:53250:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.085611] [ip-0A0C04AC:14114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.085644] [ip-0A0C04B6:87505:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.086043] [ip-0A0C0437:32325:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.086471] [ip-0A0C0492:15441:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.086239] [ip-0A0C04A4:20991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.086684] [ip-0A0C04B3:28360:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.087060] [ip-0A0C04C2:75553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.087494] [ip-0A0C04C7:48126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.087030] [ip-0A0C04BD:51070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.086971] [ip-0A0C0449:33179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.087633] [ip-0A0C04CC:46718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.088118] [ip-0A0C04C7:48127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.088239] [ip-0A0C0466:38316:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.090001] [ip-0A0C0486:35616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.090529] [ip-0A0C04A4:20986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.090608] [ip-0A0C04A4:20990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.090474] [ip-0A0C048C:16930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.091229] [ip-0A0C047E:32660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.090723] [ip-0A0C04C6:48708:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.091288] [ip-0A0C046B:22539:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.092223] [ip-0A0C04A6:20354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.091734] [ip-0A0C0438:36556:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.091992] [ip-0A0C04C0:52351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.091868] [ip-0A0C0482:23367:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.093107] [ip-0A0C04B3:28359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.093028] [ip-0A0C0441:28965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.092919] [ip-0A0C049F:8776 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.093431] [ip-0A0C04AB:11252:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.093217] [ip-0A0C0482:23369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.092984] [ip-0A0C0498:30554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.093362] [ip-0A0C04B9:53607:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.094413] [ip-0A0C046C:31420:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.094903] [ip-0A0C04A5:23303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.096480] [ip-0A0C0492:15436:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.096432] [ip-0A0C0495:20158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.097713] [ip-0A0C042D:6977 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.099139] [ip-0A0C04C6:48709:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.099965] [ip-0A0C04AB:11250:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.100480] [ip-0A0C04CC:46716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.100792] [ip-0A0C04C7:48133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.103263] [ip-0A0C04A7:95021:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.102529] [ip-0A0C04C5:55109:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.102643] [ip-0A0C0449:33178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.103355] [ip-0A0C04C8:47268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.102918] [ip-0A0C0494:17610:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.104356] [ip-0A0C045F:33740:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.104713] [ip-0A0C04C2:75549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.104885] [ip-0A0C04B0:7145 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.104848] [ip-0A0C048D:21669:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.105004] [ip-0A0C04C3:51821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.105126] [ip-0A0C04C2:75554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.105379] [ip-0A0C04C2:75550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.105174] [ip-0A0C04A9:19722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.106199] [ip-0A0C040F:5705 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.107631] [ip-0A0C04A0:10116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.107349] [ip-0A0C04BD:51063:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.107894] [ip-0A0C0482:23370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.108607] [ip-0A0C0491:17975:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.108651] [ip-0A0C0466:38309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.109364] [ip-0A0C0496:2144 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.109795] [ip-0A0C04B0:7146 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.110791] [ip-0A0C0473:34181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.110945] [ip-0A0C0466:38310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.111291] [ip-0A0C04CC:46723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.111514] [ip-0A0C040F:5711 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.113726] [ip-0A0C045F:33739:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.114177] [ip-0A0C04AE:26065:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.114282] [ip-0A0C04B0:7151 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.115029] [ip-0A0C04A7:95017:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.114443] [ip-0A0C0487:35542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.115230] [ip-0A0C04A7:95047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.115486] [ip-0A0C048F:25458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.115705] [ip-0A0C04BE:53568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.115354] [ip-0A0C04A8:26151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.116134] [ip-0A0C045F:33738:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.116217] [ip-0A0C04BE:53570:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.117327] [ip-0A0C049D:16493:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.117513] [ip-0A0C04A5:23304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.119077] [ip-0A0C047E:32634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.118576] [ip-0A0C0490:21856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.119518] [ip-0A0C04A1:38580:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.119712] [ip-0A0C04C8:47251:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.119999] [ip-0A0C0466:38313:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.120687] [ip-0A0C0487:35541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.120489] [ip-0A0C04B6:87509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.120776] [ip-0A0C04C3:51819:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.120972] [ip-0A0C0487:35543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.121334] [ip-0A0C04A0:10110:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.121850] [ip-0A0C04B3:28356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.122139] [ip-0A0C04B3:28361:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.122342] [ip-0A0C0438:36563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.122804] [ip-0A0C0486:35613:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.122440] [ip-0A0C04AA:93110:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.122670] [ip-0A0C04DA:40426:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.122563] [ip-0A0C04AA:93109:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.122844] [ip-0A0C0490:21855:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.122999] [ip-0A0C04B9:53609:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.123972] [ip-0A0C0436:35962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.124442] [ip-0A0C04AE:26066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.125068] [ip-0A0C04DA:40434:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.126247] [ip-0A0C0443:96857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.125985] [ip-0A0C0493:17429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.126455] [ip-0A0C0491:17978:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.126989] [ip-0A0C0486:35618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.127309] [ip-0A0C0486:35615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.127095] [ip-0A0C0460:35320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.127515] [ip-0A0C04C5:55112:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.127528] [ip-0A0C0490:21853:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.129361] [ip-0A0C0472:37652:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.130271] [ip-0A0C0490:21850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.130958] [ip-0A0C0487:35546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.131244] [ip-0A0C0483:34532:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.131125] [ip-0A0C04D4:43314:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.131753] [ip-0A0C049D:16488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.131877] [ip-0A0C0499:22266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.132044] [ip-0A0C0499:22261:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.132326] [ip-0A0C049D:16492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.132776] [ip-0A0C04D9:74258:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.133890] [ip-0A0C04A7:95024:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.133669] [ip-0A0C0443:96858:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.133412] [ip-0A0C045F:33737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.133330] [ip-0A0C0499:22265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.134384] [ip-0A0C04BA:85758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.135490] [ip-0A0C04BD:51067:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.136844] [ip-0A0C04A6:20353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.135818] [ip-0A0C04B5:21342:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.137084] [ip-0A0C0438:36559:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.137552] [ip-0A0C0496:2153 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.137367] [ip-0A0C0495:20153:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.137264] [ip-0A0C0493:17430:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.137571] [ip-0A0C0499:22264:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.137950] [ip-0A0C045F:33741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.139437] [ip-0A0C04CC:46722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.139496] [ip-0A0C04B2:94222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.144281] [ip-0A0C04A2:12176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.139842] [ip-0A0C04C5:55115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.144571] [ip-0A0C04A2:12173:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.141077] [ip-0A0C049F:8777 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.142136] [ip-0A0C0491:17973:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.141635] [ip-0A0C048F:25463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.142987] [ip-0A0C04A0:10113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.142728] [ip-0A0C04A1:38574:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.142256] [ip-0A0C04A9:19726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.142262] [ip-0A0C049B:9399 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.144407] [ip-0A0C04A9:19720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.144761] [ip-0A0C04A9:19723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.144723] [ip-0A0C04BC:48958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.144848] [ip-0A0C04BC:48957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.144845] [ip-0A0C0484:37707:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.146013] [ip-0A0C04C3:51817:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.146153] [ip-0A0C04CC:46720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.145360] [ip-0A0C0484:37709:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.146787] [ip-0A0C0492:15437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.146873] [ip-0A0C04CC:46721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.147765] [ip-0A0C04A6:20378:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.148095] [ip-0A0C04A6:20350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.147530] [ip-0A0C04C8:47249:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.147187] [ip-0A0C04A8:26133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.148022] [ip-0A0C04C8:47252:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.148158] [ip-0A0C04C8:47245:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.148757] [ip-0A0C04C3:51820:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.149761] [ip-0A0C049F:8781 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.150075] [ip-0A0C04B0:7150 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.150109] [ip-0A0C04B0:7147 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.149897] [ip-0A0C0494:17615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.151084] [ip-0A0C047E:32636:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.151127] [ip-0A0C047E:32630:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.151476] [ip-0A0C04A0:10123:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.151772] [ip-0A0C04A0:10115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.152529] [ip-0A0C04A6:20352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.152959] [ip-0A0C0443:96854:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.152930] [ip-0A0C0464:35680:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.152995] [ip-0A0C049D:16489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.153500] [ip-0A0C0464:35683:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.153492] [ip-0A0C04B6:87510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.153740] [ip-0A0C049D:16491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.154341] [ip-0A0C049B:9401 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.155155] [ip-0A0C04DA:40433:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.156697] [ip-0A0C042D:6974 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.156721] [ip-0A0C04BD:51068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.156942] [ip-0A0C04B6:87504:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.157491] [ip-0A0C04B7:88914:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.157127] [ip-0A0C04BC:48959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.159141] [ip-0A0C04A6:20355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.158712] [ip-0A0C04C0:52354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.158997] [ip-0A0C04C0:52349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.158954] [ip-0A0C04BA:85759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.159600] [ip-0A0C047E:32632:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.159596] [ip-0A0C04DA:40430:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.159147] [ip-0A0C04BC:48960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.160335] [ip-0A0C0449:33182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.161771] [ip-0A0C0492:15439:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.160859] [ip-0A0C0489:35977:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.161865] [ip-0A0C0492:15438:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.162089] [ip-0A0C04B1:24201:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.162248] [ip-0A0C0491:17976:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.162238] [ip-0A0C0441:28966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.162508] [ip-0A0C0435:65361:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.162447] [ip-0A0C0491:17988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.162082] [ip-0A0C049F:8775 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.161335] [ip-0A0C04DB:39113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.162583] [ip-0A0C0435:65356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.163427] [ip-0A0C04A7:95020:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.162758] [ip-0A0C04B2:94217:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.163951] [ip-0A0C0488:33833:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.164481] [ip-0A0C048C:16955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.164525] [ip-0A0C04B9:53610:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.164762] [ip-0A0C049F:8784 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.165687] [ip-0A0C04AE:26063:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.165960] [ip-0A0C046B:22544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.166115] [ip-0A0C046B:22541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.166330] [ip-0A0C042D:6975 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.165789] [ip-0A0C0498:30552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.166247] [ip-0A0C0449:33176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.167493] [ip-0A0C04A7:95018:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.166769] [ip-0A0C04D4:43313:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.166946] [ip-0A0C0495:20156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.166941] [ip-0A0C04B6:87506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.167076] [ip-0A0C04B6:87511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.172223] [ip-0A0C04A2:12175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.167270] [ip-0A0C049B:9405 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.172305] [ip-0A0C04A2:12179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.167716] [ip-0A0C0449:33181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.168783] [ip-0A0C0495:20155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.168725] [ip-0A0C0461:97193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.168784] [ip-0A0C0461:97195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.169521] [ip-0A0C0485:98080:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.169316] [ip-0A0C04BD:51064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.169476] [ip-0A0C04B7:88911:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.169898] [ip-0A0C04DA:40429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.170163] [ip-0A0C04DA:40427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.170405] [ip-0A0C0436:35961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.171335] [ip-0A0C0496:2143 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.171182] [ip-0A0C0460:35316:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.172083] [ip-0A0C0492:15440:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.171117] [ip-0A0C049B:9402 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.171583] [ip-0A0C04B9:53619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.171202] [ip-0A0C049B:9404 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.171936] [ip-0A0C04BD:51065:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.173836] [ip-0A0C04A8:26130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.174443] [ip-0A0C04BA:85762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.175178] [ip-0A0C04DB:39111:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.176704] [ip-0A0C04B7:88917:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.182218] [ip-0A0C04A2:12180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.177812] [ip-0A0C04D3:44595:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.178317] [ip-0A0C0435:65350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.177235] [ip-0A0C0484:37711:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.178537] [ip-0A0C04BA:85765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.178931] [ip-0A0C0441:28962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.178663] [ip-0A0C04B5:21344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.178919] [ip-0A0C0460:35318:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.179118] [ip-0A0C0472:37658:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.179618] [ip-0A0C0460:35321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.179710] [ip-0A0C0429:26158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.179957] [ip-0A0C0429:26168:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.179937] [ip-0A0C0461:97196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.180008] [ip-0A0C0461:97222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.180906] [ip-0A0C04AE:26069:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.180664] [ip-0A0C04D9:74265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.182392] [ip-0A0C04AE:26067:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.182080] [ip-0A0C046C:31414:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.182846] [ip-0A0C0473:34180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.184806] [ip-0A0C04AA:93113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.185012] [ip-0A0C04B1:24197:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.184823] [ip-0A0C04CD:43538:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.185500] [ip-0A0C04C6:48710:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.185648] [ip-0A0C0498:30551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.186874] [ip-0A0C0493:17431:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.187094] [ip-0A0C0489:36005:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.187510] [ip-0A0C04B1:24196:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.187330] [ip-0A0C04CD:43540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.187430] [ip-0A0C0464:35677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.191071] [ip-0A0C0495:20154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.190879] [ip-0A0C0429:26156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.191797] [ip-0A0C04B4:30121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.192635] [ip-0A0C048D:21693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.193983] [ip-0A0C04BA:85760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.193941] [ip-0A0C04A5:23307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.194867] [ip-0A0C0495:20159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.193874] [ip-0A0C04DB:39110:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.195949] [ip-0A0C0483:34533:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.196177] [ip-0A0C0483:34528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.197062] [ip-0A0C04B4:30120:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.198003] [ip-0A0C0483:34529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.198402] [ip-0A0C0441:28963:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.197697] [ip-0A0C0484:37708:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.197722] [ip-0A0C0484:37710:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.199085] [ip-0A0C0460:35323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.199377] [ip-0A0C04B7:88910:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.199831] [ip-0A0C04AA:93115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.200064] [ip-0A0C04B7:88915:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.200733] [ip-0A0C04DB:39107:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.201612] [ip-0A0C0429:26161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.201808] [ip-0A0C04C6:48707:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.201302] [ip-0A0C0484:37713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.202721] [ip-0A0C0496:2142 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.202372] [ip-0A0C0460:35319:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.202780] [ip-0A0C048F:25461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.203715] [ip-0A0C0438:36555:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.203455] [ip-0A0C04B7:88913:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.204013] [ip-0A0C04C5:55127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.204166] [ip-0A0C04C5:55110:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.204335] [ip-0A0C0473:34183:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.206388] [ip-0A0C0485:98083:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.206011] [ip-0A0C04DB:39108:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.207811] [ip-0A0C04C6:48733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.207707] [ip-0A0C04DB:39106:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.208871] [ip-0A0C048F:25456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.209830] [ip-0A0C0436:35968:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.209448] [ip-0A0C048F:25459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.210335] [ip-0A0C04C6:48705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.211023] [ip-0A0C0438:36558:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.210903] [ip-0A0C0429:26160:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.210982] [ip-0A0C0429:26157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.211598] [ip-0A0C0441:28964:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.212001] [ip-0A0C0438:36557:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.212160] [ip-0A0C0464:35679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.212043] [ip-0A0C0489:35981:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.212553] [ip-0A0C0483:34531:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.212167] [ip-0A0C0489:35980:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.213774] [ip-0A0C0443:96859:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.214031] [ip-0A0C0464:35678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.214895] [ip-0A0C0496:2146 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.214607] [ip-0A0C0489:35979:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.214834] [ip-0A0C04D3:44597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.215040] [ip-0A0C048D:21672:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.214976] [ip-0A0C046C:31418:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.216227] [ip-0A0C0488:33836:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.217497] [ip-0A0C0441:28960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.216865] [ip-0A0C0498:30557:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.217308] [ip-0A0C044D:33150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.217218] [ip-0A0C0494:17613:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.217697] [ip-0A0C04D3:44592:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.217345] [ip-0A0C044D:33155:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.217795] [ip-0A0C0472:37654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.218015] [ip-0A0C0472:37653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.218907] [ip-0A0C0496:2148 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.219345] [ip-0A0C04C0:52347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.219644] [ip-0A0C04AA:93114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.220558] [ip-0A0C0496:2145 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.220689] [ip-0A0C04C5:55111:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.221167] [ip-0A0C046B:22538:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.220936] [ip-0A0C04CD:43539:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.221139] [ip-0A0C042D:6972 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.221112] [ip-0A0C046C:31413:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.221465] [ip-0A0C0488:33832:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.222016] [ip-0A0C0438:36560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.222097] [ip-0A0C042D:6971 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.222656] [ip-0A0C0435:65352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.223219] [ip-0A0C046B:22542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.223975] [ip-0A0C04CD:43536:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.225026] [ip-0A0C04D3:44590:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.225910] [ip-0A0C04D3:44618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.226962] [ip-0A0C040F:5706 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.227457] [ip-0A0C04D8:46636:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.227603] [ip-0A0C04C5:55116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.228523] [ip-0A0C042D:6973 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.228970] [ip-0A0C0488:33835:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.232233] [ip-0A0C04D8:46638:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.232081] [ip-0A0C044D:33154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.232289] [ip-0A0C0488:33834:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.232036] [ip-0A0C04A8:26131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.232968] [ip-0A0C0441:28959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.233507] [ip-0A0C04D9:74263:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.233659] [ip-0A0C04D9:74262:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.234418] [ip-0A0C0485:98081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.234499] [ip-0A0C0464:35684:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.234530] [ip-0A0C04CD:43542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.235348] [ip-0A0C0473:34176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.235441] [ip-0A0C0473:34178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.235625] [ip-0A0C04CD:43537:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.235966] [ip-0A0C04A5:23300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.236282] [ip-0A0C044D:33152:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.237202] [ip-0A0C0435:65347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.236758] [ip-0A0C048D:21670:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.237347] [ip-0A0C044D:33149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.237614] [ip-0A0C0473:34179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.237672] [ip-0A0C048D:21671:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.239182] [ip-0A0C0435:65346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.239521] [ip-0A0C048D:21673:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.239781] [ip-0A0C040F:5709 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.240245] [ip-0A0C04B5:21341:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.241106] [ip-0A0C0435:65348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.240429] [ip-0A0C04B5:21348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.240644] [ip-0A0C04B2:94223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.241077] [ip-0A0C048C:16931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.240681] [ip-0A0C04B2:94216:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.241495] [ip-0A0C0498:30553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.241762] [ip-0A0C0494:17612:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.243848] [ip-0A0C046B:22540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.243547] [ip-0A0C04B5:21347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.244091] [ip-0A0C0498:30555:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.245063] [ip-0A0C0488:33829:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.245520] [ip-0A0C04D4:43309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.245760] [ip-0A0C04AA:93112:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.246140] [ip-0A0C04AA:93116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.246562] [ip-0A0C046B:22546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.246548] [ip-0A0C048C:16938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.247370] [ip-0A0C0443:96856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.246695] [ip-0A0C0498:30558:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.247093] [ip-0A0C048F:25485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.248447] [ip-0A0C0472:37655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.248859] [ip-0A0C048F:25462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.248692] [ip-0A0C04A8:26129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.249338] [ip-0A0C0436:35965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.250671] [ip-0A0C04B5:21346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.251288] [ip-0A0C04B2:94218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.252213] [ip-0A0C0443:96855:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.252433] [ip-0A0C0472:37659:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.254585] [ip-0A0C04A8:26128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.256346] [ip-0A0C04D4:43315:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.256953] [ip-0A0C0485:98084:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.256879] [ip-0A0C0443:96852:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.257841] [ip-0A0C04A1:38575:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.258854] [ip-0A0C0472:37657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.259611] [ip-0A0C0494:17614:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.259859] [ip-0A0C04B2:94221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.260325] [ip-0A0C04A8:26127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.260740] [ip-0A0C046C:31417:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.261771] [ip-0A0C04B4:30115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.261234] [ip-0A0C046C:31416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.261915] [ip-0A0C046C:31415:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.262678] [ip-0A0C040F:5708 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.262664] [ip-0A0C048C:16932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.264024] [ip-0A0C0436:35964:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.264883] [ip-0A0C040F:5707 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.264888] [ip-0A0C04D9:74261:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.265002] [ip-0A0C04D9:74264:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.266464] [ip-0A0C04B1:24195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.267415] [ip-0A0C0436:35963:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.267623] [ip-0A0C0436:35967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.268160] [ip-0A0C04D9:74259:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.269152] [ip-0A0C048C:16933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.269573] [ip-0A0C040F:5712 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.270893] [ip-0A0C04B9:53608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.273150] [ip-0A0C048C:16936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.272764] [ip-0A0C0494:17611:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.275127] [ip-0A0C04B1:24193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.275450] [ip-0A0C0485:98087:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.277443] [ip-0A0C04C0:52352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.277986] [ip-0A0C0493:17434:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.278237] [ip-0A0C0493:17428:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.282274] [ip-0A0C04C0:52353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.282505] [ip-0A0C0485:98082:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.282468] [ip-0A0C04A5:23299:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.283195] [ip-0A0C04C0:52350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.283175] [ip-0A0C04D4:43316:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.284779] [ip-0A0C04B9:53606:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.286056] [ip-0A0C0494:17616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.286750] [ip-0A0C04A5:23305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.287654] [ip-0A0C04B1:24198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.288533] [ip-0A0C04C0:52348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.288899] [ip-0A0C04A1:38573:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.288614] [ip-0A0C04B9:53611:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.289794] [ip-0A0C04A5:23302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.291582] [ip-0A0C04B1:24218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.291507] [ip-0A0C04B9:53605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.292739] [ip-0A0C04A5:23301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.296102] [ip-0A0C0493:17432:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.300951] [ip-0A0C04A1:38577:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.306876] [ip-0A0C04D4:43311:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.307002] [ip-0A0C04D4:43312:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.312827] [ip-0A0C0493:17427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.314090] [ip-0A0C04A1:38576:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.317763] [ip-0A0C04D4:43310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.324100] [ip-0A0C04A1:38579:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.324252] [ip-0A0C04A1:38578:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.325849] [ip-0A0C04B4:30118:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.327052] [ip-0A0C0493:17433:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.338621] [ip-0A0C04D8:46637:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.352606] [ip-0A0C04D8:46634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.357654] [ip-0A0C04B4:30116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.392507] [ip-0A0C04B4:30114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.393834] [ip-0A0C04B4:30119:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.394958] [ip-0A0C04D8:46633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.396982] [ip-0A0C04B4:30117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.440681] [ip-0A0C04D8:46640:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.440955] [ip-0A0C04D8:46635:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634621812.443482] [ip-0A0C04D8:46639:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634621813327, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634621813369, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634621813370, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634621813370, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634621813370, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634621813370, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634621813371, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:04] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:37:05] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0435:0:65352 - context.c:584] INFO job (ID: 867565172343645546) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:65352 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:65352 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:65346 - context.c:584] INFO job (ID: 867565204562603049) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:65346 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:65346 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:65347 - context.c:584] INFO job (ID: 867564759081438911) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:65347 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:65347 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:65361 - context.c:584] INFO job (ID: 867564688663846998) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:65361 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:65361 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:65349 - context.c:584] INFO job (ID: 867565077443977209) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:65349 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:65349 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:65356 - context.c:584] INFO job (ID: 867564458998116890) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:65356 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:65356 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:65350 - context.c:584] INFO job (ID: 867564587306116209) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:65350 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:65350 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:65348 - context.c:584] INFO job (ID: 867564968030997915) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:65348 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:65348 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906935, "event_type": "POINT_IN_TIME", "key": "seed", "value": 1063394932, "metadata": {"file": "main.py", "lineno": 72}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906935, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906935, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906935, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906935, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906935, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906936, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906936, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906936, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906936, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906936, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621906936, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:26] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:38:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634621930990, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634621930991, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621930996, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634621930996, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621933521, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621933522, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1634621933522, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634621933523, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634621935215, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1985.8691528626994, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621935215, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621935215, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1985.8691528626994, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634621935215, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621935216, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621935891, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4974.380063598425, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621935892, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621935892, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4974.380063598425, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621935892, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621935892, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621936543, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5160.976380051988, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621936544, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621936544, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5160.976380051988, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634621936544, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621936544, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621937177, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5309.269571743091, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621937178, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621937178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5309.269571743091, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634621937178, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621937178, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621937806, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5353.031365661256, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621937806, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621937806, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5353.031365661256, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634621937807, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621937807, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621938435, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5345.764082317914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621938436, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621938436, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5345.764082317914, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634621938436, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621938436, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621939056, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5419.622603198043, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621939057, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621939057, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5419.622603198043, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634621939057, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621939057, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621939680, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5395.361176524187, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621939681, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621939681, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5395.361176524187, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634621939681, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621939681, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621940301, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5417.4371614549, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621940302, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621940302, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5417.4371614549, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634621940302, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621940302, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621940922, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5425.796769900142, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621940922, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621940922, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5425.796769900142, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634621940922, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621940922, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621941539, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5451.111232308276, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621941539, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621941540, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5451.111232308276, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634621941540, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621941540, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621942166, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5370.165713519248, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621942166, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621942166, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5370.165713519248, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634621942166, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621942166, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621942787, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5414.448316732781, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621942788, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621942788, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5414.448316732781, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634621942788, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621942788, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621943415, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5357.086792653652, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621943416, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621943416, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5357.086792653652, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634621943416, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621943416, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621944028, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5488.725059413414, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621944029, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621944029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5488.725059413414, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634621944029, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621944029, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621944644, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5465.213336601196, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621944645, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621944645, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5465.213336601196, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634621944645, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621944645, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621945263, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5434.169645084656, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621945264, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621945264, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5434.169645084656, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634621945264, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621945264, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621945886, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5401.741023584985, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621945887, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621945887, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5401.741023584985, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634621945887, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621945887, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621946498, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5505.86923695708, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621946498, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621946498, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5505.86923695708, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634621946498, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621946498, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621947108, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5513.55493402096, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621947108, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621947108, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5513.55493402096, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634621947108, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621947109, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621947723, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5468.619230885643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621947724, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621947724, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5468.619230885643, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634621947724, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621947724, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621948339, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5463.950459902204, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621948339, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621948340, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5463.950459902204, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634621948340, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621948340, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621948955, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5467.017550257061, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621948955, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621948955, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5467.017550257061, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634621948955, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621948955, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621949567, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5494.839229631016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621949567, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621949567, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5494.839229631016, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634621949568, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621949568, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621950179, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5497.8596017065265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621950179, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621950180, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5497.8596017065265, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634621950180, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621950180, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621950795, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5464.372060200578, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621950795, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621950795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5464.372060200578, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634621950795, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621950796, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621951408, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5488.284731568716, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621951408, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621951408, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5488.284731568716, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634621951409, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621951409, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621952017, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5524.0236203034265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621952017, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621952018, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5524.0236203034265, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634621952018, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621952018, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621952632, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5474.259091581802, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621952632, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621952632, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5474.259091581802, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634621952632, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621952633, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621953244, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5496.543005908851, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621953244, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621953244, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5496.543005908851, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634621953245, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621953245, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621953859, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5472.592476383122, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621953859, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621953859, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5472.592476383122, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634621953859, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621953860, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621954476, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5449.684160377665, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621954477, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621954477, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5449.684160377665, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634621954477, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621954477, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621955082, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5549.932929938939, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621955083, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621955083, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5549.932929938939, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634621955083, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621955083, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621955701, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5444.166301928791, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621955701, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621955701, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5444.166301928791, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634621955701, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621955701, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621956318, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5446.830151765261, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621956319, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621956319, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5446.830151765261, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634621956319, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621956319, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621956935, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.905928153843, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621956936, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621956936, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.905928153843, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634621956936, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621956936, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621957556, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5420.783750028368, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621957556, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621957556, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5420.783750028368, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634621957556, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621957557, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621958167, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5502.5220719953895, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621958168, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621958168, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5502.5220719953895, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634621958168, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621958168, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621958784, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5457.797000331507, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621958784, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621958784, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5457.797000331507, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634621958784, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621958785, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621959401, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5448.165160703703, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621959402, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621959402, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5448.165160703703, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634621959402, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621959402, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621960017, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5462.961331715064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621960018, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621960018, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5462.961331715064, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634621960018, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621960018, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621960621, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5575.210675646379, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621960621, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621960621, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5575.210675646379, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634621960621, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621960622, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621961232, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5502.2256024475055, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621961233, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621961233, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5502.2256024475055, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634621961233, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621961233, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621961845, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5494.807093061339, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621961845, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621961845, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5494.807093061339, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634621961846, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621961846, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621962449, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5571.00119303533, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621962449, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621962450, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5571.00119303533, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634621962450, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621962450, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621963062, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5490.37157087024, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621963062, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621963062, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5490.37157087024, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634621963063, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621963063, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621963676, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5481.391920847503, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621963676, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621963677, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5481.391920847503, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634621963677, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621963677, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621964297, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5421.0861050653975, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621964297, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621964297, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5421.0861050653975, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634621964297, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621964298, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621964911, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5477.867897854814, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621964912, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621964912, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5477.867897854814, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634621964912, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621964912, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621965518, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5549.607290443461, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621965518, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621965518, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5549.607290443461, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634621965591, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621965591, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621965609, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621966037, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8730838298797607, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621966037, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621966187, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5637.988019007644, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621966188, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621966188, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5637.988019007644, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634621966322, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621966322, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621966334, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621966734, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8693108558654785, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621966734, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621966941, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5427.510249133373, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621966942, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621966942, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5427.510249133373, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634621967042, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621967042, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621967058, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621967457, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8666561841964722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621967457, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621967657, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5468.971514345277, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621967657, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621967657, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5468.971514345277, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634621967693, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621967693, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621967708, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621968111, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8991274833679199, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621968111, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621968291, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5618.005156034422, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621968291, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621968292, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5618.005156034422, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634621968326, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621968327, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621968343, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621968755, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8883260488510132, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621968755, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621968940, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5478.210726405523, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621968940, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621968940, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5478.210726405523, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634621968976, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621968976, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621968990, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621969390, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8936670422554016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621969390, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621969576, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5602.271556018099, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621969576, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621969576, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5602.271556018099, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634621969612, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621969612, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621969629, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621970027, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8906153440475464, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621970027, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621970208, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5640.400215004101, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621970209, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621970209, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5640.400215004101, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634621970244, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621970244, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621970260, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621970671, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8922232389450073, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621970671, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621970850, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5547.215339797342, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621970850, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621970850, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5547.215339797342, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634621970886, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621970887, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621970902, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621971320, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8610695600509644, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621971320, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621971502, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5459.714765549183, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621971503, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621971503, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5459.714765549183, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634621971540, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621971540, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621971555, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621971958, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8943648338317871, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621971958, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621972145, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5560.022614321272, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621972145, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621972145, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5560.022614321272, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634621972186, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621972186, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621972202, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621972637, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8733377456665039, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621972637, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621972829, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5232.193711504405, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621972829, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621972829, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5232.193711504405, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634621972891, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621972892, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621972906, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621973305, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.879321277141571, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621973306, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621973485, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5664.094336854755, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621973485, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621973485, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5664.094336854755, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634621973521, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621973521, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621973537, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621973937, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9021483659744263, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621973937, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621974118, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5626.865418253934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621974119, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621974119, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5626.865418253934, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634621974220, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621974220, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621974236, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621974637, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8873655200004578, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621974637, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621974829, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5516.669344193759, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621974829, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621974830, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5516.669344193759, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634621974906, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621974906, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621974921, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621975324, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8813594579696655, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621975324, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621975515, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5517.204954062641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621975516, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621975516, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5517.204954062641, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634621975580, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621975580, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621975595, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621976004, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.40190115571022034, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621976004, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621976185, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5561.367605553766, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621976185, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621976185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5561.367605553766, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634621976214, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621976214, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621976228, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621976734, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.634878396987915, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621976734, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621976938, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4642.796787929203, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621976938, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621976938, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4642.796787929203, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634621976991, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621976991, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621977006, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621977432, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7160892486572266, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621977432, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621977623, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5316.482025904005, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621977624, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621977624, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5316.482025904005, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634621977675, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621977675, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621977690, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621978089, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8034096956253052, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621978089, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621978269, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5660.5861955530245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621978269, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621978269, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5660.5861955530245, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634621978307, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621978307, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621978321, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621978720, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8455829620361328, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621978720, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621978907, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5599.773924735882, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621978907, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621978907, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5599.773924735882, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634621978943, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621978943, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621978958, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621979359, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7879787683486938, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621979359, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621979543, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5601.6012954600465, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621979543, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621979544, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5601.6012954600465, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634621979607, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621979607, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621979622, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621980052, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8721206188201904, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621980052, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621980237, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5341.480794472064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621980237, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621980237, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5341.480794472064, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634621980392, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621980393, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621980405, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621980804, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8799477815628052, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621980804, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621981016, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5393.985851412658, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621981016, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621981016, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5393.985851412658, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634621981084, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621981084, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621981099, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621981544, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8812057375907898, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621981544, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621981755, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5014.118313435109, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621981755, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621981755, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5014.118313435109, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634621981791, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621981791, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621981807, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621982228, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8638445734977722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621982228, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621982412, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5413.223344423899, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621982412, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621982412, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5413.223344423899, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634621982448, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621982449, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621982466, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621982862, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8660682439804077, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621982863, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621983042, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5663.841660048806, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621983043, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621983043, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5663.841660048806, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634621983127, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621983127, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621983141, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621983582, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8862518668174744, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621983582, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621983785, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5110.99985166966, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621983785, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621983785, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5110.99985166966, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634621983868, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621983869, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621983883, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621984298, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8687876462936401, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621984298, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621984530, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5082.688336859356, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621984531, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621984531, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5082.688336859356, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634621984568, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621984568, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621984584, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621985030, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8426908254623413, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621985030, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621985266, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4817.220833104029, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621985266, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621985266, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4817.220833104029, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634621985322, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621985323, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621985337, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621985749, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8913830518722534, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621985750, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621985936, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5477.623046588044, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621985937, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621985937, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5477.623046588044, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634621986050, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621986051, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621986065, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621986466, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8891222476959229, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621986466, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621986657, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5539.738250395643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621986658, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621986658, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5539.738250395643, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634621986720, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621986721, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621986736, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621987180, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8780999183654785, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621987180, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621987384, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5067.737630074889, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621987384, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621987384, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5067.737630074889, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634621987421, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621987421, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621987437, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621987836, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9004361629486084, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621987836, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621988015, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5657.077855531752, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621988016, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621988016, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5657.077855531752, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634621988051, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621988051, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621988067, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621988467, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.885871171951294, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621988467, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621988654, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5570.578392441679, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621988655, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621988655, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5570.578392441679, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634621988725, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621988725, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621988740, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621989153, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8973053693771362, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621989154, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621989345, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5420.187479639963, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621989346, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621989346, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5420.187479639963, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634621989381, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621989382, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621989398, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621989795, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8859216570854187, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621989795, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621989969, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5719.939557101127, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621989970, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621989970, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5719.939557101127, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634621990005, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621990005, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621990023, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621990420, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8785287141799927, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621990421, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621990606, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5590.66601501755, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621990606, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621990607, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5590.66601501755, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634621990680, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621990680, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621990695, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621991118, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8924180865287781, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621991118, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621991311, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5325.1785745324505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621991311, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621991311, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5325.1785745324505, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634621991371, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621991372, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621991386, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621991816, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.893966555595398, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621991817, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621992008, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5280.41059689497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621992009, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621992009, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5280.41059689497, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634621992128, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621992129, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621992143, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621992542, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8924553394317627, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621992542, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621992750, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5411.552120444602, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621992750, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621992750, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5411.552120444602, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634621992869, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621992869, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621992884, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621993282, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9011365175247192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621993282, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621993497, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5354.426569584673, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621993497, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621993497, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5354.426569584673, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634621993532, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621993533, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621993547, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621993947, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.901860237121582, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621993947, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621994129, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5637.942908715874, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621994129, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621994129, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5637.942908715874, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634621994164, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621994165, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621994181, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621994579, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8900384902954102, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621994579, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621994773, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5521.5325194938305, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621994774, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621994774, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5521.5325194938305, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634621994809, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621994809, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621994826, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621995231, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9016377925872803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621995231, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621995419, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5514.105041740617, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621995419, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621995419, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5514.105041740617, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634621995552, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621995552, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621995567, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621995965, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8927627801895142, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621995965, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621996177, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5376.79171814087, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621996178, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621996178, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5376.79171814087, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634621996248, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621996248, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621996262, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621996784, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8803219199180603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621996785, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621997021, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4350.174910050846, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621997021, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621997022, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4350.174910050846, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634621997075, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621997076, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621997090, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621997501, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8906261920928955, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621997501, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621997688, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5491.137428238119, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621997688, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621997688, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5491.137428238119, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634621997748, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621997748, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621997763, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621998181, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.893635630607605, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621998181, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621998357, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5520.089964289254, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621998358, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621998358, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5520.089964289254, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634621998393, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621998393, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621998408, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621998822, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8955012559890747, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621998823, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621999007, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5474.697171644108, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621999007, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621999007, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5474.697171644108, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634621999064, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621999064, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621999079, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621999486, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8974762558937073, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621999486, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621999669, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5556.924809450768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634621999670, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634621999670, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5556.924809450768, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634621999705, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621999705, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634621999723, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634622000133, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9044185280799866, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634622000133, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634622000317, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5494.577863101674, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622000317, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622000317, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5494.577863101674, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634622000406, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622000406, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622000421, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634622000820, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8942553997039795, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634622000820, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634622001009, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5578.00434275636, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622001009, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622001009, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5578.00434275636, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634622001054, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622001054, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622001069, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634622001497, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8859511613845825, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634622001497, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634622001677, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5393.5915557103435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622001678, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622001678, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5393.5915557103435, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634622001804, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622001805, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622001819, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634622002218, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8931669592857361, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634622002218, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634622002419, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5473.436286058504, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622002420, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622002420, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5473.436286058504, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634622002491, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622002492, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622002506, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634622002917, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8889725208282471, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634622002918, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634622003116, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5381.982626867177, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622003117, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622003117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5381.982626867177, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634622003179, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622003179, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622003194, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634622003634, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8959693908691406, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634622003634, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634622003829, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5171.310828082039, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622003830, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622003830, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5171.310828082039, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634622003864, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622003865, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622003881, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634622004280, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8960694670677185, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634622004280, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634622004458, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5670.327331544197, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622004458, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622004458, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5670.327331544197, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634622004509, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622004509, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622004524, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634622004949, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9097427129745483, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634622004949, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634622004949, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634622005120, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5500.5140082409, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622005121, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622005121, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5500.5140082409, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
ENDING TIMING RUN AT 2021-10-19 05:40:11 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:11 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:11 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:11 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:11 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:11 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:11 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:11 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:11 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:11 AM
RESULT,image_segmentation,,205,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:12 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:12 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:12 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:12 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:12 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:12 AM
RESULT,image_segmentation,,206,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:13 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:13 AM
RESULT,image_segmentation,,207,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:14 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,208,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:15 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:17 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:17 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:18 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:19 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:20 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:21 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:22 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:23 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
ENDING TIMING RUN AT 2021-10-19 05:40:24 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:36:46 AM
