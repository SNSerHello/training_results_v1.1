+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019054025191417133
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019054025191417133
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019054025191417133
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019054025191417133
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07385/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019054025191417133_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C0436
Clearing cache on ip-0A0C046C
Clearing cache on ip-0A0C0493
Clearing cache on ip-0A0C0443
Clearing cache on ip-0A0C045F
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C0466
Clearing cache on ip-0A0C046E
Clearing cache on ip-0A0C0499
Clearing cache on ip-0A0C0449
Clearing cache on ip-0A0C0437
Clearing cache on ip-0A0C0473
Clearing cache on ip-0A0C0486
Clearing cache on ip-0A0C0495
Clearing cache on ip-0A0C0435
Clearing cache on ip-0A0C044D
Clearing cache on ip-0A0C0438
Clearing cache on ip-0A0C0460
Clearing cache on ip-0A0C0464
Clearing cache on ip-0A0C0429
Clearing cache on ip-0A0C0484
Clearing cache on ip-0A0C0441
Clearing cache on ip-0A0C0483
Clearing cache on ip-0A0C04A0
Clearing cache on ip-0A0C0496
Clearing cache on ip-0A0C0490
Clearing cache on ip-0A0C0487
Clearing cache on ip-0A0C0489
Clearing cache on ip-0A0C047E
Clearing cache on ip-0A0C04C2
Clearing cache on ip-0A0C04A4
Clearing cache on ip-0A0C04B2
Clearing cache on ip-0A0C048D
Clearing cache on ip-0A0C0498
Clearing cache on ip-0A0C0497
Clearing cache on ip-0A0C0488
Clearing cache on ip-0A0C04B5
Clearing cache on ip-0A0C04A5
Clearing cache on ip-0A0C049C
Clearing cache on ip-0A0C04C7
Clearing cache on ip-0A0C04D9
Clearing cache on ip-0A0C048C
Clearing cache on ip-0A0C04BA
Clearing cache on ip-0A0C04CF
Clearing cache on ip-0A0C0491
Clearing cache on ip-0A0C04AF
Clearing cache on ip-0A0C04C8
Clearing cache on ip-0A0C04B0
Clearing cache on ip-0A0C04BE
Clearing cache on ip-0A0C04C9
Clearing cache on ip-0A0C04A1
Clearing cache on ip-0A0C04BB
Clearing cache on ip-0A0C04AC
Clearing cache on ip-0A0C04DA
Clearing cache on ip-0A0C0485
Clearing cache on ip-0A0C04AA
Clearing cache on ip-0A0C046B
Clearing cache on ip-0A0C0482
Clearing cache on ip-0A0C04AB
Clearing cache on ip-0A0C04B9
Clearing cache on ip-0A0C04A6
Clearing cache on ip-0A0C042D
Clearing cache on ip-0A0C04C4
Clearing cache on ip-0A0C04A8
Clearing cache on ip-0A0C04D3
Clearing cache on ip-0A0C0492
Clearing cache on ip-0A0C048F
Clearing cache on ip-0A0C04AD
Clearing cache on ip-0A0C04B6
Clearing cache on ip-0A0C04B3
Clearing cache on ip-0A0C0494
Clearing cache on ip-0A0C048B
Clearing cache on ip-0A0C04C0
Clearing cache on ip-0A0C04CD
Clearing cache on ip-0A0C049D
Clearing cache on ip-0A0C04DB
Clearing cache on ip-0A0C04A2
Clearing cache on ip-0A0C04B7
Clearing cache on ip-0A0C04CC
Clearing cache on ip-0A0C04A9
Clearing cache on ip-0A0C049F
Clearing cache on ip-0A0C0472
Clearing cache on ip-0A0C04B4
Clearing cache on ip-0A0C04C3
Clearing cache on ip-0A0C04BD
Clearing cache on ip-0A0C04AE
Clearing cache on ip-0A0C049B
Clearing cache on ip-0A0C04D8
Clearing cache on ip-0A0C0461
Clearing cache on ip-0A0C04C6
Clearing cache on ip-0A0C04BC
Clearing cache on ip-0A0C04B1
Clearing cache on ip-0A0C04D4
Clearing cache on ip-0A0C04C5
Clearing cache on ip-0A0C04A7
Clearing cache on ip-0A0C048A
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 05:40:28 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634622033.370241] [ip-0A0C049D:19240:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.378081] [ip-0A0C049D:19246:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.388850] [ip-0A0C0483:36732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.468226] [ip-0A0C0483:36730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.478052] [ip-0A0C0483:36734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.486837] [ip-0A0C0488:36069:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.488184] [ip-0A0C0492:17628:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.487568] [ip-0A0C0441:31171:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.493192] [ip-0A0C04C8:50009:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.499910] [ip-0A0C040F:7938 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.503068] [ip-0A0C049B:11680:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.507802] [ip-0A0C0466:40554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.510362] [ip-0A0C049C:9842 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.513182] [ip-0A0C04B0:9364 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.514862] [ip-0A0C048B:20721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.516319] [ip-0A0C0492:17624:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.517215] [ip-0A0C049D:19245:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.519904] [ip-0A0C040F:7937 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.520491] [ip-0A0C046E:39844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.520288] [ip-0A0C049B:11684:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.523263] [ip-0A0C042D:9188 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.523873] [ip-0A0C04C9:48908:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.523972] [ip-0A0C049D:19244:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.527630] [ip-0A0C0483:36737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.527473] [ip-0A0C049F:11045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.532405] [ip-0A0C04AD:97509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.533069] [ip-0A0C0497:70372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.533411] [ip-0A0C04B7:91130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.542451] [ip-0A0C04AF:14723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.543857] [ip-0A0C0483:36731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.543872] [ip-0A0C046C:33607:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.543739] [ip-0A0C0497:70371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.544987] [ip-0A0C0488:36070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.547668] [ip-0A0C0496:4594 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.547970] [ip-0A0C0443:1269 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.550406] [ip-0A0C049D:19242:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.551496] [ip-0A0C0492:17626:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.550718] [ip-0A0C04AD:97513:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.551456] [ip-0A0C049F:11042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.553518] [ip-0A0C04B0:9368 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.560035] [ip-0A0C0435:68205:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.559972] [ip-0A0C049C:9838 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.561435] [ip-0A0C0496:4595 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.561399] [ip-0A0C0487:37773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.561683] [ip-0A0C0488:36071:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.562208] [ip-0A0C048A:34642:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.565481] [ip-0A0C04BC:51176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.567913] [ip-0A0C049D:19243:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.569328] [ip-0A0C046E:39850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.570635] [ip-0A0C0464:37927:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.574194] [ip-0A0C0495:22354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.574118] [ip-0A0C0499:24456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.575240] [ip-0A0C0483:36735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.575544] [ip-0A0C04BC:51175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.576515] [ip-0A0C040F:7935 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.576351] [ip-0A0C049D:19239:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.576984] [ip-0A0C049D:19241:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.579796] [ip-0A0C0441:31170:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.583843] [ip-0A0C0435:68202:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.584925] [ip-0A0C042D:9192 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.585074] [ip-0A0C042D:9186 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.587125] [ip-0A0C047E:34844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.587242] [ip-0A0C0449:35415:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.587471] [ip-0A0C0460:37561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.587268] [ip-0A0C0449:35416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.591694] [ip-0A0C04C0:54583:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.591877] [ip-0A0C04B7:91132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.592607] [ip-0A0C04AD:97511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.594616] [ip-0A0C045F:35958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.595567] [ip-0A0C048A:34647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.596200] [ip-0A0C0466:40547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.598318] [ip-0A0C0460:37568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.598941] [ip-0A0C044D:35371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.600025] [ip-0A0C04C9:48905:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.601913] [ip-0A0C04CC:49489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.602976] [ip-0A0C0483:36736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.603863] [ip-0A0C0466:40551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.605951] [ip-0A0C0441:31168:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.605887] [ip-0A0C044D:35369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.606308] [ip-0A0C0441:31172:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.607095] [ip-0A0C0483:36733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.608835] [ip-0A0C04C8:50008:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.613244] [ip-0A0C04AB:13456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.613109] [ip-0A0C04A8:28363:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.615107] [ip-0A0C04C8:50007:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.614360] [ip-0A0C049B:11678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.615986] [ip-0A0C042D:9187 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.616011] [ip-0A0C048B:20722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.616140] [ip-0A0C04B5:23597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.617258] [ip-0A0C046E:39847:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.617229] [ip-0A0C046C:33611:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.617779] [ip-0A0C04BE:55796:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.618411] [ip-0A0C04C2:77803:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.618693] [ip-0A0C04B1:26389:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.618644] [ip-0A0C0461:1610 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.619137] [ip-0A0C0472:39887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.619589] [ip-0A0C0437:34542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.619636] [ip-0A0C0437:34539:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.620281] [ip-0A0C04C2:77801:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.619984] [ip-0A0C049C:9846 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.622116] [ip-0A0C04BA:87965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.622798] [ip-0A0C04B6:89706:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.623969] [ip-0A0C0488:36066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.626672] [ip-0A0C0490:24070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.627288] [ip-0A0C04B3:30590:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.628618] [ip-0A0C047E:34838:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.628132] [ip-0A0C0482:25571:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.628674] [ip-0A0C04A5:25521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.629282] [ip-0A0C048A:34645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.629098] [ip-0A0C0489:38205:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.632283] [ip-0A0C04D3:47386:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.634207] [ip-0A0C0491:20181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.635267] [ip-0A0C04A6:22568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.634844] [ip-0A0C049F:11046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.636102] [ip-0A0C04B0:9392 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.637802] [ip-0A0C042D:9191 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.638244] [ip-0A0C0466:40552:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.638333] [ip-0A0C045F:35957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.638117] [ip-0A0C0499:24451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.639992] [ip-0A0C0436:38211:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.641639] [ip-0A0C0435:68207:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.641400] [ip-0A0C04A4:23183:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.642220] [ip-0A0C04CC:49490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.642448] [ip-0A0C04B1:26387:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.643206] [ip-0A0C0495:22351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.642771] [ip-0A0C04CF:78713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.643241] [ip-0A0C04A5:25518:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.644623] [ip-0A0C0492:17630:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.644448] [ip-0A0C0485:2583 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.644332] [ip-0A0C048B:20719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.644710] [ip-0A0C0495:22348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.646068] [ip-0A0C0472:39884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.646308] [ip-0A0C04C5:57324:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.646361] [ip-0A0C04C5:57320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.646275] [ip-0A0C0484:39933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.647270] [ip-0A0C0488:36068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.647938] [ip-0A0C04C8:50010:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.647965] [ip-0A0C0464:37933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.650115] [ip-0A0C048A:34649:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.651979] [ip-0A0C04B3:30594:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.651863] [ip-0A0C0460:37563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.652686] [ip-0A0C0488:36065:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.652009] [ip-0A0C0484:39927:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.653002] [ip-0A0C0472:39891:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.653071] [ip-0A0C0487:37774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.652813] [ip-0A0C0493:19624:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.655107] [ip-0A0C04D8:49428:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.656846] [ip-0A0C04C9:48904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.657278] [ip-0A0C0490:24065:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.656811] [ip-0A0C049B:11682:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.658364] [ip-0A0C0461:1613 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.658470] [ip-0A0C04A8:28339:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.661797] [ip-0A0C0485:2584 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.662297] [ip-0A0C0487:37771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.662603] [ip-0A0C049F:11040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.663634] [ip-0A0C0496:4605 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.663677] [ip-0A0C04B7:91131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.664035] [ip-0A0C048D:23891:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.664574] [ip-0A0C04AF:14721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.665034] [ip-0A0C04C9:48909:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.665596] [ip-0A0C0443:1268 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.667745] [ip-0A0C045F:35960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.668068] [ip-0A0C0443:1270 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.668142] [ip-0A0C040F:7934 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.668025] [ip-0A0C04BB:95354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.668803] [ip-0A0C04B4:32329:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.668870] [ip-0A0C0464:37930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.668443] [ip-0A0C049B:11683:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.669446] [ip-0A0C0461:1607 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.669680] [ip-0A0C04AF:14720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.670525] [ip-0A0C0441:31173:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.671297] [ip-0A0C0466:40549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.671457] [ip-0A0C0436:38210:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.671861] [ip-0A0C04D9:76483:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.671600] [ip-0A0C04B2:96447:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.671884] [ip-0A0C04D9:76482:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.673168] [ip-0A0C04A0:12345:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.674341] [ip-0A0C040F:7932 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.674955] [ip-0A0C04B4:32334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.675769] [ip-0A0C0438:38808:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.676210] [ip-0A0C0441:31194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.677056] [ip-0A0C048B:20718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.679487] [ip-0A0C04A6:22572:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.678267] [ip-0A0C04BC:51170:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.680230] [ip-0A0C0492:17631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.679605] [ip-0A0C04A8:28338:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.680349] [ip-0A0C04C8:50011:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.680205] [ip-0A0C048B:20716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.680697] [ip-0A0C046E:39848:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.682599] [ip-0A0C04A4:23185:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.683648] [ip-0A0C04AD:97510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.683983] [ip-0A0C04B0:9369 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.683860] [ip-0A0C04CF:78718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.683513] [ip-0A0C04DB:41882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.684334] [ip-0A0C0482:25569:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.684715] [ip-0A0C04BB:95359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.685465] [ip-0A0C046C:33610:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.685405] [ip-0A0C04AA:95312:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.686029] [ip-0A0C04B0:9365 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.686332] [ip-0A0C0499:24454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.687124] [ip-0A0C0487:37776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.687617] [ip-0A0C04CC:49485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.687813] [ip-0A0C0493:19621:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.689182] [ip-0A0C0437:34545:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.688643] [ip-0A0C049C:9840 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.689704] [ip-0A0C0488:36067:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.690217] [ip-0A0C0464:37931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.690417] [ip-0A0C0488:36064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.690623] [ip-0A0C049C:9843 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.693975] [ip-0A0C04AB:13453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.693943] [ip-0A0C04DA:43224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.693884] [ip-0A0C04B7:91136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.694378] [ip-0A0C04D4:46093:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.694450] [ip-0A0C0497:70368:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.694636] [ip-0A0C0497:70375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.695672] [ip-0A0C04C0:54582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.701139] [ip-0A0C04A2:14384:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.696287] [ip-0A0C04AB:13451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.696373] [ip-0A0C04B7:91135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.697718] [ip-0A0C045F:35980:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.698180] [ip-0A0C046E:39849:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.697822] [ip-0A0C0499:24452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.698670] [ip-0A0C0443:1274 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.698282] [ip-0A0C04BE:55795:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.698499] [ip-0A0C04B9:55822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.698912] [ip-0A0C046C:33608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.699277] [ip-0A0C04AE:28276:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.699700] [ip-0A0C049B:11677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.700562] [ip-0A0C04C8:50012:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.699886] [ip-0A0C049B:11681:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.700756] [ip-0A0C0441:31169:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.700969] [ip-0A0C0441:31167:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.700997] [ip-0A0C046E:39851:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.700938] [ip-0A0C0489:38204:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.701450] [ip-0A0C04D9:76478:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.701997] [ip-0A0C048B:20717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.702672] [ip-0A0C0495:22352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.702183] [ip-0A0C0497:70373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.702580] [ip-0A0C0460:37567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.702769] [ip-0A0C0493:19618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.703361] [ip-0A0C04C8:50006:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.703175] [ip-0A0C04C3:54074:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.703398] [ip-0A0C04B6:89705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.704964] [ip-0A0C0492:17625:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.704890] [ip-0A0C040F:7936 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.705568] [ip-0A0C04A0:12344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.705035] [ip-0A0C049C:9847 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.705772] [ip-0A0C049B:11679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.707291] [ip-0A0C0492:17627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.706986] [ip-0A0C04AD:97508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.707039] [ip-0A0C04AD:97512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.707574] [ip-0A0C04AF:14717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.708337] [ip-0A0C040F:7939 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.708611] [ip-0A0C04C9:48902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.708759] [ip-0A0C04CD:46333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.709242] [ip-0A0C04AF:14722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.709968] [ip-0A0C04A6:22567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.708877] [ip-0A0C04C6:50935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.710014] [ip-0A0C0492:17629:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.711446] [ip-0A0C04C8:50013:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.711347] [ip-0A0C049F:11047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.711478] [ip-0A0C048B:20720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.711588] [ip-0A0C048D:23893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.711528] [ip-0A0C049C:9844 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.712760] [ip-0A0C042D:9190 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.712900] [ip-0A0C04C9:48906:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.712865] [ip-0A0C042D:9189 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.714054] [ip-0A0C0449:35414:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.715338] [ip-0A0C048C:19139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.715493] [ip-0A0C0491:20178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.715755] [ip-0A0C046E:39845:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.716182] [ip-0A0C048B:20715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.715815] [ip-0A0C04DB:41885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.717188] [ip-0A0C0435:68203:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.716776] [ip-0A0C04BE:55794:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.717553] [ip-0A0C046E:39846:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.717258] [ip-0A0C0449:35417:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.717745] [ip-0A0C046C:33613:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.718435] [ip-0A0C04D8:49426:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.718510] [ip-0A0C0466:40558:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.719922] [ip-0A0C04D3:47388:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.719762] [ip-0A0C04B2:96446:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.719404] [ip-0A0C04BC:51169:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.719656] [ip-0A0C0497:70374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.720607] [ip-0A0C042D:9185 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.720991] [ip-0A0C0491:20185:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.721186] [ip-0A0C049C:9839 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.722127] [ip-0A0C0466:40550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.722356] [ip-0A0C040F:7933 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.722677] [ip-0A0C047E:34841:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.722325] [ip-0A0C0466:40548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.723474] [ip-0A0C04A0:12338:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.723376] [ip-0A0C049F:11043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.723191] [ip-0A0C0497:70369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.724112] [ip-0A0C04BA:87966:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.724735] [ip-0A0C04B0:9362 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.723908] [ip-0A0C04BC:51173:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.725803] [ip-0A0C04AD:97506:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.725872] [ip-0A0C0429:28391:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.726237] [ip-0A0C04BA:87967:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.726776] [ip-0A0C04C0:54586:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.727024] [ip-0A0C04B0:9363 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.726950] [ip-0A0C04B5:23591:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.728000] [ip-0A0C04B0:9367 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.728170] [ip-0A0C0437:34540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.727506] [ip-0A0C0497:70370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.727546] [ip-0A0C0494:19810:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.727744] [ip-0A0C04B7:91134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.728183] [ip-0A0C04D8:49427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.728105] [ip-0A0C046C:33625:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.727557] [ip-0A0C0494:19813:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.727925] [ip-0A0C04B7:91129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.728976] [ip-0A0C04A1:40765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.728549] [ip-0A0C04C6:50936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.728984] [ip-0A0C04A1:40761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.729156] [ip-0A0C04C9:48907:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.729451] [ip-0A0C04BD:53272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.729693] [ip-0A0C046C:33609:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.730377] [ip-0A0C04B6:89701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.731050] [ip-0A0C04C9:48903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.731005] [ip-0A0C04B7:91133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.731937] [ip-0A0C048D:23897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.733255] [ip-0A0C04AB:13455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.733236] [ip-0A0C04D3:47391:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.733748] [ip-0A0C048A:34648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.734196] [ip-0A0C0486:37857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.734178] [ip-0A0C0486:37854:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.734165] [ip-0A0C046B:25319:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.734374] [ip-0A0C0490:24064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.734700] [ip-0A0C04AF:14718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.735948] [ip-0A0C0438:38804:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.736048] [ip-0A0C0482:25572:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.736699] [ip-0A0C0437:34541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.736589] [ip-0A0C04BD:53268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.736904] [ip-0A0C04AD:97507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.737301] [ip-0A0C044D:35370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.737797] [ip-0A0C04DA:43228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.738051] [ip-0A0C0436:38205:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.737749] [ip-0A0C0460:37566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.738425] [ip-0A0C049F:11044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.738669] [ip-0A0C049F:11041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.739450] [ip-0A0C0496:4597 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.739721] [ip-0A0C046C:33612:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.740574] [ip-0A0C048C:19137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.740373] [ip-0A0C04A9:21947:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.741943] [ip-0A0C04AA:95310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.741857] [ip-0A0C04BC:51171:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.743335] [ip-0A0C04CC:49488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.744204] [ip-0A0C0496:4596 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.743768] [ip-0A0C04D8:49424:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.743911] [ip-0A0C0495:22350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.743931] [ip-0A0C04C4:55443:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.743397] [ip-0A0C0484:39928:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.744777] [ip-0A0C0435:68218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.744330] [ip-0A0C044D:35367:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.744429] [ip-0A0C04BE:55800:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.743929] [ip-0A0C04C4:55444:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.744977] [ip-0A0C0443:1267 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.744727] [ip-0A0C0498:32763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.746017] [ip-0A0C0443:1271 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.745119] [ip-0A0C04BC:51172:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.746400] [ip-0A0C0435:68201:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.746596] [ip-0A0C0435:68200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.747557] [ip-0A0C047E:34845:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.748177] [ip-0A0C04C3:54076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.748503] [ip-0A0C048A:34643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.748250] [ip-0A0C0460:37564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.749367] [ip-0A0C047E:34843:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.750342] [ip-0A0C04AF:14719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.750490] [ip-0A0C0429:28386:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.751123] [ip-0A0C0437:34543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.751285] [ip-0A0C04A4:23187:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.751328] [ip-0A0C04AA:95307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.751645] [ip-0A0C04D3:47390:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.751130] [ip-0A0C04BC:51174:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.752172] [ip-0A0C048A:34644:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.752116] [ip-0A0C04AF:14716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.752878] [ip-0A0C048A:34646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.754087] [ip-0A0C0443:1272 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.756277] [ip-0A0C04B1:26384:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.756358] [ip-0A0C045F:35959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.756857] [ip-0A0C0435:68204:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.757069] [ip-0A0C0443:1273 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.756907] [ip-0A0C048D:23890:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.757362] [ip-0A0C0436:38207:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.757876] [ip-0A0C0461:1609 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.759122] [ip-0A0C04B9:55823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.759648] [ip-0A0C0487:37775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.760422] [ip-0A0C0472:39883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.760823] [ip-0A0C0487:37772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.760748] [ip-0A0C0499:24455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.761411] [ip-0A0C0487:37783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.761003] [ip-0A0C0489:38208:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.762097] [ip-0A0C0464:37929:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.763713] [ip-0A0C0496:4593 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.763353] [ip-0A0C044D:35368:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.764162] [ip-0A0C0487:37778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.764102] [ip-0A0C0464:37926:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.764169] [ip-0A0C0449:35420:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.764926] [ip-0A0C04AB:13458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.765372] [ip-0A0C04B1:26382:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.765596] [ip-0A0C0464:37935:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.765541] [ip-0A0C0493:19619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.766317] [ip-0A0C04CF:78712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.767771] [ip-0A0C04A6:22573:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.769133] [ip-0A0C04BA:87964:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.771394] [ip-0A0C0486:37853:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.771269] [ip-0A0C0464:37928:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.771752] [ip-0A0C0485:2585 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.771756] [ip-0A0C04CD:46341:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.772227] [ip-0A0C0460:37565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.773715] [ip-0A0C04C6:50932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.775614] [ip-0A0C0496:4600 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.775683] [ip-0A0C0496:4599 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.775137] [ip-0A0C04A8:28340:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.776127] [ip-0A0C04C0:54581:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.776473] [ip-0A0C04A4:23186:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.776640] [ip-0A0C0460:37562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.777588] [ip-0A0C04C2:77800:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.777667] [ip-0A0C04D9:76480:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.777803] [ip-0A0C04BA:87961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.778152] [ip-0A0C04B1:26383:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.777869] [ip-0A0C0482:25573:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.777952] [ip-0A0C04B5:23592:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.778399] [ip-0A0C0473:36377:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.778762] [ip-0A0C0491:20182:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.778678] [ip-0A0C04A5:25519:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.779120] [ip-0A0C0499:24457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.779692] [ip-0A0C04BB:95358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.779965] [ip-0A0C04D4:46092:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.782079] [ip-0A0C045F:35955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.782126] [ip-0A0C04CD:46334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.782516] [ip-0A0C0472:39885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.782580] [ip-0A0C0499:24450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.784435] [ip-0A0C04A7:97253:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.783440] [ip-0A0C0499:24453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.784411] [ip-0A0C04A7:97258:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.784627] [ip-0A0C04C0:54584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.784144] [ip-0A0C0429:28384:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.784270] [ip-0A0C04C4:55450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.785119] [ip-0A0C047E:34839:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.785065] [ip-0A0C04DA:43222:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.784873] [ip-0A0C04B5:23596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.785901] [ip-0A0C04C5:57318:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.785985] [ip-0A0C04C5:57322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.786424] [ip-0A0C0461:1615 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.787335] [ip-0A0C0495:22353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.787263] [ip-0A0C04D9:76477:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.787506] [ip-0A0C0495:22347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.787616] [ip-0A0C0495:22349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.787613] [ip-0A0C04BE:55797:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.788181] [ip-0A0C0489:38212:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.788929] [ip-0A0C0437:34564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.789727] [ip-0A0C04C2:77799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.789947] [ip-0A0C04C7:50899:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.790066] [ip-0A0C04B3:30614:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.790308] [ip-0A0C0449:35418:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.790520] [ip-0A0C0449:35413:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.791091] [ip-0A0C0438:38827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.790999] [ip-0A0C04C5:57323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.790812] [ip-0A0C0449:35419:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.791190] [ip-0A0C04B6:89704:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.791191] [ip-0A0C04A8:28337:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.792108] [ip-0A0C04AE:28272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.792048] [ip-0A0C0490:24068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.792628] [ip-0A0C04AB:13450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.798357] [ip-0A0C04A2:14390:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.793278] [ip-0A0C0490:24071:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.793978] [ip-0A0C0491:20184:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.794154] [ip-0A0C044D:35373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.794217] [ip-0A0C044D:35372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.795658] [ip-0A0C04B3:30591:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.795622] [ip-0A0C04CC:49492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.796067] [ip-0A0C04CC:49487:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.796140] [ip-0A0C04CC:49486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.795939] [ip-0A0C04B6:89700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.796395] [ip-0A0C0437:34538:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.795953] [ip-0A0C04B2:96444:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.796509] [ip-0A0C046B:25298:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.795663] [ip-0A0C04DB:41884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.796665] [ip-0A0C04C2:77797:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.796668] [ip-0A0C04A5:25520:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.797510] [ip-0A0C04C0:54585:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.797791] [ip-0A0C04C0:54588:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.797122] [ip-0A0C0484:39932:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.798917] [ip-0A0C04C0:54603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.798940] [ip-0A0C045F:35954:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.799612] [ip-0A0C047E:34870:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.799727] [ip-0A0C047E:34842:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.799466] [ip-0A0C045F:35956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.799955] [ip-0A0C0485:2580 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.799971] [ip-0A0C04B4:32332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.800561] [ip-0A0C04BE:55799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.801557] [ip-0A0C04A5:25515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.801589] [ip-0A0C0461:1620 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.801569] [ip-0A0C04B9:55825:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.801646] [ip-0A0C0461:1608 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.802681] [ip-0A0C04CC:49491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.802792] [ip-0A0C0461:1614 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.803166] [ip-0A0C0436:38212:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.803299] [ip-0A0C04BB:95352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.803374] [ip-0A0C044D:35366:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.803737] [ip-0A0C04B1:26386:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.804559] [ip-0A0C04B6:89702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.804976] [ip-0A0C04D9:76484:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.806801] [ip-0A0C04A9:21943:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.808037] [ip-0A0C04B4:32331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.808273] [ip-0A0C0482:25567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.809027] [ip-0A0C0491:20180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.808798] [ip-0A0C0472:39890:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.809170] [ip-0A0C0489:38209:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.809698] [ip-0A0C04DA:43223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.810916] [ip-0A0C04BA:87963:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.811642] [ip-0A0C04AA:95308:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.811902] [ip-0A0C04C3:54078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.812582] [ip-0A0C0498:32765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.812530] [ip-0A0C0484:39929:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.813631] [ip-0A0C04C5:57319:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.813839] [ip-0A0C04A9:21946:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.814433] [ip-0A0C0472:39888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.815557] [ip-0A0C04D4:46090:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.816020] [ip-0A0C04B1:26385:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.816177] [ip-0A0C04AE:28273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.816628] [ip-0A0C04C2:77802:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.816786] [ip-0A0C04AB:13452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.816999] [ip-0A0C0438:38806:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.817137] [ip-0A0C04A4:23189:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.816713] [ip-0A0C04B2:96445:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.817424] [ip-0A0C04AB:13454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.817365] [ip-0A0C0472:39889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.817933] [ip-0A0C04A5:25522:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.817914] [ip-0A0C04B6:89699:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.818996] [ip-0A0C04A4:23190:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.819555] [ip-0A0C04A6:22571:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.819726] [ip-0A0C04A6:22569:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.819123] [ip-0A0C04D8:49430:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.819228] [ip-0A0C04D3:47385:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.819006] [ip-0A0C0490:24066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.819978] [ip-0A0C04A6:22570:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.819175] [ip-0A0C04B6:89703:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.819388] [ip-0A0C048D:23895:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.824701] [ip-0A0C04A2:14391:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.819483] [ip-0A0C04CF:78716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.819756] [ip-0A0C04BE:55798:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.820427] [ip-0A0C04CF:78715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.821467] [ip-0A0C0490:24067:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.821623] [ip-0A0C0489:38206:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.821355] [ip-0A0C04A8:28336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.822752] [ip-0A0C04B1:26388:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.822843] [ip-0A0C04AC:16353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.823492] [ip-0A0C0485:2586 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.822830] [ip-0A0C04A8:28356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.823320] [ip-0A0C0493:19622:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.822951] [ip-0A0C04A8:28335:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.824101] [ip-0A0C04C5:57321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.824299] [ip-0A0C0491:20183:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.825525] [ip-0A0C04B5:23593:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.826352] [ip-0A0C04AE:28277:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.826233] [ip-0A0C04C5:57317:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.826645] [ip-0A0C0491:20179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.826917] [ip-0A0C04D9:76485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.826821] [ip-0A0C0490:24072:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.827936] [ip-0A0C0493:19617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.827952] [ip-0A0C04BA:87962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.828867] [ip-0A0C04A6:22566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.828602] [ip-0A0C04B3:30616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.828350] [ip-0A0C04BA:87960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.828577] [ip-0A0C04D9:76481:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.829131] [ip-0A0C04A0:12339:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.828369] [ip-0A0C04B9:55827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.829632] [ip-0A0C048D:23896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.829616] [ip-0A0C04BE:55793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.830188] [ip-0A0C0436:38209:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.830137] [ip-0A0C0489:38231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.830226] [ip-0A0C04B5:23595:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.830234] [ip-0A0C04B5:23598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.830760] [ip-0A0C04A5:25516:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.831861] [ip-0A0C04B3:30593:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.831926] [ip-0A0C0489:38207:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.833033] [ip-0A0C0436:38206:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.832802] [ip-0A0C04A5:25523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.832711] [ip-0A0C048F:27659:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.833441] [ip-0A0C0482:25574:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.833496] [ip-0A0C04C6:50933:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.833898] [ip-0A0C04D8:49432:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.833845] [ip-0A0C0482:25568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.834842] [ip-0A0C04C2:77804:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.835273] [ip-0A0C04C2:77798:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.836589] [ip-0A0C046B:25294:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.836900] [ip-0A0C04D8:49429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.837463] [ip-0A0C0473:36375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.838298] [ip-0A0C04A1:40762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.838733] [ip-0A0C04A4:23184:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.837682] [ip-0A0C0484:39926:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.839014] [ip-0A0C04D3:47389:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.840018] [ip-0A0C0485:2579 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.840661] [ip-0A0C04D8:49425:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.841136] [ip-0A0C04D3:47384:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.841917] [ip-0A0C0482:25570:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.842313] [ip-0A0C046B:25296:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.843052] [ip-0A0C04BB:95353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.843505] [ip-0A0C04B4:32333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.844375] [ip-0A0C0436:38208:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.844125] [ip-0A0C04D3:47387:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.845139] [ip-0A0C04B3:30592:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.845257] [ip-0A0C04B3:30589:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.845208] [ip-0A0C04D4:46094:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.845607] [ip-0A0C04B2:96442:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.847201] [ip-0A0C04A4:23188:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.847130] [ip-0A0C048C:19132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.847389] [ip-0A0C04B5:23594:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.848776] [ip-0A0C04CF:78719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.849248] [ip-0A0C048D:23894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.849759] [ip-0A0C04B4:32330:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.849407] [ip-0A0C048D:23892:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.849886] [ip-0A0C04CD:46340:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.850747] [ip-0A0C0485:2578 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.850281] [ip-0A0C04B9:55829:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.851009] [ip-0A0C0485:2587 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.851061] [ip-0A0C0493:19623:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.851748] [ip-0A0C04CD:46339:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.852003] [ip-0A0C04C4:55448:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.851282] [ip-0A0C0484:39931:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.852386] [ip-0A0C0484:39930:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.855281] [ip-0A0C048C:19134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.857176] [ip-0A0C0438:38805:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.857816] [ip-0A0C04A1:40757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.857753] [ip-0A0C04DA:43226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.858687] [ip-0A0C04D4:46088:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.858709] [ip-0A0C0493:19620:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.859196] [ip-0A0C04AC:16354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.859715] [ip-0A0C04B4:32328:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.860121] [ip-0A0C04A0:12341:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.858926] [ip-0A0C04DB:41883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.858988] [ip-0A0C04DB:41889:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.860772] [ip-0A0C04CF:78717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.866646] [ip-0A0C04A2:14385:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.861494] [ip-0A0C0498:32771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.862868] [ip-0A0C04BB:95357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.863721] [ip-0A0C04B4:32335:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.865990] [ip-0A0C04BD:53266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.867404] [ip-0A0C0486:37855:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.869388] [ip-0A0C04A1:40759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.869208] [ip-0A0C04CF:78714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.869581] [ip-0A0C0429:28389:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.871776] [ip-0A0C04A0:12342:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.872356] [ip-0A0C04DA:43225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.873574] [ip-0A0C046B:25300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.875491] [ip-0A0C04C7:50901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.875164] [ip-0A0C04B9:55828:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.875101] [ip-0A0C0494:19814:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.876606] [ip-0A0C04A7:97255:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.876967] [ip-0A0C048F:27660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.877076] [ip-0A0C04B2:96448:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.878313] [ip-0A0C04A0:12343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.878094] [ip-0A0C04BB:95356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.884360] [ip-0A0C04A2:14388:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.878815] [ip-0A0C0494:19812:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.879204] [ip-0A0C04DB:41886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.881022] [ip-0A0C04A0:12340:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.881676] [ip-0A0C04AC:16351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.881616] [ip-0A0C048C:19135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.882482] [ip-0A0C04AE:28278:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.882596] [ip-0A0C04AE:28275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.883545] [ip-0A0C04D4:46089:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.883078] [ip-0A0C04B2:96441:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.883722] [ip-0A0C04AA:95306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.883826] [ip-0A0C04AA:95311:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.884740] [ip-0A0C04BB:95355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.885097] [ip-0A0C04DA:43221:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.886719] [ip-0A0C04DA:43227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.886956] [ip-0A0C04AA:95305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.887280] [ip-0A0C04AA:95309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.887464] [ip-0A0C04C3:54097:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.888444] [ip-0A0C04BD:53273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.888619] [ip-0A0C04BD:53270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.890708] [ip-0A0C0498:32761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.891300] [ip-0A0C04DB:41887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.893365] [ip-0A0C04A7:97254:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.897771] [ip-0A0C04A2:14389:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.893522] [ip-0A0C04C3:54073:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.893657] [ip-0A0C04C4:55449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.894293] [ip-0A0C04C3:54071:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.894583] [ip-0A0C0438:38807:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.894835] [ip-0A0C0438:38810:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.894814] [ip-0A0C04B9:55826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.894308] [ip-0A0C04DB:41888:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.894883] [ip-0A0C04C6:50951:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.895419] [ip-0A0C04AE:28274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.895594] [ip-0A0C0429:28388:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.896350] [ip-0A0C04D4:46087:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.897745] [ip-0A0C0486:37852:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.897590] [ip-0A0C0438:38809:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.897372] [ip-0A0C04B2:96443:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.897659] [ip-0A0C04B9:55824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.897747] [ip-0A0C04C6:50938:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.900624] [ip-0A0C04AE:28271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.901368] [ip-0A0C0473:36371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.902357] [ip-0A0C04A7:97256:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.902628] [ip-0A0C048C:19136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.902832] [ip-0A0C04D4:46091:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.903383] [ip-0A0C04C6:50934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.905815] [ip-0A0C04BD:53271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.907126] [ip-0A0C04C6:50937:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.907329] [ip-0A0C04C3:54072:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.908315] [ip-0A0C048C:19133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.908297] [ip-0A0C04CD:46335:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.908469] [ip-0A0C04CD:46336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.909918] [ip-0A0C0486:37858:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.909954] [ip-0A0C04C4:55445:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.910574] [ip-0A0C04C3:54075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.910533] [ip-0A0C0429:28385:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.911186] [ip-0A0C048C:19138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.912897] [ip-0A0C04CD:46337:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.913891] [ip-0A0C0486:37851:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.918343] [ip-0A0C04A2:14387:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.914143] [ip-0A0C04A7:97257:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.919155] [ip-0A0C04A2:14386:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.916748] [ip-0A0C0486:37856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.916219] [ip-0A0C04A9:21949:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.917579] [ip-0A0C0494:19824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.918594] [ip-0A0C04C7:50900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.919901] [ip-0A0C04C4:55446:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.922227] [ip-0A0C04BD:53267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.922799] [ip-0A0C0429:28392:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.922640] [ip-0A0C0498:32762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.924333] [ip-0A0C04A1:40764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.924459] [ip-0A0C04A1:40758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.924093] [ip-0A0C04C4:55447:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.926044] [ip-0A0C0429:28387:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.925594] [ip-0A0C0498:32764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.928031] [ip-0A0C04A1:40760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.929162] [ip-0A0C04A7:97251:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.929296] [ip-0A0C04A7:97252:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.928629] [ip-0A0C046B:25293:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.928773] [ip-0A0C046B:25297:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.929701] [ip-0A0C04BD:53269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.930389] [ip-0A0C0494:19815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.930538] [ip-0A0C0494:19816:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.931558] [ip-0A0C046B:25295:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.933444] [ip-0A0C0473:36373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.933158] [ip-0A0C0494:19811:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.934577] [ip-0A0C04A9:21942:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.934624] [ip-0A0C04A9:21945:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.941898] [ip-0A0C0473:36376:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.942446] [ip-0A0C04A9:21944:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.942619] [ip-0A0C04A9:21965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.948732] [ip-0A0C0498:32768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.949205] [ip-0A0C0498:32766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.967020] [ip-0A0C0473:36380:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.967041] [ip-0A0C0473:36379:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.975299] [ip-0A0C048F:27656:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.978047] [ip-0A0C0473:36374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.978095] [ip-0A0C048F:27653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.979269] [ip-0A0C04C7:50897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.983974] [ip-0A0C04C7:50895:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.984761] [ip-0A0C048F:27654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.991504] [ip-0A0C04C7:50896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622033.999376] [ip-0A0C04C7:50902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622034.003599] [ip-0A0C04C7:50898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622034.004808] [ip-0A0C04AC:16350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622034.009802] [ip-0A0C04AC:16352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622034.010649] [ip-0A0C048F:27658:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622034.010781] [ip-0A0C048F:27657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622034.011826] [ip-0A0C048F:27655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622034.017204] [ip-0A0C04AC:16348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622034.031237] [ip-0A0C04AC:16347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634622034.031349] [ip-0A0C04AC:16349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634622034917, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634622034957, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634622034957, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634622034958, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634622034958, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634622034958, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634622034958, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:46] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[05:40:47] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0435:0:68202 - context.c:584] INFO job (ID: 867564178183283518) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:68202 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:68202 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:68203 - context.c:584] INFO job (ID: 867564698537966980) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:68203 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:68203 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:68205 - context.c:584] INFO job (ID: 867564795390769234) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:68205 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:68205 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:68204 - context.c:584] INFO job (ID: 867565243366290976) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:68204 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:68204 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:68218 - context.c:584] INFO job (ID: 867565037087676440) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:68218 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:68218 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:68201 - context.c:584] INFO job (ID: 867565068274892941) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:68201 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:68201 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:68207 - context.c:584] INFO job (ID: 867564973441238372) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:68207 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:68207 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:68200 - context.c:584] INFO job (ID: 867564184071838464) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:68200 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:68200 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128028, "event_type": "POINT_IN_TIME", "key": "seed", "value": 865451067, "metadata": {"file": "main.py", "lineno": 72}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128028, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128029, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128029, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128029, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128029, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128029, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128029, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128029, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128029, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128029, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622128029, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[05:42:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634622152161, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634622152178, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622152182, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634622152183, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634622154655, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1634622154656, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1634622154656, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634622154656, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634622156357, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 1975.893309404969, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622156357, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622156358, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 1975.893309404969, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634622156358, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622156358, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622157027, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5024.705349636362, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622157027, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622157027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5024.705349636362, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622157027, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622157027, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622157671, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5220.6069640388405, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622157672, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622157672, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5220.6069640388405, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634622157672, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622157672, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622158302, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5330.375092950582, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622158303, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622158303, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5330.375092950582, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634622158303, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622158303, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622158940, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5281.168471417779, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622158940, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622158940, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5281.168471417779, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634622158940, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622158940, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622159564, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5389.5528306043025, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622159564, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622159564, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5389.5528306043025, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634622159565, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622159565, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622160179, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5470.102948248738, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622160180, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622160180, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5470.102948248738, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634622160180, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622160180, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622160796, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5454.672683521757, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622160796, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622160796, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5454.672683521757, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634622160797, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622160797, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622161410, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5477.420794659413, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622161411, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622161411, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5477.420794659413, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634622161411, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622161411, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622162026, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5461.773580459734, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622162027, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622162027, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5461.773580459734, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634622162027, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622162027, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622162651, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5386.397021839335, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622162652, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622162652, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5386.397021839335, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634622162652, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622162652, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622163267, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5465.582138893004, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622163267, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622163267, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5465.582138893004, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634622163268, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622163268, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622163883, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5458.606653035186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622163884, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622163884, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5458.606653035186, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634622163884, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622163884, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622164499, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5471.200865275838, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622164499, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622164499, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5471.200865275838, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634622164499, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622164499, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622165117, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5440.120808695632, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622165118, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622165118, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5440.120808695632, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634622165118, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622165118, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622165736, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5439.747035573123, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622165736, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622165736, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5439.747035573123, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634622165736, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622165737, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622166353, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5453.288059724016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622166353, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622166353, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5453.288059724016, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634622166354, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622166354, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622166976, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5397.669415638036, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622166977, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622166977, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5397.669415638036, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634622166977, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622166977, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622167605, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5352.577979278449, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622167605, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622167606, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5352.577979278449, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634622167606, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622167606, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622168226, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5415.1515223707165, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622168227, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622168227, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5415.1515223707165, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634622168227, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622168227, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622168852, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5383.765203947497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622168852, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622168852, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5383.765203947497, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634622168852, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622168852, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622169475, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5400.047912341566, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622169475, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622169475, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5400.047912341566, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634622169476, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622169476, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622170090, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5472.934644914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622170090, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622170090, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5472.934644914, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634622170090, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622170091, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622170721, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5331.322837791215, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622170721, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622170722, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5331.322837791215, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634622170722, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622170722, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622171332, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5506.508176031821, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622171333, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622171333, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5506.508176031821, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634622171333, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622171333, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622171948, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5467.445987441782, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622171948, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622171948, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5467.445987441782, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634622171948, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622171948, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622172561, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5488.316791890935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622172561, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622172561, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5488.316791890935, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634622172562, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622172562, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622173182, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5414.5065635160945, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622173183, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622173183, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5414.5065635160945, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634622173183, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622173183, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622173811, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5349.871458327876, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622173812, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622173812, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5349.871458327876, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634622173812, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622173812, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622174428, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.5701093911985, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622174429, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622174429, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.5701093911985, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634622174429, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622174429, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622175055, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5375.78672721114, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622175055, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622175055, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5375.78672721114, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634622175055, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622175055, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622175669, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5481.402580753565, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622175669, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622175669, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5481.402580753565, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634622175669, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622175669, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622176291, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5406.092507119709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622176292, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622176292, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5406.092507119709, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634622176292, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622176292, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622176905, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5484.009105731552, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622176905, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622176905, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5484.009105731552, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634622176905, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622176905, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622177519, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5478.438592719782, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622177519, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622177519, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5478.438592719782, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634622177519, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622177519, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622178131, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5492.074717579956, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622178131, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622178132, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5492.074717579956, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634622178132, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622178132, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622178748, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5456.144616935624, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622178748, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622178748, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5456.144616935624, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634622178748, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622178748, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622179359, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5506.82877708749, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622179359, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622179359, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5506.82877708749, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634622179359, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622179359, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622179967, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5532.233512561194, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622179967, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622179967, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5532.233512561194, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634622179967, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622179967, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622180585, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5440.9945462112655, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622180585, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622180585, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5440.9945462112655, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634622180585, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622180585, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622181198, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5482.5732907006195, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622181198, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622181199, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5482.5732907006195, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634622181199, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622181199, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622181811, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5485.153175566327, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622181812, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622181812, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5485.153175566327, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634622181812, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622181812, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622182419, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5539.940775159059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622182419, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622182419, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5539.940775159059, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634622182419, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622182419, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622183032, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5488.33602826406, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622183032, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622183032, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5488.33602826406, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634622183032, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622183032, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622183637, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5553.865473990606, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622183637, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622183638, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5553.865473990606, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634622183638, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622183638, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622184245, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5538.103350913601, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622184245, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622184245, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5538.103350913601, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634622184245, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622184245, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622184856, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5501.806732547413, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622184856, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622184856, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5501.806732547413, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634622184856, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622184856, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622185466, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5508.867295699265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622185467, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622185467, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5508.867295699265, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634622185467, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622185467, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622186078, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5496.084275420761, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622186079, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622186079, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5496.084275420761, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634622186079, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622186079, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622186688, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5520.47486030237, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622186688, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622186688, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5520.47486030237, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634622186757, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622186758, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622186774, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634622187202, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8564984798431396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634622187202, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634622187371, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5479.6996536708675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622187371, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622187371, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5479.6996536708675, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634622187486, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622187486, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622187502, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634622187908, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8722560405731201, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634622187908, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634622188117, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5330.600907947224, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622188117, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622188117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5330.600907947224, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634622188153, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622188153, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622188169, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634622188596, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8611138463020325, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634622188596, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634622188789, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5283.673180624067, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622188790, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622188790, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5283.673180624067, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634622188884, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622188884, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622188900, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634622189333, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8637420535087585, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634622189333, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634622189544, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5091.140158555551, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622189545, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622189545, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5091.140158555551, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634622189581, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622189581, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622189598, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634622190036, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8664615154266357, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634622190036, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634622190232, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5165.891307375938, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622190232, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622190232, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5165.891307375938, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634622190267, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622190268, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622190283, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634622190730, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8776930570602417, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634622190730, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634622190917, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5178.402340794622, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622190917, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622190917, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5178.402340794622, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634622190952, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622190952, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622190967, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634622191397, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8847917914390564, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634622191397, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634622191591, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5260.834947846557, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622191592, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622191592, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5260.834947846557, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634622191629, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622191629, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622191645, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634622192075, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8830739259719849, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634622192075, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634622192268, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5261.858317107275, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622192269, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622192269, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5261.858317107275, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634622192304, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622192305, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622192319, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634622192749, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8692506551742554, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634622192749, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634622192938, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5308.355644114817, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622192938, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622192938, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5308.355644114817, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634622192974, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622192974, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622192989, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634622193418, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8765199184417725, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634622193418, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634622193611, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5273.465314079801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622193612, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622193612, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5273.465314079801, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634622193648, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622193648, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622193663, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634622194096, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8716061115264893, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634622194096, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634622194283, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5295.120062852224, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622194284, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622194284, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5295.120062852224, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634622194319, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622194319, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622194334, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634622194766, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8902536034584045, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634622194766, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634622194957, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5270.479430230627, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622194957, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622194957, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5270.479430230627, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634622194993, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622194993, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622195010, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634622195441, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8834526538848877, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634622195441, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634622195631, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5267.500863410674, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622195632, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622195632, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5267.500863410674, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634622195667, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622195667, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622195683, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634622196111, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8807874917984009, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634622196111, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634622196302, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5290.726829801204, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622196303, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622196303, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5290.726829801204, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634622196339, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622196339, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622196356, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634622196785, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8833460807800293, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634622196786, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634622196971, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5317.824127076606, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622196972, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622196972, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5317.824127076606, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634622197010, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622197010, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622197026, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634622197455, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8723012804985046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634622197455, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634622197643, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5308.77757159744, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622197644, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622197644, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5308.77757159744, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634622197682, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622197682, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622197698, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634622198124, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.889718234539032, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634622198125, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634622198310, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5347.800747022214, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622198311, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622198311, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5347.800747022214, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634622198347, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622198347, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622198362, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634622198790, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.889742374420166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634622198790, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634622198975, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5352.68776086206, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622198975, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622198975, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5352.68776086206, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634622199010, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622199011, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622199025, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634622199453, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8764216899871826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634622199453, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634622199641, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5329.407531052906, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622199641, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622199642, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5329.407531052906, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634622199677, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622199677, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622199693, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634622200120, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8816351890563965, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634622200120, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634622200316, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5260.508967551975, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622200316, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622200316, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5260.508967551975, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634622200351, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622200352, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622200367, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634622200795, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8793501853942871, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634622200795, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634622200985, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5303.926457116921, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622200985, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622200985, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5303.926457116921, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634622201023, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622201024, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622201038, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634622201470, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8813400268554688, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634622201470, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634622201655, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5319.36968642851, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622201656, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622201656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5319.36968642851, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634622201721, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622201722, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622201737, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634622202137, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.863108217716217, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634622202137, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634622202329, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5537.333040478762, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622202329, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622202329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5537.333040478762, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634622202365, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622202365, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622202381, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634622202804, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8811880350112915, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634622202804, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634622203003, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5272.457150809919, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622203003, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622203003, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5272.457150809919, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634622203038, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622203039, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622203055, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634622203486, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8627611398696899, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634622203486, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634622203673, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5300.909976551339, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622203673, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622203673, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5300.909976551339, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634622203709, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622203709, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622203725, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634622204139, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8816324472427368, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634622204139, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634622204329, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5420.179141124115, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622204329, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622204329, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5420.179141124115, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634622204365, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622204365, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622204382, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634622204803, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.855451226234436, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634622204804, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634622204986, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5408.951720802773, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622204986, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622204987, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5408.951720802773, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634622205022, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622205022, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622205039, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634622205465, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.875510573387146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634622205465, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634622205674, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5154.405624586021, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622205674, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622205674, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5154.405624586021, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634622205712, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622205712, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622205728, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634622206143, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8954764604568481, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634622206143, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634622206336, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5384.2917731812795, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622206337, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622206337, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5384.2917731812795, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634622206373, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622206373, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622206390, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634622206811, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8957080245018005, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634622206811, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634622207023, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5171.386732747166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622207023, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622207023, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5171.386732747166, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634622207058, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622207058, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622207075, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634622207503, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985116481781006, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634622207503, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634622207692, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5298.48651209306, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622207692, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622207693, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5298.48651209306, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634622207729, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622207729, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622207745, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634622208174, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8833782076835632, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634622208174, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634622208362, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5312.812263205633, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622208362, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622208362, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5312.812263205633, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634622208398, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622208398, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622208415, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634622208845, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8857666254043579, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634622208845, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634622209029, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5327.574158837592, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622209029, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622209029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5327.574158837592, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634622209065, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622209065, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622209082, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634622209509, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8840084075927734, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634622209509, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634622209703, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5269.334489933652, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622209703, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622209703, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5269.334489933652, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634622209739, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622209739, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622209756, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634622210185, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8924606442451477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634622210185, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634622210378, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5259.439015023864, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622210378, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622210378, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5259.439015023864, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634622210413, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622210413, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622210429, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634622210857, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8912177085876465, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634622210857, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634622211040, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5362.455985610684, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622211040, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622211040, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5362.455985610684, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634622211076, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622211076, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622211092, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634622211521, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8787370920181274, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634622211521, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634622211703, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5362.61106513165, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622211703, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622211703, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5362.61106513165, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634622211739, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622211740, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622211755, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634622212181, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8927478790283203, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634622212181, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634622212368, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5351.214216986598, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622212368, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622212368, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5351.214216986598, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634622212405, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622212405, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622212421, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634622212837, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8976457118988037, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634622212837, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634622213020, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5464.043672456576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622213021, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622213021, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5464.043672456576, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634622213058, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622213058, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622213074, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634622213496, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8955763578414917, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634622213496, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634622213682, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5384.818445429317, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622213682, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622213682, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5384.818445429317, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634622213723, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622213723, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622213740, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634622214153, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9013904929161072, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634622214153, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634622214338, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5463.84242205719, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622214339, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622214339, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5463.84242205719, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634622214375, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622214375, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622214392, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634622214812, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8990073204040527, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634622214812, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634622214996, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5417.399676405884, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622214996, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622214996, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5417.399676405884, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634622215032, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622215032, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622215048, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634622215478, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8907070159912109, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634622215478, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634622215663, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5328.510834266295, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622215663, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622215663, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5328.510834266295, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634622215699, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622215699, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622215715, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634622216145, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8880261778831482, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634622216145, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634622216330, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5332.182148800105, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622216330, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622216330, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5332.182148800105, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634622216365, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622216365, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622216382, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634622216809, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8938370943069458, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634622216809, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634622216990, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5380.20122982691, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622216990, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622216990, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5380.20122982691, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634622217026, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622217026, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622217042, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634622217458, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8858746290206909, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634622217459, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634622217645, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5425.729924351653, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622217646, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622217646, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5425.729924351653, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634622217681, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622217681, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622217696, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634622218167, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.897255003452301, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634622218168, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634622218367, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4895.732836888475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622218368, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622218368, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4895.732836888475, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634622218404, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622218404, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622218419, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634622218845, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9001099467277527, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634622218846, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634622219029, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5376.527102457173, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622219029, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622219029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5376.527102457173, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634622219065, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622219065, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622219082, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634622219510, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9049649238586426, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634622219510, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634622219697, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5318.7272669632575, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622219697, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622219697, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5318.7272669632575, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634622219734, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622219734, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622219750, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634622220175, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9006959199905396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634622220175, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634622220357, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5394.840700765804, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622220357, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622220357, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5394.840700765804, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634622220393, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622220393, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622220410, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634622220836, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8804440498352051, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634622220836, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634622221019, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5365.759485357192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622221020, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622221020, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5365.759485357192, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634622221056, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622221057, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622221073, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634622221501, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9029903411865234, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634622221501, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634622221683, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5364.4910972857915, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622221683, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622221683, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5364.4910972857915, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634622221719, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622221719, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622221735, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634622222166, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9076753258705139, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634622222166, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634622222359, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5248.343119065158, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622222360, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622222360, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5248.343119065158, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634622222396, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622222396, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622222413, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634622222839, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8956470489501953, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634622222839, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634622223039, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5227.652129399851, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622223039, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622223039, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5227.652129399851, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634622223074, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622223075, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622223090, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634622223521, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8859288692474365, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634622223521, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634622223715, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5243.549098713117, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622223716, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622223716, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5243.549098713117, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634622223755, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622223755, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622223772, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634622224197, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8982405662536621, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634622224197, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634622224395, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5252.542881155996, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622224395, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622224395, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5252.542881155996, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634622224438, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622224438, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622224453, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634622224880, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8948848247528076, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634622224880, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634622225059, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5412.869890120695, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622225059, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622225059, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5412.869890120695, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634622225095, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622225095, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622225111, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634622225541, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8997902870178223, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634622225541, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634622225723, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5355.59861459148, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622225723, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622225723, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5355.59861459148, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634622225759, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622225760, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622225777, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634622226206, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8881092071533203, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634622226206, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634622226393, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5302.419782851866, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622226394, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622226394, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5302.419782851866, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634622226430, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622226430, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622226446, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634622226876, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985996246337891, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634622226876, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634622227066, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5281.7919516437505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622227067, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622227067, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5281.7919516437505, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634622227102, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622227102, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622227118, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634622227547, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9006669521331787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634622227547, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634622227733, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5329.927551908022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622227733, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622227733, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5329.927551908022, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634622227770, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622227770, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622227787, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634622228213, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9036372900009155, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634622228213, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634622228406, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5284.231866559929, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622228406, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622228407, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5284.231866559929, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634622228443, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622228443, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622228460, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634622228884, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9072917103767395, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634622228884, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634622229079, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5286.192163770416, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622229079, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622229079, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5286.192163770416, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634622229115, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622229115, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622229131, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634622229547, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9052214026451111, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634622229547, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634622229732, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5447.114365402811, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622229732, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622229732, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5447.114365402811, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634622229769, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622229769, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622229786, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634622230248, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9009273648262024, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634622230248, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634622230450, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4933.775651562016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622230451, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622230451, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4933.775651562016, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634622230490, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622230490, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634622230507, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634622230925, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9088854193687439, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634622230925, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634622230925, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634622231112, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5406.911783945461, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634622231112, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634622231112, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5406.911783945461, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2300}}
ENDING TIMING RUN AT 2021-10-19 05:43:57 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:57 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:57 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:57 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:57 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:57 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:57 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:57 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:57 AM
RESULT,image_segmentation,,209,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:58 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:58 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:58 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:58 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:58 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:58 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:58 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:58 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:58 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:58 AM
RESULT,image_segmentation,,210,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:43:59 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:00 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:01 AM
RESULT,image_segmentation,,213,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:03 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:03 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:04 AM
RESULT,image_segmentation,,216,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:05 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:06 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:07 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:08 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:09 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
ENDING TIMING RUN AT 2021-10-19 05:44:10 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 05:40:28 AM
