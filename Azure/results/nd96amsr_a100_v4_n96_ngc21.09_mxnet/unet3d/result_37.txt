+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019064017144627071
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019064017144627071
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019064017144627071
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019064017144627071
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07400/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019064017144627071_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C048D
Clearing cache on ip-0A0C0484
Clearing cache on ip-0A0C0438
Clearing cache on ip-0A0C0498
Clearing cache on ip-0A0C0436
Clearing cache on ip-0A0C0496
Clearing cache on ip-0A0C044D
Clearing cache on ip-0A0C0437
Clearing cache on ip-0A0C0473
Clearing cache on ip-0A0C0483
Clearing cache on ip-0A0C0497
Clearing cache on ip-0A0C045F
Clearing cache on ip-0A0C048A
Clearing cache on ip-0A0C046E
Clearing cache on ip-0A0C0490
Clearing cache on ip-0A0C0441
Clearing cache on ip-0A0C0443
Clearing cache on ip-0A0C042D
Clearing cache on ip-0A0C04A6
Clearing cache on ip-0A0C0491
Clearing cache on ip-0A0C0460
Clearing cache on ip-0A0C0472
Clearing cache on ip-0A0C046C
Clearing cache on ip-0A0C04A1
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C0466
Clearing cache on ip-0A0C0492
Clearing cache on ip-0A0C0435
Clearing cache on ip-0A0C0494
Clearing cache on ip-0A0C0488
Clearing cache on ip-0A0C047E
Clearing cache on ip-0A0C048C
Clearing cache on ip-0A0C049C
Clearing cache on ip-0A0C0486
Clearing cache on ip-0A0C04C3
Clearing cache on ip-0A0C04B0
Clearing cache on ip-0A0C04BE
Clearing cache on ip-0A0C04C9
Clearing cache on ip-0A0C04B5
Clearing cache on ip-0A0C04C7
Clearing cache on ip-0A0C04D3
Clearing cache on ip-0A0C0429
Clearing cache on ip-0A0C04CF
Clearing cache on ip-0A0C048B
Clearing cache on ip-0A0C0482
Clearing cache on ip-0A0C04A8
Clearing cache on ip-0A0C04C8
Clearing cache on ip-0A0C04C0
Clearing cache on ip-0A0C04B9
Clearing cache on ip-0A0C04D4
Clearing cache on ip-0A0C0489
Clearing cache on ip-0A0C04CD
Clearing cache on ip-0A0C0485
Clearing cache on ip-0A0C04A7
Clearing cache on ip-0A0C04AE
Clearing cache on ip-0A0C04A9
Clearing cache on ip-0A0C04CC
Clearing cache on ip-0A0C0495
Clearing cache on ip-0A0C04B4
Clearing cache on ip-0A0C04A4
Clearing cache on ip-0A0C0487
Clearing cache on ip-0A0C04A0
Clearing cache on ip-0A0C04AF
Clearing cache on ip-0A0C0493
Clearing cache on ip-0A0C04AB
Clearing cache on ip-0A0C0464
Clearing cache on ip-0A0C04B7
Clearing cache on ip-0A0C04A2
Clearing cache on ip-0A0C049D
Clearing cache on ip-0A0C04BA
Clearing cache on ip-0A0C049B
Clearing cache on ip-0A0C04C6
Clearing cache on ip-0A0C04BD
Clearing cache on ip-0A0C04AA
Clearing cache on ip-0A0C046B
Clearing cache on ip-0A0C04C4
Clearing cache on ip-0A0C0449
Clearing cache on ip-0A0C04AD
Clearing cache on ip-0A0C04D9
Clearing cache on ip-0A0C04DA
Clearing cache on ip-0A0C04A5
Clearing cache on ip-0A0C04B6
Clearing cache on ip-0A0C048F
Clearing cache on ip-0A0C04C5
Clearing cache on ip-0A0C04B3
Clearing cache on ip-0A0C04AC
Clearing cache on ip-0A0C04DB
Clearing cache on ip-0A0C04D8
Clearing cache on ip-0A0C0461
Clearing cache on ip-0A0C049F
Clearing cache on ip-0A0C04BB
Clearing cache on ip-0A0C04BC
Clearing cache on ip-0A0C04C2
Clearing cache on ip-0A0C04B1
Clearing cache on ip-0A0C0499
Clearing cache on ip-0A0C04B2
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:40:19 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634625624.713340] [ip-0A0C0449:69772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.717106] [ip-0A0C04B0:43607:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.726762] [ip-0A0C0449:69773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.737953] [ip-0A0C0499:58304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.740182] [ip-0A0C04C5:91355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.753794] [ip-0A0C0494:53677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.756602] [ip-0A0C0487:72261:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.761511] [ip-0A0C0499:58310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.766308] [ip-0A0C042D:43564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.770837] [ip-0A0C0482:59413:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.782764] [ip-0A0C04BD:87233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.785873] [ip-0A0C04D4:88565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.785783] [ip-0A0C04A6:56780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.790619] [ip-0A0C0461:35849:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.793326] [ip-0A0C048A:68990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.802671] [ip-0A0C0499:58307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.803119] [ip-0A0C0494:53676:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.804191] [ip-0A0C046C:67526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.807142] [ip-0A0C04BE:90191:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.807195] [ip-0A0C04C5:91350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.807682] [ip-0A0C0487:72264:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.812503] [ip-0A0C04B0:43610:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.812415] [ip-0A0C0494:53679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.813768] [ip-0A0C04B0:43609:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.815605] [ip-0A0C04D4:88561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.818715] [ip-0A0C0449:69774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.820064] [ip-0A0C0499:58306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.823557] [ip-0A0C049C:43721:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.825653] [ip-0A0C0490:58194:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.830460] [ip-0A0C04A0:46623:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.833216] [ip-0A0C04A7:33988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.834603] [ip-0A0C04A0:46606:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.835149] [ip-0A0C040F:42150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.835519] [ip-0A0C04AD:34011:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.835700] [ip-0A0C0482:59411:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.836023] [ip-0A0C0482:59409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.837171] [ip-0A0C0495:56144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.839538] [ip-0A0C04C5:91356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.840035] [ip-0A0C04C2:14771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.839908] [ip-0A0C0449:69776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.842332] [ip-0A0C0493:53487:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.844963] [ip-0A0C042D:43570:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.845431] [ip-0A0C04B5:57773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.846004] [ip-0A0C0460:71902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.846629] [ip-0A0C04A4:57095:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.847051] [ip-0A0C049D:61497:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.850576] [ip-0A0C049D:61496:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.851772] [ip-0A0C040F:42173:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.854105] [ip-0A0C04BE:90190:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.857706] [ip-0A0C04B4:67268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.857741] [ip-0A0C04B4:67269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.858611] [ip-0A0C049C:43720:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.858393] [ip-0A0C04A6:56784:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.859294] [ip-0A0C048A:68994:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.859663] [ip-0A0C048C:52904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.859744] [ip-0A0C048F:61422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.860512] [ip-0A0C04BD:87234:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.862213] [ip-0A0C04D9:13411:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.863094] [ip-0A0C0460:71901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.864132] [ip-0A0C04BA:24445:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.864689] [ip-0A0C04A7:33987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.866871] [ip-0A0C0483:71134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.866528] [ip-0A0C04AE:62135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.868172] [ip-0A0C0436:72567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.870700] [ip-0A0C04AD:34008:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.871155] [ip-0A0C0441:65132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.870883] [ip-0A0C04C0:89047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.871537] [ip-0A0C04A4:57098:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.870962] [ip-0A0C048A:68989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.872260] [ip-0A0C04AB:47397:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.872959] [ip-0A0C049F:44908:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.875178] [ip-0A0C0437:68456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.876122] [ip-0A0C04D4:88559:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.877508] [ip-0A0C0495:56140:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.877456] [ip-0A0C0487:72267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.879517] [ip-0A0C0482:59412:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.882615] [ip-0A0C04C2:14772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.882657] [ip-0A0C048D:58020:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.883145] [ip-0A0C049D:61495:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.883860] [ip-0A0C0436:72561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.884670] [ip-0A0C047E:68744:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.887567] [ip-0A0C0449:69778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.888375] [ip-0A0C04B0:43605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.889741] [ip-0A0C04BE:90188:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.889050] [ip-0A0C0493:53490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.889825] [ip-0A0C048C:52926:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.891423] [ip-0A0C04A8:62150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.892042] [ip-0A0C0443:35463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.893273] [ip-0A0C04A1:74676:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.894326] [ip-0A0C04AF:48603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.898407] [ip-0A0C04D9:13413:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.899466] [ip-0A0C04C5:91352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.900050] [ip-0A0C04A9:56233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.902253] [ip-0A0C0487:72262:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.903285] [ip-0A0C046C:67525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.903399] [ip-0A0C0449:69775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.903612] [ip-0A0C0497:7233 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.905083] [ip-0A0C0437:68454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.907602] [ip-0A0C04C8:92369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.910617] [ip-0A0C0441:65127:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.910991] [ip-0A0C04B0:43608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.911203] [ip-0A0C0499:58311:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.911335] [ip-0A0C04B7:28079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.913561] [ip-0A0C048D:58013:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.913885] [ip-0A0C0472:74264:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.915867] [ip-0A0C048F:61423:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.916253] [ip-0A0C042D:43566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.917468] [ip-0A0C049C:43722:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.917508] [ip-0A0C042D:43593:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.919055] [ip-0A0C0483:71129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.919903] [ip-0A0C04A4:57092:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.920051] [ip-0A0C04BC:85275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.920097] [ip-0A0C04BC:85274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.920674] [ip-0A0C0449:69779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.921084] [ip-0A0C04B6:26248:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.921640] [ip-0A0C0449:69777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.923278] [ip-0A0C0495:56151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.924420] [ip-0A0C0461:35848:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.924654] [ip-0A0C0461:35846:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.924410] [ip-0A0C048A:68991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.925589] [ip-0A0C046C:67520:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.924926] [ip-0A0C04A6:56785:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.924782] [ip-0A0C049F:44912:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.925661] [ip-0A0C048C:52908:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.926197] [ip-0A0C0497:7236 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.927105] [ip-0A0C04DA:85960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.927855] [ip-0A0C04AD:34013:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.928957] [ip-0A0C04DB:84545:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.928829] [ip-0A0C0490:58192:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.929149] [ip-0A0C0429:62617:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.928704] [ip-0A0C0486:72271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.928719] [ip-0A0C0486:72265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.929765] [ip-0A0C04B5:57778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.930458] [ip-0A0C0494:53675:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.931478] [ip-0A0C046C:67521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.931480] [ip-0A0C04BD:87235:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.931983] [ip-0A0C04D9:13412:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.931905] [ip-0A0C0499:58308:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.932075] [ip-0A0C04B0:43634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.933835] [ip-0A0C04BA:24447:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.934050] [ip-0A0C045F:69891:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.933574] [ip-0A0C049B:45917:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.934066] [ip-0A0C04CF:15660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.935344] [ip-0A0C0483:71130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.936729] [ip-0A0C047E:68750:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.938267] [ip-0A0C048A:68995:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.938330] [ip-0A0C04AF:48606:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.938794] [ip-0A0C0493:53488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.939301] [ip-0A0C04C5:91353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.942555] [ip-0A0C04B0:43604:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.942650] [ip-0A0C04AB:47391:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.942899] [ip-0A0C04CD:89150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.944071] [ip-0A0C04B1:60140:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.944641] [ip-0A0C0499:58305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.944305] [ip-0A0C04C5:91354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.944683] [ip-0A0C0499:58309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.944776] [ip-0A0C04DA:85958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.946205] [ip-0A0C042D:43568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.947227] [ip-0A0C04CD:89159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.947487] [ip-0A0C04C3:88473:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.947734] [ip-0A0C046B:68139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.948705] [ip-0A0C04B0:43606:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.948198] [ip-0A0C0490:58188:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.948803] [ip-0A0C0435:13486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.948396] [ip-0A0C04A9:56234:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.949486] [ip-0A0C0437:68458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.950270] [ip-0A0C047E:68748:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.950574] [ip-0A0C04C5:91351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.950945] [ip-0A0C046E:74214:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.952401] [ip-0A0C04A0:46604:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.952140] [ip-0A0C04C2:14768:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.952970] [ip-0A0C04BB:32143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.953310] [ip-0A0C0466:74859:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.954883] [ip-0A0C04AE:62134:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.955836] [ip-0A0C04D4:88558:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.956570] [ip-0A0C0466:74855:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.956532] [ip-0A0C0487:72263:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.956926] [ip-0A0C04A1:74678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.956410] [ip-0A0C042D:43565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.956629] [ip-0A0C0494:53674:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.957163] [ip-0A0C0494:53678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.957373] [ip-0A0C04C0:89042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.958059] [ip-0A0C04BD:87236:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.958913] [ip-0A0C04D4:88571:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.958179] [ip-0A0C04A6:56781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.959397] [ip-0A0C04BD:87230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.959198] [ip-0A0C04B5:57775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.959808] [ip-0A0C048C:52906:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.960726] [ip-0A0C04AB:47399:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.960618] [ip-0A0C04AA:31745:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.960531] [ip-0A0C04A6:56783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.961788] [ip-0A0C048B:54909:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.961899] [ip-0A0C04C5:91377:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.961932] [ip-0A0C0461:35842:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.962249] [ip-0A0C0461:35847:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.962924] [ip-0A0C0464:72275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.962395] [ip-0A0C0482:59416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.963812] [ip-0A0C04D8:92326:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.963241] [ip-0A0C0429:62618:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.963194] [ip-0A0C04A8:62146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.964339] [ip-0A0C0487:72266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.965870] [ip-0A0C046C:67524:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.966123] [ip-0A0C04B7:28083:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.965750] [ip-0A0C0443:35466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.966708] [ip-0A0C0485:37304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.966649] [ip-0A0C0436:72560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.967587] [ip-0A0C04B9:90356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.967831] [ip-0A0C04CF:15661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.967938] [ip-0A0C049F:44914:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.969135] [ip-0A0C04A1:74677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.968326] [ip-0A0C0482:59410:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.969491] [ip-0A0C0460:71905:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.969245] [ip-0A0C0482:59414:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.969939] [ip-0A0C042D:43569:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.970531] [ip-0A0C04BE:90189:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.970182] [ip-0A0C0482:59415:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.970973] [ip-0A0C04C8:92372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.971555] [ip-0A0C04C8:92371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.971555] [ip-0A0C0487:72259:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.971628] [ip-0A0C04CC:92245:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.973170] [ip-0A0C04C2:14774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.973467] [ip-0A0C0496:38597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.974343] [ip-0A0C04B3:64983:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.973919] [ip-0A0C0494:53681:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.974182] [ip-0A0C042D:43567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.974577] [ip-0A0C0494:53680:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.974750] [ip-0A0C04C0:89045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.975305] [ip-0A0C045F:69893:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.975559] [ip-0A0C0487:72260:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.975915] [ip-0A0C0473:70411:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.976302] [ip-0A0C040F:42148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.975720] [ip-0A0C0498:67106:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.978139] [ip-0A0C04A2:48499:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.976763] [ip-0A0C048D:58018:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.977931] [ip-0A0C0490:58193:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.978111] [ip-0A0C048F:61424:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.979440] [ip-0A0C0485:37303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.979828] [ip-0A0C049C:43716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.981084] [ip-0A0C04A7:33986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.981592] [ip-0A0C04A0:46602:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.981387] [ip-0A0C04AE:62137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.981061] [ip-0A0C048A:68992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.981784] [ip-0A0C04C0:89041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.982699] [ip-0A0C0461:35845:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.983252] [ip-0A0C0495:56139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.983768] [ip-0A0C040F:42147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.985194] [ip-0A0C0490:58189:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.986794] [ip-0A0C04C7:93333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.986847] [ip-0A0C04C7:93331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.986857] [ip-0A0C04C7:93329:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.988216] [ip-0A0C04A5:59765:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.988273] [ip-0A0C0472:74270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.988709] [ip-0A0C0464:72272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.990413] [ip-0A0C04B5:57772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.991132] [ip-0A0C04D4:88563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.990899] [ip-0A0C046E:74210:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.991233] [ip-0A0C04AD:34012:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.991187] [ip-0A0C0489:72456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.991233] [ip-0A0C04B6:26249:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.992461] [ip-0A0C0441:65128:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.992907] [ip-0A0C04A1:74675:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.993301] [ip-0A0C046C:67523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.993165] [ip-0A0C04B4:67264:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.992468] [ip-0A0C04B6:26252:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.994834] [ip-0A0C04D4:88560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.994842] [ip-0A0C04C2:14770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.994228] [ip-0A0C0490:58191:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.995458] [ip-0A0C04B7:28078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.995238] [ip-0A0C0461:35843:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.996700] [ip-0A0C04A7:33982:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.995422] [ip-0A0C04C6:85356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.996656] [ip-0A0C0472:74267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.997391] [ip-0A0C04A4:57094:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.997138] [ip-0A0C0489:72463:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.998789] [ip-0A0C04A0:46603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.998429] [ip-0A0C0473:70412:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.997959] [ip-0A0C04A6:56787:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.998366] [ip-0A0C048A:68993:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.999035] [ip-0A0C049D:61493:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.999861] [ip-0A0C0472:74269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.999194] [ip-0A0C04A9:56231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.000142] [ip-0A0C04BD:87257:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.999414] [ip-0A0C048A:68988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.999592] [ip-0A0C048F:61426:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.999468] [ip-0A0C0498:67113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.000358] [ip-0A0C04AA:31743:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625624.999957] [ip-0A0C04A6:56786:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.000957] [ip-0A0C04D4:88562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.000219] [ip-0A0C04A6:56782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.001709] [ip-0A0C04BA:24446:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.001445] [ip-0A0C0460:71906:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.002241] [ip-0A0C04DB:84544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.001936] [ip-0A0C0461:35844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.002272] [ip-0A0C04B2:33237:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.003155] [ip-0A0C04BD:87232:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.003058] [ip-0A0C04B2:33235:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.003341] [ip-0A0C04B4:67281:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.002914] [ip-0A0C04B6:26255:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.003985] [ip-0A0C0488:70839:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.003626] [ip-0A0C04A9:56227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.005967] [ip-0A0C04A2:48498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.005306] [ip-0A0C04BD:87231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.005451] [ip-0A0C046B:68141:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.005016] [ip-0A0C049F:44915:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.006497] [ip-0A0C046B:68143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.006805] [ip-0A0C04BE:90187:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.006953] [ip-0A0C04BE:90185:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.006880] [ip-0A0C04DA:85962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.007385] [ip-0A0C04BB:32141:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.007273] [ip-0A0C04BE:90192:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.007522] [ip-0A0C04A7:33985:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.008571] [ip-0A0C04B5:57774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.009377] [ip-0A0C046C:67522:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.009891] [ip-0A0C04D9:13410:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.010153] [ip-0A0C04A7:33990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.010209] [ip-0A0C04C9:91320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.009491] [ip-0A0C049B:45923:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.011446] [ip-0A0C0435:13489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.011864] [ip-0A0C0441:65126:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.012544] [ip-0A0C04CD:89152:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.012354] [ip-0A0C0490:58195:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.014427] [ip-0A0C04C4:89455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.015152] [ip-0A0C04B5:57776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.014695] [ip-0A0C049B:45916:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.016417] [ip-0A0C04BA:24452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.015793] [ip-0A0C04C6:85360:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.016354] [ip-0A0C0490:58190:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.017157] [ip-0A0C0493:53484:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.017513] [ip-0A0C0493:53489:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.018667] [ip-0A0C046C:67519:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.019050] [ip-0A0C0492:52069:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.019947] [ip-0A0C0483:71131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.019958] [ip-0A0C04BE:90186:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.019838] [ip-0A0C049D:61494:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.019756] [ip-0A0C04B4:67291:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.019365] [ip-0A0C0497:7237 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.020055] [ip-0A0C0436:72566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.020510] [ip-0A0C04B1:60141:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.021381] [ip-0A0C0496:38595:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.021530] [ip-0A0C0496:38598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.020924] [ip-0A0C04B9:90355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.021877] [ip-0A0C040F:42151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.024803] [ip-0A0C0460:71907:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.026004] [ip-0A0C04CC:92242:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.026245] [ip-0A0C045F:69894:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.027272] [ip-0A0C04C4:89450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.026974] [ip-0A0C04AF:48607:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.027931] [ip-0A0C04D9:13414:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.029968] [ip-0A0C04A0:46601:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.030105] [ip-0A0C04A0:46605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.030207] [ip-0A0C04CC:92246:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.031190] [ip-0A0C0460:71903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.031169] [ip-0A0C0438:72961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.031811] [ip-0A0C04BA:24449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.032660] [ip-0A0C04AA:31750:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.032529] [ip-0A0C04B4:67267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.032825] [ip-0A0C048B:54911:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.033673] [ip-0A0C04A0:46608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.033050] [ip-0A0C04A4:57093:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.033727] [ip-0A0C049D:61498:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.034447] [ip-0A0C047E:68746:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.034595] [ip-0A0C048D:58014:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.034797] [ip-0A0C0460:71908:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.035498] [ip-0A0C0441:65133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.035588] [ip-0A0C04C3:88476:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.035489] [ip-0A0C049C:43718:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.036532] [ip-0A0C04A7:33984:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.036932] [ip-0A0C0441:65129:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.037019] [ip-0A0C04A5:59761:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.037170] [ip-0A0C049C:43717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.037395] [ip-0A0C04AE:62141:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.038110] [ip-0A0C04A4:57096:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.038820] [ip-0A0C04D8:92305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.039022] [ip-0A0C04C7:93334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.039485] [ip-0A0C0460:71904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.040234] [ip-0A0C04A7:33983:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.040085] [ip-0A0C049C:43723:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.040017] [ip-0A0C048F:61447:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.040862] [ip-0A0C0464:72269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.041902] [ip-0A0C0437:68453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.041862] [ip-0A0C040F:42149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.042309] [ip-0A0C04C2:14769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.041921] [ip-0A0C0443:35470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.043008] [ip-0A0C04AD:34007:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.042756] [ip-0A0C04B5:57777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.043261] [ip-0A0C046E:74213:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.043454] [ip-0A0C04AD:34006:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.043298] [ip-0A0C04C0:89057:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.043228] [ip-0A0C048C:52905:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.044015] [ip-0A0C04AD:34010:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.044231] [ip-0A0C0436:72562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.044647] [ip-0A0C04C8:92373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.044662] [ip-0A0C040F:42174:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.044660] [ip-0A0C04AE:62139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.045398] [ip-0A0C04AB:47396:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.045415] [ip-0A0C04AE:62162:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.046105] [ip-0A0C0495:56137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.047023] [ip-0A0C04B1:60139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.046630] [ip-0A0C04B5:57779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.046590] [ip-0A0C0429:62614:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.047292] [ip-0A0C04A4:57099:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.047683] [ip-0A0C0485:37300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.047056] [ip-0A0C048C:52910:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.047016] [ip-0A0C04A8:62147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.047622] [ip-0A0C049C:43719:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.048044] [ip-0A0C0493:53485:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.049143] [ip-0A0C047E:68745:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.048493] [ip-0A0C0443:35468:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.049913] [ip-0A0C04AD:34005:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.050596] [ip-0A0C0484:74277:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.050639] [ip-0A0C0484:74274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.051008] [ip-0A0C04A4:57097:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.051133] [ip-0A0C0436:72563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.051618] [ip-0A0C048D:58017:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.052085] [ip-0A0C04A5:59760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.052366] [ip-0A0C040F:42146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.052331] [ip-0A0C048F:61425:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.052627] [ip-0A0C04C0:89046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.053133] [ip-0A0C0441:65130:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.053198] [ip-0A0C0493:53483:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.053309] [ip-0A0C04CF:15659:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.054587] [ip-0A0C04BA:24448:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.054531] [ip-0A0C0493:53486:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.055355] [ip-0A0C04C2:14775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.054599] [ip-0A0C049F:44911:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.055495] [ip-0A0C0437:68455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.055637] [ip-0A0C048B:54906:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.055951] [ip-0A0C04AB:47395:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.056543] [ip-0A0C0483:71133:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.056542] [ip-0A0C04C2:14773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.057459] [ip-0A0C045F:69892:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.057567] [ip-0A0C0488:70841:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.057933] [ip-0A0C04D9:13415:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.058315] [ip-0A0C049D:61492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.058545] [ip-0A0C049D:61491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.059573] [ip-0A0C04D9:13409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.058907] [ip-0A0C048C:52925:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.059980] [ip-0A0C0495:56146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.059653] [ip-0A0C044D:69393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.059624] [ip-0A0C044D:69385:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.060841] [ip-0A0C04A8:62149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.061925] [ip-0A0C04C4:89451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.061317] [ip-0A0C04AF:48609:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.061728] [ip-0A0C0489:72460:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.062161] [ip-0A0C04B4:67266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.063408] [ip-0A0C04D9:13408:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.063236] [ip-0A0C0488:70842:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.063064] [ip-0A0C048F:61429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.063573] [ip-0A0C04B4:67263:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.064217] [ip-0A0C0472:74265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.064719] [ip-0A0C04A1:74705:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.064618] [ip-0A0C0435:13491:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.064384] [ip-0A0C048C:52907:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.066084] [ip-0A0C0495:56138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.066202] [ip-0A0C0495:56154:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.066956] [ip-0A0C04C8:92370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.067704] [ip-0A0C0483:71132:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.067016] [ip-0A0C048F:61427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.067718] [ip-0A0C04BC:85273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.067590] [ip-0A0C04B9:90360:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.069749] [ip-0A0C04C0:89044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.070883] [ip-0A0C04A1:74674:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.070601] [ip-0A0C04BC:85270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.070485] [ip-0A0C04AE:62136:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.070554] [ip-0A0C04AE:62138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.070654] [ip-0A0C04C0:89043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.071362] [ip-0A0C04DB:84547:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.071516] [ip-0A0C047E:68749:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.071452] [ip-0A0C04BA:24450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.071949] [ip-0A0C046E:74212:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.072125] [ip-0A0C04C8:92367:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.072224] [ip-0A0C04DB:84549:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.072427] [ip-0A0C04AB:47393:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.071675] [ip-0A0C04A9:56230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.072584] [ip-0A0C04BA:24451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.072395] [ip-0A0C0441:65131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.071687] [ip-0A0C049F:44913:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.071958] [ip-0A0C04A9:56228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.073555] [ip-0A0C0466:74861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.073714] [ip-0A0C0436:72565:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.074685] [ip-0A0C04B3:64980:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.074984] [ip-0A0C04B3:64978:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.073801] [ip-0A0C049B:45921:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.075158] [ip-0A0C04B7:28082:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.075746] [ip-0A0C048D:58016:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.076008] [ip-0A0C047E:68743:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.077669] [ip-0A0C04B7:28081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.078214] [ip-0A0C04C3:88474:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.078540] [ip-0A0C04AC:50555:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.079145] [ip-0A0C0483:71135:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.078602] [ip-0A0C049F:44910:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.079470] [ip-0A0C0436:72564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.080160] [ip-0A0C0491:53955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.079742] [ip-0A0C0443:35462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.082344] [ip-0A0C0483:71158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.082272] [ip-0A0C04AA:31748:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.081349] [ip-0A0C0486:72270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.081493] [ip-0A0C0486:72266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.082014] [ip-0A0C049F:44909:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.083945] [ip-0A0C0437:68457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.083846] [ip-0A0C04DA:85957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.084037] [ip-0A0C04DA:85955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.085239] [ip-0A0C0443:35464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.085140] [ip-0A0C0498:67112:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.086602] [ip-0A0C0484:74275:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.086880] [ip-0A0C0472:74268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.086455] [ip-0A0C04CF:15658:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.087117] [ip-0A0C0486:72272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.088219] [ip-0A0C04D3:90775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.089261] [ip-0A0C04B2:33238:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.089575] [ip-0A0C04A8:62144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.091076] [ip-0A0C04AB:47394:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.091719] [ip-0A0C04B7:28075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.091855] [ip-0A0C0492:52066:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.090903] [ip-0A0C0497:7238 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.091164] [ip-0A0C0497:7234 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.092677] [ip-0A0C04B7:28077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.092557] [ip-0A0C04CC:92247:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.093351] [ip-0A0C04A1:74680:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.093180] [ip-0A0C04AB:47398:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.092492] [ip-0A0C04AF:48604:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.093537] [ip-0A0C0492:52070:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.093687] [ip-0A0C048D:58015:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.094215] [ip-0A0C04A1:74679:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.094390] [ip-0A0C0473:70415:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.096504] [ip-0A0C0435:13492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.096709] [ip-0A0C04D8:92304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.097101] [ip-0A0C047E:68747:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.097110] [ip-0A0C04BC:85271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.096494] [ip-0A0C04A8:62148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.098100] [ip-0A0C046B:68138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.098403] [ip-0A0C04AC:50561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.097848] [ip-0A0C0489:72459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.099540] [ip-0A0C04BB:32140:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.099634] [ip-0A0C04C7:93337:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.099808] [ip-0A0C0437:68459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.099871] [ip-0A0C0437:68452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.100510] [ip-0A0C04BB:32139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.100199] [ip-0A0C04CD:89146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.100556] [ip-0A0C048D:58019:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.101733] [ip-0A0C0466:74854:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.102462] [ip-0A0C0472:74263:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.102820] [ip-0A0C04B2:33246:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.102752] [ip-0A0C04B6:26253:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.102728] [ip-0A0C049B:45919:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.103664] [ip-0A0C0429:62619:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.104419] [ip-0A0C04AA:31747:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.104442] [ip-0A0C04C7:93336:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.104946] [ip-0A0C04B7:28076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.105072] [ip-0A0C04BC:85269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.105240] [ip-0A0C04AF:48608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.105652] [ip-0A0C04A9:56232:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.105685] [ip-0A0C04A9:56229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.106690] [ip-0A0C04BC:85272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.106757] [ip-0A0C04BC:85276:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.106213] [ip-0A0C0497:7261 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.107111] [ip-0A0C04C7:93330:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.106511] [ip-0A0C0497:7235 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.107760] [ip-0A0C0443:35465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.107804] [ip-0A0C0443:35467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.110122] [ip-0A0C0466:74870:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.110524] [ip-0A0C04B1:60146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.110561] [ip-0A0C04C8:92368:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.109350] [ip-0A0C049B:45920:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.110752] [ip-0A0C0435:13490:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.110915] [ip-0A0C04C8:92374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.111143] [ip-0A0C0485:37302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.111581] [ip-0A0C0429:62613:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.112484] [ip-0A0C046B:68144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.111443] [ip-0A0C0486:72267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.112449] [ip-0A0C0472:74266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.111541] [ip-0A0C0486:72269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.112602] [ip-0A0C04C3:88478:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.112735] [ip-0A0C04C7:93332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.113051] [ip-0A0C04DB:84550:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.112356] [ip-0A0C04B9:90357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.113535] [ip-0A0C0491:53963:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.113640] [ip-0A0C04C3:88479:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.112966] [ip-0A0C04B6:26251:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.114337] [ip-0A0C04B3:64982:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.114076] [ip-0A0C04CD:89147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.114798] [ip-0A0C048B:54908:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.115084] [ip-0A0C045F:69897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.114149] [ip-0A0C04A8:62145:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.113818] [ip-0A0C049B:45918:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.114813] [ip-0A0C0438:72963:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.114587] [ip-0A0C04AF:48605:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.115827] [ip-0A0C0466:74856:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.115312] [ip-0A0C0429:62615:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.117815] [ip-0A0C0484:74269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.117106] [ip-0A0C0497:7232 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.119164] [ip-0A0C04DA:85956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.119490] [ip-0A0C04C9:91316:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.120458] [ip-0A0C048B:54904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.119692] [ip-0A0C04AF:48602:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.119694] [ip-0A0C04B6:26254:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.121029] [ip-0A0C0473:70413:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.120407] [ip-0A0C04A8:62158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.121197] [ip-0A0C0438:72965:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.123204] [ip-0A0C0486:72268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.124300] [ip-0A0C04CD:89148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.125233] [ip-0A0C04B1:60143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.125636] [ip-0A0C04DB:84548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.126231] [ip-0A0C04BB:32142:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.126933] [ip-0A0C04D8:92307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.126375] [ip-0A0C0489:72457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.127263] [ip-0A0C048B:54910:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.127261] [ip-0A0C04DB:84546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.127278] [ip-0A0C046B:68140:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.126480] [ip-0A0C04D3:90776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.128699] [ip-0A0C0485:37307:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.129549] [ip-0A0C04BB:32144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.128136] [ip-0A0C04C6:85359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.129434] [ip-0A0C04DB:84551:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.129467] [ip-0A0C0484:74270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.129481] [ip-0A0C04A5:59759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.129671] [ip-0A0C0464:72270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.130179] [ip-0A0C04BB:32137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.130043] [ip-0A0C04D3:90774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.132158] [ip-0A0C04DA:85959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.132660] [ip-0A0C0435:13488:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.132800] [ip-0A0C04CC:92243:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.131844] [ip-0A0C049B:45922:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.133349] [ip-0A0C04D8:92309:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.132673] [ip-0A0C0429:62616:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.133692] [ip-0A0C04C9:91317:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.134427] [ip-0A0C045F:69896:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.134455] [ip-0A0C04DA:85961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.135788] [ip-0A0C04BB:32138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.135814] [ip-0A0C045F:69898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.135717] [ip-0A0C0429:62612:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.136176] [ip-0A0C046E:74217:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.135380] [ip-0A0C04CF:15655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.136880] [ip-0A0C04CF:15657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.137442] [ip-0A0C04CD:89153:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.137072] [ip-0A0C0498:67107:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.138107] [ip-0A0C04CD:89149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.137633] [ip-0A0C04CF:15654:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.139001] [ip-0A0C04C3:88481:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.139105] [ip-0A0C04A5:59766:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.139065] [ip-0A0C0489:72461:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.139436] [ip-0A0C0435:13493:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.138733] [ip-0A0C04B6:26250:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.140059] [ip-0A0C0464:72271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.140191] [ip-0A0C04CF:15656:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.141706] [ip-0A0C04B1:60142:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.142186] [ip-0A0C0466:74857:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.142231] [ip-0A0C0466:74853:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.144084] [ip-0A0C046B:68137:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.147381] [ip-0A0C045F:69895:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.147361] [ip-0A0C04CC:92244:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.147569] [ip-0A0C0492:52068:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.148038] [ip-0A0C046B:68142:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.146874] [ip-0A0C04C6:85358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.150383] [ip-0A0C0496:38592:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.151343] [ip-0A0C04B3:64984:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.151171] [ip-0A0C0489:72458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.151677] [ip-0A0C0435:13487:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.151215] [ip-0A0C0489:72462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.152017] [ip-0A0C04D8:92303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.151820] [ip-0A0C046E:74216:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.151958] [ip-0A0C046E:74218:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.152488] [ip-0A0C0496:38593:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.152180] [ip-0A0C04B9:90361:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.153048] [ip-0A0C048B:54905:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.153317] [ip-0A0C04B1:60138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.154354] [ip-0A0C0485:37305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.155860] [ip-0A0C04A2:48508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.154307] [ip-0A0C0438:72960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.156036] [ip-0A0C04A2:48501:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.154841] [ip-0A0C04AA:31749:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.155694] [ip-0A0C0473:70410:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.156264] [ip-0A0C0496:38596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.156418] [ip-0A0C04D8:92310:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.156255] [ip-0A0C04B9:90362:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.157653] [ip-0A0C04AA:31744:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.157969] [ip-0A0C04C3:88480:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.158067] [ip-0A0C04C3:88475:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.157743] [ip-0A0C044D:69392:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.158912] [ip-0A0C04B1:60145:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.159094] [ip-0A0C04AC:50553:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.160519] [ip-0A0C04D8:92306:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.160905] [ip-0A0C046E:74211:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.161999] [ip-0A0C04B9:90359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.163222] [ip-0A0C04CC:92241:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.163318] [ip-0A0C04CC:92240:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.163883] [ip-0A0C048B:54907:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.163497] [ip-0A0C044D:69386:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.165270] [ip-0A0C04AA:31746:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.165480] [ip-0A0C04B9:90358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.167313] [ip-0A0C04C9:91318:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.167900] [ip-0A0C0464:72297:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.167822] [ip-0A0C0498:67115:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.167966] [ip-0A0C0498:67114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.170454] [ip-0A0C04A2:48497:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.169282] [ip-0A0C04B3:64977:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.169508] [ip-0A0C0491:53956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.170413] [ip-0A0C0485:37308:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.170572] [ip-0A0C0485:37301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.169737] [ip-0A0C04C6:85354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.171569] [ip-0A0C04B3:64979:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.174487] [ip-0A0C0464:72274:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.174585] [ip-0A0C0473:70414:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.174647] [ip-0A0C0464:72268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.174606] [ip-0A0C0488:70867:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.174861] [ip-0A0C04C4:89467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.175720] [ip-0A0C0492:52064:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.176611] [ip-0A0C04C4:89448:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.176864] [ip-0A0C04B3:64981:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.175775] [ip-0A0C044D:69383:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.178354] [ip-0A0C0496:38599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.178485] [ip-0A0C0473:70416:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.178879] [ip-0A0C0473:70409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.179848] [ip-0A0C0496:38594:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.180571] [ip-0A0C04A5:59763:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.180909] [ip-0A0C04A5:59764:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.181090] [ip-0A0C0488:70838:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.182862] [ip-0A0C04A5:59762:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.187151] [ip-0A0C0438:72964:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.186919] [ip-0A0C04C6:85355:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.190088] [ip-0A0C0498:67108:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.191235] [ip-0A0C04C9:91319:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.191406] [ip-0A0C0492:52071:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.191932] [ip-0A0C04B2:33234:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.197089] [ip-0A0C0498:67109:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.198170] [ip-0A0C04C4:89453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.199766] [ip-0A0C04A2:48500:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.199934] [ip-0A0C04A2:48502:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.200952] [ip-0A0C04C6:85357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.200979] [ip-0A0C04C6:85353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.202789] [ip-0A0C04C9:91322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.203855] [ip-0A0C0488:70837:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.204235] [ip-0A0C0488:70844:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.205135] [ip-0A0C0492:52067:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.204997] [ip-0A0C0488:70840:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.207717] [ip-0A0C04C4:89449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.209269] [ip-0A0C04A2:48503:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.207862] [ip-0A0C04C4:89452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.208272] [ip-0A0C0491:53959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.209000] [ip-0A0C0484:74273:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.209117] [ip-0A0C0484:74272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.209618] [ip-0A0C0492:52065:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.209762] [ip-0A0C04C9:91323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.211274] [ip-0A0C04B2:33233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.213592] [ip-0A0C0438:72958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.213995] [ip-0A0C04B2:33240:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.214910] [ip-0A0C0438:72959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.215815] [ip-0A0C0484:74271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.217788] [ip-0A0C04B2:33236:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.218578] [ip-0A0C04C9:91321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.221497] [ip-0A0C044D:69390:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.224118] [ip-0A0C0438:72962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.231589] [ip-0A0C0491:53957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.231082] [ip-0A0C044D:69384:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.231770] [ip-0A0C044D:69387:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.244016] [ip-0A0C04AC:50556:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.263648] [ip-0A0C0491:53981:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.266013] [ip-0A0C04D3:90778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.266159] [ip-0A0C04D3:90779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.274258] [ip-0A0C04D3:90781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.275275] [ip-0A0C04D3:90784:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.276848] [ip-0A0C04AC:50560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.277028] [ip-0A0C04AC:50554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.276846] [ip-0A0C0491:53961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.283959] [ip-0A0C04AC:50558:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.284459] [ip-0A0C0491:53958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.289871] [ip-0A0C04D3:90777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625625.297753] [ip-0A0C04AC:50557:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634625626181, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634625626224, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634625626224, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634625626225, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634625626225, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634625626225, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634625626225, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:37] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:38] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:40:40] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0435:0:13492 - context.c:584] INFO job (ID: 867565107250238667) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:13492 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:13492 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:13490 - context.c:584] INFO job (ID: 867565147628023140) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:13490 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:13490 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:13491 - context.c:584] INFO job (ID: 867564620503475863) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:13491 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:13491 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:13487 - context.c:584] INFO job (ID: 867565210073986850) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:13487 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:13487 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:13488 - context.c:584] INFO job (ID: 867565238854377365) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:13488 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:13488 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:13486 - context.c:584] INFO job (ID: 867565111168910316) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:13486 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:13486 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:13493 - context.c:584] INFO job (ID: 867564968357219925) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:13493 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:13493 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:13489 - context.c:584] INFO job (ID: 867564489089243798) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:13489 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:13489 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721246, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3518934335, "metadata": {"file": "main.py", "lineno": 72}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721246, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721247, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721247, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721247, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721247, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721247, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721247, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721247, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721247, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721247, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625721247, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:42:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625745251, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634625745266, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625745271, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634625745272, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625747765, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625747766, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1634625747766, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634625747766, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625749377, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2085.631060920768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625749378, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625749378, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2085.631060920768, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634625749378, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625749378, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625750051, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4997.199243161362, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625750051, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625750052, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4997.199243161362, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625750052, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625750052, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625750714, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5071.384930285314, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625750715, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625750715, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5071.384930285314, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634625750715, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625750715, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625751350, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5293.674063033392, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625751350, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625751351, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5293.674063033392, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634625751351, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625751351, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625751981, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5329.056876604253, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625751982, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625751982, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5329.056876604253, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634625751982, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625751982, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625752608, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5370.055213840269, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625752609, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625752609, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5370.055213840269, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634625752609, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625752609, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625753215, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5547.94472077931, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625753215, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625753216, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5547.94472077931, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634625753216, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625753216, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625753829, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5481.027377015006, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625753829, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625753829, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5481.027377015006, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634625753830, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625753830, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625754442, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5493.644002287449, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625754442, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625754442, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5493.644002287449, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634625754443, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625754443, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625755055, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5490.850741523443, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625755055, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625755055, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5490.850741523443, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634625755055, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625755055, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625755673, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.244062365422, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625755674, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625755674, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.244062365422, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634625755674, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625755674, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625756292, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5436.73143254826, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625756293, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625756293, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5436.73143254826, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634625756293, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625756293, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625756910, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5451.058520645608, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625756910, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625756910, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5451.058520645608, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634625756910, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625756911, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625757540, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5336.9476736920315, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625757541, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625757541, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5336.9476736920315, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634625757541, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625757541, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625758162, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5416.908253745806, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625758162, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625758162, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5416.908253745806, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634625758162, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625758163, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625758783, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5411.913715743666, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625758784, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625758784, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5411.913715743666, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634625758784, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625758784, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625759403, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5430.963478502144, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625759404, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625759404, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5430.963478502144, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634625759404, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625759404, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625760027, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5392.7969463604095, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625760028, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625760028, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5392.7969463604095, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634625760028, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625760028, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625760649, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5406.895188533417, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625760650, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625760650, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5406.895188533417, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634625760650, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625760650, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625761273, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5396.325974530225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625761274, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625761274, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5396.325974530225, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634625761274, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625761274, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625761893, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5432.382855504056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625761893, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625761893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5432.382855504056, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634625761893, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625761894, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625762507, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5478.274612244898, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625762508, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625762508, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5478.274612244898, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634625762508, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625762508, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625763131, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.695200376156, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625763132, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625763132, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.695200376156, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634625763132, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625763132, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625763747, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5466.023071320027, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625763747, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625763748, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5466.023071320027, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634625763748, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625763748, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625764361, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5483.454318364869, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625764361, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625764361, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5483.454318364869, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634625764361, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625764361, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625764970, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5523.623074571408, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625764971, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625764971, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5523.623074571408, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634625764971, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625764971, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625765585, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5469.421484524176, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625765586, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625765586, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5469.421484524176, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634625765586, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625765586, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625766200, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5470.508510367401, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625766201, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625766201, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5470.508510367401, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634625766201, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625766201, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625766814, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5488.269770213197, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625766814, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625766814, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5488.269770213197, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634625766814, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625766814, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625767439, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5383.018721767808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625767439, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625767439, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5383.018721767808, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634625767439, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625767439, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625768063, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5389.5322193404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625768063, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625768064, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5389.5322193404, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634625768064, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625768064, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625768679, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5461.291005619066, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625768680, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625768680, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5461.291005619066, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634625768680, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625768680, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625769294, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5470.376855338881, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625769295, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625769295, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5470.376855338881, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634625769295, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625769295, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625769915, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5425.803036754758, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625769915, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625769915, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5425.803036754758, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634625769915, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625769915, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625770531, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5456.383326602966, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625770532, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625770532, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5456.383326602966, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634625770532, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625770532, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625771145, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5482.0934310703515, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625771146, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625771146, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5482.0934310703515, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634625771146, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625771146, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625771762, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5456.174190451117, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625771762, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625771762, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5456.174190451117, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634625771762, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625771763, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625772381, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5431.618644436881, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625772382, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625772382, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5431.618644436881, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634625772382, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625772382, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625772990, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5525.340417715608, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625772991, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625772991, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5525.340417715608, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634625772991, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625772991, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625773603, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5490.786562031732, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625773604, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625773604, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5490.786562031732, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634625773604, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625773604, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625774212, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5533.554227440621, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625774212, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625774212, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5533.554227440621, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634625774212, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625774213, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625774826, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5482.274701502321, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625774826, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625774826, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5482.274701502321, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634625774826, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625774826, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625775441, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5471.78929230234, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625775441, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625775441, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5471.78929230234, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634625775441, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625775441, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625776049, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5528.739267930133, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625776050, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625776050, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5528.739267930133, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634625776050, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625776050, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625776662, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5489.625172514131, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625776663, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625776663, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5489.625172514131, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634625776663, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625776663, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625777273, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5511.230592890352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625777273, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625777274, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5511.230592890352, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634625777274, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625777274, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625777892, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5433.197552820275, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625777893, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625777893, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5433.197552820275, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634625777893, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625777893, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625778507, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5478.913552600887, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625778507, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625778507, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5478.913552600887, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634625778507, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625778508, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625779130, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5400.75359130843, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625779130, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625779131, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5400.75359130843, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634625779131, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625779131, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625779751, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5421.870300108261, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625779751, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625779751, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5421.870300108261, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634625779819, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625779819, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625779839, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625780267, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8860220313072205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625780267, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625780429, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5510.885774204359, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625780430, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625780430, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5510.885774204359, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625780567, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625780567, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625780583, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625780989, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.884543776512146, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625780989, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625781205, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5273.591608272282, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625781205, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625781205, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5273.591608272282, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625781249, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625781250, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625781265, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625781686, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8799934983253479, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625781686, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625781869, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5426.212502627848, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625781870, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625781870, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5426.212502627848, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625781925, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625781926, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625781940, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625782350, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8926984071731567, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625782350, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625782527, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5590.847882851682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625782528, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625782528, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5590.847882851682, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625782600, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625782600, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625782614, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625783045, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8794550895690918, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625783045, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625783241, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5242.486033415644, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625783242, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625783242, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5242.486033415644, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625783362, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625783362, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625783377, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625783775, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7891131043434143, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625783776, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625783977, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5461.597896413478, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625783978, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625783978, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5461.597896413478, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625784027, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625784027, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625784042, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625784491, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8956910371780396, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625784492, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625784695, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5031.6409316035715, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625784695, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625784696, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5031.6409316035715, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625784755, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625784755, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625784770, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625785197, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8943156003952026, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625785197, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625785387, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5317.4649633607105, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625785388, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625785388, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5317.4649633607105, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625785434, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625785434, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625785449, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625785886, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8877756595611572, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625785886, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625786076, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5238.442524691695, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625786076, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625786076, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5238.442524691695, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625786125, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625786125, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625786140, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625786575, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8757514953613281, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625786575, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625786789, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5062.54018944928, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625786789, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625786789, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5062.54018944928, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625786845, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625786845, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625786860, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625787302, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8842853307723999, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625787302, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625787501, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5122.681835546956, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625787502, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625787502, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5122.681835546956, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625787548, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625787548, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625787565, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625787984, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8573123216629028, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625787984, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625788199, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5163.718353456387, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625788199, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625788199, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5163.718353456387, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625788255, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625788255, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625788270, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625788693, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8899179697036743, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625788693, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625788889, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5300.937891189215, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625788889, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625788890, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5300.937891189215, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625788931, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625788931, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625788946, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625789373, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8843425512313843, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625789373, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625789562, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5322.081602780667, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625789563, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625789563, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5322.081602780667, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625789616, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625789616, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625789631, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625790058, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8879661560058594, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625790058, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625790247, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5327.7997365750825, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625790248, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625790248, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5327.7997365750825, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625790288, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625790288, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625790303, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625790728, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8834453821182251, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625790728, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625790919, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5326.32375734583, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625790920, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625790920, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5326.32375734583, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625790986, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625790986, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625791001, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625791417, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8850349187850952, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625791417, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625791611, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5377.052256701541, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625791612, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625791612, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5377.052256701541, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625791657, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625791658, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625791673, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625792115, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8885911703109741, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625792115, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625792313, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5125.521200401376, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625792314, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625792314, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5125.521200401376, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625792383, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625792384, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625792398, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625792802, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8843238353729248, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625792802, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625793003, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5425.2140156910455, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625793003, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625793004, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5425.2140156910455, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625793053, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625793054, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625793068, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625793492, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8917661905288696, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625793492, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625793685, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5320.638920896012, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625793686, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625793686, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5320.638920896012, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625793739, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625793739, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625793754, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625794200, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8861087560653687, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625794200, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625794399, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5095.235689054879, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625794399, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625794399, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5095.235689054879, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625794440, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625794440, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625794455, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625794895, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8977882862091064, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625794895, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625795089, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5181.559100981649, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625795090, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625795090, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5181.559100981649, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625795131, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625795132, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625795146, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625795586, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8851175308227539, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625795586, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625795773, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5236.593360574935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625795774, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625795774, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5236.593360574935, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625795841, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625795841, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625795856, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625796290, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8947168588638306, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625796290, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625796504, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5067.569980474579, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625796505, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625796505, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5067.569980474579, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625796610, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625796610, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625796626, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625797037, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8966037034988403, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625797037, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625797239, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5339.914268013815, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625797240, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625797240, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5339.914268013815, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625797304, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625797305, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625797319, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625797718, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8370227813720703, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625797718, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625797909, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5558.244188101068, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625797910, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625797910, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5558.244188101068, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625797965, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625797965, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625797979, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625798417, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8987751007080078, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625798417, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625798622, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5116.977232077696, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625798622, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625798622, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5116.977232077696, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625798679, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625798680, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625798695, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625799124, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8808844089508057, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625799124, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625799347, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5032.674114273858, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625799348, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625799348, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5032.674114273858, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625799420, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625799420, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625799435, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625799846, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8969244956970215, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625799846, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625800071, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5165.728461746548, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625800071, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625800072, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5165.728461746548, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625800115, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625800115, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625800130, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625800548, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8979617357254028, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625800549, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625800759, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5218.15781259546, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625800760, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625800760, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5218.15781259546, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625800800, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625800801, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625800816, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625801251, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.889104425907135, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625801252, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625801447, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5200.876345024502, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625801448, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625801448, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5200.876345024502, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625801515, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625801515, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625801530, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625801931, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8964639902114868, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625801931, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625802116, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5587.600440414929, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625802117, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625802117, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5587.600440414929, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625802173, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625802173, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625802188, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625802588, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9005889892578125, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625802588, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625802775, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5581.156645000018, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625802776, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625802776, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5581.156645000018, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625802856, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625802856, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625802871, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625803270, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8990987539291382, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625803270, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625803461, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5554.366737635668, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625803461, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625803462, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5554.366737635668, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625803506, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625803506, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625803521, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625803973, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8911542892456055, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625803973, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625804172, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5050.916969247989, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625804172, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625804172, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5050.916969247989, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625804253, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625804253, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625804268, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625804671, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8939321041107178, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625804671, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625804867, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5477.337769244522, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625804867, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625804868, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5477.337769244522, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625804969, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625804970, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625804984, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625805384, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8538647890090942, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625805384, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625805584, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5467.305995629371, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625805585, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625805585, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5467.305995629371, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625805642, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625805642, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625805657, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625806064, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8838834762573242, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625806064, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625806257, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5466.966651291925, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625806257, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625806258, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5466.966651291925, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625806333, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625806334, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625806348, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625806752, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8897624015808105, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625806752, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625806944, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5506.6329693207235, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625806945, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625806945, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5506.6329693207235, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625807034, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625807034, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625807049, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625807458, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8955577611923218, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625807458, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625807651, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5454.307462949976, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625807651, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625807651, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5454.307462949976, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625807712, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625807712, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625807727, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625808161, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8996025919914246, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625808161, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625808351, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5257.647574101364, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625808352, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625808352, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5257.647574101364, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625808409, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625808409, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625808424, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625808866, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8919669985771179, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625808867, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625809057, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5187.691301908712, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625809057, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625809058, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5187.691301908712, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625809149, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625809149, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625809164, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625809565, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8970757126808167, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625809565, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625809760, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5499.065247267219, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625809761, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625809761, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5499.065247267219, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625809837, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625809838, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625809852, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625810292, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8926857113838196, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625810292, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625810497, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5093.134641426135, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625810498, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625810498, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5093.134641426135, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625810580, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625810581, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625810596, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625810998, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8957898616790771, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625810998, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625811191, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5511.09912567682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625811191, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625811191, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5511.09912567682, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625811238, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625811238, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625811253, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625811666, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8905366659164429, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625811666, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625811845, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5542.3787668921705, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625811845, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625811845, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5542.3787668921705, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625811902, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625811902, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625811917, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625812344, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8998971581459045, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625812344, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625812540, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5270.936757113384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625812540, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625812540, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5270.936757113384, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625812601, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625812602, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625812616, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625813051, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8904721736907959, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625813051, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625813241, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5257.657381516875, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625813241, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625813241, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5257.657381516875, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625813298, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625813299, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625813313, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625813719, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8906764984130859, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625813719, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625813897, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5611.69218492605, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625813898, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625813898, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5611.69218492605, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625813959, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625813960, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625813974, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625814426, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8987182378768921, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625814426, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625814627, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5036.649081882717, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625814627, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625814628, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5036.649081882717, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625814669, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625814669, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625814684, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625815107, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8978860378265381, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625815107, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625815289, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5420.210410690838, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625815290, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625815290, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5420.210410690838, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625815333, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625815333, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625815348, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625815770, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.898772120475769, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625815770, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625815964, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5329.663497629367, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625815964, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625815964, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5329.663497629367, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625816007, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625816007, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625816023, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625816440, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9078035354614258, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625816440, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625816628, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5417.582941576946, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625816628, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625816628, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5417.582941576946, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625816686, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625816687, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625816702, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625817125, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8932440876960754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625817125, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625817316, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5338.146452179124, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625817317, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625817317, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5338.146452179124, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625817360, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625817360, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625817375, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625817815, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9009648561477661, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625817815, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625818007, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5195.890822174022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625818008, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625818008, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5195.890822174022, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625818051, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625818051, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625818066, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625818503, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9063342809677124, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625818503, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625818693, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5236.624493583, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625818693, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625818693, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5236.624493583, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625818753, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625818753, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625818767, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625819200, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8986631631851196, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625819200, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625819389, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5285.048315184435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625819389, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625819390, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5285.048315184435, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625819476, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625819476, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625819491, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625819911, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8951231241226196, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625819911, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625820113, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5277.525541557411, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625820113, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625820113, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5277.525541557411, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625820157, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625820157, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625820172, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625820637, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.903256893157959, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625820637, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625820834, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4965.721435545584, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625820835, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625820835, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4965.721435545584, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625820904, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625820904, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625820919, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625821340, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9040995836257935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625821340, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625821531, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5357.386156800788, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625821532, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625821532, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5357.386156800788, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625821581, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625821581, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625821596, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625822024, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9062163233757019, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625822024, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625822212, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5324.709775338338, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625822213, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625822213, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5324.709775338338, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625822269, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625822269, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625822284, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625822741, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8916596174240112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625822741, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625822942, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4998.342419437157, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625822942, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625822942, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4998.342419437157, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625823012, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625823012, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625823027, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625823449, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9034755229949951, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625823450, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625823649, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5278.679976177723, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625823650, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625823650, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5278.679976177723, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625823781, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625823782, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625823796, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625824196, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9004671573638916, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625824196, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625824410, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5348.176198199825, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625824411, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625824411, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5348.176198199825, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625824482, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625824483, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625824498, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625824961, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9040786027908325, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625824961, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625825169, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4895.732836888475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625825170, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625825170, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4895.732836888475, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625825265, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625825266, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625825280, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625825680, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8956761360168457, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625825680, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625825885, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5428.908999295811, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625825885, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625825885, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5428.908999295811, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625825976, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625825977, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625825992, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625826405, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9030550718307495, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625826406, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625826598, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5410.151914167651, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625826598, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625826598, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5410.151914167651, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625826671, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625826671, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625826686, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625827086, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8996201157569885, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625827086, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625827269, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5621.144550152446, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625827270, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625827270, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5621.144550152446, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625827368, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625827368, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625827383, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625827783, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9052532911300659, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625827783, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625827990, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5408.11522280633, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625827990, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625827990, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5408.11522280633, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625828061, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625828062, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625828076, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625828486, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9026263952255249, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625828486, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625828686, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5380.418961343297, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625828687, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625828687, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5380.418961343297, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625828727, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625828727, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625828742, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625829185, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9010821580886841, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625829185, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625829377, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5172.988840872777, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625829377, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625829377, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5172.988840872777, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2400}}
:::MLLOG {"namespace": "", "time_ms": 1634625829418, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625829418, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625829433, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625829856, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9027158617973328, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625829856, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625830035, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5443.709963636139, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625830036, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625830036, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5443.709963636139, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2420}}
:::MLLOG {"namespace": "", "time_ms": 1634625830117, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625830117, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625830132, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625830603, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9059255719184875, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625830603, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625830807, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4872.4690311840395, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625830808, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625830808, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4872.4690311840395, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2440}}
:::MLLOG {"namespace": "", "time_ms": 1634625830864, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625830864, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625830879, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625831321, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8964951038360596, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625831321, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625831524, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5098.642292700328, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625831524, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625831524, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5098.642292700328, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2460}}
:::MLLOG {"namespace": "", "time_ms": 1634625831598, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625831598, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625831613, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625832017, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9119197130203247, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625832017, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2480}}
:::MLLOG {"namespace": "", "time_ms": 1634625832017, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634625832210, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5491.426284680239, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625832211, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625832211, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5491.426284680239, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2480}}
ENDING TIMING RUN AT 2021-10-19 06:43:58 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:58 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:58 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:58 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:58 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:58 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:58 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:58 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:59 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:59 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:59 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:59 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:59 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:59 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:59 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:43:59 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:01 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:02 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:04 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:05 AM
RESULT,image_segmentation,,226,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:06 AM
RESULT,image_segmentation,,227,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:07 AM
RESULT,image_segmentation,,228,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:08 AM
RESULT,image_segmentation,,229,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:09 AM
RESULT,image_segmentation,,230,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:10 AM
RESULT,image_segmentation,,231,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
ENDING TIMING RUN AT 2021-10-19 06:44:11 AM
RESULT,image_segmentation,,232,nvidia,2021-10-19 06:40:19 AM
