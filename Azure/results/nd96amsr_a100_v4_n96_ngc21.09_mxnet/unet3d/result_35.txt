+ : DGXA100_96x8x1
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211019063247247978129
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data
+ : /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ LOGBASE=unet3d_96x8x1_211019063247247978129
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019063247247978129
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019063247247978129
+ readonly _cont_name=image_segmentation
+ _cont_name=image_segmentation
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job07398/slurm_script: line 39: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 mkdir -p /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459
+ srun --ntasks=96 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/unet3dv11.sqsh --container-name=image_segmentation true
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459/unet3d_96x8x1_211019063247247978129_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ '[' 1 -eq 1 ']'
+ srun --ntasks=96 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C044D
Clearing cache on ip-0A0C0487
Clearing cache on ip-0A0C047E
Clearing cache on ip-0A0C0498
Clearing cache on ip-0A0C0491
Clearing cache on ip-0A0C0438
Clearing cache on ip-0A0C04A4
Clearing cache on ip-0A0C0443
Clearing cache on ip-0A0C0472
Clearing cache on ip-0A0C046C
Clearing cache on ip-0A0C0493
Clearing cache on ip-0A0C0464
Clearing cache on ip-0A0C0436
Clearing cache on ip-0A0C0497
Clearing cache on ip-0A0C0499
Clearing cache on ip-0A0C0492
Clearing cache on ip-0A0C0449
Clearing cache on ip-0A0C0437
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C048A
Clearing cache on ip-0A0C0466
Clearing cache on ip-0A0C0441
Clearing cache on ip-0A0C0460
Clearing cache on ip-0A0C0484
Clearing cache on ip-0A0C045F
Clearing cache on ip-0A0C0488
Clearing cache on ip-0A0C0473
Clearing cache on ip-0A0C046E
Clearing cache on ip-0A0C0486
Clearing cache on ip-0A0C0496
Clearing cache on ip-0A0C042D
Clearing cache on ip-0A0C048B
Clearing cache on ip-0A0C0435
Clearing cache on ip-0A0C0490
Clearing cache on ip-0A0C04BE
Clearing cache on ip-0A0C04B6
Clearing cache on ip-0A0C04D8
Clearing cache on ip-0A0C04C5
Clearing cache on ip-0A0C04B3
Clearing cache on ip-0A0C04C9
Clearing cache on ip-0A0C04A1
Clearing cache on ip-0A0C04BB
Clearing cache on ip-0A0C0494
Clearing cache on ip-0A0C04D3
Clearing cache on ip-0A0C0461
Clearing cache on ip-0A0C04B0
Clearing cache on ip-0A0C048C
Clearing cache on ip-0A0C048D
Clearing cache on ip-0A0C04C6
Clearing cache on ip-0A0C04DB
Clearing cache on ip-0A0C04AA
Clearing cache on ip-0A0C04C8
Clearing cache on ip-0A0C04B4
Clearing cache on ip-0A0C04D4
Clearing cache on ip-0A0C0482
Clearing cache on ip-0A0C04B1
Clearing cache on ip-0A0C04BD
Clearing cache on ip-0A0C04A2
Clearing cache on ip-0A0C04CD
Clearing cache on ip-0A0C04B9
Clearing cache on ip-0A0C046B
Clearing cache on ip-0A0C04B2
Clearing cache on ip-0A0C049C
Clearing cache on ip-0A0C04C2
Clearing cache on ip-0A0C04AD
Clearing cache on ip-0A0C0483
Clearing cache on ip-0A0C04A9
Clearing cache on ip-0A0C04A5
Clearing cache on ip-0A0C04C3
Clearing cache on ip-0A0C04AE
Clearing cache on ip-0A0C04BC
Clearing cache on ip-0A0C04AC
Clearing cache on ip-0A0C0495
Clearing cache on ip-0A0C04D9
Clearing cache on ip-0A0C04B5
Clearing cache on ip-0A0C049F
Clearing cache on ip-0A0C0489
Clearing cache on ip-0A0C04AB
Clearing cache on ip-0A0C04B7
Clearing cache on ip-0A0C0429
Clearing cache on ip-0A0C04A0
Clearing cache on ip-0A0C04A6
Clearing cache on ip-0A0C04CF
Clearing cache on ip-0A0C04AF
Clearing cache on ip-0A0C04C7
Clearing cache on ip-0A0C0485
Clearing cache on ip-0A0C048F
Clearing cache on ip-0A0C04C4
Clearing cache on ip-0A0C04A8
Clearing cache on ip-0A0C04DA
Clearing cache on ip-0A0C049D
Clearing cache on ip-0A0C04BA
Clearing cache on ip-0A0C049B
Clearing cache on ip-0A0C04C0
Clearing cache on ip-0A0C04CC
Clearing cache on ip-0A0C04A7
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=768 --ntasks-per-node=8 --container-name=image_segmentation --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/unet3d_data:/data,/mnt/resource_nvme/mlcommons/logs/unet3d/96N-m19.051459:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/unet3d/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
STARTING TIMING RUN AT 2021-10-19 06:32:50 AM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
+ exec numactl --physcpubind=0-23 --membind=0 -- python -u main.py --data_dir /data --epochs 10000 --quality_threshold 0.908 --batch_size 1 --evaluate_every 20 --start_eval_at 1000 --lr_warmup_epochs 1500 --optimizer nag --learning_rate 1.5 --static_cast -sls 512 -gpf 512 --loss_scale_inc_cycles 70 --warmup --val_batch_size 1 --nodes_for_eval 12 -sgs 8 -ucl -sts --shard_eval --num_workers 4 --input_batch_multiplier 4
[1634625175.566083] [ip-0A0C0437:63993:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.566085] [ip-0A0C0437:63987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.604362] [ip-0A0C04B4:62735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.608952] [ip-0A0C046E:69754:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.616158] [ip-0A0C0493:49051:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.620612] [ip-0A0C04C8:86823:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.620648] [ip-0A0C0493:49055:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.621623] [ip-0A0C046E:69759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.633389] [ip-0A0C049B:41449:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.637144] [ip-0A0C0483:66692:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.641423] [ip-0A0C047E:64261:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.648336] [ip-0A0C0437:63990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.649952] [ip-0A0C048D:53567:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.650690] [ip-0A0C04C8:86824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.650842] [ip-0A0C0483:66697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.651592] [ip-0A0C04CD:83574:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.654021] [ip-0A0C0489:67986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.655778] [ip-0A0C04AB:42998:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.656101] [ip-0A0C04AB:42999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.657863] [ip-0A0C0489:67987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.659706] [ip-0A0C04B3:60437:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.663977] [ip-0A0C0429:58167:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.667742] [ip-0A0C046E:69758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.672502] [ip-0A0C0497:2568 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.677350] [ip-0A0C0497:2578 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.679776] [ip-0A0C04B4:62730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.680289] [ip-0A0C0483:66694:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.681735] [ip-0A0C04D4:83011:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.683056] [ip-0A0C049B:41453:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.687229] [ip-0A0C046B:62522:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.688283] [ip-0A0C047E:64259:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.690133] [ip-0A0C04B4:62733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.691986] [ip-0A0C047E:64265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.696767] [ip-0A0C0438:68517:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.698469] [ip-0A0C0485:32815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.701995] [ip-0A0C04C8:86826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.702313] [ip-0A0C04CD:83578:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.705079] [ip-0A0C0437:63989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.705670] [ip-0A0C048D:53560:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.707132] [ip-0A0C04AD:29539:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.709456] [ip-0A0C046B:62523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.712023] [ip-0A0C04A0:42157:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.712425] [ip-0A0C048D:53561:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.712554] [ip-0A0C0473:65999:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.720457] [ip-0A0C0461:31368:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.720336] [ip-0A0C049B:41452:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.721923] [ip-0A0C0489:67988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.723986] [ip-0A0C04D4:83012:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.724797] [ip-0A0C04B4:62732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.724845] [ip-0A0C046C:63040:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.725928] [ip-0A0C048A:64360:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.727779] [ip-0A0C0437:63992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.731130] [ip-0A0C04CF:11118:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.731879] [ip-0A0C0429:58168:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.731729] [ip-0A0C0498:62585:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.735732] [ip-0A0C0482:55013:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.737312] [ip-0A0C045F:65402:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.740187] [ip-0A0C0437:63991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.742812] [ip-0A0C0485:32788:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.745059] [ip-0A0C0443:31049:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.746785] [ip-0A0C04D9:8916 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.746031] [ip-0A0C0498:62607:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.748037] [ip-0A0C0487:67827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.748098] [ip-0A0C0487:67830:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.748943] [ip-0A0C04AD:29536:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.751127] [ip-0A0C04BD:82828:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.750392] [ip-0A0C04CF:11120:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.751612] [ip-0A0C046E:69752:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.751201] [ip-0A0C0493:49056:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.751835] [ip-0A0C04C4:84958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.751829] [ip-0A0C0493:49053:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.752726] [ip-0A0C0486:67802:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.757445] [ip-0A0C04CD:83571:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.758789] [ip-0A0C0438:68514:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.761129] [ip-0A0C0437:63988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.762058] [ip-0A0C0486:67801:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.763472] [ip-0A0C045F:65407:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.762864] [ip-0A0C04AF:44203:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.763950] [ip-0A0C04B3:60425:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.764395] [ip-0A0C04BB:27688:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.766143] [ip-0A0C04D4:83013:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.765215] [ip-0A0C04B2:28777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.766858] [ip-0A0C0437:63986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.767005] [ip-0A0C04BC:80849:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.767936] [ip-0A0C04D4:83009:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.767523] [ip-0A0C049C:39344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.769598] [ip-0A0C0473:65990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.771128] [ip-0A0C04C4:84955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.771654] [ip-0A0C046E:69757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.772015] [ip-0A0C04AE:57726:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.774554] [ip-0A0C049B:41454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.776361] [ip-0A0C046B:62524:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.779960] [ip-0A0C04C7:87777:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.781891] [ip-0A0C04A0:42163:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.780674] [ip-0A0C0493:49057:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.782497] [ip-0A0C0491:49548:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.782919] [ip-0A0C04A8:57717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.782898] [ip-0A0C04A8:57711:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.783542] [ip-0A0C0482:55007:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.784507] [ip-0A0C04B2:28779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.785662] [ip-0A0C046C:63036:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.785405] [ip-0A0C04CD:83579:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.785482] [ip-0A0C04B0:39140:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.786719] [ip-0A0C048D:53564:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.788090] [ip-0A0C04B4:62731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.789353] [ip-0A0C04C7:87776:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.790232] [ip-0A0C04BB:27689:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.789781] [ip-0A0C0490:53759:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.791985] [ip-0A0C0485:32789:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.792106] [ip-0A0C04B3:60421:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.794750] [ip-0A0C04AD:29537:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.796005] [ip-0A0C048D:53566:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.797279] [ip-0A0C0461:31369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.797281] [ip-0A0C04C5:86954:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.798290] [ip-0A0C04BE:85711:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.798878] [ip-0A0C046E:69755:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.797687] [ip-0A0C049C:39322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.798735] [ip-0A0C0429:58172:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.799486] [ip-0A0C0473:65986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.799990] [ip-0A0C04B2:28780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.800822] [ip-0A0C04AB:42997:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.800777] [ip-0A0C048C:48510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.801719] [ip-0A0C0461:31373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.803609] [ip-0A0C04C0:84597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.803320] [ip-0A0C04A9:51793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.804436] [ip-0A0C049B:41450:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.805803] [ip-0A0C04CC:86676:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.806144] [ip-0A0C0483:66693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.806595] [ip-0A0C046E:69753:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.806362] [ip-0A0C0493:49054:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.807160] [ip-0A0C0438:68516:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.807805] [ip-0A0C0487:67824:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.808665] [ip-0A0C04A6:52328:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.809557] [ip-0A0C04B4:62734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.810537] [ip-0A0C04C8:86820:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.811550] [ip-0A0C0496:34177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.811881] [ip-0A0C047E:64260:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.811549] [ip-0A0C0429:58170:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.814125] [ip-0A0C04A2:44043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.812203] [ip-0A0C0493:49052:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.812304] [ip-0A0C0493:49050:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.814265] [ip-0A0C04A0:42159:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.814321] [ip-0A0C047E:64263:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.814747] [ip-0A0C04AB:43014:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.814398] [ip-0A0C04B7:23627:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.814939] [ip-0A0C046E:69756:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.815398] [ip-0A0C04D9:8921 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.816637] [ip-0A0C04DA:80358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.817903] [ip-0A0C04CD:83573:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.818382] [ip-0A0C0441:60661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.818828] [ip-0A0C0491:49539:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.819811] [ip-0A0C0489:67990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.820238] [ip-0A0C04CD:83576:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.819445] [ip-0A0C049B:41451:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.821163] [ip-0A0C04B4:62729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.821283] [ip-0A0C04B4:62736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.821388] [ip-0A0C04B0:39167:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.822651] [ip-0A0C04BB:27687:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.822501] [ip-0A0C04CC:86671:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.822415] [ip-0A0C048A:64359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.822911] [ip-0A0C04B7:23603:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.825512] [ip-0A0C04AC:46108:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.824880] [ip-0A0C048A:64388:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.824763] [ip-0A0C049B:41447:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.827348] [ip-0A0C04AB:43000:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.827505] [ip-0A0C04B3:60422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.827263] [ip-0A0C04A6:52331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.827429] [ip-0A0C0497:2576 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.827528] [ip-0A0C0497:2575 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.828089] [ip-0A0C0486:67797:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.828627] [ip-0A0C04C8:86819:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.829111] [ip-0A0C04C8:86822:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.829309] [ip-0A0C04DA:80360:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.829573] [ip-0A0C0460:67350:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.830280] [ip-0A0C047E:64266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.830446] [ip-0A0C0483:66691:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.830518] [ip-0A0C04B5:53325:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.831271] [ip-0A0C0483:66696:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.831136] [ip-0A0C0487:67829:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.831359] [ip-0A0C04B3:60427:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.831284] [ip-0A0C04AB:43003:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.830486] [ip-0A0C049B:41448:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.834254] [ip-0A0C04A1:70258:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.834930] [ip-0A0C0482:55012:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.835769] [ip-0A0C046C:63037:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.836046] [ip-0A0C0483:66695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.836090] [ip-0A0C047E:64267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.836045] [ip-0A0C04C8:86827:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.835978] [ip-0A0C04C5:86955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.835258] [ip-0A0C044D:64902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.838205] [ip-0A0C04D3:85179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.838408] [ip-0A0C0461:31371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.838587] [ip-0A0C04A4:52689:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.838196] [ip-0A0C04D3:85174:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.839097] [ip-0A0C04C8:86821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.839136] [ip-0A0C04AE:57702:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.839605] [ip-0A0C0483:66698:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.839566] [ip-0A0C04CD:83575:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.839677] [ip-0A0C04CD:83572:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.840472] [ip-0A0C04D8:86686:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.840250] [ip-0A0C049C:39316:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.841694] [ip-0A0C0494:49206:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.842011] [ip-0A0C04AF:44205:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.842794] [ip-0A0C048D:53563:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.842731] [ip-0A0C0438:68511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.843241] [ip-0A0C047E:64262:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.842716] [ip-0A0C042D:39075:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.843860] [ip-0A0C046B:62521:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.846404] [ip-0A0C04A2:44044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.845404] [ip-0A0C04C6:80880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.845416] [ip-0A0C04C6:80881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.846024] [ip-0A0C048F:57028:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.847442] [ip-0A0C04B3:60424:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.846935] [ip-0A0C048A:64362:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.847225] [ip-0A0C04A6:52333:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.848693] [ip-0A0C048D:53562:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.848898] [ip-0A0C04BD:82833:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.848883] [ip-0A0C0441:60663:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.848798] [ip-0A0C04C0:84593:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.849253] [ip-0A0C048B:50456:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.850007] [ip-0A0C0489:67991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.849956] [ip-0A0C0429:58171:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.850832] [ip-0A0C0489:67992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.850764] [ip-0A0C04A9:51772:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.852044] [ip-0A0C04AC:46104:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.852453] [ip-0A0C0466:70388:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.852607] [ip-0A0C0441:60660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.852961] [ip-0A0C04D8:86687:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.852941] [ip-0A0C0487:67831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.853988] [ip-0A0C04AB:42996:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.853949] [ip-0A0C0464:67818:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.856170] [ip-0A0C04B1:55734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.856165] [ip-0A0C0490:53754:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.857624] [ip-0A0C0491:49542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.856915] [ip-0A0C0497:2570 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.858532] [ip-0A0C0497:2564 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.859484] [ip-0A0C04B5:53334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.859931] [ip-0A0C04A4:52690:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.860246] [ip-0A0C04AB:43001:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.860451] [ip-0A0C0466:70387:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.860590] [ip-0A0C04AD:29540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.860758] [ip-0A0C048D:53568:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.861112] [ip-0A0C04A7:29528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.861102] [ip-0A0C0492:47645:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.861865] [ip-0A0C045F:65404:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.862860] [ip-0A0C04B3:60423:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.862331] [ip-0A0C048A:64358:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.862927] [ip-0A0C046C:63035:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.862874] [ip-0A0C0435:7979 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.862233] [ip-0A0C04CF:11124:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.862670] [ip-0A0C0494:49210:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.863130] [ip-0A0C0429:58169:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.863437] [ip-0A0C049D:55963:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.863799] [ip-0A0C046B:62526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.863601] [ip-0A0C0443:31048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.863882] [ip-0A0C04BC:80847:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.864850] [ip-0A0C04B5:53323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.864930] [ip-0A0C0497:2572 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.867213] [ip-0A0C04A0:42161:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.866570] [ip-0A0C0499:53914:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.866547] [ip-0A0C0499:53916:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.867802] [ip-0A0C04D9:8919 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.868367] [ip-0A0C046B:62519:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.867741] [ip-0A0C0443:31045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.869059] [ip-0A0C0438:68518:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.869325] [ip-0A0C046C:63039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.869667] [ip-0A0C04AF:44200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.871240] [ip-0A0C04B3:60420:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.872022] [ip-0A0C04A4:52715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.871850] [ip-0A0C04C0:84592:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.871708] [ip-0A0C0429:58166:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.872580] [ip-0A0C0497:2567 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.873414] [ip-0A0C04BC:80852:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.873343] [ip-0A0C0489:67989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.874239] [ip-0A0C04BD:82835:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.874503] [ip-0A0C048B:50458:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.874375] [ip-0A0C0489:67985:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.876457] [ip-0A0C04A1:70262:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.876829] [ip-0A0C04C3:83988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.876145] [ip-0A0C04A8:57710:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.878427] [ip-0A0C04C9:85790:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.879133] [ip-0A0C0472:69799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.880149] [ip-0A0C0485:32792:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.880659] [ip-0A0C0429:58165:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.882963] [ip-0A0C04C5:86956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.882771] [ip-0A0C044D:64909:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.883866] [ip-0A0C045F:65400:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.884674] [ip-0A0C0482:55008:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.885310] [ip-0A0C040F:37695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.885028] [ip-0A0C0498:62580:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.886408] [ip-0A0C04B0:39138:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.886479] [ip-0A0C046B:62525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.886412] [ip-0A0C0473:65987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.886008] [ip-0A0C049F:40432:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.887238] [ip-0A0C0496:34181:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.887330] [ip-0A0C0496:34176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.887239] [ip-0A0C04D9:8917 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.887018] [ip-0A0C04A9:51771:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.886889] [ip-0A0C044D:64904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.888069] [ip-0A0C0485:32790:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.887656] [ip-0A0C04B6:21795:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.888007] [ip-0A0C04CF:11117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.889134] [ip-0A0C04C9:85788:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.888703] [ip-0A0C0461:31370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.888932] [ip-0A0C0491:49543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.889010] [ip-0A0C04DA:80354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.890091] [ip-0A0C04D4:83007:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.889912] [ip-0A0C04AD:29541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.890207] [ip-0A0C04D4:83010:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.889909] [ip-0A0C0443:31047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.890606] [ip-0A0C0435:7973 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.890837] [ip-0A0C049D:55962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.892525] [ip-0A0C04A0:42162:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.890873] [ip-0A0C0498:62582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.892380] [ip-0A0C04BE:85712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.892404] [ip-0A0C0438:68513:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.892866] [ip-0A0C0485:32786:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.893128] [ip-0A0C0435:7974 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.892889] [ip-0A0C048C:48516:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.893759] [ip-0A0C04BD:82834:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.893872] [ip-0A0C0486:67804:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.896388] [ip-0A0C0485:32787:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.895995] [ip-0A0C0460:67348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.896306] [ip-0A0C0490:53753:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.898172] [ip-0A0C04AE:57703:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.899053] [ip-0A0C046B:62520:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.898258] [ip-0A0C0490:53758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.900503] [ip-0A0C04A0:42160:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.902301] [ip-0A0C04A2:44046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.901562] [ip-0A0C0487:67825:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.901130] [ip-0A0C04B6:21798:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.904972] [ip-0A0C04A0:42156:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.903984] [ip-0A0C0492:47652:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.904264] [ip-0A0C0492:47647:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.904562] [ip-0A0C0487:67826:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.905256] [ip-0A0C0487:67828:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.905773] [ip-0A0C0485:32791:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.906842] [ip-0A0C04D4:83006:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.908238] [ip-0A0C04A0:42158:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.908059] [ip-0A0C04B1:55730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.908733] [ip-0A0C04C4:84963:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.908717] [ip-0A0C04C3:83985:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.909054] [ip-0A0C045F:65403:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.908929] [ip-0A0C04C4:84957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.908624] [ip-0A0C0482:55010:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.909242] [ip-0A0C048A:64365:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.909951] [ip-0A0C0438:68515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.908862] [ip-0A0C049C:39319:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.911397] [ip-0A0C04AD:29542:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.912031] [ip-0A0C04D4:83008:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.912252] [ip-0A0C0438:68512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.912600] [ip-0A0C04BC:80848:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.913077] [ip-0A0C0449:65238:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.913504] [ip-0A0C048C:48515:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.914461] [ip-0A0C04B2:28782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.915184] [ip-0A0C0473:66011:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.915402] [ip-0A0C0473:65988:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.915919] [ip-0A0C0486:67798:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.916289] [ip-0A0C04AE:57699:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.918114] [ip-0A0C04BB:27690:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.918096] [ip-0A0C0473:65989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.919260] [ip-0A0C04AA:27347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.919972] [ip-0A0C04BA:20048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.919690] [ip-0A0C04C6:80884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.920809] [ip-0A0C04BD:82831:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.920834] [ip-0A0C04BE:85710:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.920351] [ip-0A0C0482:55006:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.921668] [ip-0A0C04AD:29538:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.921829] [ip-0A0C04AD:29535:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.921694] [ip-0A0C0486:67800:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.922525] [ip-0A0C04C0:84594:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.924163] [ip-0A0C04D9:8915 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.927413] [ip-0A0C04A2:44048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.925100] [ip-0A0C04A8:57713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.925514] [ip-0A0C0498:62586:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.925923] [ip-0A0C0498:62583:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.927030] [ip-0A0C04A7:29531:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.927240] [ip-0A0C04AC:46101:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.926863] [ip-0A0C04B2:28783:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.928184] [ip-0A0C04D9:8918 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.927788] [ip-0A0C04CF:11119:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.928675] [ip-0A0C04A5:55299:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.927786] [ip-0A0C0490:53756:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.928620] [ip-0A0C0494:49211:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.928439] [ip-0A0C0498:62581:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.928619] [ip-0A0C04B9:85886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.928418] [ip-0A0C0498:62584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.929881] [ip-0A0C04AA:27346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.929961] [ip-0A0C0461:31375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.930705] [ip-0A0C0473:65991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.930765] [ip-0A0C04C2:10253:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.931023] [ip-0A0C04C7:87779:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.931382] [ip-0A0C04B2:28781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.931276] [ip-0A0C04A8:57715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.933005] [ip-0A0C046C:63038:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.933164] [ip-0A0C046C:63041:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.933326] [ip-0A0C046C:63034:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.933414] [ip-0A0C04C4:84956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.933134] [ip-0A0C0461:31374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.933338] [ip-0A0C04CF:11121:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.934042] [ip-0A0C0461:31372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.933830] [ip-0A0C048F:57024:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.934383] [ip-0A0C0441:60664:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.934036] [ip-0A0C048F:57026:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.934407] [ip-0A0C0482:55009:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.936031] [ip-0A0C0482:55011:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.936294] [ip-0A0C0443:31046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.936748] [ip-0A0C04AE:57697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.937541] [ip-0A0C045F:65406:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.937306] [ip-0A0C048A:64364:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.938044] [ip-0A0C04A1:70259:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.938181] [ip-0A0C04C9:85792:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.938412] [ip-0A0C04AE:57700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.939395] [ip-0A0C04D9:8944 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.938620] [ip-0A0C04AF:44199:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.939457] [ip-0A0C04BD:82829:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.939741] [ip-0A0C04BB:27693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.939432] [ip-0A0C048B:50459:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.939679] [ip-0A0C04C7:87781:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.940162] [ip-0A0C04BD:82832:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.939721] [ip-0A0C048A:64361:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.940096] [ip-0A0C0436:68122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.940680] [ip-0A0C04B0:39143:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.941915] [ip-0A0C045F:65399:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.941505] [ip-0A0C048C:48514:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.942966] [ip-0A0C0449:65237:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.942948] [ip-0A0C04AF:44198:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.944868] [ip-0A0C045F:65405:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.945913] [ip-0A0C04D9:8920 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.946698] [ip-0A0C0486:67803:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.947414] [ip-0A0C0495:51733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.948010] [ip-0A0C04C5:86960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.947945] [ip-0A0C0443:31051:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.948837] [ip-0A0C04A8:57714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.950129] [ip-0A0C04D8:86692:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.950014] [ip-0A0C0486:67799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.949865] [ip-0A0C04A9:51795:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.951397] [ip-0A0C04BE:85716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.951613] [ip-0A0C04BA:20044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.951813] [ip-0A0C04BC:80850:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.952389] [ip-0A0C0484:69744:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.952362] [ip-0A0C0484:69743:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.953820] [ip-0A0C0441:60667:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.953786] [ip-0A0C0460:67349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.954685] [ip-0A0C0464:67817:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.955979] [ip-0A0C04C4:84960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.956178] [ip-0A0C04C4:84961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.956792] [ip-0A0C04C4:84962:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.957216] [ip-0A0C04BD:82830:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.957168] [ip-0A0C04B2:28778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.957152] [ip-0A0C04CF:11122:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.957261] [ip-0A0C04CF:11123:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.957455] [ip-0A0C04B2:28784:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.958131] [ip-0A0C04CC:86672:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.958764] [ip-0A0C0496:34173:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.958301] [ip-0A0C04B9:85882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.959623] [ip-0A0C04DA:80362:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.958915] [ip-0A0C049C:39317:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.959083] [ip-0A0C049C:39323:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.960998] [ip-0A0C04C6:80882:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.962639] [ip-0A0C04BB:27694:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.961799] [ip-0A0C042D:39076:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.962408] [ip-0A0C04BC:80854:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.962179] [ip-0A0C0443:31050:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.963558] [ip-0A0C04BB:27695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.962667] [ip-0A0C0443:31044:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.963690] [ip-0A0C04B1:55729:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.963602] [ip-0A0C04C7:87775:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.964178] [ip-0A0C04BB:27691:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.964196] [ip-0A0C04BE:85717:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.964602] [ip-0A0C04BE:85713:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.964451] [ip-0A0C04BC:80851:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.966450] [ip-0A0C04B0:39139:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.966613] [ip-0A0C04B0:39144:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.966284] [ip-0A0C04D3:85180:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.966831] [ip-0A0C04AE:57698:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.968470] [ip-0A0C04BC:80866:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.968844] [ip-0A0C048C:48511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.970039] [ip-0A0C04D3:85175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.969842] [ip-0A0C0488:66348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.971453] [ip-0A0C0491:49544:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.973426] [ip-0A0C04A1:70260:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.973561] [ip-0A0C04B7:23597:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.973751] [ip-0A0C0491:49541:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.973822] [ip-0A0C0491:49546:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.973439] [ip-0A0C04A8:57712:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.974581] [ip-0A0C0495:51734:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.974155] [ip-0A0C04AF:44201:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.974952] [ip-0A0C04B7:23596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.975452] [ip-0A0C04A7:29532:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.975148] [ip-0A0C04A9:51773:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.975419] [ip-0A0C0449:65234:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.975178] [ip-0A0C049C:39320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.976984] [ip-0A0C04AC:46105:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.975327] [ip-0A0C049C:39318:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.977655] [ip-0A0C04CC:86674:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.977816] [ip-0A0C048B:50460:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.977242] [ip-0A0C04A6:52334:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.979020] [ip-0A0C04C7:87782:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.978673] [ip-0A0C04A8:57716:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.980008] [ip-0A0C04A1:70265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.980164] [ip-0A0C048B:50462:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.979963] [ip-0A0C04C0:84598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.979802] [ip-0A0C049F:40434:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.980273] [ip-0A0C049F:40433:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.981003] [ip-0A0C04DA:80356:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.981379] [ip-0A0C04AE:57701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.983731] [ip-0A0C04C0:84595:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.983488] [ip-0A0C04AF:44202:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.983576] [ip-0A0C04AF:44204:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.984297] [ip-0A0C04B7:23598:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.984481] [ip-0A0C04CC:86675:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.986806] [ip-0A0C04A2:44049:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.984846] [ip-0A0C048F:57031:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.985506] [ip-0A0C0460:67352:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.986017] [ip-0A0C04C0:84591:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.986285] [ip-0A0C04A6:52335:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.986347] [ip-0A0C04A6:52329:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.987800] [ip-0A0C04D8:86688:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.988114] [ip-0A0C0472:69801:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.988676] [ip-0A0C0472:69797:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.989417] [ip-0A0C0491:49540:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.989755] [ip-0A0C0436:68096:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.989889] [ip-0A0C044D:64906:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.991247] [ip-0A0C04B1:55732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.991086] [ip-0A0C04DA:80359:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.990531] [ip-0A0C04A9:51770:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.992075] [ip-0A0C048C:48513:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.992540] [ip-0A0C04C5:86957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.992949] [ip-0A0C04B0:39141:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.993247] [ip-0A0C048C:48512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.993642] [ip-0A0C04C7:87780:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.993632] [ip-0A0C042D:39077:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.993720] [ip-0A0C04D3:85173:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.994024] [ip-0A0C04B5:53324:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.993920] [ip-0A0C04B6:21794:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.995543] [ip-0A0C040F:37691:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.996568] [ip-0A0C04C7:87778:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.996997] [ip-0A0C04BE:85715:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.997087] [ip-0A0C04C5:86961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.996967] [ip-0A0C04A9:51774:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.999328] [ip-0A0C04B7:23602:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625175.999454] [ip-0A0C040F:37694:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.000049] [ip-0A0C04BE:85714:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.002381] [ip-0A0C04B0:39142:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.002327] [ip-0A0C0464:67820:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.002565] [ip-0A0C0499:53915:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.002487] [ip-0A0C04C5:86958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.002686] [ip-0A0C04C5:86959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.003706] [ip-0A0C04B7:23601:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.004250] [ip-0A0C0441:60665:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.004187] [ip-0A0C04C0:84596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.004244] [ip-0A0C0441:60662:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.003917] [ip-0A0C044D:64903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.005655] [ip-0A0C0494:49207:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.006019] [ip-0A0C0490:53752:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.007502] [ip-0A0C04AC:46102:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.006222] [ip-0A0C0490:53757:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.006465] [ip-0A0C04A9:51769:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.009646] [ip-0A0C04A2:44050:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.007703] [ip-0A0C04BA:20047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.007805] [ip-0A0C0466:70382:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.007363] [ip-0A0C042D:39079:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.008943] [ip-0A0C0466:70389:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.007906] [ip-0A0C0490:53755:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.009179] [ip-0A0C04A4:52691:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.008649] [ip-0A0C04B6:21815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.009780] [ip-0A0C04D8:86689:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.012845] [ip-0A0C04A2:44047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.012118] [ip-0A0C04A7:29526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.011499] [ip-0A0C0484:69738:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.011414] [ip-0A0C04B9:85884:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.012426] [ip-0A0C040F:37697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.012080] [ip-0A0C048C:48509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.012881] [ip-0A0C04B7:23599:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.012893] [ip-0A0C0464:67815:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.013222] [ip-0A0C04A6:52330:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.013318] [ip-0A0C04A6:52332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.014167] [ip-0A0C0494:49212:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.014564] [ip-0A0C0460:67354:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.015033] [ip-0A0C04D3:85178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.015651] [ip-0A0C0441:60666:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.015552] [ip-0A0C04B5:53326:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.016138] [ip-0A0C04A4:52692:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.016297] [ip-0A0C04CC:86673:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.016604] [ip-0A0C049D:55960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.017981] [ip-0A0C048B:50457:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.018308] [ip-0A0C04B1:55736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.018230] [ip-0A0C04C3:83992:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.018381] [ip-0A0C04D3:85177:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.019088] [ip-0A0C0499:53912:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.018870] [ip-0A0C04D3:85176:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.019019] [ip-0A0C04C6:80885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.020230] [ip-0A0C0435:7976 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.021619] [ip-0A0C048B:50454:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.021965] [ip-0A0C04A7:29525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.022371] [ip-0A0C0496:34174:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.024137] [ip-0A0C04A2:44045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.022259] [ip-0A0C048B:50455:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.023193] [ip-0A0C04C2:10223:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.022320] [ip-0A0C049F:40436:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.023340] [ip-0A0C04C2:10226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.023555] [ip-0A0C04DA:80361:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.024027] [ip-0A0C04CC:86678:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.024264] [ip-0A0C049D:55958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.024623] [ip-0A0C04A1:70261:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.024584] [ip-0A0C04CC:86677:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.024351] [ip-0A0C0460:67351:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.024969] [ip-0A0C0496:34179:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.024656] [ip-0A0C0460:67365:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.024661] [ip-0A0C0460:67353:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.025934] [ip-0A0C04AC:46103:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.026737] [ip-0A0C0492:47651:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.027168] [ip-0A0C04DA:80357:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.027273] [ip-0A0C04AA:27348:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.027848] [ip-0A0C0472:69798:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.028165] [ip-0A0C0496:34178:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.028447] [ip-0A0C0496:34175:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.028035] [ip-0A0C0494:49209:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.029760] [ip-0A0C04B5:53322:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.029817] [ip-0A0C042D:39078:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.031546] [ip-0A0C04A1:70263:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.030963] [ip-0A0C042D:39081:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.031745] [ip-0A0C0435:7992 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.033052] [ip-0A0C04A7:29527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.032961] [ip-0A0C04A5:55303:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.033516] [ip-0A0C04C9:85794:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.033612] [ip-0A0C0499:53917:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.034154] [ip-0A0C04AC:46106:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.033794] [ip-0A0C04B5:53320:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.033369] [ip-0A0C04B6:21801:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.034128] [ip-0A0C04A4:52693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.033838] [ip-0A0C04B5:53321:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.035685] [ip-0A0C04C9:85787:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.035578] [ip-0A0C0495:51738:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.036303] [ip-0A0C04D8:86690:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.037391] [ip-0A0C0492:47649:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.037576] [ip-0A0C0435:7977 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.038060] [ip-0A0C0492:47653:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.038541] [ip-0A0C0464:67816:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.039225] [ip-0A0C049D:55957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.039615] [ip-0A0C0472:69796:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.039957] [ip-0A0C04AC:46107:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.039932] [ip-0A0C0466:70384:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.040425] [ip-0A0C04A1:70264:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.039384] [ip-0A0C04C6:80883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.040103] [ip-0A0C048F:57027:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.041108] [ip-0A0C04A4:52694:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.040887] [ip-0A0C044D:64907:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.041128] [ip-0A0C044D:64901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.042432] [ip-0A0C04D8:86685:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.042070] [ip-0A0C044D:64905:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.042581] [ip-0A0C04C6:80879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.043246] [ip-0A0C04C6:80886:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.044935] [ip-0A0C04C9:85791:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.044919] [ip-0A0C04C3:83987:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.045600] [ip-0A0C0499:53910:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.045879] [ip-0A0C0466:70383:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.045358] [ip-0A0C0494:49205:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.045537] [ip-0A0C0449:65233:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.047638] [ip-0A0C0466:70385:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.048118] [ip-0A0C04A4:52695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.048874] [ip-0A0C0464:67819:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.049657] [ip-0A0C0466:70386:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.051211] [ip-0A0C0488:66347:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.052549] [ip-0A0C0499:53913:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.052713] [ip-0A0C04C3:83989:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.052875] [ip-0A0C04D8:86691:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.052486] [ip-0A0C0494:49208:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.053869] [ip-0A0C049F:40429:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.057494] [ip-0A0C0492:47648:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.057603] [ip-0A0C0464:67821:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.058259] [ip-0A0C04A5:55298:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.058268] [ip-0A0C048F:57025:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.059364] [ip-0A0C040F:37693:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.059988] [ip-0A0C04A7:29530:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.059269] [ip-0A0C042D:39080:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.060092] [ip-0A0C04A7:29529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.059743] [ip-0A0C048F:57035:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.060185] [ip-0A0C042D:39082:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.061730] [ip-0A0C0499:53911:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.062214] [ip-0A0C049D:55961:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.062994] [ip-0A0C04A5:55301:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.063883] [ip-0A0C049D:55959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.064390] [ip-0A0C04C9:85793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.064696] [ip-0A0C0492:47646:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.064603] [ip-0A0C0436:68098:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.064818] [ip-0A0C0464:67814:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.065881] [ip-0A0C0435:7978 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.066299] [ip-0A0C0435:7975 :0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.067887] [ip-0A0C049D:55964:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.068844] [ip-0A0C048F:57032:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.070441] [ip-0A0C04BA:20043:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.070507] [ip-0A0C0488:66346:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.072014] [ip-0A0C04C3:83991:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.072624] [ip-0A0C049F:40431:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.074362] [ip-0A0C040F:37696:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.075930] [ip-0A0C0484:69737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.076760] [ip-0A0C040F:37690:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.076969] [ip-0A0C04AA:27344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.077287] [ip-0A0C0472:69795:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.079396] [ip-0A0C049F:40435:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.081191] [ip-0A0C04B1:55731:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.081154] [ip-0A0C04C3:83986:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.082420] [ip-0A0C0449:65239:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.083495] [ip-0A0C04B1:55733:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.083638] [ip-0A0C04C9:85789:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.084292] [ip-0A0C04B1:55735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.085551] [ip-0A0C04C2:10228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.085742] [ip-0A0C049F:40430:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.086658] [ip-0A0C04C3:83990:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.086622] [ip-0A0C0436:68099:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.094182] [ip-0A0C040F:37692:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.093779] [ip-0A0C04B9:85880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.095127] [ip-0A0C04AA:27342:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.095547] [ip-0A0C0484:69741:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.096303] [ip-0A0C0495:51739:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.098692] [ip-0A0C04A5:55302:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.099369] [ip-0A0C0472:69794:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.099928] [ip-0A0C0472:69800:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.100164] [ip-0A0C04BA:20042:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.103031] [ip-0A0C04AA:27345:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.102878] [ip-0A0C04B9:85883:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.105385] [ip-0A0C04BA:20049:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.105732] [ip-0A0C04AA:27343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.106384] [ip-0A0C04B6:21796:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.106488] [ip-0A0C04B6:21797:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.108101] [ip-0A0C04B6:21800:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.113760] [ip-0A0C0449:65235:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.116995] [ip-0A0C04AA:27341:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.117962] [ip-0A0C0449:65236:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.119704] [ip-0A0C04BA:20046:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.120159] [ip-0A0C04A5:55300:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.119733] [ip-0A0C04B9:85881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.120259] [ip-0A0C0484:69742:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.120314] [ip-0A0C0449:65240:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.122056] [ip-0A0C0495:51736:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.122405] [ip-0A0C0436:68094:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.123017] [ip-0A0C0488:66342:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.125584] [ip-0A0C04A5:55304:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.126540] [ip-0A0C0436:68093:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.130800] [ip-0A0C04A5:55305:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.132397] [ip-0A0C0495:51735:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.132541] [ip-0A0C04BA:20045:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.133054] [ip-0A0C04C2:10225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.134772] [ip-0A0C0436:68092:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.135188] [ip-0A0C04DB:78953:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.136942] [ip-0A0C0436:68095:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.136740] [ip-0A0C0488:66344:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.137848] [ip-0A0C0495:51737:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.137452] [ip-0A0C0484:69739:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.138303] [ip-0A0C0484:69745:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.146161] [ip-0A0C04C2:10229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.145462] [ip-0A0C04B9:85887:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.145556] [ip-0A0C04B9:85885:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.157850] [ip-0A0C04C2:10230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.158434] [ip-0A0C0495:51732:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.162297] [ip-0A0C04C2:10224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.175091] [ip-0A0C0488:66345:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.184113] [ip-0A0C0488:66349:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.186406] [ip-0A0C0488:66343:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.189465] [ip-0A0C04DB:78960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.261598] [ip-0A0C04DB:78957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.285223] [ip-0A0C04DB:78956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.302742] [ip-0A0C04DB:78959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.323988] [ip-0A0C04DB:78954:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.328962] [ip-0A0C04DB:78958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1634625176.338249] [ip-0A0C04DB:78955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
:::MLLOG {"namespace": "", "time_ms": 1634625177238, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "main.py", "lineno": 46}}
:::MLLOG {"namespace": "", "time_ms": 1634625177281, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "main.py", "lineno": 47}}
:::MLLOG {"namespace": "", "time_ms": 1634625177281, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "unet3d", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 115}}
:::MLLOG {"namespace": "", "time_ms": 1634625177282, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "Azure", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634625177282, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1634625177282, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "cloud", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1634625177282, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "96xND96amsr_A100_v4", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 132}}
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[06:33:09] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[ip-0A0C0435:0:7976 - context.c:584] INFO job (ID: 867565100276737230) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:7976 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:7976 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:7974 - context.c:584] INFO job (ID: 867564901203130127) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:7974 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:7974 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:7975 - context.c:584] INFO job (ID: 867565209481242041) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:7975 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:7975 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:7992 - context.c:584] INFO job (ID: 867564514120928038) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:7992 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:7992 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:7977 - context.c:584] INFO job (ID: 867564418150896277) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:7977 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:7977 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:7973 - context.c:584] INFO job (ID: 867564870690914595) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:7973 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:7973 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:7979 - context.c:584] INFO job (ID: 867565078967015239) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:7979 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:7979 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[ip-0A0C0435:0:7978 - context.c:584] INFO job (ID: 867564220286626823) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0435:0:7978 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0435:0:7978 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270090, "event_type": "POINT_IN_TIME", "key": "seed", "value": 3337581297, "metadata": {"file": "main.py", "lineno": 72}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270091, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "nag", "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 138}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270091, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 1.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 139}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270091, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_epochs", "value": 1500, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 140}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270091, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_boundary_epochs", "value": [], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 142}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270091, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_decay_factor", "value": 1.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 143}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270091, "event_type": "POINT_IN_TIME", "key": "opt_weight_decay", "value": 0.0, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 144}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270091, "event_type": "POINT_IN_TIME", "key": "opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 145}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270092, "event_type": "POINT_IN_TIME", "key": "oversampling", "value": 0.4, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 146}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270092, "event_type": "POINT_IN_TIME", "key": "training_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 147}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270092, "event_type": "POINT_IN_TIME", "key": "validation_input_shape", "value": [128, 128, 128], "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 148}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625270092, "event_type": "POINT_IN_TIME", "key": "validation_overlap", "value": 0.5, "metadata": {"file": "/workspace/unet3d/mlperf_logger.py", "lineno": 149}}
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:30] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[06:34:31] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1634625294215, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "main.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1634625294234, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "main.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625294238, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 168, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1634625294239, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 42, "metadata": {"file": "/workspace/unet3d/data_loading/data_loader.py", "lineno": 95}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625296949, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 84, "metadata": {"file": "main.py", "lineno": 136}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625296950, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "main.py", "lineno": 137}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625296950, "event_type": "POINT_IN_TIME", "key": "samples_per_epoch", "value": 168, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634625296950, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1, "epoch_count": 20}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/usr/local/lib/python3.8/dist-packages/nvidia/dali/pipeline.py:200: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
:::MLLOG {"namespace": "", "time_ms": 1634625298421, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 2285.7683674639497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625298421, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.02989933774834437, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625298421, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 2285.7683674639497, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1634625298421, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625298421, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 20, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625299098, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4968.485762132243, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625299098, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.04976556291390729, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625299098, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4968.485762132243, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625299098, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625299099, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 40, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625299747, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5183.442040912557, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625299747, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.0696317880794702, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625299747, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5183.442040912557, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 40}}
:::MLLOG {"namespace": "", "time_ms": 1634625299748, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625299748, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 60, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625300379, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5326.732439148108, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625300379, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.08949801324503312, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625300379, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5326.732439148108, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 60}}
:::MLLOG {"namespace": "", "time_ms": 1634625300380, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625300380, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 80, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625301004, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5381.744217040741, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625301005, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.10936423841059603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625301005, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5381.744217040741, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 80}}
:::MLLOG {"namespace": "", "time_ms": 1634625301005, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625301005, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625301623, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5442.326695738006, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625301623, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.12923046357615892, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625301623, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5442.326695738006, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 100}}
:::MLLOG {"namespace": "", "time_ms": 1634625301623, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625301623, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625302236, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5488.402287914764, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625302236, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.14909668874172186, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625302236, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5488.402287914764, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 120}}
:::MLLOG {"namespace": "", "time_ms": 1634625302236, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625302236, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625302847, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5504.602553866969, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625302847, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.16896291390728477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625302847, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5504.602553866969, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 140}}
:::MLLOG {"namespace": "", "time_ms": 1634625302848, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625302848, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625303469, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5411.439911038478, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625303469, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.18882913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625303469, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5411.439911038478, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 160}}
:::MLLOG {"namespace": "", "time_ms": 1634625303469, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625303469, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625304085, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.825665822069, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625304086, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.20869536423841056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625304086, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.825665822069, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 180}}
:::MLLOG {"namespace": "", "time_ms": 1634625304086, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625304086, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625304704, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5443.018241802467, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625304704, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.22856158940397348, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625304704, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5443.018241802467, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 200}}
:::MLLOG {"namespace": "", "time_ms": 1634625304704, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625304704, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625305318, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5477.799763130349, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625305318, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.24842781456953641, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625305319, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5477.799763130349, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 220}}
:::MLLOG {"namespace": "", "time_ms": 1634625305319, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625305319, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625305930, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5496.307200299525, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625305931, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.26829403973509935, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625305931, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5496.307200299525, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 240}}
:::MLLOG {"namespace": "", "time_ms": 1634625305931, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625305931, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625306541, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5513.997168830214, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625306541, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.28816026490066227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625306541, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5513.997168830214, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 260}}
:::MLLOG {"namespace": "", "time_ms": 1634625306541, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625306541, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625307152, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5501.274108078673, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625307153, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3080264900662252, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625307153, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5501.274108078673, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 280}}
:::MLLOG {"namespace": "", "time_ms": 1634625307153, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625307153, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625307771, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.105561948245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625307772, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.32789271523178803, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625307772, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.105561948245, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 300}}
:::MLLOG {"namespace": "", "time_ms": 1634625307772, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625307772, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625308392, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5420.62528775599, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625308392, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.347758940397351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625308393, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5420.62528775599, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 320}}
:::MLLOG {"namespace": "", "time_ms": 1634625308393, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625308393, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625309009, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5456.064347581004, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625309009, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.36762516556291386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625309009, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5456.064347581004, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 340}}
:::MLLOG {"namespace": "", "time_ms": 1634625309009, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625309010, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625309625, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5459.107785609475, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625309626, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.3874913907284768, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625309626, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5459.107785609475, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 360}}
:::MLLOG {"namespace": "", "time_ms": 1634625309626, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625309626, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625310245, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5429.6159663794315, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625310245, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.40735761589403974, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625310246, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5429.6159663794315, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 380}}
:::MLLOG {"namespace": "", "time_ms": 1634625310246, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625310246, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625310860, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5475.226789208106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625310860, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.42722384105960265, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625310860, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5475.226789208106, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 400}}
:::MLLOG {"namespace": "", "time_ms": 1634625310860, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625310860, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625311477, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5451.301002735154, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625311477, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.44709006622516556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625311477, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5451.301002735154, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 420}}
:::MLLOG {"namespace": "", "time_ms": 1634625311477, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625311478, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625312096, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.821223382106, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625312096, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4669562913907285, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625312096, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.821223382106, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 440}}
:::MLLOG {"namespace": "", "time_ms": 1634625312096, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625312096, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625312716, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5419.562162139297, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625312717, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.4868225165562914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625312717, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5419.562162139297, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 460}}
:::MLLOG {"namespace": "", "time_ms": 1634625312717, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625312717, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625313340, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5391.83547260421, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625313341, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5066887417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625313341, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5391.83547260421, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 480}}
:::MLLOG {"namespace": "", "time_ms": 1634625313341, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625313341, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625313957, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5461.115352616056, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625313957, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5265549668874172, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625313957, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5461.115352616056, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 500}}
:::MLLOG {"namespace": "", "time_ms": 1634625313957, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625313957, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625314571, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5481.487861494707, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625314571, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5464211920529801, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625314571, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5481.487861494707, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 520}}
:::MLLOG {"namespace": "", "time_ms": 1634625314571, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625314571, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625315196, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5377.829919543546, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625315197, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.566287417218543, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625315197, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5377.829919543546, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 540}}
:::MLLOG {"namespace": "", "time_ms": 1634625315197, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625315197, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625315815, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5438.019527362656, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625315815, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.5861536423841059, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625315816, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5438.019527362656, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 560}}
:::MLLOG {"namespace": "", "time_ms": 1634625315816, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625315816, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625316429, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5477.499564687446, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625316430, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6060198675496689, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625316430, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5477.499564687446, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 580}}
:::MLLOG {"namespace": "", "time_ms": 1634625316430, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625316430, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625317046, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5453.14035173933, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625317047, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6258860927152318, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625317047, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5453.14035173933, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 600}}
:::MLLOG {"namespace": "", "time_ms": 1634625317047, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625317047, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625317658, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5499.202578520394, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625317659, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6457523178807947, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625317659, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5499.202578520394, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 620}}
:::MLLOG {"namespace": "", "time_ms": 1634625317659, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625317659, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625318266, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5538.458113942526, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625318266, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6656185430463576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625318266, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5538.458113942526, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 640}}
:::MLLOG {"namespace": "", "time_ms": 1634625318267, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625318267, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625318895, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5345.944560648029, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625318896, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.6854847682119205, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625318896, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5345.944560648029, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 660}}
:::MLLOG {"namespace": "", "time_ms": 1634625318896, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625318896, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625319508, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5497.739495168901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625319508, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7053509933774835, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625319508, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5497.739495168901, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 680}}
:::MLLOG {"namespace": "", "time_ms": 1634625319508, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625319508, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625320118, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5512.483078665819, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625320119, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7252172185430463, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625320119, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5512.483078665819, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 700}}
:::MLLOG {"namespace": "", "time_ms": 1634625320119, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625320119, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625320732, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5480.88029411067, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625320733, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7450834437086092, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625320733, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5480.88029411067, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 720}}
:::MLLOG {"namespace": "", "time_ms": 1634625320733, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625320733, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625321345, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5486.440824846779, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625321346, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7649496688741722, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625321346, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5486.440824846779, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 740}}
:::MLLOG {"namespace": "", "time_ms": 1634625321346, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625321346, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625321955, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5522.653344974661, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625321955, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.7848158940397352, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625321955, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5522.653344974661, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 760}}
:::MLLOG {"namespace": "", "time_ms": 1634625321956, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625321956, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625322565, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5517.61969120132, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625322565, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8046821192052981, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625322565, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5517.61969120132, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 780}}
:::MLLOG {"namespace": "", "time_ms": 1634625322565, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625322565, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625323185, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5427.754821594458, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625323185, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8245483443708609, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625323185, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5427.754821594458, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 800}}
:::MLLOG {"namespace": "", "time_ms": 1634625323185, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625323185, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625323794, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5520.187264391877, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625323794, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8444145695364238, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625323795, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5520.187264391877, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 820}}
:::MLLOG {"namespace": "", "time_ms": 1634625323795, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625323795, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625324402, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5533.191402483267, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625324403, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8642807947019867, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625324403, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5533.191402483267, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 840}}
:::MLLOG {"namespace": "", "time_ms": 1634625324403, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625324403, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625325020, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5446.512288686154, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625325021, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.8841470198675497, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625325021, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5446.512288686154, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 860}}
:::MLLOG {"namespace": "", "time_ms": 1634625325021, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625325021, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625325638, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5448.936142078163, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625325638, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9040132450331126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625325638, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5448.936142078163, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 880}}
:::MLLOG {"namespace": "", "time_ms": 1634625325638, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625325639, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625326255, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5455.168870742233, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625326255, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9238794701986754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625326255, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5455.168870742233, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 900}}
:::MLLOG {"namespace": "", "time_ms": 1634625326255, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625326255, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625326880, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5379.447521910404, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625326881, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9437456953642384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625326881, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5379.447521910404, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 920}}
:::MLLOG {"namespace": "", "time_ms": 1634625326881, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625326881, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625327489, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5525.541891100313, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625327490, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9636119205298014, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625327490, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5525.541891100313, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 940}}
:::MLLOG {"namespace": "", "time_ms": 1634625327490, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625327490, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625328100, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5507.472243520752, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625328101, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 0.9834781456953643, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625328101, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5507.472243520752, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 960}}
:::MLLOG {"namespace": "", "time_ms": 1634625328101, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625328101, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625328711, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5506.865358104116, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625328712, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0033443708609273, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625328712, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5506.865358104116, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 980}}
:::MLLOG {"namespace": "", "time_ms": 1634625328783, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625328783, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625328799, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625329229, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8800086975097656, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625329229, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625329381, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5621.747733308016, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625329381, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0232105960264901, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625329381, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5621.747733308016, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1000}}
:::MLLOG {"namespace": "", "time_ms": 1634625329507, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625329507, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625329511, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625329923, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8903529644012451, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625329923, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625330129, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5408.1048460442125, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625330129, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.043076821192053, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625330129, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5408.1048460442125, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1020}}
:::MLLOG {"namespace": "", "time_ms": 1634625330194, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625330195, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625330210, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625330636, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8271867036819458, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625330636, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625330830, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5289.650507294219, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625330830, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.062943046357616, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625330831, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5289.650507294219, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1040}}
:::MLLOG {"namespace": "", "time_ms": 1634625330860, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625330861, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625330877, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625331308, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8943434953689575, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625331308, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625331502, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5240.850340325789, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625331502, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.0828092715231787, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625331503, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5240.850340325789, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1060}}
:::MLLOG {"namespace": "", "time_ms": 1634625331531, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625331532, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625331547, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625331987, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8855971693992615, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625331987, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625332178, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5195.237660590198, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625332179, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1026754966887418, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625332179, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5195.237660590198, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1080}}
:::MLLOG {"namespace": "", "time_ms": 1634625332206, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625332206, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625332223, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625332724, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8718839883804321, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625332724, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625332933, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4623.856103579595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625332933, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1225417218543046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625332934, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4623.856103579595, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1100}}
:::MLLOG {"namespace": "", "time_ms": 1634625332969, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625332970, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625332985, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625333383, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8939919471740723, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625333383, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625333568, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5619.353702178902, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625333568, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1424079470198676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625333568, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5619.353702178902, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1120}}
:::MLLOG {"namespace": "", "time_ms": 1634625333595, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625333596, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625333612, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625334082, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8831466436386108, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625334082, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625334278, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4929.144017552444, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625334278, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1622741721854304, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625334278, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4929.144017552444, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1140}}
:::MLLOG {"namespace": "", "time_ms": 1634625334307, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625334307, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625334322, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625334775, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8734010457992554, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625334775, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625334972, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5057.197324141079, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625334972, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.1821403973509934, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625334972, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5057.197324141079, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1160}}
:::MLLOG {"namespace": "", "time_ms": 1634625335008, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625335008, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625335024, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625335428, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8681560158729553, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625335428, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625335617, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5515.8920310173635, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625335618, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2020066225165562, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625335618, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5515.8920310173635, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1634625335664, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625335664, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625335681, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625336079, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.880953311920166, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625336079, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625336270, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5552.896037321754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625336270, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.2218728476821192, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625336270, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5552.896037321754, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1200}}
:::MLLOG {"namespace": "", "time_ms": 1634625336306, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625336307, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625336322, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625336720, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8870017528533936, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625336721, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625336921, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5470.880151492036, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625336921, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.241739072847682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625336921, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5470.880151492036, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1220}}
:::MLLOG {"namespace": "", "time_ms": 1634625336968, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625336968, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625336982, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625337387, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8872594237327576, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625337387, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625337564, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5636.549356387965, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625337565, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.261605298013245, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625337565, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5636.549356387965, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1240}}
:::MLLOG {"namespace": "", "time_ms": 1634625337592, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625337592, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625337608, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625338056, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8912961483001709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625338056, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625338246, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5138.039526798422, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625338247, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.281471523178808, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625338247, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5138.039526798422, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1260}}
:::MLLOG {"namespace": "", "time_ms": 1634625338276, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625338276, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625338293, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625338760, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8769727945327759, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625338760, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625338959, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4919.760799457645, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625338960, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3013377483443709, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625338960, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4919.760799457645, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1280}}
:::MLLOG {"namespace": "", "time_ms": 1634625338999, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625339000, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625339015, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625339461, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.886748731136322, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625339461, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625339656, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5122.154924448108, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625339656, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3212039735099337, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625339656, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5122.154924448108, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1300}}
:::MLLOG {"namespace": "", "time_ms": 1634625339685, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625339686, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625339702, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625340122, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8754285573959351, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625340122, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625340308, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5401.2752086580695, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625340308, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3410701986754967, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625340308, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5401.2752086580695, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1320}}
:::MLLOG {"namespace": "", "time_ms": 1634625340335, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625340336, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625340352, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625340782, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8918332457542419, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625340782, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625340966, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5327.733269720991, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625340967, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3609364238410595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625340967, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5327.733269720991, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1340}}
:::MLLOG {"namespace": "", "time_ms": 1634625341002, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625341003, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625341019, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625341417, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8863560557365417, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625341417, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625341606, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5569.420423648435, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625341606, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.3808026490066225, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625341607, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5569.420423648435, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1360}}
:::MLLOG {"namespace": "", "time_ms": 1634625341641, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625341642, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625341657, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625342055, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8908352851867676, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625342055, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625342245, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5574.3814998172575, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625342245, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4006688741721853, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625342245, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5574.3814998172575, "iterations": 2, "loss_scale": 512.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1380}}
:::MLLOG {"namespace": "", "time_ms": 1634625342274, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625342275, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1400, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625342291, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625342723, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8855945467948914, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625342723, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1400, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625342919, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5213.345466975039, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625342920, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4205350993377484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625342920, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5213.345466975039, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1400}}
:::MLLOG {"namespace": "", "time_ms": 1634625342948, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625342948, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1420, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625342965, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625343409, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8961755037307739, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625343409, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1420, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625343604, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5122.8885334574115, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625343605, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4404013245033112, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625343605, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5122.8885334574115, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1420}}
:::MLLOG {"namespace": "", "time_ms": 1634625343633, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625343634, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1440, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625343650, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625344105, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8805724382400513, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625344105, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1440, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625344302, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5023.757813494232, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625344303, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4602675496688742, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625344303, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5023.757813494232, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1440}}
:::MLLOG {"namespace": "", "time_ms": 1634625344330, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625344331, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1460, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625344347, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625344792, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.890112578868866, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625344792, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1460, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625345000, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5021.067613528264, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625345001, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.4801337748344372, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625345001, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5021.067613528264, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1460}}
:::MLLOG {"namespace": "", "time_ms": 1634625345036, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625345036, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1480, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625345052, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625345481, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8734957575798035, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625345481, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1480, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625345671, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5291.998328233293, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625345672, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625345672, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5291.998328233293, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1480}}
:::MLLOG {"namespace": "", "time_ms": 1634625345709, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625345709, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1500, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625345725, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625346130, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8928452730178833, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625346130, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1500, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625346325, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5460.144174329593, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625346325, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625346325, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5460.144174329593, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1500}}
:::MLLOG {"namespace": "", "time_ms": 1634625346354, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625346354, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1520, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625346370, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625346794, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8924864530563354, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625346795, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1520, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625346990, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5280.135599621436, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625346991, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625346991, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5280.135599621436, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1520}}
:::MLLOG {"namespace": "", "time_ms": 1634625347032, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625347032, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1540, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625347048, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625347446, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8923007845878601, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625347446, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1540, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625347695, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5068.552346363953, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625347696, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625347696, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5068.552346363953, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1540}}
:::MLLOG {"namespace": "", "time_ms": 1634625347731, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625347732, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1560, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625347748, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625348146, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8910776376724243, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625348146, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1560, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625348362, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5328.4362910421805, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625348363, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625348363, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5328.4362910421805, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1560}}
:::MLLOG {"namespace": "", "time_ms": 1634625348398, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625348399, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1580, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625348415, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625348813, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8903993964195251, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625348813, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1580, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625349020, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5413.832641663603, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625349020, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625349020, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5413.832641663603, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1580}}
:::MLLOG {"namespace": "", "time_ms": 1634625349048, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625349048, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1600, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625349063, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625349490, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9042906761169434, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625349490, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1600, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625349678, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5337.269047133022, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625349678, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625349678, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5337.269047133022, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1600}}
:::MLLOG {"namespace": "", "time_ms": 1634625349713, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625349714, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1620, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625349729, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625350127, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8939642906188965, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625350128, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1620, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625350323, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5514.6682068602, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625350323, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625350324, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5514.6682068602, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1620}}
:::MLLOG {"namespace": "", "time_ms": 1634625350399, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625350399, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1640, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625350414, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625350830, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8965784311294556, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625350830, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1640, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625351028, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5343.30957073386, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625351028, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625351029, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5343.30957073386, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1640}}
:::MLLOG {"namespace": "", "time_ms": 1634625351064, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625351064, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1660, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625351080, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625351478, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.897203266620636, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625351478, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1660, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625351662, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5624.603959012985, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625351662, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625351663, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5624.603959012985, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1660}}
:::MLLOG {"namespace": "", "time_ms": 1634625351692, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625351693, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1680, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625351709, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625352134, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8950107097625732, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625352134, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1680, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625352324, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5319.518268023617, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625352325, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625352325, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5319.518268023617, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1680}}
:::MLLOG {"namespace": "", "time_ms": 1634625352360, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625352361, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1700, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625352377, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625352776, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9009883403778076, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625352776, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1700, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625352959, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5615.453203366038, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625352960, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625352960, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5615.453203366038, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1700}}
:::MLLOG {"namespace": "", "time_ms": 1634625352987, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625352987, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1720, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625353004, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625353444, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8852880001068115, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625353444, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1720, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625353634, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5196.967652218294, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625353634, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625353634, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5196.967652218294, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1720}}
:::MLLOG {"namespace": "", "time_ms": 1634625353670, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625353670, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1740, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625353686, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625354087, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8889644742012024, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625354088, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1740, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625354269, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5611.616211530505, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625354269, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625354269, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5611.616211530505, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1740}}
:::MLLOG {"namespace": "", "time_ms": 1634625354297, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625354297, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1760, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625354313, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625354791, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8900495767593384, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625354791, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1760, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625354995, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4818.928985665828, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625354995, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625354995, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4818.928985665828, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1760}}
:::MLLOG {"namespace": "", "time_ms": 1634625355032, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625355033, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1780, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625355049, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625355448, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8949618339538574, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625355448, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1780, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625355627, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5651.25462855658, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625355628, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625355628, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5651.25462855658, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1780}}
:::MLLOG {"namespace": "", "time_ms": 1634625355663, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625355664, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1800, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625355679, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625356080, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8792081475257874, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625356080, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1800, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625356266, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5578.812512370652, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625356266, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625356267, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5578.812512370652, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1800}}
:::MLLOG {"namespace": "", "time_ms": 1634625356301, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625356302, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1820, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625356316, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625356716, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8887485265731812, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625356716, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1820, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625356899, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5627.215916237391, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625356899, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625356899, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5627.215916237391, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1820}}
:::MLLOG {"namespace": "", "time_ms": 1634625356934, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625356935, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1840, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625356950, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625357353, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.906295895576477, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625357353, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1840, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625357533, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5616.484897951375, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625357533, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625357533, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5616.484897951375, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1840}}
:::MLLOG {"namespace": "", "time_ms": 1634625357561, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625357561, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1860, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625357576, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625358023, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8947340846061707, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625358024, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1860, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625358213, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5157.561499392856, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625358213, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625358213, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5157.561499392856, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1860}}
:::MLLOG {"namespace": "", "time_ms": 1634625358249, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625358250, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1880, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625358266, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625358665, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8867964744567871, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625358665, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1880, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625358845, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5647.902701064989, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625358845, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625358846, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5647.902701064989, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1880}}
:::MLLOG {"namespace": "", "time_ms": 1634625358876, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625358876, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1900, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625358892, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625359296, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8792634010314941, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625359296, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1900, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625359476, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5607.311436234657, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625359476, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625359476, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5607.311436234657, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1900}}
:::MLLOG {"namespace": "", "time_ms": 1634625359512, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625359512, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1920, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625359528, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625359927, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.885069727897644, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625359927, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1920, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625360106, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5657.9681620235115, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625360107, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625360107, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5657.9681620235115, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1634625360143, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625360144, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1940, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625360160, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625360557, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8936499357223511, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625360557, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1940, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625360745, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5589.264698883485, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625360745, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625360745, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5589.264698883485, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1940}}
:::MLLOG {"namespace": "", "time_ms": 1634625360777, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625360777, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1960, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625360794, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625361258, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.885463535785675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625361258, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1960, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625361445, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5037.383608772347, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625361445, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625361445, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5037.383608772347, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1960}}
:::MLLOG {"namespace": "", "time_ms": 1634625361473, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625361473, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 1980, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625361488, "event_type": "INTERVAL_START", "key": "eval_start", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625361961, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8929555416107178, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625361961, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 1980, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625362161, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4887.259168426046, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625362161, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625362161, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4887.259168426046, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 1980}}
:::MLLOG {"namespace": "", "time_ms": 1634625362191, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625362191, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2000, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625362207, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625362670, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8965166211128235, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625362670, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2000, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625362873, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4931.293090628142, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625362873, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625362873, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4931.293090628142, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2000}}
:::MLLOG {"namespace": "", "time_ms": 1634625362901, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625362901, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2020, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625362917, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625363409, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9075514078140259, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625363409, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2020, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625363616, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4702.420083431823, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625363616, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625363616, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4702.420083431823, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2020}}
:::MLLOG {"namespace": "", "time_ms": 1634625363643, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625363644, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2040, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625363660, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625364122, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9027057886123657, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625364122, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2040, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625364320, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4971.602160673263, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625364320, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625364320, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4971.602160673263, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2040}}
:::MLLOG {"namespace": "", "time_ms": 1634625364355, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625364355, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2060, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625364371, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625364770, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8860225677490234, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625364770, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2060, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625364947, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5685.789920241619, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625364947, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625364947, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5685.789920241619, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2060}}
:::MLLOG {"namespace": "", "time_ms": 1634625364974, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625364974, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2080, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625364991, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625365434, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8752593994140625, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625365434, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2080, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625365624, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5174.536842638632, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625365624, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625365624, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5174.536842638632, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2080}}
:::MLLOG {"namespace": "", "time_ms": 1634625365659, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625365660, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2100, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625365676, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625366074, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8873438835144043, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625366074, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2100, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625366266, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5540.376362453389, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625366267, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625366267, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5540.376362453389, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2100}}
:::MLLOG {"namespace": "", "time_ms": 1634625366304, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625366304, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2120, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625366320, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625366719, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8987287282943726, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625366719, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2120, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625366904, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5604.548521797227, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625366904, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625366904, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5604.548521797227, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2120}}
:::MLLOG {"namespace": "", "time_ms": 1634625366940, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625366940, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2140, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625366956, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625367355, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8940448760986328, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625367355, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2140, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625367539, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5610.760535657126, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625367540, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625367540, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5610.760535657126, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2140}}
:::MLLOG {"namespace": "", "time_ms": 1634625367567, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625367567, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2160, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625367584, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625368047, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9018446803092957, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625368047, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2160, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625368241, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4987.892549552031, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625368242, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625368242, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4987.892549552031, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2160}}
:::MLLOG {"namespace": "", "time_ms": 1634625368269, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625368270, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2180, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625368286, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625368790, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9028460383415222, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625368790, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2180, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625369002, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4590.737401570827, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625369002, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625369002, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4590.737401570827, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2180}}
:::MLLOG {"namespace": "", "time_ms": 1634625369038, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625369038, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2200, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625369054, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625369452, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9025849103927612, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625369452, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2200, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625369630, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5676.226530910626, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625369630, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625369631, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5676.226530910626, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2200}}
:::MLLOG {"namespace": "", "time_ms": 1634625369659, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625369660, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2220, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625369676, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625370143, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8872961401939392, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625370143, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2220, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625370341, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 4935.266733951033, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625370341, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625370341, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 4935.266733951033, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2220}}
:::MLLOG {"namespace": "", "time_ms": 1634625370371, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625370372, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2240, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625370388, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625370823, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8912189602851868, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625370823, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2240, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625371007, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5286.555047597469, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625371008, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625371008, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5286.555047597469, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2240}}
:::MLLOG {"namespace": "", "time_ms": 1634625371043, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625371044, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2260, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625371060, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625371458, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8981684446334839, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625371458, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2260, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625371632, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5712.230706186682, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625371633, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625371633, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5712.230706186682, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2260}}
:::MLLOG {"namespace": "", "time_ms": 1634625371668, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625371668, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2280, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625371684, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625372083, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9004003405570984, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625372083, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2280, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625372261, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5673.180619293754, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625372261, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625372261, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5673.180619293754, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2280}}
:::MLLOG {"namespace": "", "time_ms": 1634625372297, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625372297, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2300, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625372313, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625372712, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8911685943603516, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625372712, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2300, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625372897, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5606.022183247484, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625372897, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625372897, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5606.022183247484, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2300}}
:::MLLOG {"namespace": "", "time_ms": 1634625372932, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625372933, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2320, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625372949, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625373348, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8979693055152893, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625373348, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2320, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625373522, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5701.274795408675, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625373522, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625373522, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5701.274795408675, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2320}}
:::MLLOG {"namespace": "", "time_ms": 1634625373558, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625373559, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2340, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625373574, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625373974, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.8985782861709595, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625373974, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2340, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625374155, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5631.933910745778, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625374156, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625374156, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5631.933910745778, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2340}}
:::MLLOG {"namespace": "", "time_ms": 1634625374192, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625374193, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2360, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625374209, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625374613, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9013506174087524, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625374614, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2360, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625374797, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5559.097076682212, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625374798, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625374798, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5559.097076682212, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2360}}
:::MLLOG {"namespace": "", "time_ms": 1634625374833, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 176, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625374834, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 51, "first_epoch_num": 2380, "epoch_count": 20}}
:::MLLOG {"namespace": "", "time_ms": 1634625374849, "event_type": "INTERVAL_START", "key": "eval_start", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 152, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625375248, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9098459482192993, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 155, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625375248, "event_type": "INTERVAL_END", "key": "eval_stop", "value": 2380, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 160, "epoch_num": 2380}}
:::MLLOG {"namespace": "", "time_ms": 1634625375248, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 165, "status": "success"}}
:::MLLOG {"namespace": "", "time_ms": 1634625375427, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 5662.239622004725, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 117}}
:::MLLOG {"namespace": "", "time_ms": 1634625375428, "event_type": "POINT_IN_TIME", "key": "current_lr", "value": 1.5, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 118}}
:::MLLOG {"namespace": "", "time_ms": 1634625375428, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"throughput": 5662.239622004725, "iterations": 2, "loss_scale": 1024.0}, "metadata": {"file": "/workspace/unet3d/runtime/training.py", "lineno": 119, "step": 2380}}
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:21 AM
RESULT,image_segmentation,,211,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:22 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:22 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:22 AM
RESULT,image_segmentation,,212,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:24 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,214,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:25 AM
RESULT,image_segmentation,,215,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:27 AM
RESULT,image_segmentation,,217,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:28 AM
RESULT,image_segmentation,,218,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:29 AM
RESULT,image_segmentation,,219,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:30 AM
RESULT,image_segmentation,,220,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:31 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,221,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:32 AM
RESULT,image_segmentation,,222,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
ENDING TIMING RUN AT 2021-10-19 06:36:33 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,223,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:34 AM
RESULT,image_segmentation,,224,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:35 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:35 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:32:50 AM
ENDING TIMING RUN AT 2021-10-19 06:36:35 AM
RESULT,image_segmentation,,225,nvidia,2021-10-19 06:32:50 AM
