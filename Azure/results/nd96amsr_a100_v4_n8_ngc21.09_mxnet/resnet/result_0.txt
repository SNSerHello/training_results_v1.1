+ : DGXA100_multi_8x8x51
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/resnetv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211105202651706565012
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data
+ : /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.202650
+ : ''
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ echo

+ '[' '!' -z ']'
+ LOGBASE=rsnt50_8x8x51_211105202651706565012
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _seed_override=
+ _seed_override=
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.202650/rsnt50_8x8x51_211105202651706565012
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.202650/rsnt50_8x8x51_211105202651706565012
+ readonly _cont_name=image_classification
+ _cont_name=image_classification
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data:/data,/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.202650:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job10869/slurm_script: line 48: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.202650
+ srun --ntasks=8 mkdir -p /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.202650
+ srun --ntasks=8 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/resnetv11.sqsh --container-name=image_classification true
+ echo 'RUN_NCCL_BW_TEST = 0'
RUN_NCCL_BW_TEST = 0
+ [[ 0 -eq 1 ]]
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.202650/rsnt50_8x8x51_211105202651706565012_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun -N1 -n1 --container-name=image_classification python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.RESNET)'
:::MLLOG {"namespace": "", "time_ms": 1636144025400, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "resnet", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 70}}
:::MLLOG {"namespace": "", "time_ms": 1636144025407, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1636144025407, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 79}}
:::MLLOG {"namespace": "", "time_ms": 1636144025407, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 83}}
:::MLLOG {"namespace": "", "time_ms": 1636144025407, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 87}}
[1636144025.381900] [ip-0A0C0406:84861:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C0406
Clearing cache on ip-0A0C040C
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C040A
Clearing cache on ip-0A0C0409
Clearing cache on ip-0A0C0407
Clearing cache on ip-0A0C040D
Clearing cache on ip-0A0C0408
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=image_classification python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import mx_resnet_print_event
mx_resnet_print_event(key=constants.CACHE_CLEAR, val=True)'
:::MLLOG {"namespace": "", "time_ms": 1636144101161, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
[1636144100.973894] [ip-0A0C0409:84409:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636144101.084022] [ip-0A0C040A:84843:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636144100.975965] [ip-0A0C040D:85200:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636144100.970118] [ip-0A0C040F:85087:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636144101.126393] [ip-0A0C0408:85244:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636144100.908526] [ip-0A0C040C:84525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636144101.136933] [ip-0A0C0407:85013:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636144101.107876] [ip-0A0C0406:85492:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
+ export SEED=32107
+ SEED=32107
+ srun --kill-on-bad-exit=0 --mpi=pmix --ntasks=64 --ntasks-per-node=8 --container-name=image_classification --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data:/data,/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.202650:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:28:22 PM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 32107 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
:::MLLOG {"namespace": "", "time_ms": 1636144107952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107950, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107953, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107953, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107953, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107950, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107951, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107950, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107950, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107953, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107952, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107951, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107950, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107950, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107953, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107953, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107954, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107968, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107949, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107949, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107949, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107949, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107949, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107949, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107949, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107949, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636144107955, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
[1636144107.790627] [ip-0A0C040C:85380:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.683386] [ip-0A0C040C:85373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.629198] [ip-0A0C040C:85375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.859524] [ip-0A0C0409:85271:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.859407] [ip-0A0C0409:85272:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.831560] [ip-0A0C040C:85377:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.823928] [ip-0A0C040C:85379:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.654725] [ip-0A0C0409:85270:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.600809] [ip-0A0C040C:85374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.805343] [ip-0A0C040C:85376:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.822048] [ip-0A0C0409:85265:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.818086] [ip-0A0C040C:85378:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.814134] [ip-0A0C0409:85266:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.815956] [ip-0A0C0407:85877:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.694205] [ip-0A0C0409:85267:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.586162] [ip-0A0C0407:85879:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.691312] [ip-0A0C0409:85269:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.921444] [ip-0A0C040D:86054:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.847427] [ip-0A0C0409:85268:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.820343] [ip-0A0C040A:85694:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.824067] [ip-0A0C040A:85701:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.739817] [ip-0A0C0407:85881:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.767079] [ip-0A0C040D:86052:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.841463] [ip-0A0C0408:86110:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.670901] [ip-0A0C040A:85700:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.918234] [ip-0A0C040D:86051:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.819390] [ip-0A0C0407:85876:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.783063] [ip-0A0C0407:85874:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.768552] [ip-0A0C0407:85875:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.879462] [ip-0A0C040D:86047:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.815313] [ip-0A0C040D:86053:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.730594] [ip-0A0C040D:86048:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.818453] [ip-0A0C0407:85873:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.631818] [ip-0A0C0407:85880:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.812965] [ip-0A0C0408:86109:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.709611] [ip-0A0C040A:85696:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.912685] [ip-0A0C040D:86049:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.808511] [ip-0A0C040A:85699:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.688431] [ip-0A0C0406:86376:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.729158] [ip-0A0C040A:85698:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.869895] [ip-0A0C0408:86111:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.602508] [ip-0A0C040A:85697:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.791548] [ip-0A0C040A:85695:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.813296] [ip-0A0C0408:86116:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.864307] [ip-0A0C0408:86112:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.855816] [ip-0A0C040D:86050:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.869734] [ip-0A0C0408:86114:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.650156] [ip-0A0C0406:86370:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636144107.656071] [ip-0A0C0408:86113:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.668785] [ip-0A0C0408:86117:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.475030] [ip-0A0C0406:86374:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
:::MLLOG {"namespace": "", "time_ms": 1636144121207, "event_type": "POINT_IN_TIME", "key": "seed", "value": 32107, "metadata": {"file": "train_imagenet.py", "lineno": 176}}
[1636144107.596381] [ip-0A0C0406:86373:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.689128] [ip-0A0C0406:86369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.689007] [ip-0A0C0406:86372:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.542653] [ip-0A0C0406:86375:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.672792] [ip-0A0C0406:86371:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.889352] [ip-0A0C040F:85956:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.778832] [ip-0A0C040F:85954:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.829426] [ip-0A0C040F:85953:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.929627] [ip-0A0C040F:85955:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.819802] [ip-0A0C040F:85960:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.932757] [ip-0A0C040F:85959:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.929694] [ip-0A0C040F:85958:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636144107.701496] [ip-0A0C040F:85957:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:28:41] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
NCCL version 2.11.4+cuda11.4

ip-0A0C0409:85267:85461 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86111:86310 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85875:86074 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85954:86155 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86053:86247 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85375:85575 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85698:85890 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86374 - context.c:584] INFO job (ID: 867530741527070361) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86374 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86374 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86374:86568 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85271:85462 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85960:86154 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86047:86245 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86109:86311 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85879:86076 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85377:85570 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85696:85895 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86375 - context.c:584] INFO job (ID: 867530849750099016) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86375 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86375 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86375:86567 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85266:85465 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85957:86156 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86052:86246 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86112:86312 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85877:86073 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85374:85576 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85700:85894 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86371 - context.c:584] INFO job (ID: 867531158732028198) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86371 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86371 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86371:86572 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85268:85467 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86113:86307 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85959:86153 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86048:86243 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85880:86077 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85378:85569 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85695:85896 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86373 - context.c:584] INFO job (ID: 867530531850707917) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86373 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86373 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86373:86571 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86054:86242 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85955:86151 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85265:85466 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86117:86313 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85881:86079 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85373:85572 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85697:85897 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86372 - context.c:584] INFO job (ID: 867530614405347823) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86372 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86372 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86372:86570 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85270:85464 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85958:86149 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86049:86248 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86110:86309 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85873:86080 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85376:85571 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85701:85891 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86369 - context.c:584] INFO job (ID: 867530708732545453) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86369 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86369 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86369:86569 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85272:85463 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85953:86152 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86050:86244 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86114:86308 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85874:86078 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85380:85573 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85699:85893 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86376 - context.c:584] INFO job (ID: 867530743790928542) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86376 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86376 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86376:86565 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86116:86306 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85379:85574 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85694:85892 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85269:85468 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85956:86150 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86051:86249 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85876:86075 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86111:86310 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040F:85954:86155 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0409:85267:85461 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040C:85375:85575 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:85875:86074 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040D:86053:86247 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040A:85698:85890 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
[ip-0A0C0406:0:86370 - context.c:584] INFO job (ID: 867531266070304955) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86370 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86370 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86370:86566 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0406:86374:86568 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040C:85375:85575 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85267:85461 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86111:86310 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85875:86074 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85698:85890 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86053:86247 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85954:86155 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86374 - context.c:584] INFO job (ID: 867530740316314078) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86374 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86374 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86374:86568 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85271:85462 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85960:86154 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86047:86245 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86109:86311 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85879:86076 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85377:85570 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85696:85895 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86375 - context.c:584] INFO job (ID: 867530850192293487) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86375 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86375 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86375:86567 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85266:85465 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85957:86156 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86052:86246 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86112:86312 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85877:86073 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85374:85576 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85700:85894 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86371 - context.c:584] INFO job (ID: 867531159644567640) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86371 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86371 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86371:86572 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85268:85467 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85959:86153 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86048:86243 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85880:86077 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85378:85569 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85695:85896 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86113:86307 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86373 - context.c:584] INFO job (ID: 867530531514236092) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86373 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86373 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86373:86571 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85265:85466 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85955:86151 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86054:86242 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85881:86079 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85373:85572 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85697:85897 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86117:86313 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86372 - context.c:584] INFO job (ID: 867530614306694272) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86372 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86372 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86372:86570 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85270:85464 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85958:86149 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86049:86248 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85701:85891 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86110:86309 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85376:85571 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85873:86080 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86369 - context.c:584] INFO job (ID: 867530708514152208) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86369 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86369 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86369:86569 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86114:86308 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85380:85573 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85699:85893 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85272:85463 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85953:86152 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86050:86244 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85874:86078 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:86376 - context.c:584] INFO job (ID: 867530741969870677) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86376 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86376 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86376:86565 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85269:85468 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:85956:86150 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:86051:86249 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:86116:86306 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:85876:86075 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:85379:85574 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:85694:85892 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:85267:85461 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040D:86053:86247 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0408:86111:86310 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040A:85698:85890 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040F:85954:86155 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040C:85375:85575 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:85875:86074 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
[ip-0A0C0406:0:86370 - context.c:584] INFO job (ID: 867531266559271417) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:86370 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:86370 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:86370:86566 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0406:86374:86568 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
:::MLLOG {"namespace": "", "time_ms": 1636144195326, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 51, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 309}}
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636144201692, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "bn0_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201692, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "bn0_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201692, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "conv0_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201693, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 81, "tensor": "fc1_bias"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201693, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 72, "tensor": "fc1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201693, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201693, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201694, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201694, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201694, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201695, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201695, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201695, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201695, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201696, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201696, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201696, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201696, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201696, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201697, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201697, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201697, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201697, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201698, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201698, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201698, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201698, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201698, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201699, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201699, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201699, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201699, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201700, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201701, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201701, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201701, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201701, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201702, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201702, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201702, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201702, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201702, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201703, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201703, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201703, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201703, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201703, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201704, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201704, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201704, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201704, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201705, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201705, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201705, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201705, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201705, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201706, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201706, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201706, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201706, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201706, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201707, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201707, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201707, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201707, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201708, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201708, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201708, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201708, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201708, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201709, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201709, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201709, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201709, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201710, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201710, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201710, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201710, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201710, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201711, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201711, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201711, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201711, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201711, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201712, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201712, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201712, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201712, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201713, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201713, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201713, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201713, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201713, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201714, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201714, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201714, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201714, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201715, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201715, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201715, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201715, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201715, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201716, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201717, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201718, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201719, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201720, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201721, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201722, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201723, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201724, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201725, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201726, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636144201727, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv3_weight"}}
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:01] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:30:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,541 Node[1] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=18538, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,541 Node[2] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=10054, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,542 Node[7] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=34697, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636144203542, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 233}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,542 Node[4] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=467, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,539 Node[8] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=59971, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,539 Node[9] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=32284, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,539 Node[11] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=28401, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,539 Node[15] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=5681, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,554 Node[16] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:30:03,539 Node[14] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=59544, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=57753, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,554 Node[17] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:30:03,539 Node[10] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=60038, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=55565, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,542 Node[33] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=49644, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,554 Node[19] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=18467, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,540 Node[12] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=46085, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,543 Node[34] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=7293, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,542 Node[30] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:30:03,538 Node[49] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=36547, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=42911, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:30:03,555 Node[18] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=10735, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,555 Node[22] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=23528, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,538 Node[50] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:30:03,555 Node[20] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=2186, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=13037, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,543 Node[25] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=46535, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,543 Node[42] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=55155, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:30:03,538 Node[53] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=21860, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,544 Node[43] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=34338, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:30:03,543 Node[26] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=4507, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:30:03,539 Node[54] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=64190, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,543 Node[31] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=65100, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,544 Node[32] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:30:03,539 Node[52] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=56548, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=3240, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,543 Node[24] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:30:03,544 Node[44] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=28524, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=1314, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,544 Node[38] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=14647, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,539 Node[55] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=15210, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,544 Node[39] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:30:03,543 Node[27] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=43928, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=34991, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:30:03,543 Node[29] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=25546, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,545 Node[60] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=45659, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,544 Node[40] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:30:03,541 Node[13] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=52567, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=50880, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 20:30:03,545 Node[59] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=1245, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,545 Node[37] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=25994, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,545 Node[35] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=42833, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,545 Node[56] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=64052, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 20:30:03,540 Node[51] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=7155, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:30:03,545 Node[57] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=23695, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,546 Node[63] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:30:03,540 Node[48] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=24419, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,557 Node[21] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=63911, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,545 Node[45] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=26622, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=10146, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:30:03,546 Node[47] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=15809, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,546 Node[46] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=50857, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:30:03,558 Node[23] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=42417, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,546 Node[41] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=8763, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,546 Node[36] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=59200, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,546 Node[62] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=27579, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,547 Node[58] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=44362, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,546 Node[28] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=25514, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,547 Node[61] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=25958, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:30:03,542 Node[0] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=54812, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,543 Node[5] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=31371, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,543 Node[6] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=53224, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636144203543, "event_type": "POINT_IN_TIME", "key": "sgd_opt_learning_rate_decay_poly_power", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 711}}
:::MLLOG {"namespace": "", "time_ms": 1636144203543, "event_type": "POINT_IN_TIME", "key": "sgd_opt_end_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 712}}
:::MLLOG {"namespace": "", "time_ms": 1636144203543, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_decay_poly_power", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 713}}
:::MLLOG {"namespace": "", "time_ms": 1636144203543, "event_type": "POINT_IN_TIME", "key": "lars_opt_end_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 714}}
:::MLLOG {"namespace": "", "time_ms": 1636144203543, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 51, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1164}}
:::MLLOG {"namespace": "", "time_ms": 1636144203543, "event_type": "POINT_IN_TIME", "key": "s_optimizer", "value": "sgdwfastlars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1165}}
:::MLLOG {"namespace": "", "time_ms": 1636144203543, "event_type": "POINT_IN_TIME", "key": "s_network", "value": "resnet-v1b-fl", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1166}}
:::MLLOG {"namespace": "", "time_ms": 1636144203543, "event_type": "POINT_IN_TIME", "key": "s_process", "value": "horovod", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1167}}
:::MLLOG {"namespace": "", "time_ms": 1636144203543, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 3264, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1168}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "s_optimizer", "value": "sgdwfastlars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1169}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "s_network", "value": "resnet-v1b-fl", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1170}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "s_process", "value": "horovod", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1171}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1172}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "lars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1178}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "lars_epsilon", "value": 0, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "lars_opt_weight_decay", "value": 5e-05, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1182}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "lars_opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1184}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "lars_opt_base_learning_rate", "value": 10.5, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1185}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_warmup_epochs", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1186}}
:::MLLOG {"namespace": "", "time_ms": 1636144203544, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_decay_steps", "value": 37, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1187}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:30:03,544 Node[3] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=17067, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:30:25] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
:::MLLOG {"namespace": "", "time_ms": 1636144237787, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1336}}
:::MLLOG {"namespace": "", "time_ms": 1636144237788, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1281167, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 486}}
:::MLLOG {"namespace": "", "time_ms": 1636144238016, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 50000, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 508}}
:::MLLOG {"namespace": "", "time_ms": 1636144238017, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 903, "first_epoch_num": 1, "epoch_count": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636144238017, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 1}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:30:38,899 Node[0] Epoch[0] Batch [0-20]	Speed: 113783.59 samples/sec	accuracy=nan
2021-11-05 20:30:39,396 Node[0] Epoch[0] Batch [20-40]	Speed: 131248.11 samples/sec	accuracy=nan
2021-11-05 20:30:39,869 Node[0] Epoch[0] Batch [40-60]	Speed: 138195.59 samples/sec	accuracy=nan
2021-11-05 20:30:40,374 Node[0] Epoch[0] Batch [60-80]	Speed: 129035.80 samples/sec	accuracy=nan
2021-11-05 20:30:40,835 Node[0] Epoch[0] Batch [80-100]	Speed: 141710.46 samples/sec	accuracy=nan
2021-11-05 20:30:41,362 Node[0] Epoch[0] Batch [100-120]	Speed: 123984.79 samples/sec	accuracy=nan
2021-11-05 20:30:41,848 Node[0] Epoch[0] Batch [120-140]	Speed: 134310.30 samples/sec	accuracy=nan
2021-11-05 20:30:42,355 Node[0] Epoch[0] Batch [140-160]	Speed: 128566.35 samples/sec	accuracy=nan
2021-11-05 20:30:42,855 Node[0] Epoch[0] Batch [160-180]	Speed: 130573.14 samples/sec	accuracy=nan
2021-11-05 20:30:43,339 Node[0] Epoch[0] Batch [180-200]	Speed: 135024.63 samples/sec	accuracy=nan
2021-11-05 20:30:43,835 Node[0] Epoch[0] Batch [200-220]	Speed: 131472.59 samples/sec	accuracy=nan
2021-11-05 20:30:44,321 Node[0] Epoch[0] Batch [220-240]	Speed: 134567.67 samples/sec	accuracy=nan
2021-11-05 20:30:44,795 Node[0] Epoch[0] Batch [240-260]	Speed: 137454.79 samples/sec	accuracy=nan
2021-11-05 20:30:45,257 Node[0] Epoch[0] Batch [260-280]	Speed: 141515.56 samples/sec	accuracy=nan
2021-11-05 20:30:45,746 Node[0] Epoch[0] Batch [280-300]	Speed: 133288.95 samples/sec	accuracy=nan
2021-11-05 20:30:46,253 Node[0] Epoch[0] Batch [300-320]	Speed: 128795.92 samples/sec	accuracy=nan
2021-11-05 20:30:46,719 Node[0] Epoch[0] Batch [320-340]	Speed: 140295.91 samples/sec	accuracy=nan
2021-11-05 20:30:47,184 Node[0] Epoch[0] Batch [340-360]	Speed: 140222.19 samples/sec	accuracy=nan
2021-11-05 20:30:47,642 Node[0] Epoch[0] Batch [360-380]	Speed: 142481.59 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144247888, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 1}}
2021-11-05 20:30:47,888 Node[0] Epoch[0] Time cost=9.871
:::MLLOG {"namespace": "", "time_ms": 1636144247888, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 129788.04086204548}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1636144247888, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 129788.04086204548, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144247888, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 2}}
2021-11-05 20:30:48,306 Node[0] Epoch[1] Batch [0-20]	Speed: 163690.33 samples/sec	accuracy=nan
2021-11-05 20:30:48,705 Node[0] Epoch[1] Batch [20-40]	Speed: 163714.61 samples/sec	accuracy=nan
2021-11-05 20:30:49,099 Node[0] Epoch[1] Batch [40-60]	Speed: 165364.94 samples/sec	accuracy=nan
2021-11-05 20:30:49,497 Node[0] Epoch[1] Batch [60-80]	Speed: 164364.81 samples/sec	accuracy=nan
2021-11-05 20:30:49,893 Node[0] Epoch[1] Batch [80-100]	Speed: 164791.18 samples/sec	accuracy=nan
2021-11-05 20:30:50,285 Node[0] Epoch[1] Batch [100-120]	Speed: 166459.76 samples/sec	accuracy=nan
2021-11-05 20:30:50,680 Node[0] Epoch[1] Batch [120-140]	Speed: 165283.29 samples/sec	accuracy=nan
2021-11-05 20:30:51,078 Node[0] Epoch[1] Batch [140-160]	Speed: 164173.42 samples/sec	accuracy=nan
2021-11-05 20:30:51,476 Node[0] Epoch[1] Batch [160-180]	Speed: 163639.66 samples/sec	accuracy=nan
2021-11-05 20:30:51,875 Node[0] Epoch[1] Batch [180-200]	Speed: 163948.60 samples/sec	accuracy=nan
2021-11-05 20:30:52,272 Node[0] Epoch[1] Batch [200-220]	Speed: 164354.85 samples/sec	accuracy=nan
2021-11-05 20:30:52,673 Node[0] Epoch[1] Batch [220-240]	Speed: 162672.50 samples/sec	accuracy=nan
2021-11-05 20:30:53,071 Node[0] Epoch[1] Batch [240-260]	Speed: 164170.27 samples/sec	accuracy=nan
2021-11-05 20:30:53,468 Node[0] Epoch[1] Batch [260-280]	Speed: 164255.36 samples/sec	accuracy=nan
2021-11-05 20:30:53,867 Node[0] Epoch[1] Batch [280-300]	Speed: 163666.36 samples/sec	accuracy=nan
2021-11-05 20:30:54,270 Node[0] Epoch[1] Batch [300-320]	Speed: 161936.49 samples/sec	accuracy=nan
2021-11-05 20:30:54,668 Node[0] Epoch[1] Batch [320-340]	Speed: 163984.83 samples/sec	accuracy=nan
2021-11-05 20:30:55,065 Node[0] Epoch[1] Batch [340-360]	Speed: 164434.21 samples/sec	accuracy=nan
2021-11-05 20:30:55,465 Node[0] Epoch[1] Batch [360-380]	Speed: 163382.95 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144255703, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 2}}
2021-11-05 20:30:55,703 Node[0] Epoch[1] Time cost=7.815
:::MLLOG {"namespace": "", "time_ms": 1636144255703, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 163941.4613462124}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1636144255704, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 163941.4613462124, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144255704, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 3}}
2021-11-05 20:30:56,122 Node[0] Epoch[2] Batch [0-20]	Speed: 163577.38 samples/sec	accuracy=nan
2021-11-05 20:30:56,515 Node[0] Epoch[2] Batch [20-40]	Speed: 166204.52 samples/sec	accuracy=nan
2021-11-05 20:30:56,913 Node[0] Epoch[2] Batch [40-60]	Speed: 163896.69 samples/sec	accuracy=nan
2021-11-05 20:30:57,306 Node[0] Epoch[2] Batch [60-80]	Speed: 166171.64 samples/sec	accuracy=nan
2021-11-05 20:30:57,702 Node[0] Epoch[2] Batch [80-100]	Speed: 164695.82 samples/sec	accuracy=nan
2021-11-05 20:30:58,097 Node[0] Epoch[2] Batch [100-120]	Speed: 165266.73 samples/sec	accuracy=nan
2021-11-05 20:30:58,496 Node[0] Epoch[2] Batch [120-140]	Speed: 163853.73 samples/sec	accuracy=nan
2021-11-05 20:30:58,889 Node[0] Epoch[2] Batch [140-160]	Speed: 165753.36 samples/sec	accuracy=nan
2021-11-05 20:30:59,286 Node[0] Epoch[2] Batch [160-180]	Speed: 164564.96 samples/sec	accuracy=nan
2021-11-05 20:30:59,684 Node[0] Epoch[2] Batch [180-200]	Speed: 163965.88 samples/sec	accuracy=nan
2021-11-05 20:31:00,081 Node[0] Epoch[2] Batch [200-220]	Speed: 164487.15 samples/sec	accuracy=nan
2021-11-05 20:31:00,481 Node[0] Epoch[2] Batch [220-240]	Speed: 163299.83 samples/sec	accuracy=nan
2021-11-05 20:31:00,876 Node[0] Epoch[2] Batch [240-260]	Speed: 165030.35 samples/sec	accuracy=nan
2021-11-05 20:31:01,274 Node[0] Epoch[2] Batch [260-280]	Speed: 164202.57 samples/sec	accuracy=nan
2021-11-05 20:31:01,670 Node[0] Epoch[2] Batch [280-300]	Speed: 164777.29 samples/sec	accuracy=nan
2021-11-05 20:31:02,064 Node[0] Epoch[2] Batch [300-320]	Speed: 165620.91 samples/sec	accuracy=nan
2021-11-05 20:31:02,464 Node[0] Epoch[2] Batch [320-340]	Speed: 163513.40 samples/sec	accuracy=nan
2021-11-05 20:31:02,861 Node[0] Epoch[2] Batch [340-360]	Speed: 164062.56 samples/sec	accuracy=nan
2021-11-05 20:31:03,263 Node[0] Epoch[2] Batch [360-380]	Speed: 162678.20 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144263501, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 3}}
2021-11-05 20:31:03,501 Node[0] Epoch[2] Time cost=7.797
:::MLLOG {"namespace": "", "time_ms": 1636144263501, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164318.58483466785}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636144263501, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164318.58483466785, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144263518, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 3}}
2021-11-05 20:31:03,518 Node[0] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,518 Node[4] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,518 Node[6] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,518 Node[2] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,518 Node[5] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,518 Node[7] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,518 Node[1] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,518 Node[3] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,516 Node[24] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[56] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,512 Node[48] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,528 Node[16] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,514 Node[8] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[40] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[32] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,516 Node[25] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[57] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,512 Node[49] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,528 Node[17] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,514 Node[9] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[41] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[33] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,516 Node[26] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[58] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,512 Node[50] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,528 Node[18] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,514 Node[10] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[42] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[34] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,516 Node[27] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[59] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,512 Node[52] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,528 Node[20] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,514 Node[11] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[43] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[35] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,516 Node[28] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[60] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,512 Node[53] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,528 Node[21] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,514 Node[12] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[44] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[36] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[61] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[63] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[62] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,512 Node[54] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,512 Node[55] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,512 Node[51] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,516 Node[29] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,516 Node[30] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,516 Node[31] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[45] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[46] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,514 Node[13] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[47] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,514 Node[14] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,514 Node[15] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,528 Node[22] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[37] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,528 Node[19] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[38] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,528 Node[23] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:31:03,517 Node[39] DALI iterator does not support resetting while epoch is not finished. Ignoring...
2021-11-05 20:31:03,896 Node[0] Epoch[2] Validation-accuracy=0.284251
2021-11-05 20:31:03,897 Node[0] Epoch[2] Validation-correct-count=222.000000
2021-11-05 20:31:03,897 Node[0] Epoch[2] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636144264004, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636144264004, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.30178, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636144264005, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1636144264005, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 4, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636144264005, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 4}}
2021-11-05 20:31:04,403 Node[0] Epoch[3] Batch [0-20]	Speed: 165890.14 samples/sec	accuracy=nan
2021-11-05 20:31:04,800 Node[0] Epoch[3] Batch [20-40]	Speed: 164556.95 samples/sec	accuracy=nan
2021-11-05 20:31:05,196 Node[0] Epoch[3] Batch [40-60]	Speed: 164752.41 samples/sec	accuracy=nan
2021-11-05 20:31:05,589 Node[0] Epoch[3] Batch [60-80]	Speed: 166207.04 samples/sec	accuracy=nan
2021-11-05 20:31:05,985 Node[0] Epoch[3] Batch [80-100]	Speed: 165021.00 samples/sec	accuracy=nan
2021-11-05 20:31:06,376 Node[0] Epoch[3] Batch [100-120]	Speed: 166581.59 samples/sec	accuracy=nan
2021-11-05 20:31:06,769 Node[0] Epoch[3] Batch [120-140]	Speed: 166270.73 samples/sec	accuracy=nan
2021-11-05 20:31:07,163 Node[0] Epoch[3] Batch [140-160]	Speed: 165755.57 samples/sec	accuracy=nan
2021-11-05 20:31:07,556 Node[0] Epoch[3] Batch [160-180]	Speed: 166205.23 samples/sec	accuracy=nan
2021-11-05 20:31:07,951 Node[0] Epoch[3] Batch [180-200]	Speed: 165295.96 samples/sec	accuracy=nan
2021-11-05 20:31:08,347 Node[0] Epoch[3] Batch [200-220]	Speed: 164764.50 samples/sec	accuracy=nan
2021-11-05 20:31:08,743 Node[0] Epoch[3] Batch [220-240]	Speed: 164903.03 samples/sec	accuracy=nan
2021-11-05 20:31:09,137 Node[0] Epoch[3] Batch [240-260]	Speed: 165514.99 samples/sec	accuracy=nan
2021-11-05 20:31:09,530 Node[0] Epoch[3] Batch [260-280]	Speed: 166227.63 samples/sec	accuracy=nan
2021-11-05 20:31:09,925 Node[0] Epoch[3] Batch [280-300]	Speed: 165089.26 samples/sec	accuracy=nan
2021-11-05 20:31:10,321 Node[0] Epoch[3] Batch [300-320]	Speed: 165045.77 samples/sec	accuracy=nan
2021-11-05 20:31:10,719 Node[0] Epoch[3] Batch [320-340]	Speed: 163743.49 samples/sec	accuracy=nan
2021-11-05 20:31:11,117 Node[0] Epoch[3] Batch [340-360]	Speed: 164157.48 samples/sec	accuracy=nan
2021-11-05 20:31:11,517 Node[0] Epoch[3] Batch [360-380]	Speed: 163256.11 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144271754, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 4}}
2021-11-05 20:31:11,754 Node[0] Epoch[3] Time cost=7.750
:::MLLOG {"namespace": "", "time_ms": 1636144271754, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165321.95124704213}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636144271755, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165321.95124704213, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144271755, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 5}}
2021-11-05 20:31:12,179 Node[0] Epoch[4] Batch [0-20]	Speed: 161139.09 samples/sec	accuracy=nan
2021-11-05 20:31:12,572 Node[0] Epoch[4] Batch [20-40]	Speed: 166037.11 samples/sec	accuracy=nan
2021-11-05 20:31:12,966 Node[0] Epoch[4] Batch [40-60]	Speed: 165354.86 samples/sec	accuracy=nan
2021-11-05 20:31:13,363 Node[0] Epoch[4] Batch [60-80]	Speed: 164554.87 samples/sec	accuracy=nan
2021-11-05 20:31:13,757 Node[0] Epoch[4] Batch [80-100]	Speed: 165862.81 samples/sec	accuracy=nan
2021-11-05 20:31:14,151 Node[0] Epoch[4] Batch [100-120]	Speed: 165720.36 samples/sec	accuracy=nan
2021-11-05 20:31:14,544 Node[0] Epoch[4] Batch [120-140]	Speed: 166163.57 samples/sec	accuracy=nan
2021-11-05 20:31:14,937 Node[0] Epoch[4] Batch [140-160]	Speed: 165886.32 samples/sec	accuracy=nan
2021-11-05 20:31:15,333 Node[0] Epoch[4] Batch [160-180]	Speed: 164666.90 samples/sec	accuracy=nan
2021-11-05 20:31:15,729 Node[0] Epoch[4] Batch [180-200]	Speed: 164907.10 samples/sec	accuracy=nan
2021-11-05 20:31:16,126 Node[0] Epoch[4] Batch [200-220]	Speed: 164581.97 samples/sec	accuracy=nan
2021-11-05 20:31:16,526 Node[0] Epoch[4] Batch [220-240]	Speed: 163331.10 samples/sec	accuracy=nan
2021-11-05 20:31:16,919 Node[0] Epoch[4] Batch [240-260]	Speed: 166086.87 samples/sec	accuracy=nan
2021-11-05 20:31:17,319 Node[0] Epoch[4] Batch [260-280]	Speed: 162911.47 samples/sec	accuracy=nan
2021-11-05 20:31:17,714 Node[0] Epoch[4] Batch [280-300]	Speed: 165484.98 samples/sec	accuracy=nan
2021-11-05 20:31:18,109 Node[0] Epoch[4] Batch [300-320]	Speed: 165152.29 samples/sec	accuracy=nan
2021-11-05 20:31:18,506 Node[0] Epoch[4] Batch [320-340]	Speed: 164363.83 samples/sec	accuracy=nan
2021-11-05 20:31:18,903 Node[0] Epoch[4] Batch [340-360]	Speed: 164728.02 samples/sec	accuracy=nan
2021-11-05 20:31:19,302 Node[0] Epoch[4] Batch [360-380]	Speed: 163597.03 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144279542, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 5}}
2021-11-05 20:31:19,542 Node[0] Epoch[4] Time cost=7.787
:::MLLOG {"namespace": "", "time_ms": 1636144279542, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164524.13466732827}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 5}}
:::MLLOG {"namespace": "", "time_ms": 1636144279542, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164524.13466732827, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144279542, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 6}}
2021-11-05 20:31:19,955 Node[0] Epoch[5] Batch [0-20]	Speed: 165654.48 samples/sec	accuracy=nan
2021-11-05 20:31:20,348 Node[0] Epoch[5] Batch [20-40]	Speed: 166446.40 samples/sec	accuracy=nan
2021-11-05 20:31:20,744 Node[0] Epoch[5] Batch [40-60]	Speed: 164587.12 samples/sec	accuracy=nan
2021-11-05 20:31:21,139 Node[0] Epoch[5] Batch [60-80]	Speed: 165377.23 samples/sec	accuracy=nan
2021-11-05 20:31:21,533 Node[0] Epoch[5] Batch [80-100]	Speed: 165521.49 samples/sec	accuracy=nan
2021-11-05 20:31:21,926 Node[0] Epoch[5] Batch [100-120]	Speed: 166187.67 samples/sec	accuracy=nan
2021-11-05 20:31:22,321 Node[0] Epoch[5] Batch [120-140]	Speed: 165420.99 samples/sec	accuracy=nan
2021-11-05 20:31:22,715 Node[0] Epoch[5] Batch [140-160]	Speed: 165645.46 samples/sec	accuracy=nan
2021-11-05 20:31:23,109 Node[0] Epoch[5] Batch [160-180]	Speed: 165488.88 samples/sec	accuracy=nan
2021-11-05 20:31:23,508 Node[0] Epoch[5] Batch [180-200]	Speed: 163805.79 samples/sec	accuracy=nan
2021-11-05 20:31:23,910 Node[0] Epoch[5] Batch [200-220]	Speed: 162283.07 samples/sec	accuracy=nan
2021-11-05 20:31:24,306 Node[0] Epoch[5] Batch [220-240]	Speed: 164999.42 samples/sec	accuracy=nan
2021-11-05 20:31:24,700 Node[0] Epoch[5] Batch [240-260]	Speed: 165568.94 samples/sec	accuracy=nan
2021-11-05 20:31:25,093 Node[0] Epoch[5] Batch [260-280]	Speed: 166146.83 samples/sec	accuracy=nan
2021-11-05 20:31:25,485 Node[0] Epoch[5] Batch [280-300]	Speed: 166453.79 samples/sec	accuracy=nan
2021-11-05 20:31:25,879 Node[0] Epoch[5] Batch [300-320]	Speed: 165563.23 samples/sec	accuracy=nan
2021-11-05 20:31:26,275 Node[0] Epoch[5] Batch [320-340]	Speed: 164891.61 samples/sec	accuracy=nan
2021-11-05 20:31:26,673 Node[0] Epoch[5] Batch [340-360]	Speed: 164265.02 samples/sec	accuracy=nan
2021-11-05 20:31:27,070 Node[0] Epoch[5] Batch [360-380]	Speed: 164144.78 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144287307, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 6}}
2021-11-05 20:31:27,307 Node[0] Epoch[5] Time cost=7.765
:::MLLOG {"namespace": "", "time_ms": 1636144287308, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164989.6965263946}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 6}}
:::MLLOG {"namespace": "", "time_ms": 1636144287308, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164989.6965263946, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144287308, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 7}}
2021-11-05 20:31:27,722 Node[0] Epoch[6] Batch [0-20]	Speed: 165829.15 samples/sec	accuracy=nan
2021-11-05 20:31:28,116 Node[0] Epoch[6] Batch [20-40]	Speed: 165559.13 samples/sec	accuracy=nan
2021-11-05 20:31:28,508 Node[0] Epoch[6] Batch [40-60]	Speed: 166488.10 samples/sec	accuracy=nan
2021-11-05 20:31:28,900 Node[0] Epoch[6] Batch [60-80]	Speed: 166381.06 samples/sec	accuracy=nan
2021-11-05 20:31:29,299 Node[0] Epoch[6] Batch [80-100]	Speed: 163795.60 samples/sec	accuracy=nan
2021-11-05 20:31:29,695 Node[0] Epoch[6] Batch [100-120]	Speed: 164589.29 samples/sec	accuracy=nan
2021-11-05 20:31:30,089 Node[0] Epoch[6] Batch [120-140]	Speed: 165876.87 samples/sec	accuracy=nan
2021-11-05 20:31:30,480 Node[0] Epoch[6] Batch [140-160]	Speed: 166902.47 samples/sec	accuracy=nan
2021-11-05 20:31:30,875 Node[0] Epoch[6] Batch [160-180]	Speed: 165113.75 samples/sec	accuracy=nan
2021-11-05 20:31:31,269 Node[0] Epoch[6] Batch [180-200]	Speed: 165847.23 samples/sec	accuracy=nan
2021-11-05 20:31:31,667 Node[0] Epoch[6] Batch [200-220]	Speed: 163990.82 samples/sec	accuracy=nan
2021-11-05 20:31:32,062 Node[0] Epoch[6] Batch [220-240]	Speed: 165540.61 samples/sec	accuracy=nan
2021-11-05 20:31:32,459 Node[0] Epoch[6] Batch [240-260]	Speed: 164389.39 samples/sec	accuracy=nan
2021-11-05 20:31:32,852 Node[0] Epoch[6] Batch [260-280]	Speed: 165902.91 samples/sec	accuracy=nan
2021-11-05 20:31:33,247 Node[0] Epoch[6] Batch [280-300]	Speed: 165146.21 samples/sec	accuracy=nan
2021-11-05 20:31:33,640 Node[0] Epoch[6] Batch [300-320]	Speed: 166379.14 samples/sec	accuracy=nan
2021-11-05 20:31:34,039 Node[0] Epoch[6] Batch [320-340]	Speed: 163453.07 samples/sec	accuracy=nan
2021-11-05 20:31:34,435 Node[0] Epoch[6] Batch [340-360]	Speed: 164897.17 samples/sec	accuracy=nan
2021-11-05 20:31:34,838 Node[0] Epoch[6] Batch [360-380]	Speed: 161968.58 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144295080, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 7}}
2021-11-05 20:31:35,080 Node[0] Epoch[6] Time cost=7.772
:::MLLOG {"namespace": "", "time_ms": 1636144295080, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164840.90139735202}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636144295080, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164840.90139735202, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144295097, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 7}}
2021-11-05 20:31:35,210 Node[0] Epoch[6] Validation-accuracy=0.485275
2021-11-05 20:31:35,210 Node[0] Epoch[6] Validation-correct-count=379.000000
2021-11-05 20:31:35,210 Node[0] Epoch[6] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636144295230, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636144295230, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.47566, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636144295230, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636144295230, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 8, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636144295231, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 8}}
2021-11-05 20:31:35,627 Node[0] Epoch[7] Batch [0-20]	Speed: 166732.84 samples/sec	accuracy=nan
2021-11-05 20:31:36,021 Node[0] Epoch[7] Batch [20-40]	Speed: 165433.69 samples/sec	accuracy=nan
2021-11-05 20:31:36,413 Node[0] Epoch[7] Batch [40-60]	Speed: 166546.84 samples/sec	accuracy=nan
2021-11-05 20:31:36,806 Node[0] Epoch[7] Batch [60-80]	Speed: 166283.56 samples/sec	accuracy=nan
2021-11-05 20:31:37,200 Node[0] Epoch[7] Batch [80-100]	Speed: 165614.50 samples/sec	accuracy=nan
2021-11-05 20:31:37,596 Node[0] Epoch[7] Batch [100-120]	Speed: 164870.76 samples/sec	accuracy=nan
2021-11-05 20:31:37,990 Node[0] Epoch[7] Batch [120-140]	Speed: 165700.80 samples/sec	accuracy=nan
2021-11-05 20:31:38,384 Node[0] Epoch[7] Batch [140-160]	Speed: 165826.84 samples/sec	accuracy=nan
2021-11-05 20:31:38,777 Node[0] Epoch[7] Batch [160-180]	Speed: 165948.96 samples/sec	accuracy=nan
2021-11-05 20:31:39,172 Node[0] Epoch[7] Batch [180-200]	Speed: 165435.98 samples/sec	accuracy=nan
2021-11-05 20:31:39,566 Node[0] Epoch[7] Batch [200-220]	Speed: 165668.01 samples/sec	accuracy=nan
2021-11-05 20:31:39,960 Node[0] Epoch[7] Batch [220-240]	Speed: 165722.06 samples/sec	accuracy=nan
2021-11-05 20:31:40,353 Node[0] Epoch[7] Batch [240-260]	Speed: 166090.80 samples/sec	accuracy=nan
2021-11-05 20:31:40,746 Node[0] Epoch[7] Batch [260-280]	Speed: 166079.92 samples/sec	accuracy=nan
2021-11-05 20:31:41,139 Node[0] Epoch[7] Batch [280-300]	Speed: 165843.92 samples/sec	accuracy=nan
2021-11-05 20:31:41,533 Node[0] Epoch[7] Batch [300-320]	Speed: 165671.02 samples/sec	accuracy=nan
2021-11-05 20:31:41,930 Node[0] Epoch[7] Batch [320-340]	Speed: 164693.64 samples/sec	accuracy=nan
2021-11-05 20:31:42,327 Node[0] Epoch[7] Batch [340-360]	Speed: 164504.05 samples/sec	accuracy=nan
2021-11-05 20:31:42,723 Node[0] Epoch[7] Batch [360-380]	Speed: 164831.55 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144302960, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 8}}
2021-11-05 20:31:42,960 Node[0] Epoch[7] Time cost=7.729
:::MLLOG {"namespace": "", "time_ms": 1636144302960, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165754.33491623838}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 8}}
:::MLLOG {"namespace": "", "time_ms": 1636144302960, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165754.33491623838, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144302960, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 9}}
2021-11-05 20:31:43,376 Node[0] Epoch[8] Batch [0-20]	Speed: 165187.06 samples/sec	accuracy=nan
2021-11-05 20:31:43,772 Node[0] Epoch[8] Batch [20-40]	Speed: 164860.53 samples/sec	accuracy=nan
2021-11-05 20:31:44,168 Node[0] Epoch[8] Batch [40-60]	Speed: 165045.97 samples/sec	accuracy=nan
2021-11-05 20:31:44,562 Node[0] Epoch[8] Batch [60-80]	Speed: 165420.49 samples/sec	accuracy=nan
2021-11-05 20:31:44,958 Node[0] Epoch[8] Batch [80-100]	Speed: 164962.94 samples/sec	accuracy=nan
2021-11-05 20:31:45,350 Node[0] Epoch[8] Batch [100-120]	Speed: 166429.71 samples/sec	accuracy=nan
2021-11-05 20:31:45,744 Node[0] Epoch[8] Batch [120-140]	Speed: 165625.42 samples/sec	accuracy=nan
2021-11-05 20:31:46,136 Node[0] Epoch[8] Batch [140-160]	Speed: 166553.93 samples/sec	accuracy=nan
2021-11-05 20:31:46,533 Node[0] Epoch[8] Batch [160-180]	Speed: 164528.27 samples/sec	accuracy=nan
2021-11-05 20:31:46,928 Node[0] Epoch[8] Batch [180-200]	Speed: 165527.90 samples/sec	accuracy=nan
2021-11-05 20:31:47,323 Node[0] Epoch[8] Batch [200-220]	Speed: 165118.53 samples/sec	accuracy=nan
2021-11-05 20:31:47,720 Node[0] Epoch[8] Batch [220-240]	Speed: 164329.99 samples/sec	accuracy=nan
2021-11-05 20:31:48,113 Node[0] Epoch[8] Batch [240-260]	Speed: 166337.80 samples/sec	accuracy=nan
2021-11-05 20:31:48,506 Node[0] Epoch[8] Batch [260-280]	Speed: 165882.50 samples/sec	accuracy=nan
2021-11-05 20:31:48,900 Node[0] Epoch[8] Batch [280-300]	Speed: 165933.87 samples/sec	accuracy=nan
2021-11-05 20:31:49,293 Node[0] Epoch[8] Batch [300-320]	Speed: 165707.22 samples/sec	accuracy=nan
2021-11-05 20:31:49,690 Node[0] Epoch[8] Batch [320-340]	Speed: 164491.01 samples/sec	accuracy=nan
2021-11-05 20:31:50,089 Node[0] Epoch[8] Batch [340-360]	Speed: 163634.57 samples/sec	accuracy=nan
2021-11-05 20:31:50,488 Node[0] Epoch[8] Batch [360-380]	Speed: 163781.98 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144310726, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 9}}
2021-11-05 20:31:50,726 Node[0] Epoch[8] Time cost=7.765
:::MLLOG {"namespace": "", "time_ms": 1636144310726, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164983.17710002238}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 9}}
:::MLLOG {"namespace": "", "time_ms": 1636144310726, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164983.17710002238, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144310726, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 10}}
2021-11-05 20:31:51,142 Node[0] Epoch[9] Batch [0-20]	Speed: 164747.15 samples/sec	accuracy=nan
2021-11-05 20:31:51,535 Node[0] Epoch[9] Batch [20-40]	Speed: 165986.18 samples/sec	accuracy=nan
2021-11-05 20:31:51,926 Node[0] Epoch[9] Batch [40-60]	Speed: 166801.10 samples/sec	accuracy=nan
2021-11-05 20:31:52,318 Node[0] Epoch[9] Batch [60-80]	Speed: 166657.84 samples/sec	accuracy=nan
2021-11-05 20:31:52,710 Node[0] Epoch[9] Batch [80-100]	Speed: 166436.89 samples/sec	accuracy=nan
2021-11-05 20:31:53,103 Node[0] Epoch[9] Batch [100-120]	Speed: 166346.90 samples/sec	accuracy=nan
2021-11-05 20:31:53,495 Node[0] Epoch[9] Batch [120-140]	Speed: 166251.95 samples/sec	accuracy=nan
2021-11-05 20:31:53,889 Node[0] Epoch[9] Batch [140-160]	Speed: 165927.04 samples/sec	accuracy=nan
2021-11-05 20:31:54,281 Node[0] Epoch[9] Batch [160-180]	Speed: 166159.54 samples/sec	accuracy=nan
2021-11-05 20:31:54,674 Node[0] Epoch[9] Batch [180-200]	Speed: 166503.29 samples/sec	accuracy=nan
2021-11-05 20:31:55,070 Node[0] Epoch[9] Batch [200-220]	Speed: 164821.43 samples/sec	accuracy=nan
2021-11-05 20:31:55,463 Node[0] Epoch[9] Batch [220-240]	Speed: 165919.80 samples/sec	accuracy=nan
2021-11-05 20:31:55,854 Node[0] Epoch[9] Batch [240-260]	Speed: 166908.67 samples/sec	accuracy=nan
2021-11-05 20:31:56,248 Node[0] Epoch[9] Batch [260-280]	Speed: 165637.45 samples/sec	accuracy=nan
2021-11-05 20:31:56,640 Node[0] Epoch[9] Batch [280-300]	Speed: 166684.83 samples/sec	accuracy=nan
2021-11-05 20:31:57,034 Node[0] Epoch[9] Batch [300-320]	Speed: 165447.18 samples/sec	accuracy=nan
2021-11-05 20:31:57,432 Node[0] Epoch[9] Batch [320-340]	Speed: 164300.80 samples/sec	accuracy=nan
2021-11-05 20:31:57,831 Node[0] Epoch[9] Batch [340-360]	Speed: 163554.13 samples/sec	accuracy=nan
2021-11-05 20:31:58,230 Node[0] Epoch[9] Batch [360-380]	Speed: 163690.33 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144318466, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 10}}
2021-11-05 20:31:58,466 Node[0] Epoch[9] Time cost=7.740
:::MLLOG {"namespace": "", "time_ms": 1636144318466, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165523.2697552062}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 10}}
:::MLLOG {"namespace": "", "time_ms": 1636144318467, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165523.2697552062, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144318467, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 11}}
2021-11-05 20:31:58,882 Node[0] Epoch[10] Batch [0-20]	Speed: 164545.38 samples/sec	accuracy=nan
2021-11-05 20:31:59,275 Node[0] Epoch[10] Batch [20-40]	Speed: 166231.06 samples/sec	accuracy=nan
2021-11-05 20:31:59,669 Node[0] Epoch[10] Batch [40-60]	Speed: 165606.49 samples/sec	accuracy=nan
2021-11-05 20:32:00,063 Node[0] Epoch[10] Batch [60-80]	Speed: 165793.11 samples/sec	accuracy=nan
2021-11-05 20:32:00,460 Node[0] Epoch[10] Batch [80-100]	Speed: 164565.85 samples/sec	accuracy=nan
2021-11-05 20:32:00,854 Node[0] Epoch[10] Batch [100-120]	Speed: 165671.92 samples/sec	accuracy=nan
2021-11-05 20:32:01,245 Node[0] Epoch[10] Batch [120-140]	Speed: 167012.11 samples/sec	accuracy=nan
2021-11-05 20:32:01,637 Node[0] Epoch[10] Batch [140-160]	Speed: 166557.58 samples/sec	accuracy=nan
2021-11-05 20:32:02,029 Node[0] Epoch[10] Batch [160-180]	Speed: 166401.08 samples/sec	accuracy=nan
2021-11-05 20:32:02,422 Node[0] Epoch[10] Batch [180-200]	Speed: 165914.06 samples/sec	accuracy=nan
2021-11-05 20:32:02,816 Node[0] Epoch[10] Batch [200-220]	Speed: 165965.05 samples/sec	accuracy=nan
2021-11-05 20:32:03,212 Node[0] Epoch[10] Batch [220-240]	Speed: 164943.56 samples/sec	accuracy=nan
2021-11-05 20:32:03,603 Node[0] Epoch[10] Batch [240-260]	Speed: 166570.95 samples/sec	accuracy=nan
2021-11-05 20:32:03,998 Node[0] Epoch[10] Batch [260-280]	Speed: 165527.00 samples/sec	accuracy=nan
2021-11-05 20:32:04,394 Node[0] Epoch[10] Batch [280-300]	Speed: 164714.35 samples/sec	accuracy=nan
2021-11-05 20:32:04,788 Node[0] Epoch[10] Batch [300-320]	Speed: 165745.23 samples/sec	accuracy=nan
2021-11-05 20:32:05,186 Node[0] Epoch[10] Batch [320-340]	Speed: 164138.39 samples/sec	accuracy=nan
2021-11-05 20:32:05,582 Node[0] Epoch[10] Batch [340-360]	Speed: 164776.90 samples/sec	accuracy=nan
2021-11-05 20:32:05,980 Node[0] Epoch[10] Batch [360-380]	Speed: 164014.99 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144326216, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 11}}
2021-11-05 20:32:06,216 Node[0] Epoch[10] Time cost=7.749
:::MLLOG {"namespace": "", "time_ms": 1636144326216, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165322.88203108995}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636144326216, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165322.88203108995, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144326233, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 11}}
2021-11-05 20:32:06,352 Node[0] Epoch[10] Validation-accuracy=0.522407
2021-11-05 20:32:06,352 Node[0] Epoch[10] Validation-correct-count=408.000000
2021-11-05 20:32:06,352 Node[0] Epoch[10] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636144326365, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636144326365, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.5178, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636144326365, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1636144326365, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 12, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636144326365, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 12}}
2021-11-05 20:32:06,763 Node[0] Epoch[11] Batch [0-20]	Speed: 165934.68 samples/sec	accuracy=nan
2021-11-05 20:32:07,159 Node[0] Epoch[11] Batch [20-40]	Speed: 165063.78 samples/sec	accuracy=nan
2021-11-05 20:32:07,551 Node[0] Epoch[11] Batch [40-60]	Speed: 166625.39 samples/sec	accuracy=nan
2021-11-05 20:32:07,945 Node[0] Epoch[11] Batch [60-80]	Speed: 165333.09 samples/sec	accuracy=nan
2021-11-05 20:32:08,339 Node[0] Epoch[11] Batch [80-100]	Speed: 165720.56 samples/sec	accuracy=nan
2021-11-05 20:32:08,733 Node[0] Epoch[11] Batch [100-120]	Speed: 165792.60 samples/sec	accuracy=nan
2021-11-05 20:32:09,127 Node[0] Epoch[11] Batch [120-140]	Speed: 165781.16 samples/sec	accuracy=nan
2021-11-05 20:32:09,522 Node[0] Epoch[11] Batch [140-160]	Speed: 165348.27 samples/sec	accuracy=nan
2021-11-05 20:32:09,920 Node[0] Epoch[11] Batch [160-180]	Speed: 164031.69 samples/sec	accuracy=nan
2021-11-05 20:32:10,315 Node[0] Epoch[11] Batch [180-200]	Speed: 165024.08 samples/sec	accuracy=nan
2021-11-05 20:32:10,711 Node[0] Epoch[11] Batch [200-220]	Speed: 165017.42 samples/sec	accuracy=nan
2021-11-05 20:32:11,103 Node[0] Epoch[11] Batch [220-240]	Speed: 166397.34 samples/sec	accuracy=nan
2021-11-05 20:32:11,498 Node[0] Epoch[11] Batch [240-260]	Speed: 165153.88 samples/sec	accuracy=nan
2021-11-05 20:32:11,894 Node[0] Epoch[11] Batch [260-280]	Speed: 164991.57 samples/sec	accuracy=nan
2021-11-05 20:32:12,286 Node[0] Epoch[11] Batch [280-300]	Speed: 166655.00 samples/sec	accuracy=nan
2021-11-05 20:32:12,678 Node[0] Epoch[11] Batch [300-320]	Speed: 166273.96 samples/sec	accuracy=nan
2021-11-05 20:32:13,072 Node[0] Epoch[11] Batch [320-340]	Speed: 165818.71 samples/sec	accuracy=nan
2021-11-05 20:32:13,472 Node[0] Epoch[11] Batch [340-360]	Speed: 163072.14 samples/sec	accuracy=nan
2021-11-05 20:32:13,870 Node[0] Epoch[11] Batch [360-380]	Speed: 164259.70 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144334111, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 12}}
2021-11-05 20:32:14,111 Node[0] Epoch[11] Time cost=7.746
:::MLLOG {"namespace": "", "time_ms": 1636144334111, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165391.1121106305}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 12}}
:::MLLOG {"namespace": "", "time_ms": 1636144334112, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165391.1121106305, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144334112, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 13}}
2021-11-05 20:32:14,529 Node[0] Epoch[12] Batch [0-20]	Speed: 163797.76 samples/sec	accuracy=nan
2021-11-05 20:32:14,923 Node[0] Epoch[12] Batch [20-40]	Speed: 165875.67 samples/sec	accuracy=nan
2021-11-05 20:32:15,316 Node[0] Epoch[12] Batch [40-60]	Speed: 166305.47 samples/sec	accuracy=nan
2021-11-05 20:32:15,708 Node[0] Epoch[12] Batch [60-80]	Speed: 166185.86 samples/sec	accuracy=nan
2021-11-05 20:32:16,102 Node[0] Epoch[12] Batch [80-100]	Speed: 165945.94 samples/sec	accuracy=nan
2021-11-05 20:32:16,496 Node[0] Epoch[12] Batch [100-120]	Speed: 165705.91 samples/sec	accuracy=nan
2021-11-05 20:32:16,890 Node[0] Epoch[12] Batch [120-140]	Speed: 165716.64 samples/sec	accuracy=nan
2021-11-05 20:32:17,281 Node[0] Epoch[12] Batch [140-160]	Speed: 166749.29 samples/sec	accuracy=nan
2021-11-05 20:32:17,674 Node[0] Epoch[12] Batch [160-180]	Speed: 166021.81 samples/sec	accuracy=nan
2021-11-05 20:32:18,074 Node[0] Epoch[12] Batch [180-200]	Speed: 163442.14 samples/sec	accuracy=nan
2021-11-05 20:32:18,469 Node[0] Epoch[12] Batch [200-220]	Speed: 165197.83 samples/sec	accuracy=nan
2021-11-05 20:32:18,862 Node[0] Epoch[12] Batch [220-240]	Speed: 166072.06 samples/sec	accuracy=nan
2021-11-05 20:32:19,255 Node[0] Epoch[12] Batch [240-260]	Speed: 165891.45 samples/sec	accuracy=nan
2021-11-05 20:32:19,652 Node[0] Epoch[12] Batch [260-280]	Speed: 164648.97 samples/sec	accuracy=nan
2021-11-05 20:32:20,046 Node[0] Epoch[12] Batch [280-300]	Speed: 165463.28 samples/sec	accuracy=nan
2021-11-05 20:32:20,444 Node[0] Epoch[12] Batch [300-320]	Speed: 164266.60 samples/sec	accuracy=nan
2021-11-05 20:32:20,845 Node[0] Epoch[12] Batch [320-340]	Speed: 162900.03 samples/sec	accuracy=nan
2021-11-05 20:32:21,242 Node[0] Epoch[12] Batch [340-360]	Speed: 164307.41 samples/sec	accuracy=nan
2021-11-05 20:32:21,637 Node[0] Epoch[12] Batch [360-380]	Speed: 165082.59 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144341873, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 13}}
2021-11-05 20:32:21,873 Node[0] Epoch[12] Time cost=7.761
:::MLLOG {"namespace": "", "time_ms": 1636144341873, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165068.00027425302}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 13}}
:::MLLOG {"namespace": "", "time_ms": 1636144341873, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165068.00027425302, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144341873, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 14}}
2021-11-05 20:32:22,288 Node[0] Epoch[13] Batch [0-20]	Speed: 165331.39 samples/sec	accuracy=nan
2021-11-05 20:32:22,682 Node[0] Epoch[13] Batch [20-40]	Speed: 165496.68 samples/sec	accuracy=nan
2021-11-05 20:32:23,074 Node[0] Epoch[13] Batch [40-60]	Speed: 166504.40 samples/sec	accuracy=nan
2021-11-05 20:32:23,469 Node[0] Epoch[13] Batch [60-80]	Speed: 165368.54 samples/sec	accuracy=nan
2021-11-05 20:32:23,863 Node[0] Epoch[13] Batch [80-100]	Speed: 165597.88 samples/sec	accuracy=nan
2021-11-05 20:32:24,259 Node[0] Epoch[13] Batch [100-120]	Speed: 164812.11 samples/sec	accuracy=nan
2021-11-05 20:32:24,652 Node[0] Epoch[13] Batch [120-140]	Speed: 166128.69 samples/sec	accuracy=nan
2021-11-05 20:32:25,047 Node[0] Epoch[13] Batch [140-160]	Speed: 165469.98 samples/sec	accuracy=nan
2021-11-05 20:32:25,441 Node[0] Epoch[13] Batch [160-180]	Speed: 165723.06 samples/sec	accuracy=nan
2021-11-05 20:32:25,834 Node[0] Epoch[13] Batch [180-200]	Speed: 165842.21 samples/sec	accuracy=nan
2021-11-05 20:32:26,228 Node[0] Epoch[13] Batch [200-220]	Speed: 165961.43 samples/sec	accuracy=nan
2021-11-05 20:32:26,619 Node[0] Epoch[13] Batch [220-240]	Speed: 166735.99 samples/sec	accuracy=nan
2021-11-05 20:32:27,013 Node[0] Epoch[13] Batch [240-260]	Speed: 165551.82 samples/sec	accuracy=nan
2021-11-05 20:32:27,409 Node[0] Epoch[13] Batch [260-280]	Speed: 164998.43 samples/sec	accuracy=nan
2021-11-05 20:32:27,802 Node[0] Epoch[13] Batch [280-300]	Speed: 166178.19 samples/sec	accuracy=nan
2021-11-05 20:32:28,198 Node[0] Epoch[13] Batch [300-320]	Speed: 164834.43 samples/sec	accuracy=nan
2021-11-05 20:32:28,594 Node[0] Epoch[13] Batch [320-340]	Speed: 164861.82 samples/sec	accuracy=nan
2021-11-05 20:32:28,988 Node[0] Epoch[13] Batch [340-360]	Speed: 165642.36 samples/sec	accuracy=nan
2021-11-05 20:32:29,384 Node[0] Epoch[13] Batch [360-380]	Speed: 164818.75 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144349623, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 14}}
2021-11-05 20:32:29,623 Node[0] Epoch[13] Time cost=7.750
:::MLLOG {"namespace": "", "time_ms": 1636144349623, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165318.39605362606}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 14}}
:::MLLOG {"namespace": "", "time_ms": 1636144349623, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165318.39605362606, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144349624, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 15}}
2021-11-05 20:32:30,036 Node[0] Epoch[14] Batch [0-20]	Speed: 165884.31 samples/sec	accuracy=nan
2021-11-05 20:32:30,431 Node[0] Epoch[14] Batch [20-40]	Speed: 165307.24 samples/sec	accuracy=nan
2021-11-05 20:32:30,824 Node[0] Epoch[14] Batch [40-60]	Speed: 166209.57 samples/sec	accuracy=nan
2021-11-05 20:32:31,218 Node[0] Epoch[14] Batch [60-80]	Speed: 165684.35 samples/sec	accuracy=nan
2021-11-05 20:32:31,610 Node[0] Epoch[14] Batch [80-100]	Speed: 166485.06 samples/sec	accuracy=nan
2021-11-05 20:32:32,004 Node[0] Epoch[14] Batch [100-120]	Speed: 165796.92 samples/sec	accuracy=nan
2021-11-05 20:32:32,396 Node[0] Epoch[14] Batch [120-140]	Speed: 166589.09 samples/sec	accuracy=nan
2021-11-05 20:32:32,788 Node[0] Epoch[14] Batch [140-160]	Speed: 166455.71 samples/sec	accuracy=nan
2021-11-05 20:32:33,185 Node[0] Epoch[14] Batch [160-180]	Speed: 164445.37 samples/sec	accuracy=nan
2021-11-05 20:32:33,580 Node[0] Epoch[14] Batch [180-200]	Speed: 165313.13 samples/sec	accuracy=nan
2021-11-05 20:32:33,974 Node[0] Epoch[14] Batch [200-220]	Speed: 165579.15 samples/sec	accuracy=nan
2021-11-05 20:32:34,370 Node[0] Epoch[14] Batch [220-240]	Speed: 164959.76 samples/sec	accuracy=nan
2021-11-05 20:32:34,761 Node[0] Epoch[14] Batch [240-260]	Speed: 166637.25 samples/sec	accuracy=nan
2021-11-05 20:32:35,156 Node[0] Epoch[14] Batch [260-280]	Speed: 165535.60 samples/sec	accuracy=nan
2021-11-05 20:32:35,549 Node[0] Epoch[14] Batch [280-300]	Speed: 165830.06 samples/sec	accuracy=nan
2021-11-05 20:32:35,942 Node[0] Epoch[14] Batch [300-320]	Speed: 166190.70 samples/sec	accuracy=nan
2021-11-05 20:32:36,340 Node[0] Epoch[14] Batch [320-340]	Speed: 163865.49 samples/sec	accuracy=nan
2021-11-05 20:32:36,737 Node[0] Epoch[14] Batch [340-360]	Speed: 164744.08 samples/sec	accuracy=nan
2021-11-05 20:32:37,134 Node[0] Epoch[14] Batch [360-380]	Speed: 164301.20 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144357371, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 15}}
2021-11-05 20:32:37,371 Node[0] Epoch[14] Time cost=7.748
:::MLLOG {"namespace": "", "time_ms": 1636144357371, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165361.77070300272}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636144357372, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165361.77070300272, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144357388, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 15}}
2021-11-05 20:32:37,504 Node[0] Epoch[14] Validation-accuracy=0.606914
2021-11-05 20:32:37,504 Node[0] Epoch[14] Validation-correct-count=474.000000
2021-11-05 20:32:37,504 Node[0] Epoch[14] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636144357529, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636144357530, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.59642, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636144357530, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1636144357530, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 16, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636144357530, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 16}}
2021-11-05 20:32:37,925 Node[0] Epoch[15] Batch [0-20]	Speed: 167306.63 samples/sec	accuracy=nan
2021-11-05 20:32:38,318 Node[0] Epoch[15] Batch [20-40]	Speed: 166153.39 samples/sec	accuracy=nan
2021-11-05 20:32:38,713 Node[0] Epoch[15] Batch [40-60]	Speed: 165157.47 samples/sec	accuracy=nan
2021-11-05 20:32:39,105 Node[0] Epoch[15] Batch [60-80]	Speed: 166404.42 samples/sec	accuracy=nan
2021-11-05 20:32:39,499 Node[0] Epoch[15] Batch [80-100]	Speed: 165616.71 samples/sec	accuracy=nan
2021-11-05 20:32:39,895 Node[0] Epoch[15] Batch [100-120]	Speed: 165202.31 samples/sec	accuracy=nan
2021-11-05 20:32:40,288 Node[0] Epoch[15] Batch [120-140]	Speed: 165751.66 samples/sec	accuracy=nan
2021-11-05 20:32:40,681 Node[0] Epoch[15] Batch [140-160]	Speed: 166235.60 samples/sec	accuracy=nan
2021-11-05 20:32:41,076 Node[0] Epoch[15] Batch [160-180]	Speed: 165476.98 samples/sec	accuracy=nan
2021-11-05 20:32:41,469 Node[0] Epoch[15] Batch [180-200]	Speed: 165920.50 samples/sec	accuracy=nan
2021-11-05 20:32:41,864 Node[0] Epoch[15] Batch [200-220]	Speed: 165128.58 samples/sec	accuracy=nan
2021-11-05 20:32:42,260 Node[0] Epoch[15] Batch [220-240]	Speed: 164857.85 samples/sec	accuracy=nan
2021-11-05 20:32:42,652 Node[0] Epoch[15] Batch [240-260]	Speed: 166657.23 samples/sec	accuracy=nan
2021-11-05 20:32:43,048 Node[0] Epoch[15] Batch [260-280]	Speed: 164943.16 samples/sec	accuracy=nan
2021-11-05 20:32:43,441 Node[0] Epoch[15] Batch [280-300]	Speed: 166025.03 samples/sec	accuracy=nan
2021-11-05 20:32:43,838 Node[0] Epoch[15] Batch [300-320]	Speed: 164667.29 samples/sec	accuracy=nan
2021-11-05 20:32:44,235 Node[0] Epoch[15] Batch [320-340]	Speed: 164404.88 samples/sec	accuracy=nan
2021-11-05 20:32:44,629 Node[0] Epoch[15] Batch [340-360]	Speed: 165446.48 samples/sec	accuracy=nan
2021-11-05 20:32:45,029 Node[0] Epoch[15] Batch [360-380]	Speed: 163131.02 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144365266, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 16}}
2021-11-05 20:32:45,267 Node[0] Epoch[15] Time cost=7.737
:::MLLOG {"namespace": "", "time_ms": 1636144365267, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165596.64078346852}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 16}}
:::MLLOG {"namespace": "", "time_ms": 1636144365267, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165596.64078346852, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144365267, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 17}}
2021-11-05 20:32:45,678 Node[0] Epoch[16] Batch [0-20]	Speed: 166585.44 samples/sec	accuracy=nan
2021-11-05 20:32:46,075 Node[0] Epoch[16] Batch [20-40]	Speed: 164312.24 samples/sec	accuracy=nan
2021-11-05 20:32:46,469 Node[0] Epoch[16] Batch [40-60]	Speed: 165991.11 samples/sec	accuracy=nan
2021-11-05 20:32:46,862 Node[0] Epoch[16] Batch [60-80]	Speed: 165942.32 samples/sec	accuracy=nan
2021-11-05 20:32:47,254 Node[0] Epoch[16] Batch [80-100]	Speed: 166458.24 samples/sec	accuracy=nan
2021-11-05 20:32:47,646 Node[0] Epoch[16] Batch [100-120]	Speed: 166728.17 samples/sec	accuracy=nan
2021-11-05 20:32:48,039 Node[0] Epoch[16] Batch [120-140]	Speed: 166032.38 samples/sec	accuracy=nan
2021-11-05 20:32:48,432 Node[0] Epoch[16] Batch [140-160]	Speed: 166177.08 samples/sec	accuracy=nan
2021-11-05 20:32:48,825 Node[0] Epoch[16] Batch [160-180]	Speed: 165927.54 samples/sec	accuracy=nan
2021-11-05 20:32:49,217 Node[0] Epoch[16] Batch [180-200]	Speed: 166586.15 samples/sec	accuracy=nan
2021-11-05 20:32:49,611 Node[0] Epoch[16] Batch [200-220]	Speed: 165696.19 samples/sec	accuracy=nan
2021-11-05 20:32:50,004 Node[0] Epoch[16] Batch [220-240]	Speed: 166278.20 samples/sec	accuracy=nan
2021-11-05 20:32:50,395 Node[0] Epoch[16] Batch [240-260]	Speed: 166847.44 samples/sec	accuracy=nan
2021-11-05 20:32:50,789 Node[0] Epoch[16] Batch [260-280]	Speed: 165739.72 samples/sec	accuracy=nan
2021-11-05 20:32:51,182 Node[0] Epoch[16] Batch [280-300]	Speed: 165806.66 samples/sec	accuracy=nan
2021-11-05 20:32:51,577 Node[0] Epoch[16] Batch [300-320]	Speed: 165385.22 samples/sec	accuracy=nan
2021-11-05 20:32:51,975 Node[0] Epoch[16] Batch [320-340]	Speed: 164105.92 samples/sec	accuracy=nan
2021-11-05 20:32:52,372 Node[0] Epoch[16] Batch [340-360]	Speed: 164246.10 samples/sec	accuracy=nan
2021-11-05 20:32:52,772 Node[0] Epoch[16] Batch [360-380]	Speed: 163459.32 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144373009, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 17}}
2021-11-05 20:32:53,009 Node[0] Epoch[16] Time cost=7.742
:::MLLOG {"namespace": "", "time_ms": 1636144373009, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165477.7261391182}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 17}}
:::MLLOG {"namespace": "", "time_ms": 1636144373009, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165477.7261391182, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144373009, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 18}}
2021-11-05 20:32:53,422 Node[0] Epoch[17] Batch [0-20]	Speed: 165880.39 samples/sec	accuracy=nan
2021-11-05 20:32:53,814 Node[0] Epoch[17] Batch [20-40]	Speed: 166365.49 samples/sec	accuracy=nan
2021-11-05 20:32:54,207 Node[0] Epoch[17] Batch [40-60]	Speed: 166334.97 samples/sec	accuracy=nan
2021-11-05 20:32:54,599 Node[0] Epoch[17] Batch [60-80]	Speed: 166266.89 samples/sec	accuracy=nan
2021-11-05 20:32:54,992 Node[0] Epoch[17] Batch [80-100]	Speed: 166100.77 samples/sec	accuracy=nan
2021-11-05 20:32:55,384 Node[0] Epoch[17] Batch [100-120]	Speed: 166747.16 samples/sec	accuracy=nan
2021-11-05 20:32:55,778 Node[0] Epoch[17] Batch [120-140]	Speed: 165857.18 samples/sec	accuracy=nan
2021-11-05 20:32:56,170 Node[0] Epoch[17] Batch [140-160]	Speed: 166410.39 samples/sec	accuracy=nan
2021-11-05 20:32:56,564 Node[0] Epoch[17] Batch [160-180]	Speed: 165434.49 samples/sec	accuracy=nan
2021-11-05 20:32:56,957 Node[0] Epoch[17] Batch [180-200]	Speed: 166087.27 samples/sec	accuracy=nan
2021-11-05 20:32:57,350 Node[0] Epoch[17] Batch [200-220]	Speed: 166202.50 samples/sec	accuracy=nan
2021-11-05 20:32:57,746 Node[0] Epoch[17] Batch [220-240]	Speed: 165090.35 samples/sec	accuracy=nan
2021-11-05 20:32:58,140 Node[0] Epoch[17] Batch [240-260]	Speed: 165526.20 samples/sec	accuracy=nan
2021-11-05 20:32:58,536 Node[0] Epoch[17] Batch [260-280]	Speed: 165014.24 samples/sec	accuracy=nan
2021-11-05 20:32:58,929 Node[0] Epoch[17] Batch [280-300]	Speed: 166029.06 samples/sec	accuracy=nan
2021-11-05 20:32:59,322 Node[0] Epoch[17] Batch [300-320]	Speed: 166116.39 samples/sec	accuracy=nan
2021-11-05 20:32:59,715 Node[0] Epoch[17] Batch [320-340]	Speed: 166067.93 samples/sec	accuracy=nan
2021-11-05 20:33:00,113 Node[0] Epoch[17] Batch [340-360]	Speed: 163937.51 samples/sec	accuracy=nan
2021-11-05 20:33:00,510 Node[0] Epoch[17] Batch [360-380]	Speed: 164540.73 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144380746, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 18}}
2021-11-05 20:33:00,747 Node[0] Epoch[17] Time cost=7.737
:::MLLOG {"namespace": "", "time_ms": 1636144380747, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165588.94050481418}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 18}}
:::MLLOG {"namespace": "", "time_ms": 1636144380747, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165588.94050481418, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144380747, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 19}}
2021-11-05 20:33:01,160 Node[0] Epoch[18] Batch [0-20]	Speed: 165760.29 samples/sec	accuracy=nan
2021-11-05 20:33:01,553 Node[0] Epoch[18] Batch [20-40]	Speed: 166207.55 samples/sec	accuracy=nan
2021-11-05 20:33:01,948 Node[0] Epoch[18] Batch [40-60]	Speed: 165432.69 samples/sec	accuracy=nan
2021-11-05 20:33:02,340 Node[0] Epoch[18] Batch [60-80]	Speed: 166418.08 samples/sec	accuracy=nan
2021-11-05 20:33:02,732 Node[0] Epoch[18] Batch [80-100]	Speed: 166281.84 samples/sec	accuracy=nan
2021-11-05 20:33:03,124 Node[0] Epoch[18] Batch [100-120]	Speed: 166783.82 samples/sec	accuracy=nan
2021-11-05 20:33:03,519 Node[0] Epoch[18] Batch [120-140]	Speed: 165367.64 samples/sec	accuracy=nan
2021-11-05 20:33:03,910 Node[0] Epoch[18] Batch [140-160]	Speed: 166735.48 samples/sec	accuracy=nan
2021-11-05 20:33:04,308 Node[0] Epoch[18] Batch [160-180]	Speed: 164198.82 samples/sec	accuracy=nan
2021-11-05 20:33:04,701 Node[0] Epoch[18] Batch [180-200]	Speed: 165936.39 samples/sec	accuracy=nan
2021-11-05 20:33:05,095 Node[0] Epoch[18] Batch [200-220]	Speed: 165606.49 samples/sec	accuracy=nan
2021-11-05 20:33:05,489 Node[0] Epoch[18] Batch [220-240]	Speed: 165981.05 samples/sec	accuracy=nan
2021-11-05 20:33:05,883 Node[0] Epoch[18] Batch [240-260]	Speed: 165426.49 samples/sec	accuracy=nan
2021-11-05 20:33:06,275 Node[0] Epoch[18] Batch [260-280]	Speed: 166684.73 samples/sec	accuracy=nan
2021-11-05 20:33:06,668 Node[0] Epoch[18] Batch [280-300]	Speed: 166260.63 samples/sec	accuracy=nan
2021-11-05 20:33:07,061 Node[0] Epoch[18] Batch [300-320]	Speed: 165849.95 samples/sec	accuracy=nan
2021-11-05 20:33:07,456 Node[0] Epoch[18] Batch [320-340]	Speed: 165172.12 samples/sec	accuracy=nan
2021-11-05 20:33:07,854 Node[0] Epoch[18] Batch [340-360]	Speed: 164253.39 samples/sec	accuracy=nan
2021-11-05 20:33:08,253 Node[0] Epoch[18] Batch [360-380]	Speed: 163638.58 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144388491, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 19}}
2021-11-05 20:33:08,491 Node[0] Epoch[18] Time cost=7.744
:::MLLOG {"namespace": "", "time_ms": 1636144388491, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165436.47053748404}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636144388491, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165436.47053748404, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144388508, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 19}}
2021-11-05 20:33:08,621 Node[0] Epoch[18] Validation-accuracy=0.656850
2021-11-05 20:33:08,621 Node[0] Epoch[18] Validation-correct-count=513.000000
2021-11-05 20:33:08,621 Node[0] Epoch[18] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636144388639, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636144388639, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.65124, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636144388639, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1636144388639, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 20, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636144388639, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 20}}
2021-11-05 20:33:09,035 Node[0] Epoch[19] Batch [0-20]	Speed: 167153.94 samples/sec	accuracy=nan
2021-11-05 20:33:09,430 Node[0] Epoch[19] Batch [20-40]	Speed: 165335.09 samples/sec	accuracy=nan
2021-11-05 20:33:09,822 Node[0] Epoch[19] Batch [40-60]	Speed: 166266.79 samples/sec	accuracy=nan
2021-11-05 20:33:10,215 Node[0] Epoch[19] Batch [60-80]	Speed: 166376.41 samples/sec	accuracy=nan
2021-11-05 20:33:10,607 Node[0] Epoch[19] Batch [80-100]	Speed: 166220.87 samples/sec	accuracy=nan
2021-11-05 20:33:10,999 Node[0] Epoch[19] Batch [100-120]	Speed: 166671.54 samples/sec	accuracy=nan
2021-11-05 20:33:11,394 Node[0] Epoch[19] Batch [120-140]	Speed: 165142.83 samples/sec	accuracy=nan
2021-11-05 20:33:11,787 Node[0] Epoch[19] Batch [140-160]	Speed: 166187.17 samples/sec	accuracy=nan
2021-11-05 20:33:12,182 Node[0] Epoch[19] Batch [160-180]	Speed: 165440.58 samples/sec	accuracy=nan
2021-11-05 20:33:12,574 Node[0] Epoch[19] Batch [180-200]	Speed: 166213.50 samples/sec	accuracy=nan
2021-11-05 20:33:12,967 Node[0] Epoch[19] Batch [200-220]	Speed: 166147.24 samples/sec	accuracy=nan
2021-11-05 20:33:13,360 Node[0] Epoch[19] Batch [220-240]	Speed: 166120.62 samples/sec	accuracy=nan
2021-11-05 20:33:13,753 Node[0] Epoch[19] Batch [240-260]	Speed: 166338.00 samples/sec	accuracy=nan
2021-11-05 20:33:14,147 Node[0] Epoch[19] Batch [260-280]	Speed: 165664.61 samples/sec	accuracy=nan
2021-11-05 20:33:14,543 Node[0] Epoch[19] Batch [280-300]	Speed: 164889.92 samples/sec	accuracy=nan
2021-11-05 20:33:14,934 Node[0] Epoch[19] Batch [300-320]	Speed: 166599.94 samples/sec	accuracy=nan
2021-11-05 20:33:15,333 Node[0] Epoch[19] Batch [320-340]	Speed: 163831.37 samples/sec	accuracy=nan
2021-11-05 20:33:15,731 Node[0] Epoch[19] Batch [340-360]	Speed: 164071.90 samples/sec	accuracy=nan
2021-11-05 20:33:16,127 Node[0] Epoch[19] Batch [360-380]	Speed: 164727.33 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144396362, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 20}}
2021-11-05 20:33:16,362 Node[0] Epoch[19] Time cost=7.722
:::MLLOG {"namespace": "", "time_ms": 1636144396362, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165903.26314058268}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1636144396362, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165903.26314058268, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144396362, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 21}}
2021-11-05 20:33:16,777 Node[0] Epoch[20] Batch [0-20]	Speed: 164845.05 samples/sec	accuracy=nan
2021-11-05 20:33:17,172 Node[0] Epoch[20] Batch [20-40]	Speed: 165049.25 samples/sec	accuracy=nan
2021-11-05 20:33:17,566 Node[0] Epoch[20] Batch [40-60]	Speed: 166032.78 samples/sec	accuracy=nan
2021-11-05 20:33:17,959 Node[0] Epoch[20] Batch [60-80]	Speed: 166055.54 samples/sec	accuracy=nan
2021-11-05 20:33:18,350 Node[0] Epoch[20] Batch [80-100]	Speed: 166683.31 samples/sec	accuracy=nan
2021-11-05 20:33:18,746 Node[0] Epoch[20] Batch [100-120]	Speed: 164932.33 samples/sec	accuracy=nan
2021-11-05 20:33:19,140 Node[0] Epoch[20] Batch [120-140]	Speed: 165595.37 samples/sec	accuracy=nan
2021-11-05 20:33:19,535 Node[0] Epoch[20] Batch [140-160]	Speed: 165269.62 samples/sec	accuracy=nan
2021-11-05 20:33:19,928 Node[0] Epoch[20] Batch [160-180]	Speed: 166461.68 samples/sec	accuracy=nan
2021-11-05 20:33:20,322 Node[0] Epoch[20] Batch [180-200]	Speed: 165539.11 samples/sec	accuracy=nan
2021-11-05 20:33:20,714 Node[0] Epoch[20] Batch [200-220]	Speed: 166330.32 samples/sec	accuracy=nan
2021-11-05 20:33:21,108 Node[0] Epoch[20] Batch [220-240]	Speed: 165878.98 samples/sec	accuracy=nan
2021-11-05 20:33:21,501 Node[0] Epoch[20] Batch [240-260]	Speed: 165948.96 samples/sec	accuracy=nan
2021-11-05 20:33:21,894 Node[0] Epoch[20] Batch [260-280]	Speed: 166116.49 samples/sec	accuracy=nan
2021-11-05 20:33:22,286 Node[0] Epoch[20] Batch [280-300]	Speed: 166595.17 samples/sec	accuracy=nan
2021-11-05 20:33:22,681 Node[0] Epoch[20] Batch [300-320]	Speed: 165232.82 samples/sec	accuracy=nan
2021-11-05 20:33:23,076 Node[0] Epoch[20] Batch [320-340]	Speed: 165506.39 samples/sec	accuracy=nan
2021-11-05 20:33:23,474 Node[0] Epoch[20] Batch [340-360]	Speed: 163868.24 samples/sec	accuracy=nan
2021-11-05 20:33:23,872 Node[0] Epoch[20] Batch [360-380]	Speed: 164033.46 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144404108, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 21}}
2021-11-05 20:33:24,108 Node[0] Epoch[20] Time cost=7.746
:::MLLOG {"namespace": "", "time_ms": 1636144404108, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165399.6085572505}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 21}}
:::MLLOG {"namespace": "", "time_ms": 1636144404108, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165399.6085572505, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144404108, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 22}}
2021-11-05 20:33:24,521 Node[0] Epoch[21] Batch [0-20]	Speed: 165850.65 samples/sec	accuracy=nan
2021-11-05 20:33:24,914 Node[0] Epoch[21] Batch [20-40]	Speed: 166195.14 samples/sec	accuracy=nan
2021-11-05 20:33:25,309 Node[0] Epoch[21] Batch [40-60]	Speed: 165193.14 samples/sec	accuracy=nan
2021-11-05 20:33:25,700 Node[0] Epoch[21] Batch [60-80]	Speed: 166762.69 samples/sec	accuracy=nan
2021-11-05 20:33:26,093 Node[0] Epoch[21] Batch [80-100]	Speed: 166366.30 samples/sec	accuracy=nan
2021-11-05 20:33:26,486 Node[0] Epoch[21] Batch [100-120]	Speed: 166191.10 samples/sec	accuracy=nan
2021-11-05 20:33:26,877 Node[0] Epoch[21] Batch [120-140]	Speed: 166792.05 samples/sec	accuracy=nan
2021-11-05 20:33:27,269 Node[0] Epoch[21] Batch [140-160]	Speed: 166432.34 samples/sec	accuracy=nan
2021-11-05 20:33:27,663 Node[0] Epoch[21] Batch [160-180]	Speed: 165695.88 samples/sec	accuracy=nan
2021-11-05 20:33:28,056 Node[0] Epoch[21] Batch [180-200]	Speed: 166283.96 samples/sec	accuracy=nan
2021-11-05 20:33:28,449 Node[0] Epoch[21] Batch [200-220]	Speed: 165980.75 samples/sec	accuracy=nan
2021-11-05 20:33:28,843 Node[0] Epoch[21] Batch [220-240]	Speed: 165743.63 samples/sec	accuracy=nan
2021-11-05 20:33:29,235 Node[0] Epoch[21] Batch [240-260]	Speed: 166479.39 samples/sec	accuracy=nan
2021-11-05 20:33:29,628 Node[0] Epoch[21] Batch [260-280]	Speed: 166111.55 samples/sec	accuracy=nan
2021-11-05 20:33:30,020 Node[0] Epoch[21] Batch [280-300]	Speed: 166367.62 samples/sec	accuracy=nan
2021-11-05 20:33:30,416 Node[0] Epoch[21] Batch [300-320]	Speed: 164908.49 samples/sec	accuracy=nan
2021-11-05 20:33:30,811 Node[0] Epoch[21] Batch [320-340]	Speed: 165399.11 samples/sec	accuracy=nan
2021-11-05 20:33:31,209 Node[0] Epoch[21] Batch [340-360]	Speed: 164071.40 samples/sec	accuracy=nan
2021-11-05 20:33:31,607 Node[0] Epoch[21] Batch [360-380]	Speed: 164071.31 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144411842, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 22}}
2021-11-05 20:33:31,842 Node[0] Epoch[21] Time cost=7.734
:::MLLOG {"namespace": "", "time_ms": 1636144411842, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165664.39735651162}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 22}}
:::MLLOG {"namespace": "", "time_ms": 1636144411842, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165664.39735651162, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144411842, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 23}}
2021-11-05 20:33:32,254 Node[0] Epoch[22] Batch [0-20]	Speed: 166186.67 samples/sec	accuracy=nan
2021-11-05 20:33:32,650 Node[0] Epoch[22] Batch [20-40]	Speed: 165087.86 samples/sec	accuracy=nan
2021-11-05 20:33:33,044 Node[0] Epoch[22] Batch [40-60]	Speed: 165435.69 samples/sec	accuracy=nan
2021-11-05 20:33:33,436 Node[0] Epoch[22] Batch [60-80]	Speed: 166467.55 samples/sec	accuracy=nan
2021-11-05 20:33:33,830 Node[0] Epoch[22] Batch [80-100]	Speed: 165750.45 samples/sec	accuracy=nan
2021-11-05 20:33:34,222 Node[0] Epoch[22] Batch [100-120]	Speed: 166536.81 samples/sec	accuracy=nan
2021-11-05 20:33:34,615 Node[0] Epoch[22] Batch [120-140]	Speed: 166387.74 samples/sec	accuracy=nan
2021-11-05 20:33:35,006 Node[0] Epoch[22] Batch [140-160]	Speed: 166700.05 samples/sec	accuracy=nan
2021-11-05 20:33:35,400 Node[0] Epoch[22] Batch [160-180]	Speed: 165661.30 samples/sec	accuracy=nan
2021-11-05 20:33:35,794 Node[0] Epoch[22] Batch [180-200]	Speed: 165673.63 samples/sec	accuracy=nan
2021-11-05 20:33:36,186 Node[0] Epoch[22] Batch [200-220]	Speed: 166550.69 samples/sec	accuracy=nan
2021-11-05 20:33:36,580 Node[0] Epoch[22] Batch [220-240]	Speed: 165915.47 samples/sec	accuracy=nan
2021-11-05 20:33:36,974 Node[0] Epoch[22] Batch [240-260]	Speed: 165447.08 samples/sec	accuracy=nan
2021-11-05 20:33:37,367 Node[0] Epoch[22] Batch [260-280]	Speed: 166265.18 samples/sec	accuracy=nan
2021-11-05 20:33:37,761 Node[0] Epoch[22] Batch [280-300]	Speed: 165673.93 samples/sec	accuracy=nan
2021-11-05 20:33:38,155 Node[0] Epoch[22] Batch [300-320]	Speed: 165814.19 samples/sec	accuracy=nan
2021-11-05 20:33:38,550 Node[0] Epoch[22] Batch [320-340]	Speed: 165142.03 samples/sec	accuracy=nan
2021-11-05 20:33:38,946 Node[0] Epoch[22] Batch [340-360]	Speed: 164765.29 samples/sec	accuracy=nan
2021-11-05 20:33:39,345 Node[0] Epoch[22] Batch [360-380]	Speed: 163654.82 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144419580, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 23}}
2021-11-05 20:33:39,580 Node[0] Epoch[22] Time cost=7.738
:::MLLOG {"namespace": "", "time_ms": 1636144419580, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165565.7164340986}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636144419581, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165565.7164340986, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144419597, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 23}}
2021-11-05 20:33:39,715 Node[0] Epoch[22] Validation-accuracy=0.706786
2021-11-05 20:33:39,716 Node[0] Epoch[22] Validation-correct-count=552.000000
2021-11-05 20:33:39,716 Node[0] Epoch[22] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636144419727, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636144419727, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.68826, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636144419727, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1636144419727, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 24, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636144419727, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 24}}
2021-11-05 20:33:40,123 Node[0] Epoch[23] Batch [0-20]	Speed: 167117.92 samples/sec	accuracy=nan
2021-11-05 20:33:40,517 Node[0] Epoch[23] Batch [20-40]	Speed: 165637.05 samples/sec	accuracy=nan
2021-11-05 20:33:40,909 Node[0] Epoch[23] Batch [40-60]	Speed: 166712.53 samples/sec	accuracy=nan
2021-11-05 20:33:41,303 Node[0] Epoch[23] Batch [60-80]	Speed: 165769.22 samples/sec	accuracy=nan
2021-11-05 20:33:41,696 Node[0] Epoch[23] Batch [80-100]	Speed: 166028.35 samples/sec	accuracy=nan
2021-11-05 20:33:42,089 Node[0] Epoch[23] Batch [100-120]	Speed: 165939.81 samples/sec	accuracy=nan
2021-11-05 20:33:42,482 Node[0] Epoch[23] Batch [120-140]	Speed: 166398.35 samples/sec	accuracy=nan
2021-11-05 20:33:42,874 Node[0] Epoch[23] Batch [140-160]	Speed: 166189.49 samples/sec	accuracy=nan
2021-11-05 20:33:43,268 Node[0] Epoch[23] Batch [160-180]	Speed: 165858.59 samples/sec	accuracy=nan
2021-11-05 20:33:43,661 Node[0] Epoch[23] Batch [180-200]	Speed: 166267.40 samples/sec	accuracy=nan
2021-11-05 20:33:44,054 Node[0] Epoch[23] Batch [200-220]	Speed: 166030.27 samples/sec	accuracy=nan
2021-11-05 20:33:44,447 Node[0] Epoch[23] Batch [220-240]	Speed: 166020.40 samples/sec	accuracy=nan
2021-11-05 20:33:44,840 Node[0] Epoch[23] Batch [240-260]	Speed: 166150.06 samples/sec	accuracy=nan
2021-11-05 20:33:45,235 Node[0] Epoch[23] Batch [260-280]	Speed: 165293.97 samples/sec	accuracy=nan
2021-11-05 20:33:45,626 Node[0] Epoch[23] Batch [280-300]	Speed: 166677.52 samples/sec	accuracy=nan
2021-11-05 20:33:46,020 Node[0] Epoch[23] Batch [300-320]	Speed: 165696.59 samples/sec	accuracy=nan
2021-11-05 20:33:46,415 Node[0] Epoch[23] Batch [320-340]	Speed: 165616.31 samples/sec	accuracy=nan
2021-11-05 20:33:46,810 Node[0] Epoch[23] Batch [340-360]	Speed: 165033.43 samples/sec	accuracy=nan
2021-11-05 20:33:47,210 Node[0] Epoch[23] Batch [360-380]	Speed: 163408.10 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144427446, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 24}}
2021-11-05 20:33:47,446 Node[0] Epoch[23] Time cost=7.719
:::MLLOG {"namespace": "", "time_ms": 1636144427446, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165980.33975684035}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 24}}
:::MLLOG {"namespace": "", "time_ms": 1636144427446, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165980.33975684035, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144427446, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 25}}
2021-11-05 20:33:47,864 Node[0] Epoch[24] Batch [0-20]	Speed: 171689.46 samples/sec	accuracy=nan
2021-11-05 20:33:48,260 Node[0] Epoch[24] Batch [20-40]	Speed: 164813.20 samples/sec	accuracy=nan
2021-11-05 20:33:48,651 Node[0] Epoch[24] Batch [40-60]	Speed: 167040.34 samples/sec	accuracy=nan
2021-11-05 20:33:49,044 Node[0] Epoch[24] Batch [60-80]	Speed: 165846.83 samples/sec	accuracy=nan
2021-11-05 20:33:49,437 Node[0] Epoch[24] Batch [80-100]	Speed: 166340.73 samples/sec	accuracy=nan
2021-11-05 20:33:49,831 Node[0] Epoch[24] Batch [100-120]	Speed: 165783.57 samples/sec	accuracy=nan
2021-11-05 20:33:50,223 Node[0] Epoch[24] Batch [120-140]	Speed: 166522.83 samples/sec	accuracy=nan
2021-11-05 20:33:50,618 Node[0] Epoch[24] Batch [140-160]	Speed: 165253.06 samples/sec	accuracy=nan
2021-11-05 20:33:51,011 Node[0] Epoch[24] Batch [160-180]	Speed: 166068.53 samples/sec	accuracy=nan
2021-11-05 20:33:51,405 Node[0] Epoch[24] Batch [180-200]	Speed: 165427.99 samples/sec	accuracy=nan
2021-11-05 20:33:51,799 Node[0] Epoch[24] Batch [200-220]	Speed: 165901.30 samples/sec	accuracy=nan
2021-11-05 20:33:52,193 Node[0] Epoch[24] Batch [220-240]	Speed: 165615.30 samples/sec	accuracy=nan
2021-11-05 20:33:52,585 Node[0] Epoch[24] Batch [240-260]	Speed: 166530.93 samples/sec	accuracy=nan
2021-11-05 20:33:52,979 Node[0] Epoch[24] Batch [260-280]	Speed: 165800.94 samples/sec	accuracy=nan
2021-11-05 20:33:53,371 Node[0] Epoch[24] Batch [280-300]	Speed: 166396.03 samples/sec	accuracy=nan
2021-11-05 20:33:53,765 Node[0] Epoch[24] Batch [300-320]	Speed: 165872.65 samples/sec	accuracy=nan
2021-11-05 20:33:54,162 Node[0] Epoch[24] Batch [320-340]	Speed: 164342.81 samples/sec	accuracy=nan
2021-11-05 20:33:54,560 Node[0] Epoch[24] Batch [340-360]	Speed: 163783.55 samples/sec	accuracy=nan
2021-11-05 20:33:54,957 Node[0] Epoch[24] Batch [360-380]	Speed: 164469.37 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144435195, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 25}}
2021-11-05 20:33:55,195 Node[0] Epoch[24] Time cost=7.749
:::MLLOG {"namespace": "", "time_ms": 1636144435195, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165338.18806534584}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 25}}
:::MLLOG {"namespace": "", "time_ms": 1636144435195, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165338.18806534584, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144435196, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 26}}
2021-11-05 20:33:55,606 Node[0] Epoch[25] Batch [0-20]	Speed: 166664.03 samples/sec	accuracy=nan
2021-11-05 20:33:55,999 Node[0] Epoch[25] Batch [20-40]	Speed: 166160.85 samples/sec	accuracy=nan
2021-11-05 20:33:56,394 Node[0] Epoch[25] Batch [40-60]	Speed: 165262.84 samples/sec	accuracy=nan
2021-11-05 20:33:56,788 Node[0] Epoch[25] Batch [60-80]	Speed: 165850.15 samples/sec	accuracy=nan
2021-11-05 20:33:57,184 Node[0] Epoch[25] Batch [80-100]	Speed: 164888.43 samples/sec	accuracy=nan
2021-11-05 20:33:57,576 Node[0] Epoch[25] Batch [100-120]	Speed: 166601.15 samples/sec	accuracy=nan
2021-11-05 20:33:57,970 Node[0] Epoch[25] Batch [120-140]	Speed: 165586.06 samples/sec	accuracy=nan
2021-11-05 20:33:58,362 Node[0] Epoch[25] Batch [140-160]	Speed: 166486.38 samples/sec	accuracy=nan
2021-11-05 20:33:58,755 Node[0] Epoch[25] Batch [160-180]	Speed: 166117.20 samples/sec	accuracy=nan
2021-11-05 20:33:59,149 Node[0] Epoch[25] Batch [180-200]	Speed: 165831.56 samples/sec	accuracy=nan
2021-11-05 20:33:59,542 Node[0] Epoch[25] Batch [200-220]	Speed: 166083.44 samples/sec	accuracy=nan
2021-11-05 20:33:59,936 Node[0] Epoch[25] Batch [220-240]	Speed: 165482.88 samples/sec	accuracy=nan
2021-11-05 20:34:00,330 Node[0] Epoch[25] Batch [240-260]	Speed: 165866.83 samples/sec	accuracy=nan
2021-11-05 20:34:00,724 Node[0] Epoch[25] Batch [260-280]	Speed: 165690.27 samples/sec	accuracy=nan
2021-11-05 20:34:01,116 Node[0] Epoch[25] Batch [280-300]	Speed: 166369.94 samples/sec	accuracy=nan
2021-11-05 20:34:01,510 Node[0] Epoch[25] Batch [300-320]	Speed: 165555.62 samples/sec	accuracy=nan
2021-11-05 20:34:01,906 Node[0] Epoch[25] Batch [320-340]	Speed: 165175.01 samples/sec	accuracy=nan
2021-11-05 20:34:02,302 Node[0] Epoch[25] Batch [340-360]	Speed: 164924.38 samples/sec	accuracy=nan
2021-11-05 20:34:02,698 Node[0] Epoch[25] Batch [360-380]	Speed: 164668.98 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144442935, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 26}}
2021-11-05 20:34:02,936 Node[0] Epoch[25] Time cost=7.740
:::MLLOG {"namespace": "", "time_ms": 1636144442936, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165526.6145161278}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 26}}
:::MLLOG {"namespace": "", "time_ms": 1636144442936, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165526.6145161278, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144442936, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 27}}
2021-11-05 20:34:03,348 Node[0] Epoch[26] Batch [0-20]	Speed: 166059.97 samples/sec	accuracy=nan
2021-11-05 20:34:03,744 Node[0] Epoch[26] Batch [20-40]	Speed: 165187.66 samples/sec	accuracy=nan
2021-11-05 20:34:04,138 Node[0] Epoch[26] Batch [40-60]	Speed: 165665.61 samples/sec	accuracy=nan
2021-11-05 20:34:04,531 Node[0] Epoch[26] Batch [60-80]	Speed: 165883.51 samples/sec	accuracy=nan
2021-11-05 20:34:04,926 Node[0] Epoch[26] Batch [80-100]	Speed: 165492.58 samples/sec	accuracy=nan
2021-11-05 20:34:05,317 Node[0] Epoch[26] Batch [100-120]	Speed: 166778.34 samples/sec	accuracy=nan
2021-11-05 20:34:05,710 Node[0] Epoch[26] Batch [120-140]	Speed: 165897.28 samples/sec	accuracy=nan
2021-11-05 20:34:06,104 Node[0] Epoch[26] Batch [140-160]	Speed: 166019.60 samples/sec	accuracy=nan
2021-11-05 20:34:06,498 Node[0] Epoch[26] Batch [160-180]	Speed: 165689.97 samples/sec	accuracy=nan
2021-11-05 20:34:06,893 Node[0] Epoch[26] Batch [180-200]	Speed: 165243.39 samples/sec	accuracy=nan
2021-11-05 20:34:07,286 Node[0] Epoch[26] Batch [200-220]	Speed: 165851.76 samples/sec	accuracy=nan
2021-11-05 20:34:07,679 Node[0] Epoch[26] Batch [220-240]	Speed: 166275.88 samples/sec	accuracy=nan
2021-11-05 20:34:08,071 Node[0] Epoch[26] Batch [240-260]	Speed: 166618.08 samples/sec	accuracy=nan
2021-11-05 20:34:08,464 Node[0] Epoch[26] Batch [260-280]	Speed: 165811.48 samples/sec	accuracy=nan
2021-11-05 20:34:08,858 Node[0] Epoch[26] Batch [280-300]	Speed: 165894.86 samples/sec	accuracy=nan
2021-11-05 20:34:09,252 Node[0] Epoch[26] Batch [300-320]	Speed: 165754.77 samples/sec	accuracy=nan
2021-11-05 20:34:09,646 Node[0] Epoch[26] Batch [320-340]	Speed: 165499.08 samples/sec	accuracy=nan
2021-11-05 20:34:10,049 Node[0] Epoch[26] Batch [340-360]	Speed: 161976.25 samples/sec	accuracy=nan
2021-11-05 20:34:10,447 Node[0] Epoch[26] Batch [360-380]	Speed: 164257.33 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144450684, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 27}}
2021-11-05 20:34:10,684 Node[0] Epoch[26] Time cost=7.748
:::MLLOG {"namespace": "", "time_ms": 1636144450684, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165358.5038392065}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636144450684, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165358.5038392065, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144450701, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 27}}
2021-11-05 20:34:10,813 Node[0] Epoch[26] Validation-accuracy=0.740077
2021-11-05 20:34:10,813 Node[0] Epoch[26] Validation-correct-count=578.000000
2021-11-05 20:34:10,813 Node[0] Epoch[26] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636144450835, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636144450835, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.7268, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636144450835, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1636144450835, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 28, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636144450835, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 28}}
2021-11-05 20:34:11,233 Node[0] Epoch[27] Batch [0-20]	Speed: 166241.25 samples/sec	accuracy=nan
2021-11-05 20:34:11,625 Node[0] Epoch[27] Batch [20-40]	Speed: 166349.93 samples/sec	accuracy=nan
2021-11-05 20:34:12,018 Node[0] Epoch[27] Batch [40-60]	Speed: 166000.07 samples/sec	accuracy=nan
2021-11-05 20:34:12,412 Node[0] Epoch[27] Batch [60-80]	Speed: 165705.01 samples/sec	accuracy=nan
2021-11-05 20:34:12,807 Node[0] Epoch[27] Batch [80-100]	Speed: 165559.63 samples/sec	accuracy=nan
2021-11-05 20:34:13,199 Node[0] Epoch[27] Batch [100-120]	Speed: 166501.36 samples/sec	accuracy=nan
2021-11-05 20:34:13,593 Node[0] Epoch[27] Batch [120-140]	Speed: 165511.49 samples/sec	accuracy=nan
2021-11-05 20:34:13,986 Node[0] Epoch[27] Batch [140-160]	Speed: 166394.81 samples/sec	accuracy=nan
2021-11-05 20:34:14,379 Node[0] Epoch[27] Batch [160-180]	Speed: 165934.88 samples/sec	accuracy=nan
2021-11-05 20:34:14,773 Node[0] Epoch[27] Batch [180-200]	Speed: 165455.58 samples/sec	accuracy=nan
2021-11-05 20:34:15,166 Node[0] Epoch[27] Batch [200-220]	Speed: 166462.19 samples/sec	accuracy=nan
2021-11-05 20:34:15,559 Node[0] Epoch[27] Batch [220-240]	Speed: 165869.84 samples/sec	accuracy=nan
2021-11-05 20:34:15,952 Node[0] Epoch[27] Batch [240-260]	Speed: 166260.13 samples/sec	accuracy=nan
2021-11-05 20:34:16,345 Node[0] Epoch[27] Batch [260-280]	Speed: 166120.22 samples/sec	accuracy=nan
2021-11-05 20:34:16,741 Node[0] Epoch[27] Batch [280-300]	Speed: 164968.31 samples/sec	accuracy=nan
2021-11-05 20:34:17,134 Node[0] Epoch[27] Batch [300-320]	Speed: 165872.75 samples/sec	accuracy=nan
2021-11-05 20:34:17,532 Node[0] Epoch[27] Batch [320-340]	Speed: 164159.74 samples/sec	accuracy=nan
2021-11-05 20:34:17,928 Node[0] Epoch[27] Batch [340-360]	Speed: 164954.09 samples/sec	accuracy=nan
2021-11-05 20:34:18,325 Node[0] Epoch[27] Batch [360-380]	Speed: 164080.35 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144458561, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 28}}
2021-11-05 20:34:18,561 Node[0] Epoch[27] Time cost=7.726
:::MLLOG {"namespace": "", "time_ms": 1636144458561, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165831.79006233902}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 28}}
:::MLLOG {"namespace": "", "time_ms": 1636144458561, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165831.79006233902, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144458561, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 29}}
2021-11-05 20:34:18,974 Node[0] Epoch[28] Batch [0-20]	Speed: 165893.16 samples/sec	accuracy=nan
2021-11-05 20:34:19,368 Node[0] Epoch[28] Batch [20-40]	Speed: 165755.37 samples/sec	accuracy=nan
2021-11-05 20:34:19,762 Node[0] Epoch[28] Batch [40-60]	Speed: 165586.56 samples/sec	accuracy=nan
2021-11-05 20:34:20,156 Node[0] Epoch[28] Batch [60-80]	Speed: 165802.34 samples/sec	accuracy=nan
2021-11-05 20:34:20,548 Node[0] Epoch[28] Batch [80-100]	Speed: 166326.79 samples/sec	accuracy=nan
2021-11-05 20:34:20,941 Node[0] Epoch[28] Batch [100-120]	Speed: 165957.41 samples/sec	accuracy=nan
2021-11-05 20:34:21,334 Node[0] Epoch[28] Batch [120-140]	Speed: 166246.50 samples/sec	accuracy=nan
2021-11-05 20:34:21,728 Node[0] Epoch[28] Batch [140-160]	Speed: 165937.39 samples/sec	accuracy=nan
2021-11-05 20:34:22,121 Node[0] Epoch[28] Batch [160-180]	Speed: 165916.68 samples/sec	accuracy=nan
2021-11-05 20:34:22,521 Node[0] Epoch[28] Batch [180-200]	Speed: 163187.71 samples/sec	accuracy=nan
2021-11-05 20:34:22,915 Node[0] Epoch[28] Batch [200-220]	Speed: 165550.52 samples/sec	accuracy=nan
2021-11-05 20:34:23,308 Node[0] Epoch[28] Batch [220-240]	Speed: 166342.75 samples/sec	accuracy=nan
2021-11-05 20:34:23,701 Node[0] Epoch[28] Batch [240-260]	Speed: 165860.50 samples/sec	accuracy=nan
2021-11-05 20:34:24,095 Node[0] Epoch[28] Batch [260-280]	Speed: 165728.08 samples/sec	accuracy=nan
2021-11-05 20:34:24,489 Node[0] Epoch[28] Batch [280-300]	Speed: 165708.32 samples/sec	accuracy=nan
2021-11-05 20:34:24,884 Node[0] Epoch[28] Batch [300-320]	Speed: 165194.14 samples/sec	accuracy=nan
2021-11-05 20:34:25,280 Node[0] Epoch[28] Batch [320-340]	Speed: 165044.28 samples/sec	accuracy=nan
2021-11-05 20:34:25,677 Node[0] Epoch[28] Batch [340-360]	Speed: 164360.37 samples/sec	accuracy=nan
2021-11-05 20:34:26,074 Node[0] Epoch[28] Batch [360-380]	Speed: 164397.48 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144466310, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 29}}
2021-11-05 20:34:26,310 Node[0] Epoch[28] Time cost=7.749
:::MLLOG {"namespace": "", "time_ms": 1636144466310, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165337.50638039364}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 29}}
:::MLLOG {"namespace": "", "time_ms": 1636144466310, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165337.50638039364, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144466310, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 30}}
2021-11-05 20:34:26,721 Node[0] Epoch[29] Batch [0-20]	Speed: 166470.99 samples/sec	accuracy=nan
2021-11-05 20:34:27,115 Node[0] Epoch[29] Batch [20-40]	Speed: 165907.33 samples/sec	accuracy=nan
2021-11-05 20:34:27,508 Node[0] Epoch[29] Batch [40-60]	Speed: 165902.00 samples/sec	accuracy=nan
2021-11-05 20:34:27,901 Node[0] Epoch[29] Batch [60-80]	Speed: 166344.57 samples/sec	accuracy=nan
2021-11-05 20:34:28,295 Node[0] Epoch[29] Batch [80-100]	Speed: 165400.61 samples/sec	accuracy=nan
2021-11-05 20:34:28,689 Node[0] Epoch[29] Batch [100-120]	Speed: 165735.00 samples/sec	accuracy=nan
2021-11-05 20:34:29,081 Node[0] Epoch[29] Batch [120-140]	Speed: 166477.98 samples/sec	accuracy=nan
2021-11-05 20:34:29,475 Node[0] Epoch[29] Batch [140-160]	Speed: 165774.13 samples/sec	accuracy=nan
2021-11-05 20:34:29,870 Node[0] Epoch[29] Batch [160-180]	Speed: 165138.74 samples/sec	accuracy=nan
2021-11-05 20:34:30,264 Node[0] Epoch[29] Batch [180-200]	Speed: 165706.11 samples/sec	accuracy=nan
2021-11-05 20:34:30,657 Node[0] Epoch[29] Batch [200-220]	Speed: 166240.45 samples/sec	accuracy=nan
2021-11-05 20:34:31,049 Node[0] Epoch[29] Batch [220-240]	Speed: 166536.00 samples/sec	accuracy=nan
2021-11-05 20:34:31,442 Node[0] Epoch[29] Batch [240-260]	Speed: 165973.81 samples/sec	accuracy=nan
2021-11-05 20:34:31,836 Node[0] Epoch[29] Batch [260-280]	Speed: 165690.47 samples/sec	accuracy=nan
2021-11-05 20:34:32,229 Node[0] Epoch[29] Batch [280-300]	Speed: 166282.14 samples/sec	accuracy=nan
2021-11-05 20:34:32,624 Node[0] Epoch[29] Batch [300-320]	Speed: 165042.88 samples/sec	accuracy=nan
2021-11-05 20:34:33,020 Node[0] Epoch[29] Batch [320-340]	Speed: 165013.44 samples/sec	accuracy=nan
2021-11-05 20:34:33,418 Node[0] Epoch[29] Batch [340-360]	Speed: 163861.96 samples/sec	accuracy=nan
2021-11-05 20:34:33,815 Node[0] Epoch[29] Batch [360-380]	Speed: 164717.52 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144474051, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 30}}
2021-11-05 20:34:34,051 Node[0] Epoch[29] Time cost=7.741
:::MLLOG {"namespace": "", "time_ms": 1636144474052, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165502.56685770984}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 30}}
:::MLLOG {"namespace": "", "time_ms": 1636144474052, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165502.56685770984, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144474052, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 31}}
2021-11-05 20:34:34,464 Node[0] Epoch[30] Batch [0-20]	Speed: 166383.69 samples/sec	accuracy=nan
2021-11-05 20:34:34,856 Node[0] Epoch[30] Batch [20-40]	Speed: 166373.78 samples/sec	accuracy=nan
2021-11-05 20:34:35,248 Node[0] Epoch[30] Batch [40-60]	Speed: 166661.09 samples/sec	accuracy=nan
2021-11-05 20:34:35,643 Node[0] Epoch[30] Batch [60-80]	Speed: 165236.11 samples/sec	accuracy=nan
2021-11-05 20:34:36,036 Node[0] Epoch[30] Batch [80-100]	Speed: 166253.57 samples/sec	accuracy=nan
2021-11-05 20:34:36,431 Node[0] Epoch[30] Batch [100-120]	Speed: 165228.53 samples/sec	accuracy=nan
2021-11-05 20:34:36,822 Node[0] Epoch[30] Batch [120-140]	Speed: 166903.48 samples/sec	accuracy=nan
2021-11-05 20:34:37,215 Node[0] Epoch[30] Batch [140-160]	Speed: 166071.45 samples/sec	accuracy=nan
2021-11-05 20:34:37,609 Node[0] Epoch[30] Batch [160-180]	Speed: 165662.20 samples/sec	accuracy=nan
2021-11-05 20:34:38,001 Node[0] Epoch[30] Batch [180-200]	Speed: 166562.14 samples/sec	accuracy=nan
2021-11-05 20:34:38,393 Node[0] Epoch[30] Batch [200-220]	Speed: 166404.12 samples/sec	accuracy=nan
2021-11-05 20:34:38,786 Node[0] Epoch[30] Batch [220-240]	Speed: 166034.80 samples/sec	accuracy=nan
2021-11-05 20:34:39,180 Node[0] Epoch[30] Batch [240-260]	Speed: 165906.22 samples/sec	accuracy=nan
2021-11-05 20:34:39,574 Node[0] Epoch[30] Batch [260-280]	Speed: 165700.90 samples/sec	accuracy=nan
2021-11-05 20:34:39,967 Node[0] Epoch[30] Batch [280-300]	Speed: 166029.46 samples/sec	accuracy=nan
2021-11-05 20:34:40,361 Node[0] Epoch[30] Batch [300-320]	Speed: 165679.04 samples/sec	accuracy=nan
2021-11-05 20:34:40,757 Node[0] Epoch[30] Batch [320-340]	Speed: 164687.60 samples/sec	accuracy=nan
2021-11-05 20:34:41,155 Node[0] Epoch[30] Batch [340-360]	Speed: 164427.49 samples/sec	accuracy=nan
2021-11-05 20:34:41,551 Node[0] Epoch[30] Batch [360-380]	Speed: 164616.21 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144481787, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 31}}
2021-11-05 20:34:41,788 Node[0] Epoch[30] Time cost=7.736
:::MLLOG {"namespace": "", "time_ms": 1636144481788, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165614.6466154411}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636144481788, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165614.6466154411, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144481804, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 31}}
2021-11-05 20:34:41,916 Node[0] Epoch[30] Validation-accuracy=0.772087
2021-11-05 20:34:41,917 Node[0] Epoch[30] Validation-correct-count=603.000000
2021-11-05 20:34:41,917 Node[0] Epoch[30] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636144481937, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636144481938, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.74992, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636144481938, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1636144481938, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 32, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636144481938, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 32}}
2021-11-05 20:34:42,335 Node[0] Epoch[31] Batch [0-20]	Speed: 166523.54 samples/sec	accuracy=nan
2021-11-05 20:34:42,729 Node[0] Epoch[31] Batch [20-40]	Speed: 165505.69 samples/sec	accuracy=nan
2021-11-05 20:34:43,122 Node[0] Epoch[31] Batch [40-60]	Speed: 166020.60 samples/sec	accuracy=nan
2021-11-05 20:34:43,514 Node[0] Epoch[31] Batch [60-80]	Speed: 166679.55 samples/sec	accuracy=nan
2021-11-05 20:34:43,907 Node[0] Epoch[31] Batch [80-100]	Speed: 166154.29 samples/sec	accuracy=nan
2021-11-05 20:34:44,301 Node[0] Epoch[31] Batch [100-120]	Speed: 165856.58 samples/sec	accuracy=nan
2021-11-05 20:34:44,693 Node[0] Epoch[31] Batch [120-140]	Speed: 166325.07 samples/sec	accuracy=nan
2021-11-05 20:34:45,086 Node[0] Epoch[31] Batch [140-160]	Speed: 166003.39 samples/sec	accuracy=nan
2021-11-05 20:34:45,481 Node[0] Epoch[31] Batch [160-180]	Speed: 165300.85 samples/sec	accuracy=nan
2021-11-05 20:34:45,873 Node[0] Epoch[31] Batch [180-200]	Speed: 166558.28 samples/sec	accuracy=nan
2021-11-05 20:34:46,267 Node[0] Epoch[31] Batch [200-220]	Speed: 165768.21 samples/sec	accuracy=nan
2021-11-05 20:34:46,662 Node[0] Epoch[31] Batch [220-240]	Speed: 165361.45 samples/sec	accuracy=nan
2021-11-05 20:34:47,053 Node[0] Epoch[31] Batch [240-260]	Speed: 166855.68 samples/sec	accuracy=nan
2021-11-05 20:34:47,445 Node[0] Epoch[31] Batch [260-280]	Speed: 166547.75 samples/sec	accuracy=nan
2021-11-05 20:34:47,838 Node[0] Epoch[31] Batch [280-300]	Speed: 166037.21 samples/sec	accuracy=nan
2021-11-05 20:34:48,234 Node[0] Epoch[31] Batch [300-320]	Speed: 164801.29 samples/sec	accuracy=nan
2021-11-05 20:34:48,628 Node[0] Epoch[31] Batch [320-340]	Speed: 165602.08 samples/sec	accuracy=nan
2021-11-05 20:34:49,028 Node[0] Epoch[31] Batch [340-360]	Speed: 163443.22 samples/sec	accuracy=nan
2021-11-05 20:34:49,424 Node[0] Epoch[31] Batch [360-380]	Speed: 164925.18 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144489660, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 32}}
2021-11-05 20:34:49,660 Node[0] Epoch[31] Time cost=7.723
:::MLLOG {"namespace": "", "time_ms": 1636144489661, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165900.45118023996}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 32}}
:::MLLOG {"namespace": "", "time_ms": 1636144489661, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165900.45118023996, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144489661, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 33}}
2021-11-05 20:34:50,075 Node[0] Epoch[32] Batch [0-20]	Speed: 165272.12 samples/sec	accuracy=nan
2021-11-05 20:34:50,469 Node[0] Epoch[32] Batch [20-40]	Speed: 165868.33 samples/sec	accuracy=nan
2021-11-05 20:34:50,860 Node[0] Epoch[32] Batch [40-60]	Speed: 166661.29 samples/sec	accuracy=nan
2021-11-05 20:34:51,254 Node[0] Epoch[32] Batch [60-80]	Speed: 165731.59 samples/sec	accuracy=nan
2021-11-05 20:34:51,646 Node[0] Epoch[32] Batch [80-100]	Speed: 166526.78 samples/sec	accuracy=nan
2021-11-05 20:34:52,040 Node[0] Epoch[32] Batch [100-120]	Speed: 165620.61 samples/sec	accuracy=nan
2021-11-05 20:34:52,434 Node[0] Epoch[32] Batch [120-140]	Speed: 165840.00 samples/sec	accuracy=nan
2021-11-05 20:34:52,827 Node[0] Epoch[32] Batch [140-160]	Speed: 165998.06 samples/sec	accuracy=nan
2021-11-05 20:34:53,220 Node[0] Epoch[32] Batch [160-180]	Speed: 166359.33 samples/sec	accuracy=nan
2021-11-05 20:34:53,613 Node[0] Epoch[32] Batch [180-200]	Speed: 165753.16 samples/sec	accuracy=nan
2021-11-05 20:34:54,006 Node[0] Epoch[32] Batch [200-220]	Speed: 166226.42 samples/sec	accuracy=nan
2021-11-05 20:34:54,398 Node[0] Epoch[32] Batch [220-240]	Speed: 166450.96 samples/sec	accuracy=nan
2021-11-05 20:34:54,793 Node[0] Epoch[32] Batch [240-260]	Speed: 165483.08 samples/sec	accuracy=nan
2021-11-05 20:34:55,186 Node[0] Epoch[32] Batch [260-280]	Speed: 166216.63 samples/sec	accuracy=nan
2021-11-05 20:34:55,579 Node[0] Epoch[32] Batch [280-300]	Speed: 165972.70 samples/sec	accuracy=nan
2021-11-05 20:34:55,972 Node[0] Epoch[32] Batch [300-320]	Speed: 165925.73 samples/sec	accuracy=nan
2021-11-05 20:34:56,370 Node[0] Epoch[32] Batch [320-340]	Speed: 164372.31 samples/sec	accuracy=nan
2021-11-05 20:34:56,765 Node[0] Epoch[32] Batch [340-360]	Speed: 164886.94 samples/sec	accuracy=nan
2021-11-05 20:34:57,164 Node[0] Epoch[32] Batch [360-380]	Speed: 163844.61 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144497400, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 33}}
2021-11-05 20:34:57,400 Node[0] Epoch[32] Time cost=7.740
:::MLLOG {"namespace": "", "time_ms": 1636144497400, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165535.55323718872}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 33}}
:::MLLOG {"namespace": "", "time_ms": 1636144497401, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165535.55323718872, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144497401, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 34}}
2021-11-05 20:34:57,813 Node[0] Epoch[33] Batch [0-20]	Speed: 165962.64 samples/sec	accuracy=nan
2021-11-05 20:34:58,206 Node[0] Epoch[33] Batch [20-40]	Speed: 165980.55 samples/sec	accuracy=nan
2021-11-05 20:34:58,599 Node[0] Epoch[33] Batch [40-60]	Speed: 166315.78 samples/sec	accuracy=nan
2021-11-05 20:34:58,992 Node[0] Epoch[33] Batch [60-80]	Speed: 166078.10 samples/sec	accuracy=nan
2021-11-05 20:34:59,384 Node[0] Epoch[33] Batch [80-100]	Speed: 166498.43 samples/sec	accuracy=nan
2021-11-05 20:34:59,777 Node[0] Epoch[33] Batch [100-120]	Speed: 165988.60 samples/sec	accuracy=nan
2021-11-05 20:35:00,170 Node[0] Epoch[33] Batch [120-140]	Speed: 166354.78 samples/sec	accuracy=nan
2021-11-05 20:35:00,562 Node[0] Epoch[33] Batch [140-160]	Speed: 166361.75 samples/sec	accuracy=nan
2021-11-05 20:35:00,955 Node[0] Epoch[33] Batch [160-180]	Speed: 166164.18 samples/sec	accuracy=nan
2021-11-05 20:35:01,350 Node[0] Epoch[33] Batch [180-200]	Speed: 165380.63 samples/sec	accuracy=nan
2021-11-05 20:35:01,744 Node[0] Epoch[33] Batch [200-220]	Speed: 165405.40 samples/sec	accuracy=nan
2021-11-05 20:35:02,138 Node[0] Epoch[33] Batch [220-240]	Speed: 165752.76 samples/sec	accuracy=nan
2021-11-05 20:35:02,531 Node[0] Epoch[33] Batch [240-260]	Speed: 166002.28 samples/sec	accuracy=nan
2021-11-05 20:35:02,926 Node[0] Epoch[33] Batch [260-280]	Speed: 165573.04 samples/sec	accuracy=nan
2021-11-05 20:35:03,318 Node[0] Epoch[33] Batch [280-300]	Speed: 166382.68 samples/sec	accuracy=nan
2021-11-05 20:35:03,712 Node[0] Epoch[33] Batch [300-320]	Speed: 165499.78 samples/sec	accuracy=nan
2021-11-05 20:35:04,108 Node[0] Epoch[33] Batch [320-340]	Speed: 165061.99 samples/sec	accuracy=nan
2021-11-05 20:35:04,505 Node[0] Epoch[33] Batch [340-360]	Speed: 164495.95 samples/sec	accuracy=nan
2021-11-05 20:35:04,900 Node[0] Epoch[33] Batch [360-380]	Speed: 165122.01 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144505136, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 34}}
2021-11-05 20:35:05,137 Node[0] Epoch[33] Time cost=7.736
:::MLLOG {"namespace": "", "time_ms": 1636144505137, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165613.25827140332}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 34}}
:::MLLOG {"namespace": "", "time_ms": 1636144505137, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165613.25827140332, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144505137, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 35}}
2021-11-05 20:35:05,549 Node[0] Epoch[34] Batch [0-20]	Speed: 166194.94 samples/sec	accuracy=nan
2021-11-05 20:35:05,943 Node[0] Epoch[34] Batch [20-40]	Speed: 165648.07 samples/sec	accuracy=nan
2021-11-05 20:35:06,336 Node[0] Epoch[34] Batch [40-60]	Speed: 166059.57 samples/sec	accuracy=nan
2021-11-05 20:35:06,728 Node[0] Epoch[34] Batch [60-80]	Speed: 166403.01 samples/sec	accuracy=nan
2021-11-05 20:35:07,120 Node[0] Epoch[34] Batch [80-100]	Speed: 166914.68 samples/sec	accuracy=nan
2021-11-05 20:35:07,512 Node[0] Epoch[34] Batch [100-120]	Speed: 166524.55 samples/sec	accuracy=nan
2021-11-05 20:35:07,902 Node[0] Epoch[34] Batch [120-140]	Speed: 167173.84 samples/sec	accuracy=nan
2021-11-05 20:35:08,295 Node[0] Epoch[34] Batch [140-160]	Speed: 166030.57 samples/sec	accuracy=nan
2021-11-05 20:35:08,688 Node[0] Epoch[34] Batch [160-180]	Speed: 166344.88 samples/sec	accuracy=nan
2021-11-05 20:35:09,082 Node[0] Epoch[34] Batch [180-200]	Speed: 165424.89 samples/sec	accuracy=nan
2021-11-05 20:35:09,476 Node[0] Epoch[34] Batch [200-220]	Speed: 165636.24 samples/sec	accuracy=nan
2021-11-05 20:35:09,870 Node[0] Epoch[34] Batch [220-240]	Speed: 165987.89 samples/sec	accuracy=nan
2021-11-05 20:35:10,263 Node[0] Epoch[34] Batch [240-260]	Speed: 166073.27 samples/sec	accuracy=nan
2021-11-05 20:35:10,659 Node[0] Epoch[34] Batch [260-280]	Speed: 164885.15 samples/sec	accuracy=nan
2021-11-05 20:35:11,051 Node[0] Epoch[34] Batch [280-300]	Speed: 166245.49 samples/sec	accuracy=nan
2021-11-05 20:35:11,447 Node[0] Epoch[34] Batch [300-320]	Speed: 165006.68 samples/sec	accuracy=nan
2021-11-05 20:35:11,843 Node[0] Epoch[34] Batch [320-340]	Speed: 164746.26 samples/sec	accuracy=nan
2021-11-05 20:35:12,240 Node[0] Epoch[34] Batch [340-360]	Speed: 164535.69 samples/sec	accuracy=nan
2021-11-05 20:35:12,639 Node[0] Epoch[34] Batch [360-380]	Speed: 163725.37 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636144512873, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 35}}
2021-11-05 20:35:12,873 Node[0] Epoch[34] Time cost=7.736
:::MLLOG {"namespace": "", "time_ms": 1636144512873, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165603.02505646914}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636144512874, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165603.02505646914, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636144512890, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 35}}
2021-11-05 20:35:13,003 Node[0] Epoch[34] Validation-accuracy=0.769526
2021-11-05 20:35:13,004 Node[0] Epoch[34] Validation-correct-count=601.000000
2021-11-05 20:35:13,004 Node[0] Epoch[34] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636144513018, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636144513019, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.76172, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636144513019, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1636144513019, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1051, "status": "success"}}
ENDING TIMING RUN AT 2021-11-05 08:35:32 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:32 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:34 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:34 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:34 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:34 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:34 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:34 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:34 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:34 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:35 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:35 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:35 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:35 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:35 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:35 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:35 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:35 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:36 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:37 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:38 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:38 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:38 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:38 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:38 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:38 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:38 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:38 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:38 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:38 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:39 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:40 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:40 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:40 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:40 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:40 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:40 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:41 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:28:22 PM
ENDING TIMING RUN AT 2021-11-05 08:35:42 PM
RESULT,IMAGE_CLASSIFICATION,,440,root,2021-11-05 08:28:22 PM
