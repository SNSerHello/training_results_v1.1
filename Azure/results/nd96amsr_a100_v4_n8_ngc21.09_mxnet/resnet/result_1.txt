+ : DGXA100_multi_8x8x51
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/resnetv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211105204339954871567
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data
+ : /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.204339
+ : ''
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ echo

+ '[' '!' -z ']'
+ LOGBASE=rsnt50_8x8x51_211105204339954871567
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _seed_override=
+ _seed_override=
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.204339/rsnt50_8x8x51_211105204339954871567
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.204339/rsnt50_8x8x51_211105204339954871567
+ readonly _cont_name=image_classification
+ _cont_name=image_classification
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data:/data,/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.204339:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job10870/slurm_script: line 48: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.204339
+ srun --ntasks=8 mkdir -p /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.204339
+ srun --ntasks=8 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/resnetv11.sqsh --container-name=image_classification true
+ echo 'RUN_NCCL_BW_TEST = 0'
RUN_NCCL_BW_TEST = 0
+ [[ 0 -eq 1 ]]
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.204339/rsnt50_8x8x51_211105204339954871567_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun -N1 -n1 --container-name=image_classification python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.RESNET)'
:::MLLOG {"namespace": "", "time_ms": 1636145023354, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "resnet", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 70}}
:::MLLOG {"namespace": "", "time_ms": 1636145023361, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1636145023361, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 79}}
:::MLLOG {"namespace": "", "time_ms": 1636145023361, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 83}}
:::MLLOG {"namespace": "", "time_ms": 1636145023361, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 87}}
[1636145023.336011] [ip-0A0C0406:88131:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C0406
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C0409
Clearing cache on ip-0A0C0408
Clearing cache on ip-0A0C0407
Clearing cache on ip-0A0C040C
Clearing cache on ip-0A0C040D
Clearing cache on ip-0A0C040A
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=image_classification python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import mx_resnet_print_event
mx_resnet_print_event(key=constants.CACHE_CLEAR, val=True)'
:::MLLOG {"namespace": "", "time_ms": 1636145028345, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
[1636145028.157224] [ip-0A0C0409:86934:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145028.275063] [ip-0A0C040A:87369:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145028.129525] [ip-0A0C040D:87730:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145028.080000] [ip-0A0C040C:87039:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145028.120251] [ip-0A0C040F:87643:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145028.255553] [ip-0A0C0406:88655:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145028.319404] [ip-0A0C0407:87596:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145028.306687] [ip-0A0C0408:87799:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
+ export SEED=26721
+ SEED=26721
+ srun --kill-on-bad-exit=0 --mpi=pmix --ntasks=64 --ntasks-per-node=8 --container-name=image_classification --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data:/data,/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.204339:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 08:43:49 PM
running benchmark
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 num_sockets = 2 num_nodes=4 cores_per_socket=48
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 + exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 + exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 26721 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
:::MLLOG {"namespace": "", "time_ms": 1636145035080, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035073, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035072, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035072, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035072, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035072, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035072, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035072, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035080, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035072, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035081, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035081, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035080, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035080, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035081, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035082, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035077, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035079, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035079, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636145035078, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
[1636145034.838704] [ip-0A0C040C:87899:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.707899] [ip-0A0C040C:87900:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.861668] [ip-0A0C040C:87904:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.858401] [ip-0A0C040C:87897:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.861531] [ip-0A0C040C:87903:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.840409] [ip-0A0C040C:87901:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.649182] [ip-0A0C040C:87898:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.704802] [ip-0A0C040C:87902:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.757222] [ip-0A0C0409:87791:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.917373] [ip-0A0C0408:88659:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.875774] [ip-0A0C0409:87789:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.919457] [ip-0A0C040A:88228:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.875930] [ip-0A0C0409:87793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.838594] [ip-0A0C0409:87788:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.788899] [ip-0A0C0409:87787:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.773679] [ip-0A0C0408:88661:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.750245] [ip-0A0C0409:87790:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145034.836218] [ip-0A0C040D:88587:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.988089] [ip-0A0C040D:88589:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.960971] [ip-0A0C040A:88230:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.740772] [ip-0A0C040A:88224:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636145034.851276] [ip-0A0C0409:87794:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.935949] [ip-0A0C0406:89527:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.979726] [ip-0A0C0407:88469:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.994410] [ip-0A0C0407:88464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.637564] [ip-0A0C0409:87792:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.995410] [ip-0A0C0407:88465:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.997240] [ip-0A0C0407:88467:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.854695] [ip-0A0C0408:88665:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.904140] [ip-0A0C0407:88470:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.853333] [ip-0A0C0407:88471:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.826361] [ip-0A0C0407:88468:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.837368] [ip-0A0C0406:89530:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.786914] [ip-0A0C0408:88660:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.775182] [ip-0A0C0407:88466:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.908171] [ip-0A0C040A:88231:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.788068] [ip-0A0C040A:88227:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.938772] [ip-0A0C040A:88225:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.962598] [ip-0A0C040A:88226:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.708296] [ip-0A0C0408:88664:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.917163] [ip-0A0C0408:88658:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.963480] [ip-0A0C040A:88229:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.928285] [ip-0A0C0408:88657:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.928382] [ip-0A0C0408:88663:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145035.006580] [ip-0A0C040D:88584:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.988307] [ip-0A0C040D:88582:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145035.050106] [ip-0A0C040D:88586:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.970345] [ip-0A0C0406:89525:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
:::MLLOG {"namespace": "", "time_ms": 1636145048164, "event_type": "POINT_IN_TIME", "key": "seed", "value": 26721, "metadata": {"file": "train_imagenet.py", "lineno": 176}}
[1636145034.750931] [ip-0A0C0406:89526:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.875512] [ip-0A0C0406:89524:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.991405] [ip-0A0C040D:88588:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145035.049326] [ip-0A0C040D:88583:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.837431] [ip-0A0C0406:89528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.970246] [ip-0A0C0406:89523:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.965322] [ip-0A0C0406:89529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145035.049411] [ip-0A0C040D:88585:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.659377] [ip-0A0C040F:88512:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.664157] [ip-0A0C040F:88507:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.834587] [ip-0A0C040F:88508:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.831805] [ip-0A0C040F:88513:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.804540] [ip-0A0C040F:88510:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.607548] [ip-0A0C040F:88509:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.823177] [ip-0A0C040F:88511:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636145034.802565] [ip-0A0C040F:88514:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[20:44:08] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
NCCL version 2.11.4+cuda11.4

ip-0A0C0408:88664:88853 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88584:88790 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87794:87985 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87900:88095 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88228:88423 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88468:88666 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88513:88706 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89525 - context.c:584] INFO job (ID: 867530645345469251) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89525 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89525 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89525:89725 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87787:87983 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87898:88092 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88657:88855 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88227:88429 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88469:88662 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88511:88709 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88582:88788 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89523 - context.c:584] INFO job (ID: 867531219767901145) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89523 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89523 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89523:89726 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88471:88663 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87789:87984 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87902:88094 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88663:88854 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88510:88703 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88587:88786 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88224:88424 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89527 - context.c:584] INFO job (ID: 867530812115586830) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89527 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89527 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89527:89719 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88465:88659 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87791:87990 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87899:88096 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88586:88783 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88665:88856 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88230:88427 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88514:88710 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89529 - context.c:584] INFO job (ID: 867530993339108072) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89529 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89529 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89529:89722 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88512:88705 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87897:88099 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88589:88787 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88231:88428 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88464:88665 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87792:87989 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88658:88860 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89528 - context.c:584] INFO job (ID: 867530685623646139) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89528 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89528 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89528:89724 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88509:88707 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88583:88785 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88661:88859 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88229:88430 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88466:88660 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87793:87988 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87903:88098 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89526 - context.c:584] INFO job (ID: 867530510038400287) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89526 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89526 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89526:89720 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88585:88784 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87904:88097 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88225:88425 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88467:88661 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88508:88708 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87790:87986 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88659:88858 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89524 - context.c:584] INFO job (ID: 867531152031858936) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89524 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89524 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89524:89721 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88470:88664 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87788:87987 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87901:88093 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88660:88857 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88226:88426 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88588:88789 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88507:88704 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87794:87985 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040C:87900:88095 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040A:88228:88423 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:88468:88666 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040F:88513:88706 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040D:88584:88790 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0408:88664:88853 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
[ip-0A0C0406:0:89530 - context.c:584] INFO job (ID: 867530648881769439) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89530 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89530 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89530:89723 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0406:89525:89725 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040F:88513:88706 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87794:87985 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87900:88095 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88228:88423 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88468:88666 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88664:88853 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88584:88790 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89525 - context.c:584] INFO job (ID: 867530645644365076) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89525 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89525 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89525:89725 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87898:88092 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88469:88662 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88511:88709 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87787:87983 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88582:88788 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88227:88429 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88657:88855 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89523 - context.c:584] INFO job (ID: 867531218791657591) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89523 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89523 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89523:89726 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87902:88094 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88587:88786 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88663:88854 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88224:88424 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88471:88663 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88510:88703 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87789:87984 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89527 - context.c:584] INFO job (ID: 867530810749973747) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89527 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89527 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89527:89719 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88586:88783 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88230:88427 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87791:87990 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87899:88096 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88465:88659 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88514:88710 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88665:88856 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89529 - context.c:584] INFO job (ID: 867530994774775985) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89529 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89529 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89529:89722 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88589:88787 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88464:88665 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87897:88099 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88512:88705 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88658:88860 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87792:87989 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88231:88428 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89528 - context.c:584] INFO job (ID: 867530685363935815) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89528 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89528 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89528:89724 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88583:88785 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87793:87988 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87903:88098 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88661:88859 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88466:88660 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88509:88707 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88229:88430 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89526 - context.c:584] INFO job (ID: 867530511233211332) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89526 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89526 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89526:89720 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88467:88661 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88508:88708 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87904:88097 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88659:88858 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88225:88425 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87790:87986 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88585:88784 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:89524 - context.c:584] INFO job (ID: 867531153519656988) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89524 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89524 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89524:89721 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:88507:88704 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:88588:88789 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88660:88857 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:88470:88664 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:87901:88093 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:87788:87987 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:88226:88426 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:88664:88853 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040F:88513:88706 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040D:88584:88790 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040A:88228:88423 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0409:87794:87985 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040C:87900:88095 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:88468:88666 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
[ip-0A0C0406:0:89530 - context.c:584] INFO job (ID: 867530648104764647) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:89530 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:89530 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:89530:89723 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0406:89525:89725 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
:::MLLOG {"namespace": "", "time_ms": 1636145121722, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 51, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 309}}
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:27] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636145128078, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "bn0_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "bn0_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "conv0_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 81, "tensor": "fc1_bias"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128079, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 72, "tensor": "fc1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128080, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128081, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128082, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128082, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128082, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128082, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128082, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128083, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128083, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn1_gamma"}}
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636145128083, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn2_beta"}}
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636145128083, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128083, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128084, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128084, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128084, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128084, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128085, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128085, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128085, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128085, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128085, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128086, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128086, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128086, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128086, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128086, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128087, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128087, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128087, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128087, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128088, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128088, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128088, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128088, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128088, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128089, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128089, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128089, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128089, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128090, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128090, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128090, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128090, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128090, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128091, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128091, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128091, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128091, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128091, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128092, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128092, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128092, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128092, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128093, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128093, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128093, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128093, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128093, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128094, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128094, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128094, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128094, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128094, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128095, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128095, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128095, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128095, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128096, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128096, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128096, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128096, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128096, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128097, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128097, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128097, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128097, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128097, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128098, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128098, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128098, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128098, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128099, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128099, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128099, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128099, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128099, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128100, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128100, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128100, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128100, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128101, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128101, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128101, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128101, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128101, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128102, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128102, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128102, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128102, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128102, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128103, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128103, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128103, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128103, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128103, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128104, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128104, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128104, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128104, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128105, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128105, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128105, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128105, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128105, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128106, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128106, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128106, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128106, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128106, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128107, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128107, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128107, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128107, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128108, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128108, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128108, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128108, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128108, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128109, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128109, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128109, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128109, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128109, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128110, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128110, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128110, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128110, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128112, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128112, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128112, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128112, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128112, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128113, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128113, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128113, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636145128113, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv3_weight"}}
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[20:45:28] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,627 Node[7] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=11875, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,627 Node[5] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=48723, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,627 Node[6] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=42840, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636145129628, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 233}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 20:45:29,623 Node[15] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=41309, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,624 Node[11] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:45:29,628 Node[2] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=21139, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=24271, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,624 Node[10] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=56639, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,624 Node[13] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=39455, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,624 Node[12] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=2308, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,632 Node[19] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=51243, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 20:45:29,628 Node[35] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:45:29,625 Node[9] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=34793, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=57622, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 20:45:29,628 Node[25] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=26752, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 20:45:29,625 Node[8] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=11841, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,629 Node[33] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:45:29,628 Node[31] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=59154, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,629 Node[57] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=39229, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=19534, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:45:29,628 Node[26] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=50922, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,623 Node[53] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=3870, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,624 Node[50] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:45:29,633 Node[16] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=37354, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=11084, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,629 Node[34] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:45:29,629 Node[60] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=50631, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=1145, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,624 Node[49] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=46655, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,629 Node[40] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=53374, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,629 Node[37] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=6426, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:45:29,629 Node[46] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=30271, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:45:29,624 Node[48] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,630 Node[43] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=42114, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=50691, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,629 Node[30] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=32867, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:45:29,630 Node[39] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=23767, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,630 Node[38] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=27429, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,624 Node[51] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=45101, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,629 Node[29] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=27020, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,629 Node[27] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=1609, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:45:29,625 Node[52] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=50876, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,630 Node[63] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 20:45:29,633 Node[20] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=9105, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=12394, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,625 Node[55] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=3828, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,630 Node[42] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=38241, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:45:29,626 Node[14] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=13633, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,630 Node[62] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:45:29,630 Node[36] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=57796, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=53377, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,630 Node[45] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=34978, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,630 Node[44] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=4016, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:45:29,630 Node[32] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=6941, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,630 Node[47] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=63627, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,634 Node[23] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=61114, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,634 Node[18] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=11121, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 20:45:29,630 Node[24] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 20:45:29,634 Node[21] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=45417, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=57987, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,631 Node[56] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=9534, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,631 Node[41] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=13551, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,632 Node[61] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=2833, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,635 Node[22] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=48327, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 20:45:29,632 Node[59] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=23869, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,632 Node[58] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=57774, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,636 Node[17] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=64788, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,632 Node[28] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 20:45:29,627 Node[54] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=42791, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=62916, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,628 Node[0] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=58714, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636145129628, "event_type": "POINT_IN_TIME", "key": "sgd_opt_learning_rate_decay_poly_power", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 711}}
:::MLLOG {"namespace": "", "time_ms": 1636145129629, "event_type": "POINT_IN_TIME", "key": "sgd_opt_end_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 712}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_decay_poly_power", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 713}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "lars_opt_end_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 714}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 51, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1164}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "s_optimizer", "value": "sgdwfastlars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1165}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,630 Node[1] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=31709, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "s_network", "value": "resnet-v1b-fl", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1166}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "s_process", "value": "horovod", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1167}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,630 Node[3] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=31522, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 20:45:29,630 Node[4] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=15559, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 3264, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1168}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "s_optimizer", "value": "sgdwfastlars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1169}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "s_network", "value": "resnet-v1b-fl", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1170}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "s_process", "value": "horovod", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1171}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1172}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "lars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1178}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "lars_epsilon", "value": 0, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1636145129630, "event_type": "POINT_IN_TIME", "key": "lars_opt_weight_decay", "value": 5e-05, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1182}}
:::MLLOG {"namespace": "", "time_ms": 1636145129631, "event_type": "POINT_IN_TIME", "key": "lars_opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1184}}
:::MLLOG {"namespace": "", "time_ms": 1636145129631, "event_type": "POINT_IN_TIME", "key": "lars_opt_base_learning_rate", "value": 10.5, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1185}}
:::MLLOG {"namespace": "", "time_ms": 1636145129631, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_warmup_epochs", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1186}}
:::MLLOG {"namespace": "", "time_ms": 1636145129631, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_decay_steps", "value": 37, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1187}}
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[20:45:51] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
:::MLLOG {"namespace": "", "time_ms": 1636145163683, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1336}}
:::MLLOG {"namespace": "", "time_ms": 1636145163683, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1281167, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 486}}
:::MLLOG {"namespace": "", "time_ms": 1636145163903, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 50000, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 508}}
:::MLLOG {"namespace": "", "time_ms": 1636145163903, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 903, "first_epoch_num": 1, "epoch_count": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636145163903, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 1}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:04,801 Node[0] Epoch[0] Batch [0-20]	Speed: 115912.28 samples/sec	accuracy=nan
2021-11-05 20:46:05,307 Node[0] Epoch[0] Batch [20-40]	Speed: 129051.92 samples/sec	accuracy=nan
2021-11-05 20:46:05,797 Node[0] Epoch[0] Batch [40-60]	Speed: 133191.63 samples/sec	accuracy=nan
2021-11-05 20:46:06,301 Node[0] Epoch[0] Batch [60-80]	Speed: 129569.73 samples/sec	accuracy=nan
2021-11-05 20:46:06,786 Node[0] Epoch[0] Batch [80-100]	Speed: 134366.65 samples/sec	accuracy=nan
2021-11-05 20:46:07,244 Node[0] Epoch[0] Batch [100-120]	Speed: 142636.57 samples/sec	accuracy=nan
2021-11-05 20:46:07,736 Node[0] Epoch[0] Batch [120-140]	Speed: 132749.99 samples/sec	accuracy=nan
2021-11-05 20:46:08,234 Node[0] Epoch[0] Batch [140-160]	Speed: 131062.78 samples/sec	accuracy=nan
2021-11-05 20:46:08,725 Node[0] Epoch[0] Batch [160-180]	Speed: 132883.49 samples/sec	accuracy=nan
2021-11-05 20:46:09,234 Node[0] Epoch[0] Batch [180-200]	Speed: 128425.79 samples/sec	accuracy=nan
2021-11-05 20:46:09,728 Node[0] Epoch[0] Batch [200-220]	Speed: 132056.02 samples/sec	accuracy=nan
2021-11-05 20:46:10,240 Node[0] Epoch[0] Batch [220-240]	Speed: 127521.95 samples/sec	accuracy=nan
2021-11-05 20:46:10,704 Node[0] Epoch[0] Batch [240-260]	Speed: 140711.42 samples/sec	accuracy=nan
2021-11-05 20:46:11,204 Node[0] Epoch[0] Batch [260-280]	Speed: 130499.95 samples/sec	accuracy=nan
2021-11-05 20:46:11,699 Node[0] Epoch[0] Batch [280-300]	Speed: 131924.95 samples/sec	accuracy=nan
2021-11-05 20:46:12,221 Node[0] Epoch[0] Batch [300-320]	Speed: 124969.78 samples/sec	accuracy=nan
2021-11-05 20:46:12,714 Node[0] Epoch[0] Batch [320-340]	Speed: 132420.25 samples/sec	accuracy=nan
2021-11-05 20:46:13,189 Node[0] Epoch[0] Batch [340-360]	Speed: 137551.46 samples/sec	accuracy=nan
2021-11-05 20:46:13,636 Node[0] Epoch[0] Batch [360-380]	Speed: 145898.16 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145173878, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1636145173878, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 128442.39147456353}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 1}}
2021-11-05 20:46:13,878 Node[0] Epoch[0] Time cost=9.975
:::MLLOG {"namespace": "", "time_ms": 1636145173878, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 128442.39147456353, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145173878, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 2}}
2021-11-05 20:46:14,302 Node[0] Epoch[1] Batch [0-20]	Speed: 161567.93 samples/sec	accuracy=nan
2021-11-05 20:46:14,698 Node[0] Epoch[1] Batch [20-40]	Speed: 164917.33 samples/sec	accuracy=nan
2021-11-05 20:46:15,099 Node[0] Epoch[1] Batch [40-60]	Speed: 162755.85 samples/sec	accuracy=nan
2021-11-05 20:46:15,493 Node[0] Epoch[1] Batch [60-80]	Speed: 165729.88 samples/sec	accuracy=nan
2021-11-05 20:46:15,887 Node[0] Epoch[1] Batch [80-100]	Speed: 165449.08 samples/sec	accuracy=nan
2021-11-05 20:46:16,287 Node[0] Epoch[1] Batch [100-120]	Speed: 163320.96 samples/sec	accuracy=nan
2021-11-05 20:46:16,681 Node[0] Epoch[1] Batch [120-140]	Speed: 165487.38 samples/sec	accuracy=nan
2021-11-05 20:46:17,077 Node[0] Epoch[1] Batch [140-160]	Speed: 165124.80 samples/sec	accuracy=nan
2021-11-05 20:46:17,475 Node[0] Epoch[1] Batch [160-180]	Speed: 164094.41 samples/sec	accuracy=nan
2021-11-05 20:46:17,874 Node[0] Epoch[1] Batch [180-200]	Speed: 163621.27 samples/sec	accuracy=nan
2021-11-05 20:46:18,267 Node[0] Epoch[1] Batch [200-220]	Speed: 165881.10 samples/sec	accuracy=nan
2021-11-05 20:46:18,663 Node[0] Epoch[1] Batch [220-240]	Speed: 164877.91 samples/sec	accuracy=nan
2021-11-05 20:46:19,062 Node[0] Epoch[1] Batch [240-260]	Speed: 163708.73 samples/sec	accuracy=nan
2021-11-05 20:46:19,459 Node[0] Epoch[1] Batch [260-280]	Speed: 164300.31 samples/sec	accuracy=nan
2021-11-05 20:46:19,855 Node[0] Epoch[1] Batch [280-300]	Speed: 164734.56 samples/sec	accuracy=nan
2021-11-05 20:46:20,251 Node[0] Epoch[1] Batch [300-320]	Speed: 165067.06 samples/sec	accuracy=nan
2021-11-05 20:46:20,653 Node[0] Epoch[1] Batch [320-340]	Speed: 162545.60 samples/sec	accuracy=nan
2021-11-05 20:46:21,049 Node[0] Epoch[1] Batch [340-360]	Speed: 164637.19 samples/sec	accuracy=nan
2021-11-05 20:46:21,452 Node[0] Epoch[1] Batch [360-380]	Speed: 161822.03 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145181691, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 2}}
2021-11-05 20:46:21,691 Node[0] Epoch[1] Time cost=7.813
:::MLLOG {"namespace": "", "time_ms": 1636145181691, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 163981.9795960131}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1636145181691, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 163981.9795960131, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145181691, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 3}}
2021-11-05 20:46:22,107 Node[0] Epoch[2] Batch [0-20]	Speed: 164609.68 samples/sec	accuracy=nan
2021-11-05 20:46:22,505 Node[0] Epoch[2] Batch [20-40]	Speed: 163924.65 samples/sec	accuracy=nan
2021-11-05 20:46:22,909 Node[0] Epoch[2] Batch [40-60]	Speed: 161536.29 samples/sec	accuracy=nan
2021-11-05 20:46:23,301 Node[0] Epoch[2] Batch [60-80]	Speed: 166488.61 samples/sec	accuracy=nan
2021-11-05 20:46:23,696 Node[0] Epoch[2] Batch [80-100]	Speed: 165366.34 samples/sec	accuracy=nan
2021-11-05 20:46:24,089 Node[0] Epoch[2] Batch [100-120]	Speed: 165957.01 samples/sec	accuracy=nan
2021-11-05 20:46:24,484 Node[0] Epoch[2] Batch [120-140]	Speed: 165461.78 samples/sec	accuracy=nan
2021-11-05 20:46:24,877 Node[0] Epoch[2] Batch [140-160]	Speed: 166177.18 samples/sec	accuracy=nan
2021-11-05 20:46:25,273 Node[0] Epoch[2] Batch [160-180]	Speed: 164560.21 samples/sec	accuracy=nan
2021-11-05 20:46:25,667 Node[0] Epoch[2] Batch [180-200]	Speed: 165967.87 samples/sec	accuracy=nan
2021-11-05 20:46:26,069 Node[0] Epoch[2] Batch [200-220]	Speed: 162437.60 samples/sec	accuracy=nan
2021-11-05 20:46:26,467 Node[0] Epoch[2] Batch [220-240]	Speed: 164000.84 samples/sec	accuracy=nan
2021-11-05 20:46:26,859 Node[0] Epoch[2] Batch [240-260]	Speed: 166557.47 samples/sec	accuracy=nan
2021-11-05 20:46:27,252 Node[0] Epoch[2] Batch [260-280]	Speed: 166040.84 samples/sec	accuracy=nan
2021-11-05 20:46:27,647 Node[0] Epoch[2] Batch [280-300]	Speed: 165244.19 samples/sec	accuracy=nan
2021-11-05 20:46:28,039 Node[0] Epoch[2] Batch [300-320]	Speed: 166369.64 samples/sec	accuracy=nan
2021-11-05 20:46:28,435 Node[0] Epoch[2] Batch [320-340]	Speed: 164968.21 samples/sec	accuracy=nan
2021-11-05 20:46:28,835 Node[0] Epoch[2] Batch [340-360]	Speed: 163358.77 samples/sec	accuracy=nan
2021-11-05 20:46:29,233 Node[0] Epoch[2] Batch [360-380]	Speed: 164042.70 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145189475, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636145189475, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164596.27453153837}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 3}}
2021-11-05 20:46:29,475 Node[0] Epoch[2] Time cost=7.784
:::MLLOG {"namespace": "", "time_ms": 1636145189475, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164596.27453153837, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145189494, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 3}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[3] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[4] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[5] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[6] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[7] DALI iterator does not support resetting while epoch is not finished. Ignoring...
2021-11-05 20:46:29,494 Node[0] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[1] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[2] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,490 Node[8] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[56] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[25] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[40] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,489 Node[48] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,497 Node[16] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[32] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,490 Node[9] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[57] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[26] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[42] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,489 Node[49] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,497 Node[17] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[33] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,490 Node[10] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[58] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[27] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[45] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,489 Node[50] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,497 Node[18] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[34] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,490 Node[11] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[59] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[28] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[46] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,489 Node[51] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,497 Node[19] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[35] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,490 Node[13] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[60] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[29] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[41] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,489 Node[52] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,497 Node[20] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[36] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[61] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[43] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,490 Node[12] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[62] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[44] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,489 Node[53] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[37] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,490 Node[14] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[63] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[47] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,489 Node[55] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,497 Node[21] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[38] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,490 Node[15] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,489 Node[54] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,497 Node[23] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[39] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[30] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,497 Node[22] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[31] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 20:46:29,494 Node[24] DALI iterator does not support resetting while epoch is not finished. Ignoring...
2021-11-05 20:46:29,933 Node[0] Epoch[2] Validation-accuracy=0.311140
2021-11-05 20:46:29,933 Node[0] Epoch[2] Validation-correct-count=243.000000
2021-11-05 20:46:29,933 Node[0] Epoch[2] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636145190030, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636145190030, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.31882, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636145190031, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1636145190031, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 4, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636145190031, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 4}}
2021-11-05 20:46:30,428 Node[0] Epoch[3] Batch [0-20]	Speed: 166190.50 samples/sec	accuracy=nan
2021-11-05 20:46:30,821 Node[0] Epoch[3] Batch [20-40]	Speed: 166398.56 samples/sec	accuracy=nan
2021-11-05 20:46:31,218 Node[0] Epoch[3] Batch [40-60]	Speed: 164271.92 samples/sec	accuracy=nan
2021-11-05 20:46:31,611 Node[0] Epoch[3] Batch [60-80]	Speed: 165913.96 samples/sec	accuracy=nan
2021-11-05 20:46:32,006 Node[0] Epoch[3] Batch [80-100]	Speed: 165269.42 samples/sec	accuracy=nan
2021-11-05 20:46:32,398 Node[0] Epoch[3] Batch [100-120]	Speed: 166652.67 samples/sec	accuracy=nan
2021-11-05 20:46:32,793 Node[0] Epoch[3] Batch [120-140]	Speed: 165413.10 samples/sec	accuracy=nan
2021-11-05 20:46:33,187 Node[0] Epoch[3] Batch [140-160]	Speed: 165582.65 samples/sec	accuracy=nan
2021-11-05 20:46:33,583 Node[0] Epoch[3] Batch [160-180]	Speed: 164933.62 samples/sec	accuracy=nan
2021-11-05 20:46:33,981 Node[0] Epoch[3] Batch [180-200]	Speed: 163911.40 samples/sec	accuracy=nan
2021-11-05 20:46:34,378 Node[0] Epoch[3] Batch [200-220]	Speed: 164409.62 samples/sec	accuracy=nan
2021-11-05 20:46:34,772 Node[0] Epoch[3] Batch [220-240]	Speed: 165893.86 samples/sec	accuracy=nan
2021-11-05 20:46:35,163 Node[0] Epoch[3] Batch [240-260]	Speed: 166574.90 samples/sec	accuracy=nan
2021-11-05 20:46:35,560 Node[0] Epoch[3] Batch [260-280]	Speed: 164741.70 samples/sec	accuracy=nan
2021-11-05 20:46:35,954 Node[0] Epoch[3] Batch [280-300]	Speed: 165649.27 samples/sec	accuracy=nan
2021-11-05 20:46:36,355 Node[0] Epoch[3] Batch [300-320]	Speed: 162672.98 samples/sec	accuracy=nan
2021-11-05 20:46:36,751 Node[0] Epoch[3] Batch [320-340]	Speed: 165098.81 samples/sec	accuracy=nan
2021-11-05 20:46:37,148 Node[0] Epoch[3] Batch [340-360]	Speed: 164279.41 samples/sec	accuracy=nan
2021-11-05 20:46:37,550 Node[0] Epoch[3] Batch [360-380]	Speed: 162488.30 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145197789, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 4}}
2021-11-05 20:46:37,789 Node[0] Epoch[3] Time cost=7.758
:::MLLOG {"namespace": "", "time_ms": 1636145197789, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165135.5887332718}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636145197789, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165135.5887332718, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145197789, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 5}}
2021-11-05 20:46:38,208 Node[0] Epoch[4] Batch [0-20]	Speed: 163340.25 samples/sec	accuracy=nan
2021-11-05 20:46:38,606 Node[0] Epoch[4] Batch [20-40]	Speed: 163880.11 samples/sec	accuracy=nan
2021-11-05 20:46:39,002 Node[0] Epoch[4] Batch [40-60]	Speed: 164870.56 samples/sec	accuracy=nan
2021-11-05 20:46:39,396 Node[0] Epoch[4] Batch [60-80]	Speed: 165805.15 samples/sec	accuracy=nan
2021-11-05 20:46:39,791 Node[0] Epoch[4] Batch [80-100]	Speed: 165320.01 samples/sec	accuracy=nan
2021-11-05 20:46:40,185 Node[0] Epoch[4] Batch [100-120]	Speed: 165688.57 samples/sec	accuracy=nan
2021-11-05 20:46:40,584 Node[0] Epoch[4] Batch [120-140]	Speed: 163462.93 samples/sec	accuracy=nan
2021-11-05 20:46:40,979 Node[0] Epoch[4] Batch [140-160]	Speed: 165223.65 samples/sec	accuracy=nan
2021-11-05 20:46:41,375 Node[0] Epoch[4] Batch [160-180]	Speed: 165136.15 samples/sec	accuracy=nan
2021-11-05 20:46:41,769 Node[0] Epoch[4] Batch [180-200]	Speed: 165439.48 samples/sec	accuracy=nan
2021-11-05 20:46:42,165 Node[0] Epoch[4] Batch [200-220]	Speed: 165126.69 samples/sec	accuracy=nan
2021-11-05 20:46:42,558 Node[0] Epoch[4] Batch [220-240]	Speed: 165943.33 samples/sec	accuracy=nan
2021-11-05 20:46:42,951 Node[0] Epoch[4] Batch [240-260]	Speed: 166085.46 samples/sec	accuracy=nan
2021-11-05 20:46:43,352 Node[0] Epoch[4] Batch [260-280]	Speed: 163006.52 samples/sec	accuracy=nan
2021-11-05 20:46:43,745 Node[0] Epoch[4] Batch [280-300]	Speed: 165918.39 samples/sec	accuracy=nan
2021-11-05 20:46:44,141 Node[0] Epoch[4] Batch [300-320]	Speed: 165074.43 samples/sec	accuracy=nan
2021-11-05 20:46:44,535 Node[0] Epoch[4] Batch [320-340]	Speed: 165595.57 samples/sec	accuracy=nan
2021-11-05 20:46:44,930 Node[0] Epoch[4] Batch [340-360]	Speed: 165173.91 samples/sec	accuracy=nan
2021-11-05 20:46:45,330 Node[0] Epoch[4] Batch [360-380]	Speed: 163121.69 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145205568, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 5}}
2021-11-05 20:46:45,568 Node[0] Epoch[4] Time cost=7.779
:::MLLOG {"namespace": "", "time_ms": 1636145205568, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164702.3086004605}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 5}}
:::MLLOG {"namespace": "", "time_ms": 1636145205568, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164702.3086004605, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145205569, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 6}}
2021-11-05 20:46:45,985 Node[0] Epoch[5] Batch [0-20]	Speed: 164178.05 samples/sec	accuracy=nan
2021-11-05 20:46:46,378 Node[0] Epoch[5] Batch [20-40]	Speed: 166093.31 samples/sec	accuracy=nan
2021-11-05 20:46:46,771 Node[0] Epoch[5] Batch [40-60]	Speed: 166250.14 samples/sec	accuracy=nan
2021-11-05 20:46:47,166 Node[0] Epoch[5] Batch [60-80]	Speed: 165097.22 samples/sec	accuracy=nan
2021-11-05 20:46:47,558 Node[0] Epoch[5] Batch [80-100]	Speed: 166520.20 samples/sec	accuracy=nan
2021-11-05 20:46:47,950 Node[0] Epoch[5] Batch [100-120]	Speed: 166617.37 samples/sec	accuracy=nan
2021-11-05 20:46:48,341 Node[0] Epoch[5] Batch [120-140]	Speed: 166892.09 samples/sec	accuracy=nan
2021-11-05 20:46:48,741 Node[0] Epoch[5] Batch [140-160]	Speed: 163290.57 samples/sec	accuracy=nan
2021-11-05 20:46:49,133 Node[0] Epoch[5] Batch [160-180]	Speed: 166566.29 samples/sec	accuracy=nan
2021-11-05 20:46:49,527 Node[0] Epoch[5] Batch [180-200]	Speed: 165632.54 samples/sec	accuracy=nan
2021-11-05 20:46:49,919 Node[0] Epoch[5] Batch [200-220]	Speed: 166449.74 samples/sec	accuracy=nan
2021-11-05 20:46:50,319 Node[0] Epoch[5] Batch [220-240]	Speed: 163423.71 samples/sec	accuracy=nan
2021-11-05 20:46:50,713 Node[0] Epoch[5] Batch [240-260]	Speed: 165666.31 samples/sec	accuracy=nan
2021-11-05 20:46:51,105 Node[0] Epoch[5] Batch [260-280]	Speed: 166377.42 samples/sec	accuracy=nan
2021-11-05 20:46:51,497 Node[0] Epoch[5] Batch [280-300]	Speed: 166618.29 samples/sec	accuracy=nan
2021-11-05 20:46:51,893 Node[0] Epoch[5] Batch [300-320]	Speed: 164692.15 samples/sec	accuracy=nan
2021-11-05 20:46:52,289 Node[0] Epoch[5] Batch [320-340]	Speed: 164792.47 samples/sec	accuracy=nan
2021-11-05 20:46:52,685 Node[0] Epoch[5] Batch [340-360]	Speed: 165030.65 samples/sec	accuracy=nan
2021-11-05 20:46:53,088 Node[0] Epoch[5] Batch [360-380]	Speed: 162077.88 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145213328, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 6}}
2021-11-05 20:46:53,328 Node[0] Epoch[5] Time cost=7.760
:::MLLOG {"namespace": "", "time_ms": 1636145213328, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165103.4463712064}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 6}}
:::MLLOG {"namespace": "", "time_ms": 1636145213329, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165103.4463712064, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145213329, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 7}}
2021-11-05 20:46:53,741 Node[0] Epoch[6] Batch [0-20]	Speed: 166354.88 samples/sec	accuracy=nan
2021-11-05 20:46:54,131 Node[0] Epoch[6] Batch [20-40]	Speed: 167046.25 samples/sec	accuracy=nan
2021-11-05 20:46:54,526 Node[0] Epoch[6] Batch [40-60]	Speed: 165512.29 samples/sec	accuracy=nan
2021-11-05 20:46:54,918 Node[0] Epoch[6] Batch [60-80]	Speed: 166522.02 samples/sec	accuracy=nan
2021-11-05 20:46:55,311 Node[0] Epoch[6] Batch [80-100]	Speed: 165873.56 samples/sec	accuracy=nan
2021-11-05 20:46:55,706 Node[0] Epoch[6] Batch [100-120]	Speed: 165505.39 samples/sec	accuracy=nan
2021-11-05 20:46:56,099 Node[0] Epoch[6] Batch [120-140]	Speed: 165856.98 samples/sec	accuracy=nan
2021-11-05 20:46:56,494 Node[0] Epoch[6] Batch [140-160]	Speed: 165669.22 samples/sec	accuracy=nan
2021-11-05 20:46:56,886 Node[0] Epoch[6] Batch [160-180]	Speed: 166426.88 samples/sec	accuracy=nan
2021-11-05 20:46:57,280 Node[0] Epoch[6] Batch [180-200]	Speed: 165599.88 samples/sec	accuracy=nan
2021-11-05 20:46:57,676 Node[0] Epoch[6] Batch [200-220]	Speed: 164695.72 samples/sec	accuracy=nan
2021-11-05 20:46:58,069 Node[0] Epoch[6] Batch [220-240]	Speed: 166138.26 samples/sec	accuracy=nan
2021-11-05 20:46:58,463 Node[0] Epoch[6] Batch [240-260]	Speed: 165761.59 samples/sec	accuracy=nan
2021-11-05 20:46:58,858 Node[0] Epoch[6] Batch [260-280]	Speed: 165457.08 samples/sec	accuracy=nan
2021-11-05 20:46:59,252 Node[0] Epoch[6] Batch [280-300]	Speed: 165620.21 samples/sec	accuracy=nan
2021-11-05 20:46:59,645 Node[0] Epoch[6] Batch [300-320]	Speed: 166061.38 samples/sec	accuracy=nan
2021-11-05 20:47:00,041 Node[0] Epoch[6] Batch [320-340]	Speed: 164779.67 samples/sec	accuracy=nan
2021-11-05 20:47:00,440 Node[0] Epoch[6] Batch [340-360]	Speed: 163826.86 samples/sec	accuracy=nan
2021-11-05 20:47:00,842 Node[0] Epoch[6] Batch [360-380]	Speed: 162292.21 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145221080, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 7}}
2021-11-05 20:47:01,080 Node[0] Epoch[6] Time cost=7.752
:::MLLOG {"namespace": "", "time_ms": 1636145221081, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165274.10374073562}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636145221081, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165274.10374073562, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145221097, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 7}}
2021-11-05 20:47:01,214 Node[0] Epoch[6] Validation-accuracy=0.428937
2021-11-05 20:47:01,214 Node[0] Epoch[6] Validation-correct-count=335.000000
2021-11-05 20:47:01,214 Node[0] Epoch[6] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636145221231, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636145221231, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.43638, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636145221231, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636145221231, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 8, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636145221232, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 8}}
2021-11-05 20:47:01,628 Node[0] Epoch[7] Batch [0-20]	Speed: 167026.17 samples/sec	accuracy=nan
2021-11-05 20:47:02,021 Node[0] Epoch[7] Batch [20-40]	Speed: 165711.43 samples/sec	accuracy=nan
2021-11-05 20:47:02,415 Node[0] Epoch[7] Batch [40-60]	Speed: 165901.60 samples/sec	accuracy=nan
2021-11-05 20:47:02,808 Node[0] Epoch[7] Batch [60-80]	Speed: 166095.33 samples/sec	accuracy=nan
2021-11-05 20:47:03,200 Node[0] Epoch[7] Batch [80-100]	Speed: 166543.39 samples/sec	accuracy=nan
2021-11-05 20:47:03,593 Node[0] Epoch[7] Batch [100-120]	Speed: 166135.54 samples/sec	accuracy=nan
2021-11-05 20:47:03,984 Node[0] Epoch[7] Batch [120-140]	Speed: 166977.28 samples/sec	accuracy=nan
2021-11-05 20:47:04,377 Node[0] Epoch[7] Batch [140-160]	Speed: 166151.47 samples/sec	accuracy=nan
2021-11-05 20:47:04,771 Node[0] Epoch[7] Batch [160-180]	Speed: 165731.89 samples/sec	accuracy=nan
2021-11-05 20:47:05,165 Node[0] Epoch[7] Batch [180-200]	Speed: 165645.36 samples/sec	accuracy=nan
2021-11-05 20:47:05,562 Node[0] Epoch[7] Batch [200-220]	Speed: 164453.37 samples/sec	accuracy=nan
2021-11-05 20:47:05,954 Node[0] Epoch[7] Batch [220-240]	Speed: 166212.59 samples/sec	accuracy=nan
2021-11-05 20:47:06,347 Node[0] Epoch[7] Batch [240-260]	Speed: 166101.68 samples/sec	accuracy=nan
2021-11-05 20:47:06,741 Node[0] Epoch[7] Batch [260-280]	Speed: 165805.86 samples/sec	accuracy=nan
2021-11-05 20:47:07,135 Node[0] Epoch[7] Batch [280-300]	Speed: 165724.87 samples/sec	accuracy=nan
2021-11-05 20:47:07,530 Node[0] Epoch[7] Batch [300-320]	Speed: 165342.58 samples/sec	accuracy=nan
2021-11-05 20:47:07,925 Node[0] Epoch[7] Batch [320-340]	Speed: 165224.24 samples/sec	accuracy=nan
2021-11-05 20:47:08,325 Node[0] Epoch[7] Batch [340-360]	Speed: 163227.40 samples/sec	accuracy=nan
2021-11-05 20:47:08,725 Node[0] Epoch[7] Batch [360-380]	Speed: 163020.78 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145228963, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1636145228963, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165713.73850485892}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 8}}
2021-11-05 20:47:08,963 Node[0] Epoch[7] Time cost=7.731
:::MLLOG {"namespace": "", "time_ms": 1636145228963, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165713.73850485892, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145228963, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 9}}
2021-11-05 20:47:09,377 Node[0] Epoch[8] Batch [0-20]	Speed: 165581.05 samples/sec	accuracy=nan
2021-11-05 20:47:09,787 Node[0] Epoch[8] Batch [20-40]	Speed: 159167.46 samples/sec	accuracy=nan
2021-11-05 20:47:10,162 Node[0] Epoch[8] Batch [40-60]	Speed: 174006.98 samples/sec	accuracy=nan
2021-11-05 20:47:10,555 Node[0] Epoch[8] Batch [60-80]	Speed: 166218.34 samples/sec	accuracy=nan
2021-11-05 20:47:10,949 Node[0] Epoch[8] Batch [80-100]	Speed: 165368.04 samples/sec	accuracy=nan
2021-11-05 20:47:11,340 Node[0] Epoch[8] Batch [100-120]	Speed: 166924.95 samples/sec	accuracy=nan
2021-11-05 20:47:11,736 Node[0] Epoch[8] Batch [120-140]	Speed: 165101.20 samples/sec	accuracy=nan
2021-11-05 20:47:12,131 Node[0] Epoch[8] Batch [140-160]	Speed: 165303.15 samples/sec	accuracy=nan
2021-11-05 20:47:12,526 Node[0] Epoch[8] Batch [160-180]	Speed: 165038.01 samples/sec	accuracy=nan
2021-11-05 20:47:12,920 Node[0] Epoch[8] Batch [180-200]	Speed: 165594.47 samples/sec	accuracy=nan
2021-11-05 20:47:13,314 Node[0] Epoch[8] Batch [200-220]	Speed: 165998.56 samples/sec	accuracy=nan
2021-11-05 20:47:13,707 Node[0] Epoch[8] Batch [220-240]	Speed: 165927.74 samples/sec	accuracy=nan
2021-11-05 20:47:14,099 Node[0] Epoch[8] Batch [240-260]	Speed: 166573.89 samples/sec	accuracy=nan
2021-11-05 20:47:14,490 Node[0] Epoch[8] Batch [260-280]	Speed: 166813.49 samples/sec	accuracy=nan
2021-11-05 20:47:14,887 Node[0] Epoch[8] Batch [280-300]	Speed: 164741.80 samples/sec	accuracy=nan
2021-11-05 20:47:15,281 Node[0] Epoch[8] Batch [300-320]	Speed: 165702.20 samples/sec	accuracy=nan
2021-11-05 20:47:15,676 Node[0] Epoch[8] Batch [320-340]	Speed: 165120.82 samples/sec	accuracy=nan
2021-11-05 20:47:16,074 Node[0] Epoch[8] Batch [340-360]	Speed: 164019.31 samples/sec	accuracy=nan
2021-11-05 20:47:16,470 Node[0] Epoch[8] Batch [360-380]	Speed: 164763.81 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145236707, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 9}}
2021-11-05 20:47:16,707 Node[0] Epoch[8] Time cost=7.744
:::MLLOG {"namespace": "", "time_ms": 1636145236707, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165438.9306244093}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 9}}
:::MLLOG {"namespace": "", "time_ms": 1636145236708, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165438.9306244093, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145236708, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 10}}
2021-11-05 20:47:17,121 Node[0] Epoch[9] Batch [0-20]	Speed: 165946.14 samples/sec	accuracy=nan
2021-11-05 20:47:17,515 Node[0] Epoch[9] Batch [20-40]	Speed: 165403.90 samples/sec	accuracy=nan
2021-11-05 20:47:17,906 Node[0] Epoch[9] Batch [40-60]	Speed: 167012.82 samples/sec	accuracy=nan
2021-11-05 20:47:18,299 Node[0] Epoch[9] Batch [60-80]	Speed: 166310.12 samples/sec	accuracy=nan
2021-11-05 20:47:18,693 Node[0] Epoch[9] Batch [80-100]	Speed: 165838.50 samples/sec	accuracy=nan
2021-11-05 20:47:19,083 Node[0] Epoch[9] Batch [100-120]	Speed: 167372.50 samples/sec	accuracy=nan
2021-11-05 20:47:19,475 Node[0] Epoch[9] Batch [120-140]	Speed: 166304.77 samples/sec	accuracy=nan
2021-11-05 20:47:19,869 Node[0] Epoch[9] Batch [140-160]	Speed: 165522.09 samples/sec	accuracy=nan
2021-11-05 20:47:20,263 Node[0] Epoch[9] Batch [160-180]	Speed: 166063.60 samples/sec	accuracy=nan
2021-11-05 20:47:20,655 Node[0] Epoch[9] Batch [180-200]	Speed: 166393.80 samples/sec	accuracy=nan
2021-11-05 20:47:21,052 Node[0] Epoch[9] Batch [200-220]	Speed: 164281.78 samples/sec	accuracy=nan
2021-11-05 20:47:21,448 Node[0] Epoch[9] Batch [220-240]	Speed: 165132.57 samples/sec	accuracy=nan
2021-11-05 20:47:21,842 Node[0] Epoch[9] Batch [240-260]	Speed: 165417.69 samples/sec	accuracy=nan
2021-11-05 20:47:22,234 Node[0] Epoch[9] Batch [260-280]	Speed: 166779.25 samples/sec	accuracy=nan
2021-11-05 20:47:22,626 Node[0] Epoch[9] Batch [280-300]	Speed: 166252.76 samples/sec	accuracy=nan
2021-11-05 20:47:23,020 Node[0] Epoch[9] Batch [300-320]	Speed: 165855.77 samples/sec	accuracy=nan
2021-11-05 20:47:23,414 Node[0] Epoch[9] Batch [320-340]	Speed: 165526.90 samples/sec	accuracy=nan
2021-11-05 20:47:23,810 Node[0] Epoch[9] Batch [340-360]	Speed: 164928.95 samples/sec	accuracy=nan
2021-11-05 20:47:24,211 Node[0] Epoch[9] Batch [360-380]	Speed: 162640.61 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145244448, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 10}}
2021-11-05 20:47:24,449 Node[0] Epoch[9] Time cost=7.741
:::MLLOG {"namespace": "", "time_ms": 1636145244449, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165503.33146262387}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 10}}
:::MLLOG {"namespace": "", "time_ms": 1636145244449, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165503.33146262387, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145244449, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 11}}
2021-11-05 20:47:24,864 Node[0] Epoch[10] Batch [0-20]	Speed: 165264.13 samples/sec	accuracy=nan
2021-11-05 20:47:25,261 Node[0] Epoch[10] Batch [20-40]	Speed: 164591.47 samples/sec	accuracy=nan
2021-11-05 20:47:25,656 Node[0] Epoch[10] Batch [40-60]	Speed: 165319.12 samples/sec	accuracy=nan
2021-11-05 20:47:26,049 Node[0] Epoch[10] Batch [60-80]	Speed: 166117.90 samples/sec	accuracy=nan
2021-11-05 20:47:26,441 Node[0] Epoch[10] Batch [80-100]	Speed: 166236.81 samples/sec	accuracy=nan
2021-11-05 20:47:26,836 Node[0] Epoch[10] Batch [100-120]	Speed: 165349.87 samples/sec	accuracy=nan
2021-11-05 20:47:27,229 Node[0] Epoch[10] Batch [120-140]	Speed: 166350.74 samples/sec	accuracy=nan
2021-11-05 20:47:27,620 Node[0] Epoch[10] Batch [140-160]	Speed: 166984.61 samples/sec	accuracy=nan
2021-11-05 20:47:28,011 Node[0] Epoch[10] Batch [160-180]	Speed: 166833.62 samples/sec	accuracy=nan
2021-11-05 20:47:28,406 Node[0] Epoch[10] Batch [180-200]	Speed: 165215.87 samples/sec	accuracy=nan
2021-11-05 20:47:28,801 Node[0] Epoch[10] Batch [200-220]	Speed: 165429.09 samples/sec	accuracy=nan
2021-11-05 20:47:29,199 Node[0] Epoch[10] Batch [220-240]	Speed: 163661.18 samples/sec	accuracy=nan
2021-11-05 20:47:29,591 Node[0] Epoch[10] Batch [240-260]	Speed: 166672.25 samples/sec	accuracy=nan
2021-11-05 20:47:29,983 Node[0] Epoch[10] Batch [260-280]	Speed: 166514.53 samples/sec	accuracy=nan
2021-11-05 20:47:30,375 Node[0] Epoch[10] Batch [280-300]	Speed: 166532.65 samples/sec	accuracy=nan
2021-11-05 20:47:30,770 Node[0] Epoch[10] Batch [300-320]	Speed: 165335.69 samples/sec	accuracy=nan
2021-11-05 20:47:31,164 Node[0] Epoch[10] Batch [320-340]	Speed: 165723.87 samples/sec	accuracy=nan
2021-11-05 20:47:31,562 Node[0] Epoch[10] Batch [340-360]	Speed: 163896.88 samples/sec	accuracy=nan
2021-11-05 20:47:31,961 Node[0] Epoch[10] Batch [360-380]	Speed: 163719.01 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145252196, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 11}}
2021-11-05 20:47:32,196 Node[0] Epoch[10] Time cost=7.747
:::MLLOG {"namespace": "", "time_ms": 1636145252197, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165369.35826321185}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636145252197, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165369.35826321185, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145252213, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 11}}
2021-11-05 20:47:32,333 Node[0] Epoch[10] Validation-accuracy=0.532650
2021-11-05 20:47:32,333 Node[0] Epoch[10] Validation-correct-count=416.000000
2021-11-05 20:47:32,333 Node[0] Epoch[10] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636145252347, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636145252347, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.52694, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636145252347, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1636145252347, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 12, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636145252347, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 12}}
2021-11-05 20:47:32,750 Node[0] Epoch[11] Batch [0-20]	Speed: 164109.56 samples/sec	accuracy=nan
2021-11-05 20:47:33,147 Node[0] Epoch[11] Batch [20-40]	Speed: 164383.07 samples/sec	accuracy=nan
2021-11-05 20:47:33,541 Node[0] Epoch[11] Batch [40-60]	Speed: 165366.34 samples/sec	accuracy=nan
2021-11-05 20:47:33,932 Node[0] Epoch[11] Batch [60-80]	Speed: 166945.72 samples/sec	accuracy=nan
2021-11-05 20:47:34,329 Node[0] Epoch[11] Batch [80-100]	Speed: 164448.92 samples/sec	accuracy=nan
2021-11-05 20:47:34,724 Node[0] Epoch[11] Batch [100-120]	Speed: 165505.49 samples/sec	accuracy=nan
2021-11-05 20:47:35,117 Node[0] Epoch[11] Batch [120-140]	Speed: 166165.49 samples/sec	accuracy=nan
2021-11-05 20:47:35,509 Node[0] Epoch[11] Batch [140-160]	Speed: 166363.27 samples/sec	accuracy=nan
2021-11-05 20:47:35,902 Node[0] Epoch[11] Batch [160-180]	Speed: 166335.68 samples/sec	accuracy=nan
2021-11-05 20:47:36,295 Node[0] Epoch[11] Batch [180-200]	Speed: 165841.11 samples/sec	accuracy=nan
2021-11-05 20:47:36,688 Node[0] Epoch[11] Batch [200-220]	Speed: 166356.20 samples/sec	accuracy=nan
2021-11-05 20:47:37,083 Node[0] Epoch[11] Batch [220-240]	Speed: 165235.01 samples/sec	accuracy=nan
2021-11-05 20:47:37,475 Node[0] Epoch[11] Batch [240-260]	Speed: 166582.71 samples/sec	accuracy=nan
2021-11-05 20:47:37,867 Node[0] Epoch[11] Batch [260-280]	Speed: 166309.01 samples/sec	accuracy=nan
2021-11-05 20:47:38,261 Node[0] Epoch[11] Batch [280-300]	Speed: 165842.41 samples/sec	accuracy=nan
2021-11-05 20:47:38,655 Node[0] Epoch[11] Batch [300-320]	Speed: 165492.08 samples/sec	accuracy=nan
2021-11-05 20:47:39,053 Node[0] Epoch[11] Batch [320-340]	Speed: 164235.07 samples/sec	accuracy=nan
2021-11-05 20:47:39,452 Node[0] Epoch[11] Batch [340-360]	Speed: 163624.99 samples/sec	accuracy=nan
2021-11-05 20:47:39,848 Node[0] Epoch[11] Batch [360-380]	Speed: 164837.21 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145260085, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 12}}
2021-11-05 20:47:40,085 Node[0] Epoch[11] Time cost=7.738
:::MLLOG {"namespace": "", "time_ms": 1636145260085, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165564.0942578361}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 12}}
:::MLLOG {"namespace": "", "time_ms": 1636145260085, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165564.0942578361, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145260086, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 13}}
2021-11-05 20:47:40,503 Node[0] Epoch[12] Batch [0-20]	Speed: 164073.67 samples/sec	accuracy=nan
2021-11-05 20:47:40,896 Node[0] Epoch[12] Batch [20-40]	Speed: 166096.34 samples/sec	accuracy=nan
2021-11-05 20:47:41,290 Node[0] Epoch[12] Batch [40-60]	Speed: 165653.78 samples/sec	accuracy=nan
2021-11-05 20:47:41,682 Node[0] Epoch[12] Batch [60-80]	Speed: 166323.05 samples/sec	accuracy=nan
2021-11-05 20:47:42,074 Node[0] Epoch[12] Batch [80-100]	Speed: 166466.84 samples/sec	accuracy=nan
2021-11-05 20:47:42,466 Node[0] Epoch[12] Batch [100-120]	Speed: 166582.00 samples/sec	accuracy=nan
2021-11-05 20:47:42,857 Node[0] Epoch[12] Batch [120-140]	Speed: 167200.99 samples/sec	accuracy=nan
2021-11-05 20:47:43,249 Node[0] Epoch[12] Batch [140-160]	Speed: 166526.78 samples/sec	accuracy=nan
2021-11-05 20:47:43,642 Node[0] Epoch[12] Batch [160-180]	Speed: 165925.23 samples/sec	accuracy=nan
2021-11-05 20:47:44,041 Node[0] Epoch[12] Batch [180-200]	Speed: 163779.24 samples/sec	accuracy=nan
2021-11-05 20:47:44,432 Node[0] Epoch[12] Batch [200-220]	Speed: 166652.06 samples/sec	accuracy=nan
2021-11-05 20:47:44,830 Node[0] Epoch[12] Batch [220-240]	Speed: 164190.65 samples/sec	accuracy=nan
2021-11-05 20:47:45,221 Node[0] Epoch[12] Batch [240-260]	Speed: 166704.21 samples/sec	accuracy=nan
2021-11-05 20:47:45,616 Node[0] Epoch[12] Batch [260-280]	Speed: 165440.48 samples/sec	accuracy=nan
2021-11-05 20:47:46,008 Node[0] Epoch[12] Batch [280-300]	Speed: 166657.13 samples/sec	accuracy=nan
2021-11-05 20:47:46,403 Node[0] Epoch[12] Batch [300-320]	Speed: 165363.95 samples/sec	accuracy=nan
2021-11-05 20:47:46,796 Node[0] Epoch[12] Batch [320-340]	Speed: 165775.44 samples/sec	accuracy=nan
2021-11-05 20:47:47,193 Node[0] Epoch[12] Batch [340-360]	Speed: 164654.92 samples/sec	accuracy=nan
2021-11-05 20:47:47,593 Node[0] Epoch[12] Batch [360-380]	Speed: 163216.60 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145267829, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 13}}
2021-11-05 20:47:47,829 Node[0] Epoch[12] Time cost=7.743
:::MLLOG {"namespace": "", "time_ms": 1636145267829, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165453.8760787201}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 13}}
:::MLLOG {"namespace": "", "time_ms": 1636145267829, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165453.8760787201, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145267829, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 14}}
2021-11-05 20:47:48,242 Node[0] Epoch[13] Batch [0-20]	Speed: 165796.32 samples/sec	accuracy=nan
2021-11-05 20:47:48,638 Node[0] Epoch[13] Batch [20-40]	Speed: 165107.38 samples/sec	accuracy=nan
2021-11-05 20:47:49,030 Node[0] Epoch[13] Batch [40-60]	Speed: 166294.06 samples/sec	accuracy=nan
2021-11-05 20:47:49,422 Node[0] Epoch[13] Batch [60-80]	Speed: 166526.27 samples/sec	accuracy=nan
2021-11-05 20:47:49,817 Node[0] Epoch[13] Batch [80-100]	Speed: 165538.81 samples/sec	accuracy=nan
2021-11-05 20:47:50,209 Node[0] Epoch[13] Batch [100-120]	Speed: 166301.23 samples/sec	accuracy=nan
2021-11-05 20:47:50,600 Node[0] Epoch[13] Batch [120-140]	Speed: 166941.75 samples/sec	accuracy=nan
2021-11-05 20:47:50,993 Node[0] Epoch[13] Batch [140-160]	Speed: 166162.97 samples/sec	accuracy=nan
2021-11-05 20:47:51,390 Node[0] Epoch[13] Batch [160-180]	Speed: 164614.33 samples/sec	accuracy=nan
2021-11-05 20:47:51,784 Node[0] Epoch[13] Batch [180-200]	Speed: 165503.18 samples/sec	accuracy=nan
2021-11-05 20:47:52,176 Node[0] Epoch[13] Batch [200-220]	Speed: 166362.66 samples/sec	accuracy=nan
2021-11-05 20:47:52,572 Node[0] Epoch[13] Batch [220-240]	Speed: 165206.90 samples/sec	accuracy=nan
2021-11-05 20:47:52,966 Node[0] Epoch[13] Batch [240-260]	Speed: 165503.38 samples/sec	accuracy=nan
2021-11-05 20:47:53,359 Node[0] Epoch[13] Batch [260-280]	Speed: 165951.77 samples/sec	accuracy=nan
2021-11-05 20:47:53,751 Node[0] Epoch[13] Batch [280-300]	Speed: 166731.62 samples/sec	accuracy=nan
2021-11-05 20:47:54,145 Node[0] Epoch[13] Batch [300-320]	Speed: 165663.10 samples/sec	accuracy=nan
2021-11-05 20:47:54,541 Node[0] Epoch[13] Batch [320-340]	Speed: 165056.32 samples/sec	accuracy=nan
2021-11-05 20:47:54,937 Node[0] Epoch[13] Batch [340-360]	Speed: 164565.65 samples/sec	accuracy=nan
2021-11-05 20:47:55,339 Node[0] Epoch[13] Batch [360-380]	Speed: 162575.33 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145275577, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 14}}
2021-11-05 20:47:55,577 Node[0] Epoch[13] Time cost=7.748
:::MLLOG {"namespace": "", "time_ms": 1636145275577, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165358.44786602948}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 14}}
:::MLLOG {"namespace": "", "time_ms": 1636145275577, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165358.44786602948, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145275578, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 15}}
2021-11-05 20:47:55,993 Node[0] Epoch[14] Batch [0-20]	Speed: 164912.37 samples/sec	accuracy=nan
2021-11-05 20:47:56,385 Node[0] Epoch[14] Batch [20-40]	Speed: 166317.19 samples/sec	accuracy=nan
2021-11-05 20:47:56,779 Node[0] Epoch[14] Batch [40-60]	Speed: 165765.70 samples/sec	accuracy=nan
2021-11-05 20:47:57,171 Node[0] Epoch[14] Batch [60-80]	Speed: 166642.63 samples/sec	accuracy=nan
2021-11-05 20:47:57,563 Node[0] Epoch[14] Batch [80-100]	Speed: 166372.67 samples/sec	accuracy=nan
2021-11-05 20:47:57,956 Node[0] Epoch[14] Batch [100-120]	Speed: 166014.56 samples/sec	accuracy=nan
2021-11-05 20:47:58,348 Node[0] Epoch[14] Batch [120-140]	Speed: 166621.23 samples/sec	accuracy=nan
2021-11-05 20:47:58,739 Node[0] Epoch[14] Batch [140-160]	Speed: 167020.57 samples/sec	accuracy=nan
2021-11-05 20:47:59,132 Node[0] Epoch[14] Batch [160-180]	Speed: 166235.10 samples/sec	accuracy=nan
2021-11-05 20:47:59,528 Node[0] Epoch[14] Batch [180-200]	Speed: 164858.75 samples/sec	accuracy=nan
2021-11-05 20:47:59,919 Node[0] Epoch[14] Batch [200-220]	Speed: 166582.30 samples/sec	accuracy=nan
2021-11-05 20:48:00,311 Node[0] Epoch[14] Batch [220-240]	Speed: 166732.23 samples/sec	accuracy=nan
2021-11-05 20:48:00,705 Node[0] Epoch[14] Batch [240-260]	Speed: 165752.06 samples/sec	accuracy=nan
2021-11-05 20:48:01,099 Node[0] Epoch[14] Batch [260-280]	Speed: 165712.03 samples/sec	accuracy=nan
2021-11-05 20:48:01,492 Node[0] Epoch[14] Batch [280-300]	Speed: 165869.24 samples/sec	accuracy=nan
2021-11-05 20:48:01,886 Node[0] Epoch[14] Batch [300-320]	Speed: 165836.89 samples/sec	accuracy=nan
2021-11-05 20:48:02,281 Node[0] Epoch[14] Batch [320-340]	Speed: 165076.62 samples/sec	accuracy=nan
2021-11-05 20:48:02,679 Node[0] Epoch[14] Batch [340-360]	Speed: 164003.01 samples/sec	accuracy=nan
2021-11-05 20:48:03,081 Node[0] Epoch[14] Batch [360-380]	Speed: 162499.49 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145283320, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 15}}
2021-11-05 20:48:03,320 Node[0] Epoch[14] Time cost=7.743
:::MLLOG {"namespace": "", "time_ms": 1636145283320, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165466.0677415179}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636145283321, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165466.0677415179, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145283337, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 15}}
2021-11-05 20:48:03,452 Node[0] Epoch[14] Validation-accuracy=0.606914
2021-11-05 20:48:03,452 Node[0] Epoch[14] Validation-correct-count=474.000000
2021-11-05 20:48:03,452 Node[0] Epoch[14] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636145283478, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636145283478, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6068, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636145283478, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1636145283478, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 16, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636145283478, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 16}}
2021-11-05 20:48:03,874 Node[0] Epoch[15] Batch [0-20]	Speed: 166842.67 samples/sec	accuracy=nan
2021-11-05 20:48:04,266 Node[0] Epoch[15] Batch [20-40]	Speed: 166868.19 samples/sec	accuracy=nan
2021-11-05 20:48:04,659 Node[0] Epoch[15] Batch [40-60]	Speed: 165874.56 samples/sec	accuracy=nan
2021-11-05 20:48:05,052 Node[0] Epoch[15] Batch [60-80]	Speed: 166230.76 samples/sec	accuracy=nan
2021-11-05 20:48:05,444 Node[0] Epoch[15] Batch [80-100]	Speed: 166458.85 samples/sec	accuracy=nan
2021-11-05 20:48:05,836 Node[0] Epoch[15] Batch [100-120]	Speed: 166567.20 samples/sec	accuracy=nan
2021-11-05 20:48:06,229 Node[0] Epoch[15] Batch [120-140]	Speed: 166283.05 samples/sec	accuracy=nan
2021-11-05 20:48:06,623 Node[0] Epoch[15] Batch [140-160]	Speed: 165558.93 samples/sec	accuracy=nan
2021-11-05 20:48:07,019 Node[0] Epoch[15] Batch [160-180]	Speed: 164696.02 samples/sec	accuracy=nan
2021-11-05 20:48:07,412 Node[0] Epoch[15] Batch [180-200]	Speed: 166186.26 samples/sec	accuracy=nan
2021-11-05 20:48:07,809 Node[0] Epoch[15] Batch [200-220]	Speed: 164470.65 samples/sec	accuracy=nan
2021-11-05 20:48:08,204 Node[0] Epoch[15] Batch [220-240]	Speed: 165289.38 samples/sec	accuracy=nan
2021-11-05 20:48:08,598 Node[0] Epoch[15] Batch [240-260]	Speed: 165660.80 samples/sec	accuracy=nan
2021-11-05 20:48:08,992 Node[0] Epoch[15] Batch [260-280]	Speed: 165564.23 samples/sec	accuracy=nan
2021-11-05 20:48:09,382 Node[0] Epoch[15] Batch [280-300]	Speed: 167289.05 samples/sec	accuracy=nan
2021-11-05 20:48:09,776 Node[0] Epoch[15] Batch [300-320]	Speed: 165723.87 samples/sec	accuracy=nan
2021-11-05 20:48:10,174 Node[0] Epoch[15] Batch [320-340]	Speed: 164008.60 samples/sec	accuracy=nan
2021-11-05 20:48:10,572 Node[0] Epoch[15] Batch [340-360]	Speed: 164101.00 samples/sec	accuracy=nan
2021-11-05 20:48:10,973 Node[0] Epoch[15] Batch [360-380]	Speed: 162825.54 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145291209, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 16}}
2021-11-05 20:48:11,210 Node[0] Epoch[15] Time cost=7.731
:::MLLOG {"namespace": "", "time_ms": 1636145291210, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165717.3209437295}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 16}}
:::MLLOG {"namespace": "", "time_ms": 1636145291210, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165717.3209437295, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145291210, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 17}}
2021-11-05 20:48:11,621 Node[0] Epoch[16] Batch [0-20]	Speed: 166528.81 samples/sec	accuracy=nan
2021-11-05 20:48:12,014 Node[0] Epoch[16] Batch [20-40]	Speed: 166098.05 samples/sec	accuracy=nan
2021-11-05 20:48:12,406 Node[0] Epoch[16] Batch [40-60]	Speed: 166452.78 samples/sec	accuracy=nan
2021-11-05 20:48:12,799 Node[0] Epoch[16] Batch [60-80]	Speed: 166301.23 samples/sec	accuracy=nan
2021-11-05 20:48:13,191 Node[0] Epoch[16] Batch [80-100]	Speed: 166642.83 samples/sec	accuracy=nan
2021-11-05 20:48:13,585 Node[0] Epoch[16] Batch [100-120]	Speed: 165692.28 samples/sec	accuracy=nan
2021-11-05 20:48:13,977 Node[0] Epoch[16] Batch [120-140]	Speed: 166477.37 samples/sec	accuracy=nan
2021-11-05 20:48:14,371 Node[0] Epoch[16] Batch [140-160]	Speed: 165652.88 samples/sec	accuracy=nan
2021-11-05 20:48:14,764 Node[0] Epoch[16] Batch [160-180]	Speed: 166237.92 samples/sec	accuracy=nan
2021-11-05 20:48:15,158 Node[0] Epoch[16] Batch [180-200]	Speed: 165401.81 samples/sec	accuracy=nan
2021-11-05 20:48:15,551 Node[0] Epoch[16] Batch [200-220]	Speed: 166142.20 samples/sec	accuracy=nan
2021-11-05 20:48:15,947 Node[0] Epoch[16] Batch [220-240]	Speed: 165090.15 samples/sec	accuracy=nan
2021-11-05 20:48:16,341 Node[0] Epoch[16] Batch [240-260]	Speed: 165347.07 samples/sec	accuracy=nan
2021-11-05 20:48:16,735 Node[0] Epoch[16] Batch [260-280]	Speed: 165752.96 samples/sec	accuracy=nan
2021-11-05 20:48:17,129 Node[0] Epoch[16] Batch [280-300]	Speed: 165867.03 samples/sec	accuracy=nan
2021-11-05 20:48:17,525 Node[0] Epoch[16] Batch [300-320]	Speed: 164927.76 samples/sec	accuracy=nan
2021-11-05 20:48:17,921 Node[0] Epoch[16] Batch [320-340]	Speed: 164632.64 samples/sec	accuracy=nan
2021-11-05 20:48:18,319 Node[0] Epoch[16] Batch [340-360]	Speed: 164225.81 samples/sec	accuracy=nan
2021-11-05 20:48:18,715 Node[0] Epoch[16] Batch [360-380]	Speed: 164646.90 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145298953, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 17}}
2021-11-05 20:48:18,953 Node[0] Epoch[16] Time cost=7.743
:::MLLOG {"namespace": "", "time_ms": 1636145298953, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165454.94589781735}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 17}}
:::MLLOG {"namespace": "", "time_ms": 1636145298953, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165454.94589781735, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145298953, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 18}}
2021-11-05 20:48:19,367 Node[0] Epoch[17] Batch [0-20]	Speed: 165562.23 samples/sec	accuracy=nan
2021-11-05 20:48:19,759 Node[0] Epoch[17] Batch [20-40]	Speed: 166341.34 samples/sec	accuracy=nan
2021-11-05 20:48:20,152 Node[0] Epoch[17] Batch [40-60]	Speed: 166141.69 samples/sec	accuracy=nan
2021-11-05 20:48:20,544 Node[0] Epoch[17] Batch [60-80]	Speed: 166404.62 samples/sec	accuracy=nan
2021-11-05 20:48:20,938 Node[0] Epoch[17] Batch [80-100]	Speed: 165825.44 samples/sec	accuracy=nan
2021-11-05 20:48:21,331 Node[0] Epoch[17] Batch [100-120]	Speed: 166264.07 samples/sec	accuracy=nan
2021-11-05 20:48:21,723 Node[0] Epoch[17] Batch [120-140]	Speed: 166423.94 samples/sec	accuracy=nan
2021-11-05 20:48:22,116 Node[0] Epoch[17] Batch [140-160]	Speed: 166285.07 samples/sec	accuracy=nan
2021-11-05 20:48:22,507 Node[0] Epoch[17] Batch [160-180]	Speed: 166741.57 samples/sec	accuracy=nan
2021-11-05 20:48:22,901 Node[0] Epoch[17] Batch [180-200]	Speed: 165802.04 samples/sec	accuracy=nan
2021-11-05 20:48:23,295 Node[0] Epoch[17] Batch [200-220]	Speed: 165608.79 samples/sec	accuracy=nan
2021-11-05 20:48:23,689 Node[0] Epoch[17] Batch [220-240]	Speed: 165690.57 samples/sec	accuracy=nan
2021-11-05 20:48:24,082 Node[0] Epoch[17] Batch [240-260]	Speed: 165885.92 samples/sec	accuracy=nan
2021-11-05 20:48:24,477 Node[0] Epoch[17] Batch [260-280]	Speed: 165330.80 samples/sec	accuracy=nan
2021-11-05 20:48:24,869 Node[0] Epoch[17] Batch [280-300]	Speed: 166517.16 samples/sec	accuracy=nan
2021-11-05 20:48:25,264 Node[0] Epoch[17] Batch [300-320]	Speed: 165504.08 samples/sec	accuracy=nan
2021-11-05 20:48:25,658 Node[0] Epoch[17] Batch [320-340]	Speed: 165614.20 samples/sec	accuracy=nan
2021-11-05 20:48:26,054 Node[0] Epoch[17] Batch [340-360]	Speed: 164705.23 samples/sec	accuracy=nan
2021-11-05 20:48:26,451 Node[0] Epoch[17] Batch [360-380]	Speed: 164376.85 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145306687, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 18}}
2021-11-05 20:48:26,687 Node[0] Epoch[17] Time cost=7.734
:::MLLOG {"namespace": "", "time_ms": 1636145306687, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165658.16155851737}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 18}}
:::MLLOG {"namespace": "", "time_ms": 1636145306688, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165658.16155851737, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145306688, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 19}}
2021-11-05 20:48:27,100 Node[0] Epoch[18] Batch [0-20]	Speed: 166032.98 samples/sec	accuracy=nan
2021-11-05 20:48:27,493 Node[0] Epoch[18] Batch [20-40]	Speed: 165951.17 samples/sec	accuracy=nan
2021-11-05 20:48:27,885 Node[0] Epoch[18] Batch [40-60]	Speed: 166711.52 samples/sec	accuracy=nan
2021-11-05 20:48:28,278 Node[0] Epoch[18] Batch [60-80]	Speed: 166126.67 samples/sec	accuracy=nan
2021-11-05 20:48:28,671 Node[0] Epoch[18] Batch [80-100]	Speed: 165896.07 samples/sec	accuracy=nan
2021-11-05 20:48:29,063 Node[0] Epoch[18] Batch [100-120]	Speed: 166912.34 samples/sec	accuracy=nan
2021-11-05 20:48:29,455 Node[0] Epoch[18] Batch [120-140]	Speed: 166310.12 samples/sec	accuracy=nan
2021-11-05 20:48:29,849 Node[0] Epoch[18] Batch [140-160]	Speed: 165810.48 samples/sec	accuracy=nan
2021-11-05 20:48:30,244 Node[0] Epoch[18] Batch [160-180]	Speed: 165063.98 samples/sec	accuracy=nan
2021-11-05 20:48:30,639 Node[0] Epoch[18] Batch [180-200]	Speed: 165194.34 samples/sec	accuracy=nan
2021-11-05 20:48:31,032 Node[0] Epoch[18] Batch [200-220]	Speed: 166261.24 samples/sec	accuracy=nan
2021-11-05 20:48:31,428 Node[0] Epoch[18] Batch [220-240]	Speed: 164938.59 samples/sec	accuracy=nan
2021-11-05 20:48:31,820 Node[0] Epoch[18] Batch [240-260]	Speed: 166432.44 samples/sec	accuracy=nan
2021-11-05 20:48:32,214 Node[0] Epoch[18] Batch [260-280]	Speed: 165658.79 samples/sec	accuracy=nan
2021-11-05 20:48:32,606 Node[0] Epoch[18] Batch [280-300]	Speed: 166534.58 samples/sec	accuracy=nan
2021-11-05 20:48:32,999 Node[0] Epoch[18] Batch [300-320]	Speed: 166303.35 samples/sec	accuracy=nan
2021-11-05 20:48:33,393 Node[0] Epoch[18] Batch [320-340]	Speed: 165374.33 samples/sec	accuracy=nan
2021-11-05 20:48:33,792 Node[0] Epoch[18] Batch [340-360]	Speed: 163666.65 samples/sec	accuracy=nan
2021-11-05 20:48:34,189 Node[0] Epoch[18] Batch [360-380]	Speed: 164736.25 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145314424, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 19}}
2021-11-05 20:48:34,424 Node[0] Epoch[18] Time cost=7.737
:::MLLOG {"namespace": "", "time_ms": 1636145314425, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165595.81918216753}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636145314425, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165595.81918216753, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145314441, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 19}}
2021-11-05 20:48:34,554 Node[0] Epoch[18] Validation-accuracy=0.644046
2021-11-05 20:48:34,554 Node[0] Epoch[18] Validation-correct-count=503.000000
2021-11-05 20:48:34,554 Node[0] Epoch[18] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636145314572, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636145314572, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.63614, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636145314572, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1636145314572, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 20, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636145314572, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 20}}
2021-11-05 20:48:34,967 Node[0] Epoch[19] Batch [0-20]	Speed: 167272.29 samples/sec	accuracy=nan
2021-11-05 20:48:35,360 Node[0] Epoch[19] Batch [20-40]	Speed: 166159.13 samples/sec	accuracy=nan
2021-11-05 20:48:35,754 Node[0] Epoch[19] Batch [40-60]	Speed: 165664.10 samples/sec	accuracy=nan
2021-11-05 20:48:36,146 Node[0] Epoch[19] Batch [60-80]	Speed: 166543.19 samples/sec	accuracy=nan
2021-11-05 20:48:36,538 Node[0] Epoch[19] Batch [80-100]	Speed: 166459.76 samples/sec	accuracy=nan
2021-11-05 20:48:36,931 Node[0] Epoch[19] Batch [100-120]	Speed: 166104.60 samples/sec	accuracy=nan
2021-11-05 20:48:37,324 Node[0] Epoch[19] Batch [120-140]	Speed: 166223.39 samples/sec	accuracy=nan
2021-11-05 20:48:37,715 Node[0] Epoch[19] Batch [140-160]	Speed: 166796.22 samples/sec	accuracy=nan
2021-11-05 20:48:38,108 Node[0] Epoch[19] Batch [160-180]	Speed: 166256.80 samples/sec	accuracy=nan
2021-11-05 20:48:38,500 Node[0] Epoch[19] Batch [180-200]	Speed: 166467.65 samples/sec	accuracy=nan
2021-11-05 20:48:38,895 Node[0] Epoch[19] Batch [200-220]	Speed: 165520.99 samples/sec	accuracy=nan
2021-11-05 20:48:39,292 Node[0] Epoch[19] Batch [220-240]	Speed: 164271.43 samples/sec	accuracy=nan
2021-11-05 20:48:39,684 Node[0] Epoch[19] Batch [240-260]	Speed: 166482.33 samples/sec	accuracy=nan
2021-11-05 20:48:40,077 Node[0] Epoch[19] Batch [260-280]	Speed: 166053.22 samples/sec	accuracy=nan
2021-11-05 20:48:40,471 Node[0] Epoch[19] Batch [280-300]	Speed: 165897.48 samples/sec	accuracy=nan
2021-11-05 20:48:40,863 Node[0] Epoch[19] Batch [300-320]	Speed: 166329.31 samples/sec	accuracy=nan
2021-11-05 20:48:41,259 Node[0] Epoch[19] Batch [320-340]	Speed: 164871.25 samples/sec	accuracy=nan
2021-11-05 20:48:41,656 Node[0] Epoch[19] Batch [340-360]	Speed: 164385.34 samples/sec	accuracy=nan
2021-11-05 20:48:42,054 Node[0] Epoch[19] Batch [360-380]	Speed: 164195.77 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145322291, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 20}}
2021-11-05 20:48:42,291 Node[0] Epoch[19] Time cost=7.719
:::MLLOG {"namespace": "", "time_ms": 1636145322292, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165976.14612809088}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1636145322292, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165976.14612809088, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145322292, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 21}}
2021-11-05 20:48:42,702 Node[0] Epoch[20] Batch [0-20]	Speed: 166779.45 samples/sec	accuracy=nan
2021-11-05 20:48:43,097 Node[0] Epoch[20] Batch [20-40]	Speed: 165101.10 samples/sec	accuracy=nan
2021-11-05 20:48:43,490 Node[0] Epoch[20] Batch [40-60]	Speed: 166368.63 samples/sec	accuracy=nan
2021-11-05 20:48:43,885 Node[0] Epoch[20] Batch [60-80]	Speed: 165168.13 samples/sec	accuracy=nan
2021-11-05 20:48:44,278 Node[0] Epoch[20] Batch [80-100]	Speed: 166266.29 samples/sec	accuracy=nan
2021-11-05 20:48:44,670 Node[0] Epoch[20] Batch [100-120]	Speed: 166207.35 samples/sec	accuracy=nan
2021-11-05 20:48:45,062 Node[0] Epoch[20] Batch [120-140]	Speed: 166747.97 samples/sec	accuracy=nan
2021-11-05 20:48:45,456 Node[0] Epoch[20] Batch [140-160]	Speed: 165717.15 samples/sec	accuracy=nan
2021-11-05 20:48:45,849 Node[0] Epoch[20] Batch [160-180]	Speed: 166159.13 samples/sec	accuracy=nan
2021-11-05 20:48:46,241 Node[0] Epoch[20] Batch [180-200]	Speed: 166301.43 samples/sec	accuracy=nan
2021-11-05 20:48:46,637 Node[0] Epoch[20] Batch [200-220]	Speed: 165058.11 samples/sec	accuracy=nan
2021-11-05 20:48:47,031 Node[0] Epoch[20] Batch [220-240]	Speed: 165593.77 samples/sec	accuracy=nan
2021-11-05 20:48:47,424 Node[0] Epoch[20] Batch [240-260]	Speed: 166079.31 samples/sec	accuracy=nan
2021-11-05 20:48:47,818 Node[0] Epoch[20] Batch [260-280]	Speed: 165519.59 samples/sec	accuracy=nan
2021-11-05 20:48:48,211 Node[0] Epoch[20] Batch [280-300]	Speed: 166172.14 samples/sec	accuracy=nan
2021-11-05 20:48:48,604 Node[0] Epoch[20] Batch [300-320]	Speed: 166180.51 samples/sec	accuracy=nan
2021-11-05 20:48:48,999 Node[0] Epoch[20] Batch [320-340]	Speed: 165150.00 samples/sec	accuracy=nan
2021-11-05 20:48:49,403 Node[0] Epoch[20] Batch [340-360]	Speed: 161683.47 samples/sec	accuracy=nan
2021-11-05 20:48:49,801 Node[0] Epoch[20] Batch [360-380]	Speed: 164074.94 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145330037, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 21}}
2021-11-05 20:48:50,038 Node[0] Epoch[20] Time cost=7.746
:::MLLOG {"namespace": "", "time_ms": 1636145330038, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165405.47869140893}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 21}}
:::MLLOG {"namespace": "", "time_ms": 1636145330038, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165405.47869140893, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145330038, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 22}}
2021-11-05 20:48:50,450 Node[0] Epoch[21] Batch [0-20]	Speed: 166258.62 samples/sec	accuracy=nan
2021-11-05 20:48:50,843 Node[0] Epoch[21] Batch [20-40]	Speed: 165934.07 samples/sec	accuracy=nan
2021-11-05 20:48:51,237 Node[0] Epoch[21] Batch [40-60]	Speed: 165676.84 samples/sec	accuracy=nan
2021-11-05 20:48:51,631 Node[0] Epoch[21] Batch [60-80]	Speed: 165761.69 samples/sec	accuracy=nan
2021-11-05 20:48:52,024 Node[0] Epoch[21] Batch [80-100]	Speed: 166073.07 samples/sec	accuracy=nan
2021-11-05 20:48:52,418 Node[0] Epoch[21] Batch [100-120]	Speed: 165683.05 samples/sec	accuracy=nan
2021-11-05 20:48:52,810 Node[0] Epoch[21] Batch [120-140]	Speed: 166427.08 samples/sec	accuracy=nan
2021-11-05 20:48:53,204 Node[0] Epoch[21] Batch [140-160]	Speed: 165935.48 samples/sec	accuracy=nan
2021-11-05 20:48:53,597 Node[0] Epoch[21] Batch [160-180]	Speed: 165878.88 samples/sec	accuracy=nan
2021-11-05 20:48:53,989 Node[0] Epoch[21] Batch [180-200]	Speed: 166526.68 samples/sec	accuracy=nan
2021-11-05 20:48:54,383 Node[0] Epoch[21] Batch [200-220]	Speed: 165692.68 samples/sec	accuracy=nan
2021-11-05 20:48:54,776 Node[0] Epoch[21] Batch [220-240]	Speed: 166241.76 samples/sec	accuracy=nan
2021-11-05 20:48:55,170 Node[0] Epoch[21] Batch [240-260]	Speed: 165569.04 samples/sec	accuracy=nan
2021-11-05 20:48:55,563 Node[0] Epoch[21] Batch [260-280]	Speed: 166137.96 samples/sec	accuracy=nan
2021-11-05 20:48:55,957 Node[0] Epoch[21] Batch [280-300]	Speed: 165499.18 samples/sec	accuracy=nan
2021-11-05 20:48:56,350 Node[0] Epoch[21] Batch [300-320]	Speed: 166210.98 samples/sec	accuracy=nan
2021-11-05 20:48:56,744 Node[0] Epoch[21] Batch [320-340]	Speed: 165557.52 samples/sec	accuracy=nan
2021-11-05 20:48:57,141 Node[0] Epoch[21] Batch [340-360]	Speed: 164520.16 samples/sec	accuracy=nan
2021-11-05 20:48:57,545 Node[0] Epoch[21] Batch [360-380]	Speed: 161658.84 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145337780, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 22}}
2021-11-05 20:48:57,780 Node[0] Epoch[21] Time cost=7.742
:::MLLOG {"namespace": "", "time_ms": 1636145337780, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165473.52220059917}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 22}}
:::MLLOG {"namespace": "", "time_ms": 1636145337781, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165473.52220059917, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145337781, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 23}}
2021-11-05 20:48:58,194 Node[0] Epoch[22] Batch [0-20]	Speed: 165541.51 samples/sec	accuracy=nan
2021-11-05 20:48:58,586 Node[0] Epoch[22] Batch [20-40]	Speed: 166568.62 samples/sec	accuracy=nan
2021-11-05 20:48:58,979 Node[0] Epoch[22] Batch [40-60]	Speed: 166273.76 samples/sec	accuracy=nan
2021-11-05 20:48:59,373 Node[0] Epoch[22] Batch [60-80]	Speed: 165668.92 samples/sec	accuracy=nan
2021-11-05 20:48:59,769 Node[0] Epoch[22] Batch [80-100]	Speed: 164988.48 samples/sec	accuracy=nan
2021-11-05 20:49:00,163 Node[0] Epoch[22] Batch [100-120]	Speed: 165312.93 samples/sec	accuracy=nan
2021-11-05 20:49:00,554 Node[0] Epoch[22] Batch [120-140]	Speed: 167019.65 samples/sec	accuracy=nan
2021-11-05 20:49:00,948 Node[0] Epoch[22] Batch [140-160]	Speed: 165990.81 samples/sec	accuracy=nan
2021-11-05 20:49:01,340 Node[0] Epoch[22] Batch [160-180]	Speed: 166332.24 samples/sec	accuracy=nan
2021-11-05 20:49:01,732 Node[0] Epoch[22] Batch [180-200]	Speed: 166427.89 samples/sec	accuracy=nan
2021-11-05 20:49:02,126 Node[0] Epoch[22] Batch [200-220]	Speed: 165807.36 samples/sec	accuracy=nan
2021-11-05 20:49:02,519 Node[0] Epoch[22] Batch [220-240]	Speed: 165908.23 samples/sec	accuracy=nan
2021-11-05 20:49:02,914 Node[0] Epoch[22] Batch [240-260]	Speed: 165325.01 samples/sec	accuracy=nan
2021-11-05 20:49:03,308 Node[0] Epoch[22] Batch [260-280]	Speed: 166018.79 samples/sec	accuracy=nan
2021-11-05 20:49:03,702 Node[0] Epoch[22] Batch [280-300]	Speed: 165421.09 samples/sec	accuracy=nan
2021-11-05 20:49:04,099 Node[0] Epoch[22] Batch [300-320]	Speed: 164639.67 samples/sec	accuracy=nan
2021-11-05 20:49:04,495 Node[0] Epoch[22] Batch [320-340]	Speed: 164623.93 samples/sec	accuracy=nan
2021-11-05 20:49:04,894 Node[0] Epoch[22] Batch [340-360]	Speed: 163873.24 samples/sec	accuracy=nan
2021-11-05 20:49:05,291 Node[0] Epoch[22] Batch [360-380]	Speed: 164084.58 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145345528, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 23}}
2021-11-05 20:49:05,528 Node[0] Epoch[22] Time cost=7.747
:::MLLOG {"namespace": "", "time_ms": 1636145345528, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165365.2565177763}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636145345528, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165365.2565177763, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145345545, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 23}}
2021-11-05 20:49:05,655 Node[0] Epoch[22] Validation-accuracy=0.718310
2021-11-05 20:49:05,655 Node[0] Epoch[22] Validation-correct-count=561.000000
2021-11-05 20:49:05,655 Node[0] Epoch[22] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636145345675, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636145345675, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.70046, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636145345675, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1636145345675, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 24, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636145345675, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 24}}
2021-11-05 20:49:06,073 Node[0] Epoch[23] Batch [0-20]	Speed: 165965.76 samples/sec	accuracy=nan
2021-11-05 20:49:06,467 Node[0] Epoch[23] Batch [20-40]	Speed: 165843.72 samples/sec	accuracy=nan
2021-11-05 20:49:06,859 Node[0] Epoch[23] Batch [40-60]	Speed: 166635.42 samples/sec	accuracy=nan
2021-11-05 20:49:07,250 Node[0] Epoch[23] Batch [60-80]	Speed: 166598.21 samples/sec	accuracy=nan
2021-11-05 20:49:07,643 Node[0] Epoch[23] Batch [80-100]	Speed: 166224.80 samples/sec	accuracy=nan
2021-11-05 20:49:08,036 Node[0] Epoch[23] Batch [100-120]	Speed: 166024.73 samples/sec	accuracy=nan
2021-11-05 20:49:08,427 Node[0] Epoch[23] Batch [120-140]	Speed: 167048.08 samples/sec	accuracy=nan
2021-11-05 20:49:08,820 Node[0] Epoch[23] Batch [140-160]	Speed: 166303.55 samples/sec	accuracy=nan
2021-11-05 20:49:09,212 Node[0] Epoch[23] Batch [160-180]	Speed: 166556.16 samples/sec	accuracy=nan
2021-11-05 20:49:09,608 Node[0] Epoch[23] Batch [180-200]	Speed: 164575.84 samples/sec	accuracy=nan
2021-11-05 20:49:10,004 Node[0] Epoch[23] Batch [200-220]	Speed: 164978.54 samples/sec	accuracy=nan
2021-11-05 20:49:10,396 Node[0] Epoch[23] Batch [220-240]	Speed: 166482.53 samples/sec	accuracy=nan
2021-11-05 20:49:10,791 Node[0] Epoch[23] Batch [240-260]	Speed: 165422.39 samples/sec	accuracy=nan
2021-11-05 20:49:11,185 Node[0] Epoch[23] Batch [260-280]	Speed: 165656.79 samples/sec	accuracy=nan
2021-11-05 20:49:11,576 Node[0] Epoch[23] Batch [280-300]	Speed: 166715.78 samples/sec	accuracy=nan
2021-11-05 20:49:11,973 Node[0] Epoch[23] Batch [300-320]	Speed: 164749.04 samples/sec	accuracy=nan
2021-11-05 20:49:12,371 Node[0] Epoch[23] Batch [320-340]	Speed: 163925.34 samples/sec	accuracy=nan
2021-11-05 20:49:12,776 Node[0] Epoch[23] Batch [340-360]	Speed: 161030.87 samples/sec	accuracy=nan
2021-11-05 20:49:13,172 Node[0] Epoch[23] Batch [360-380]	Speed: 165059.30 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145353407, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 24}}
2021-11-05 20:49:13,407 Node[0] Epoch[23] Time cost=7.732
:::MLLOG {"namespace": "", "time_ms": 1636145353407, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165697.46872038546}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 24}}
:::MLLOG {"namespace": "", "time_ms": 1636145353408, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165697.46872038546, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145353408, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 25}}
2021-11-05 20:49:13,826 Node[0] Epoch[24] Batch [0-20]	Speed: 171223.70 samples/sec	accuracy=nan
2021-11-05 20:49:14,221 Node[0] Epoch[24] Batch [20-40]	Speed: 165445.28 samples/sec	accuracy=nan
2021-11-05 20:49:14,612 Node[0] Epoch[24] Batch [40-60]	Speed: 166777.22 samples/sec	accuracy=nan
2021-11-05 20:49:15,005 Node[0] Epoch[24] Batch [60-80]	Speed: 166344.37 samples/sec	accuracy=nan
2021-11-05 20:49:15,399 Node[0] Epoch[24] Batch [80-100]	Speed: 165610.20 samples/sec	accuracy=nan
2021-11-05 20:49:15,791 Node[0] Epoch[24] Batch [100-120]	Speed: 166698.43 samples/sec	accuracy=nan
2021-11-05 20:49:16,184 Node[0] Epoch[24] Batch [120-140]	Speed: 165789.29 samples/sec	accuracy=nan
2021-11-05 20:49:16,575 Node[0] Epoch[24] Batch [140-160]	Speed: 167190.17 samples/sec	accuracy=nan
2021-11-05 20:49:16,967 Node[0] Epoch[24] Batch [160-180]	Speed: 166323.66 samples/sec	accuracy=nan
2021-11-05 20:49:17,360 Node[0] Epoch[24] Batch [180-200]	Speed: 166381.16 samples/sec	accuracy=nan
2021-11-05 20:49:17,752 Node[0] Epoch[24] Batch [200-220]	Speed: 166367.62 samples/sec	accuracy=nan
2021-11-05 20:49:18,146 Node[0] Epoch[24] Batch [220-240]	Speed: 165912.46 samples/sec	accuracy=nan
2021-11-05 20:49:18,537 Node[0] Epoch[24] Batch [240-260]	Speed: 166569.03 samples/sec	accuracy=nan
2021-11-05 20:49:18,932 Node[0] Epoch[24] Batch [260-280]	Speed: 165276.31 samples/sec	accuracy=nan
2021-11-05 20:49:19,323 Node[0] Epoch[24] Batch [280-300]	Speed: 166960.07 samples/sec	accuracy=nan
2021-11-05 20:49:19,717 Node[0] Epoch[24] Batch [300-320]	Speed: 165708.02 samples/sec	accuracy=nan
2021-11-05 20:49:20,115 Node[0] Epoch[24] Batch [320-340]	Speed: 164156.00 samples/sec	accuracy=nan
2021-11-05 20:49:20,510 Node[0] Epoch[24] Batch [340-360]	Speed: 165127.49 samples/sec	accuracy=nan
2021-11-05 20:49:20,906 Node[0] Epoch[24] Batch [360-380]	Speed: 164982.12 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145361142, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 25}}
2021-11-05 20:49:21,142 Node[0] Epoch[24] Time cost=7.734
:::MLLOG {"namespace": "", "time_ms": 1636145361142, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165649.3117191594}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 25}}
:::MLLOG {"namespace": "", "time_ms": 1636145361142, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165649.3117191594, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145361142, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 26}}
2021-11-05 20:49:21,554 Node[0] Epoch[25] Batch [0-20]	Speed: 166443.16 samples/sec	accuracy=nan
2021-11-05 20:49:21,947 Node[0] Epoch[25] Batch [20-40]	Speed: 166304.77 samples/sec	accuracy=nan
2021-11-05 20:49:22,340 Node[0] Epoch[25] Batch [40-60]	Speed: 166096.64 samples/sec	accuracy=nan
2021-11-05 20:49:22,732 Node[0] Epoch[25] Batch [60-80]	Speed: 166288.20 samples/sec	accuracy=nan
2021-11-05 20:49:23,125 Node[0] Epoch[25] Batch [80-100]	Speed: 166005.20 samples/sec	accuracy=nan
2021-11-05 20:49:23,517 Node[0] Epoch[25] Batch [100-120]	Speed: 166900.64 samples/sec	accuracy=nan
2021-11-05 20:49:23,912 Node[0] Epoch[25] Batch [120-140]	Speed: 165271.92 samples/sec	accuracy=nan
2021-11-05 20:49:24,303 Node[0] Epoch[25] Batch [140-160]	Speed: 166697.72 samples/sec	accuracy=nan
2021-11-05 20:49:24,695 Node[0] Epoch[25] Batch [160-180]	Speed: 166645.77 samples/sec	accuracy=nan
2021-11-05 20:49:25,090 Node[0] Epoch[25] Batch [180-200]	Speed: 165042.09 samples/sec	accuracy=nan
2021-11-05 20:49:25,488 Node[0] Epoch[25] Batch [200-220]	Speed: 164272.22 samples/sec	accuracy=nan
2021-11-05 20:49:25,883 Node[0] Epoch[25] Batch [220-240]	Speed: 165274.91 samples/sec	accuracy=nan
2021-11-05 20:49:26,277 Node[0] Epoch[25] Batch [240-260]	Speed: 165722.26 samples/sec	accuracy=nan
2021-11-05 20:49:26,670 Node[0] Epoch[25] Batch [260-280]	Speed: 165801.54 samples/sec	accuracy=nan
2021-11-05 20:49:27,064 Node[0] Epoch[25] Batch [280-300]	Speed: 165697.69 samples/sec	accuracy=nan
2021-11-05 20:49:27,459 Node[0] Epoch[25] Batch [300-320]	Speed: 165537.91 samples/sec	accuracy=nan
2021-11-05 20:49:27,854 Node[0] Epoch[25] Batch [320-340]	Speed: 165076.32 samples/sec	accuracy=nan
2021-11-05 20:49:28,251 Node[0] Epoch[25] Batch [340-360]	Speed: 164472.73 samples/sec	accuracy=nan
2021-11-05 20:49:28,651 Node[0] Epoch[25] Batch [360-380]	Speed: 163385.48 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145368888, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 26}}
2021-11-05 20:49:28,889 Node[0] Epoch[25] Time cost=7.746
:::MLLOG {"namespace": "", "time_ms": 1636145368889, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165394.09518537816}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 26}}
:::MLLOG {"namespace": "", "time_ms": 1636145368889, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165394.09518537816, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145368889, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 27}}
2021-11-05 20:49:29,303 Node[0] Epoch[26] Batch [0-20]	Speed: 165363.95 samples/sec	accuracy=nan
2021-11-05 20:49:29,695 Node[0] Epoch[26] Batch [20-40]	Speed: 166427.69 samples/sec	accuracy=nan
2021-11-05 20:49:30,089 Node[0] Epoch[26] Batch [40-60]	Speed: 165396.01 samples/sec	accuracy=nan
2021-11-05 20:49:30,482 Node[0] Epoch[26] Batch [60-80]	Speed: 166162.16 samples/sec	accuracy=nan
2021-11-05 20:49:30,875 Node[0] Epoch[26] Batch [80-100]	Speed: 166467.15 samples/sec	accuracy=nan
2021-11-05 20:49:31,267 Node[0] Epoch[26] Batch [100-120]	Speed: 166433.96 samples/sec	accuracy=nan
2021-11-05 20:49:31,659 Node[0] Epoch[26] Batch [120-140]	Speed: 166514.32 samples/sec	accuracy=nan
2021-11-05 20:49:32,052 Node[0] Epoch[26] Batch [140-160]	Speed: 166215.62 samples/sec	accuracy=nan
2021-11-05 20:49:32,446 Node[0] Epoch[26] Batch [160-180]	Speed: 165616.31 samples/sec	accuracy=nan
2021-11-05 20:49:32,839 Node[0] Epoch[26] Batch [180-200]	Speed: 165964.85 samples/sec	accuracy=nan
2021-11-05 20:49:33,232 Node[0] Epoch[26] Batch [200-220]	Speed: 166115.28 samples/sec	accuracy=nan
2021-11-05 20:49:33,625 Node[0] Epoch[26] Batch [220-240]	Speed: 166070.25 samples/sec	accuracy=nan
2021-11-05 20:49:34,017 Node[0] Epoch[26] Batch [240-260]	Speed: 166676.10 samples/sec	accuracy=nan
2021-11-05 20:49:34,409 Node[0] Epoch[26] Batch [260-280]	Speed: 166277.50 samples/sec	accuracy=nan
2021-11-05 20:49:34,802 Node[0] Epoch[26] Batch [280-300]	Speed: 166082.03 samples/sec	accuracy=nan
2021-11-05 20:49:35,199 Node[0] Epoch[26] Batch [300-320]	Speed: 164591.57 samples/sec	accuracy=nan
2021-11-05 20:49:35,595 Node[0] Epoch[26] Batch [320-340]	Speed: 164779.57 samples/sec	accuracy=nan
2021-11-05 20:49:35,994 Node[0] Epoch[26] Batch [340-360]	Speed: 163887.66 samples/sec	accuracy=nan
2021-11-05 20:49:36,390 Node[0] Epoch[26] Batch [360-380]	Speed: 164520.76 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145376625, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 27}}
2021-11-05 20:49:36,626 Node[0] Epoch[26] Time cost=7.737
:::MLLOG {"namespace": "", "time_ms": 1636145376626, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165598.24828785477}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636145376626, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165598.24828785477, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145376642, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 27}}
2021-11-05 20:49:36,759 Node[0] Epoch[26] Validation-accuracy=0.725992
2021-11-05 20:49:36,759 Node[0] Epoch[26] Validation-correct-count=567.000000
2021-11-05 20:49:36,759 Node[0] Epoch[26] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636145376778, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636145376779, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.72336, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636145376779, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1636145376779, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 28, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636145376779, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 28}}
2021-11-05 20:49:37,174 Node[0] Epoch[27] Batch [0-20]	Speed: 167630.82 samples/sec	accuracy=nan
2021-11-05 20:49:37,569 Node[0] Epoch[27] Batch [20-40]	Speed: 165119.03 samples/sec	accuracy=nan
2021-11-05 20:49:37,960 Node[0] Epoch[27] Batch [40-60]	Speed: 166776.00 samples/sec	accuracy=nan
2021-11-05 20:49:38,353 Node[0] Epoch[27] Batch [60-80]	Speed: 166156.31 samples/sec	accuracy=nan
2021-11-05 20:49:38,746 Node[0] Epoch[27] Batch [80-100]	Speed: 166315.88 samples/sec	accuracy=nan
2021-11-05 20:49:39,141 Node[0] Epoch[27] Batch [100-120]	Speed: 165119.92 samples/sec	accuracy=nan
2021-11-05 20:49:39,533 Node[0] Epoch[27] Batch [120-140]	Speed: 166702.99 samples/sec	accuracy=nan
2021-11-05 20:49:39,925 Node[0] Epoch[27] Batch [140-160]	Speed: 166448.22 samples/sec	accuracy=nan
2021-11-05 20:49:40,317 Node[0] Epoch[27] Batch [160-180]	Speed: 166546.23 samples/sec	accuracy=nan
2021-11-05 20:49:40,711 Node[0] Epoch[27] Batch [180-200]	Speed: 165711.73 samples/sec	accuracy=nan
2021-11-05 20:49:41,103 Node[0] Epoch[27] Batch [200-220]	Speed: 166452.78 samples/sec	accuracy=nan
2021-11-05 20:49:41,497 Node[0] Epoch[27] Batch [220-240]	Speed: 165654.38 samples/sec	accuracy=nan
2021-11-05 20:49:41,889 Node[0] Epoch[27] Batch [240-260]	Speed: 166680.26 samples/sec	accuracy=nan
2021-11-05 20:49:42,281 Node[0] Epoch[27] Batch [260-280]	Speed: 166394.81 samples/sec	accuracy=nan
2021-11-05 20:49:42,674 Node[0] Epoch[27] Batch [280-300]	Speed: 166029.96 samples/sec	accuracy=nan
2021-11-05 20:49:43,069 Node[0] Epoch[27] Batch [300-320]	Speed: 165219.76 samples/sec	accuracy=nan
2021-11-05 20:49:43,464 Node[0] Epoch[27] Batch [320-340]	Speed: 165460.18 samples/sec	accuracy=nan
2021-11-05 20:49:43,861 Node[0] Epoch[27] Batch [340-360]	Speed: 164258.81 samples/sec	accuracy=nan
2021-11-05 20:49:44,258 Node[0] Epoch[27] Batch [360-380]	Speed: 164384.94 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145384495, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 28}}
2021-11-05 20:49:44,495 Node[0] Epoch[27] Time cost=7.716
:::MLLOG {"namespace": "", "time_ms": 1636145384495, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 166044.3316900613}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 28}}
:::MLLOG {"namespace": "", "time_ms": 1636145384495, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 166044.3316900613, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145384495, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 29}}
2021-11-05 20:49:44,907 Node[0] Epoch[28] Batch [0-20]	Speed: 166254.68 samples/sec	accuracy=nan
2021-11-05 20:49:45,299 Node[0] Epoch[28] Batch [20-40]	Speed: 166340.83 samples/sec	accuracy=nan
2021-11-05 20:49:45,692 Node[0] Epoch[28] Batch [40-60]	Speed: 166090.09 samples/sec	accuracy=nan
2021-11-05 20:49:46,085 Node[0] Epoch[28] Batch [60-80]	Speed: 166392.19 samples/sec	accuracy=nan
2021-11-05 20:49:46,478 Node[0] Epoch[28] Batch [80-100]	Speed: 165961.43 samples/sec	accuracy=nan
2021-11-05 20:49:46,870 Node[0] Epoch[28] Batch [100-120]	Speed: 166701.37 samples/sec	accuracy=nan
2021-11-05 20:49:47,263 Node[0] Epoch[28] Batch [120-140]	Speed: 166063.90 samples/sec	accuracy=nan
2021-11-05 20:49:47,657 Node[0] Epoch[28] Batch [140-160]	Speed: 165576.25 samples/sec	accuracy=nan
2021-11-05 20:49:48,051 Node[0] Epoch[28] Batch [160-180]	Speed: 165865.22 samples/sec	accuracy=nan
2021-11-05 20:49:48,446 Node[0] Epoch[28] Batch [180-200]	Speed: 164998.92 samples/sec	accuracy=nan
2021-11-05 20:49:48,838 Node[0] Epoch[28] Batch [200-220]	Speed: 166486.38 samples/sec	accuracy=nan
2021-11-05 20:49:49,231 Node[0] Epoch[28] Batch [220-240]	Speed: 166192.31 samples/sec	accuracy=nan
2021-11-05 20:49:49,625 Node[0] Epoch[28] Batch [240-260]	Speed: 165778.25 samples/sec	accuracy=nan
2021-11-05 20:49:50,019 Node[0] Epoch[28] Batch [260-280]	Speed: 165648.47 samples/sec	accuracy=nan
2021-11-05 20:49:50,411 Node[0] Epoch[28] Batch [280-300]	Speed: 166421.72 samples/sec	accuracy=nan
2021-11-05 20:49:50,805 Node[0] Epoch[28] Batch [300-320]	Speed: 165671.72 samples/sec	accuracy=nan
2021-11-05 20:49:51,206 Node[0] Epoch[28] Batch [320-340]	Speed: 162923.10 samples/sec	accuracy=nan
2021-11-05 20:49:51,603 Node[0] Epoch[28] Batch [340-360]	Speed: 164334.23 samples/sec	accuracy=nan
2021-11-05 20:49:51,999 Node[0] Epoch[28] Batch [360-380]	Speed: 164809.53 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145392236, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 29}}
2021-11-05 20:49:52,236 Node[0] Epoch[28] Time cost=7.741
:::MLLOG {"namespace": "", "time_ms": 1636145392236, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165508.66350396766}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 29}}
:::MLLOG {"namespace": "", "time_ms": 1636145392236, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165508.66350396766, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145392236, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 30}}
2021-11-05 20:49:52,648 Node[0] Epoch[29] Batch [0-20]	Speed: 166284.46 samples/sec	accuracy=nan
2021-11-05 20:49:53,042 Node[0] Epoch[29] Batch [20-40]	Speed: 165474.98 samples/sec	accuracy=nan
2021-11-05 20:49:53,435 Node[0] Epoch[29] Batch [40-60]	Speed: 166410.59 samples/sec	accuracy=nan
2021-11-05 20:49:53,829 Node[0] Epoch[29] Batch [60-80]	Speed: 165494.58 samples/sec	accuracy=nan
2021-11-05 20:49:54,223 Node[0] Epoch[29] Batch [80-100]	Speed: 165882.10 samples/sec	accuracy=nan
2021-11-05 20:49:54,617 Node[0] Epoch[29] Batch [100-120]	Speed: 165642.86 samples/sec	accuracy=nan
2021-11-05 20:49:55,009 Node[0] Epoch[29] Batch [120-140]	Speed: 166584.23 samples/sec	accuracy=nan
2021-11-05 20:49:55,402 Node[0] Epoch[29] Batch [140-160]	Speed: 165730.59 samples/sec	accuracy=nan
2021-11-05 20:49:55,795 Node[0] Epoch[29] Batch [160-180]	Speed: 166094.22 samples/sec	accuracy=nan
2021-11-05 20:49:56,187 Node[0] Epoch[29] Batch [180-200]	Speed: 166523.94 samples/sec	accuracy=nan
2021-11-05 20:49:56,582 Node[0] Epoch[29] Batch [200-220]	Speed: 165500.48 samples/sec	accuracy=nan
2021-11-05 20:49:56,974 Node[0] Epoch[29] Batch [220-240]	Speed: 166504.91 samples/sec	accuracy=nan
2021-11-05 20:49:57,368 Node[0] Epoch[29] Batch [240-260]	Speed: 165850.25 samples/sec	accuracy=nan
2021-11-05 20:49:57,760 Node[0] Epoch[29] Batch [260-280]	Speed: 166284.87 samples/sec	accuracy=nan
2021-11-05 20:49:58,152 Node[0] Epoch[29] Batch [280-300]	Speed: 166405.43 samples/sec	accuracy=nan
2021-11-05 20:49:58,547 Node[0] Epoch[29] Batch [300-320]	Speed: 165299.85 samples/sec	accuracy=nan
2021-11-05 20:49:58,942 Node[0] Epoch[29] Batch [320-340]	Speed: 165249.27 samples/sec	accuracy=nan
2021-11-05 20:49:59,341 Node[0] Epoch[29] Batch [340-360]	Speed: 163624.21 samples/sec	accuracy=nan
2021-11-05 20:49:59,738 Node[0] Epoch[29] Batch [360-380]	Speed: 164537.17 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145399973, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 30}}
2021-11-05 20:49:59,973 Node[0] Epoch[29] Time cost=7.737
:::MLLOG {"namespace": "", "time_ms": 1636145399973, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165592.80331187832}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 30}}
:::MLLOG {"namespace": "", "time_ms": 1636145399973, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165592.80331187832, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145399973, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 31}}
2021-11-05 20:50:00,385 Node[0] Epoch[30] Batch [0-20]	Speed: 166319.51 samples/sec	accuracy=nan
2021-11-05 20:50:00,779 Node[0] Epoch[30] Batch [20-40]	Speed: 165853.66 samples/sec	accuracy=nan
2021-11-05 20:50:01,172 Node[0] Epoch[30] Batch [40-60]	Speed: 165908.54 samples/sec	accuracy=nan
2021-11-05 20:50:01,568 Node[0] Epoch[30] Batch [60-80]	Speed: 164951.31 samples/sec	accuracy=nan
2021-11-05 20:50:01,960 Node[0] Epoch[30] Batch [80-100]	Speed: 166575.61 samples/sec	accuracy=nan
2021-11-05 20:50:02,353 Node[0] Epoch[30] Batch [100-120]	Speed: 165806.66 samples/sec	accuracy=nan
2021-11-05 20:50:02,746 Node[0] Epoch[30] Batch [120-140]	Speed: 166135.44 samples/sec	accuracy=nan
2021-11-05 20:50:03,139 Node[0] Epoch[30] Batch [140-160]	Speed: 166328.81 samples/sec	accuracy=nan
2021-11-05 20:50:03,530 Node[0] Epoch[30] Batch [160-180]	Speed: 166674.58 samples/sec	accuracy=nan
2021-11-05 20:50:03,925 Node[0] Epoch[30] Batch [180-200]	Speed: 165450.58 samples/sec	accuracy=nan
2021-11-05 20:50:04,318 Node[0] Epoch[30] Batch [200-220]	Speed: 166163.47 samples/sec	accuracy=nan
2021-11-05 20:50:04,713 Node[0] Epoch[30] Batch [220-240]	Speed: 165243.69 samples/sec	accuracy=nan
2021-11-05 20:50:05,107 Node[0] Epoch[30] Batch [240-260]	Speed: 165588.06 samples/sec	accuracy=nan
2021-11-05 20:50:05,500 Node[0] Epoch[30] Batch [260-280]	Speed: 166343.36 samples/sec	accuracy=nan
2021-11-05 20:50:05,891 Node[0] Epoch[30] Batch [280-300]	Speed: 166811.97 samples/sec	accuracy=nan
2021-11-05 20:50:06,286 Node[0] Epoch[30] Batch [300-320]	Speed: 165186.37 samples/sec	accuracy=nan
2021-11-05 20:50:06,680 Node[0] Epoch[30] Batch [320-340]	Speed: 165654.88 samples/sec	accuracy=nan
2021-11-05 20:50:07,080 Node[0] Epoch[30] Batch [340-360]	Speed: 163128.50 samples/sec	accuracy=nan
2021-11-05 20:50:07,476 Node[0] Epoch[30] Batch [360-380]	Speed: 164951.41 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145407711, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 31}}
2021-11-05 20:50:07,711 Node[0] Epoch[30] Time cost=7.738
:::MLLOG {"namespace": "", "time_ms": 1636145407711, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165572.1748472458}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636145407712, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165572.1748472458, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145407728, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 31}}
2021-11-05 20:50:07,844 Node[0] Epoch[30] Validation-accuracy=0.759283
2021-11-05 20:50:07,844 Node[0] Epoch[30] Validation-correct-count=593.000000
2021-11-05 20:50:07,844 Node[0] Epoch[30] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636145407861, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636145407862, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.75344, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636145407862, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1636145407862, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 32, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636145407862, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 32}}
2021-11-05 20:50:08,257 Node[0] Epoch[31] Batch [0-20]	Speed: 167252.88 samples/sec	accuracy=nan
2021-11-05 20:50:08,649 Node[0] Epoch[31] Batch [20-40]	Speed: 166663.12 samples/sec	accuracy=nan
2021-11-05 20:50:09,044 Node[0] Epoch[31] Batch [40-60]	Speed: 165410.60 samples/sec	accuracy=nan
2021-11-05 20:50:09,436 Node[0] Epoch[31] Batch [60-80]	Speed: 166258.31 samples/sec	accuracy=nan
2021-11-05 20:50:09,828 Node[0] Epoch[31] Batch [80-100]	Speed: 166646.07 samples/sec	accuracy=nan
2021-11-05 20:50:10,222 Node[0] Epoch[31] Batch [100-120]	Speed: 165890.74 samples/sec	accuracy=nan
2021-11-05 20:50:10,614 Node[0] Epoch[31] Batch [120-140]	Speed: 166209.26 samples/sec	accuracy=nan
2021-11-05 20:50:11,007 Node[0] Epoch[31] Batch [140-160]	Speed: 166178.29 samples/sec	accuracy=nan
2021-11-05 20:50:11,398 Node[0] Epoch[31] Batch [160-180]	Speed: 166941.24 samples/sec	accuracy=nan
2021-11-05 20:50:11,793 Node[0] Epoch[31] Batch [180-200]	Speed: 165326.60 samples/sec	accuracy=nan
2021-11-05 20:50:12,187 Node[0] Epoch[31] Batch [200-220]	Speed: 165866.52 samples/sec	accuracy=nan
2021-11-05 20:50:12,580 Node[0] Epoch[31] Batch [220-240]	Speed: 166043.86 samples/sec	accuracy=nan
2021-11-05 20:50:12,974 Node[0] Epoch[31] Batch [240-260]	Speed: 165610.90 samples/sec	accuracy=nan
2021-11-05 20:50:13,369 Node[0] Epoch[31] Batch [260-280]	Speed: 165232.52 samples/sec	accuracy=nan
2021-11-05 20:50:13,765 Node[0] Epoch[31] Batch [280-300]	Speed: 164918.82 samples/sec	accuracy=nan
2021-11-05 20:50:14,160 Node[0] Epoch[31] Batch [300-320]	Speed: 165252.56 samples/sec	accuracy=nan
2021-11-05 20:50:14,555 Node[0] Epoch[31] Batch [320-340]	Speed: 165292.97 samples/sec	accuracy=nan
2021-11-05 20:50:14,954 Node[0] Epoch[31] Batch [340-360]	Speed: 163396.99 samples/sec	accuracy=nan
2021-11-05 20:50:15,351 Node[0] Epoch[31] Batch [360-380]	Speed: 164705.23 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145415590, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 32}}
2021-11-05 20:50:15,590 Node[0] Epoch[31] Time cost=7.728
:::MLLOG {"namespace": "", "time_ms": 1636145415590, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165787.67748766567}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 32}}
:::MLLOG {"namespace": "", "time_ms": 1636145415590, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165787.67748766567, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145415590, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 33}}
2021-11-05 20:50:16,003 Node[0] Epoch[32] Batch [0-20]	Speed: 165681.85 samples/sec	accuracy=nan
2021-11-05 20:50:16,397 Node[0] Epoch[32] Batch [20-40]	Speed: 165668.01 samples/sec	accuracy=nan
2021-11-05 20:50:16,791 Node[0] Epoch[32] Batch [40-60]	Speed: 165862.91 samples/sec	accuracy=nan
2021-11-05 20:50:17,184 Node[0] Epoch[32] Batch [60-80]	Speed: 165983.36 samples/sec	accuracy=nan
2021-11-05 20:50:17,577 Node[0] Epoch[32] Batch [80-100]	Speed: 166204.52 samples/sec	accuracy=nan
2021-11-05 20:50:17,969 Node[0] Epoch[32] Batch [100-120]	Speed: 166464.92 samples/sec	accuracy=nan
2021-11-05 20:50:18,361 Node[0] Epoch[32] Batch [120-140]	Speed: 166719.34 samples/sec	accuracy=nan
2021-11-05 20:50:18,756 Node[0] Epoch[32] Batch [140-160]	Speed: 165338.38 samples/sec	accuracy=nan
2021-11-05 20:50:19,148 Node[0] Epoch[32] Batch [160-180]	Speed: 166559.40 samples/sec	accuracy=nan
2021-11-05 20:50:19,540 Node[0] Epoch[32] Batch [180-200]	Speed: 166471.09 samples/sec	accuracy=nan
2021-11-05 20:50:19,933 Node[0] Epoch[32] Batch [200-220]	Speed: 165852.16 samples/sec	accuracy=nan
2021-11-05 20:50:20,326 Node[0] Epoch[32] Batch [220-240]	Speed: 166026.74 samples/sec	accuracy=nan
2021-11-05 20:50:20,719 Node[0] Epoch[32] Batch [240-260]	Speed: 166451.66 samples/sec	accuracy=nan
2021-11-05 20:50:21,114 Node[0] Epoch[32] Batch [260-280]	Speed: 165090.45 samples/sec	accuracy=nan
2021-11-05 20:50:21,505 Node[0] Epoch[32] Batch [280-300]	Speed: 166793.88 samples/sec	accuracy=nan
2021-11-05 20:50:21,899 Node[0] Epoch[32] Batch [300-320]	Speed: 165717.75 samples/sec	accuracy=nan
2021-11-05 20:50:22,296 Node[0] Epoch[32] Batch [320-340]	Speed: 164796.83 samples/sec	accuracy=nan
2021-11-05 20:50:22,693 Node[0] Epoch[32] Batch [340-360]	Speed: 164278.92 samples/sec	accuracy=nan
2021-11-05 20:50:23,091 Node[0] Epoch[32] Batch [360-380]	Speed: 163775.32 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145423326, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 33}}
2021-11-05 20:50:23,326 Node[0] Epoch[32] Time cost=7.736
:::MLLOG {"namespace": "", "time_ms": 1636145423326, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165613.6972306048}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 33}}
:::MLLOG {"namespace": "", "time_ms": 1636145423326, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165613.6972306048, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145423327, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 34}}
2021-11-05 20:50:23,739 Node[0] Epoch[33] Batch [0-20]	Speed: 166062.59 samples/sec	accuracy=nan
2021-11-05 20:50:24,133 Node[0] Epoch[33] Batch [20-40]	Speed: 165723.46 samples/sec	accuracy=nan
2021-11-05 20:50:24,524 Node[0] Epoch[33] Batch [40-60]	Speed: 166867.07 samples/sec	accuracy=nan
2021-11-05 20:50:24,917 Node[0] Epoch[33] Batch [60-80]	Speed: 166274.77 samples/sec	accuracy=nan
2021-11-05 20:50:25,310 Node[0] Epoch[33] Batch [80-100]	Speed: 166015.27 samples/sec	accuracy=nan
2021-11-05 20:50:25,701 Node[0] Epoch[33] Batch [100-120]	Speed: 166992.55 samples/sec	accuracy=nan
2021-11-05 20:50:26,094 Node[0] Epoch[33] Batch [120-140]	Speed: 166336.29 samples/sec	accuracy=nan
2021-11-05 20:50:26,486 Node[0] Epoch[33] Batch [140-160]	Speed: 166353.67 samples/sec	accuracy=nan
2021-11-05 20:50:26,878 Node[0] Epoch[33] Batch [160-180]	Speed: 166498.93 samples/sec	accuracy=nan
2021-11-05 20:50:27,271 Node[0] Epoch[33] Batch [180-200]	Speed: 166265.99 samples/sec	accuracy=nan
2021-11-05 20:50:27,663 Node[0] Epoch[33] Batch [200-220]	Speed: 166187.47 samples/sec	accuracy=nan
2021-11-05 20:50:28,056 Node[0] Epoch[33] Batch [220-240]	Speed: 166309.41 samples/sec	accuracy=nan
2021-11-05 20:50:28,449 Node[0] Epoch[33] Batch [240-260]	Speed: 166160.04 samples/sec	accuracy=nan
2021-11-05 20:50:28,842 Node[0] Epoch[33] Batch [260-280]	Speed: 166177.18 samples/sec	accuracy=nan
2021-11-05 20:50:29,234 Node[0] Epoch[33] Batch [280-300]	Speed: 166272.55 samples/sec	accuracy=nan
2021-11-05 20:50:29,631 Node[0] Epoch[33] Batch [300-320]	Speed: 164667.29 samples/sec	accuracy=nan
2021-11-05 20:50:30,027 Node[0] Epoch[33] Batch [320-340]	Speed: 164666.01 samples/sec	accuracy=nan
2021-11-05 20:50:30,425 Node[0] Epoch[33] Batch [340-360]	Speed: 163992.00 samples/sec	accuracy=nan
2021-11-05 20:50:30,822 Node[0] Epoch[33] Batch [360-380]	Speed: 164733.57 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145431058, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 34}}
2021-11-05 20:50:31,058 Node[0] Epoch[33] Time cost=7.731
:::MLLOG {"namespace": "", "time_ms": 1636145431058, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165708.76627507093}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 34}}
:::MLLOG {"namespace": "", "time_ms": 1636145431058, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165708.76627507093, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145431058, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 35}}
2021-11-05 20:50:31,469 Node[0] Epoch[34] Batch [0-20]	Speed: 166839.11 samples/sec	accuracy=nan
2021-11-05 20:50:31,863 Node[0] Epoch[34] Batch [20-40]	Speed: 165657.89 samples/sec	accuracy=nan
2021-11-05 20:50:32,257 Node[0] Epoch[34] Batch [40-60]	Speed: 165723.77 samples/sec	accuracy=nan
2021-11-05 20:50:32,649 Node[0] Epoch[34] Batch [60-80]	Speed: 166671.54 samples/sec	accuracy=nan
2021-11-05 20:50:33,040 Node[0] Epoch[34] Batch [80-100]	Speed: 166567.61 samples/sec	accuracy=nan
2021-11-05 20:50:33,433 Node[0] Epoch[34] Batch [100-120]	Speed: 166344.07 samples/sec	accuracy=nan
2021-11-05 20:50:33,824 Node[0] Epoch[34] Batch [120-140]	Speed: 166866.66 samples/sec	accuracy=nan
2021-11-05 20:50:34,215 Node[0] Epoch[34] Batch [140-160]	Speed: 166835.65 samples/sec	accuracy=nan
2021-11-05 20:50:34,610 Node[0] Epoch[34] Batch [160-180]	Speed: 165537.10 samples/sec	accuracy=nan
2021-11-05 20:50:35,004 Node[0] Epoch[34] Batch [180-200]	Speed: 165738.71 samples/sec	accuracy=nan
2021-11-05 20:50:35,397 Node[0] Epoch[34] Batch [200-220]	Speed: 165994.43 samples/sec	accuracy=nan
2021-11-05 20:50:35,790 Node[0] Epoch[34] Batch [220-240]	Speed: 166253.77 samples/sec	accuracy=nan
2021-11-05 20:50:36,182 Node[0] Epoch[34] Batch [240-260]	Speed: 166396.84 samples/sec	accuracy=nan
2021-11-05 20:50:36,574 Node[0] Epoch[34] Batch [260-280]	Speed: 166427.89 samples/sec	accuracy=nan
2021-11-05 20:50:36,965 Node[0] Epoch[34] Batch [280-300]	Speed: 166900.53 samples/sec	accuracy=nan
2021-11-05 20:50:37,358 Node[0] Epoch[34] Batch [300-320]	Speed: 166121.33 samples/sec	accuracy=nan
2021-11-05 20:50:37,754 Node[0] Epoch[34] Batch [320-340]	Speed: 165002.11 samples/sec	accuracy=nan
2021-11-05 20:50:38,152 Node[0] Epoch[34] Batch [340-360]	Speed: 164069.24 samples/sec	accuracy=nan
2021-11-05 20:50:38,549 Node[0] Epoch[34] Batch [360-380]	Speed: 164176.87 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636145438785, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 35}}
2021-11-05 20:50:38,785 Node[0] Epoch[34] Time cost=7.727
:::MLLOG {"namespace": "", "time_ms": 1636145438785, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165807.21366905095}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636145438786, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165807.21366905095, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636145438802, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 35}}
2021-11-05 20:50:38,915 Node[0] Epoch[34] Validation-accuracy=0.781050
2021-11-05 20:50:38,915 Node[0] Epoch[34] Validation-correct-count=610.000000
2021-11-05 20:50:38,915 Node[0] Epoch[34] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636145438934, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636145438935, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.76142, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636145438935, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1636145438935, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1051, "status": "success"}}
ENDING TIMING RUN AT 2021-11-05 08:50:58 PM
RESULT,IMAGE_CLASSIFICATION,,429,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:50:58 PM
RESULT,IMAGE_CLASSIFICATION,,429,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:00 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:00 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:01 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:02 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:03 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:04 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:04 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:04 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:04 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:04 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:04 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:04 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:04 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:04 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:04 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:05 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:05 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:06 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:07 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:07 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:07 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:07 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:07 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:07 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:07 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:07 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 08:43:49 PM
ENDING TIMING RUN AT 2021-11-05 08:51:08 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 08:43:49 PM
