+ : DGXA100_multi_8x8x51
+ : /mnt/resource_nvme/mlcommons/v1.1/sqsh_files/resnetv11.sqsh
+ : 1
++ date +%y%m%d%H%M%S%N
+ : 211105210634377695444
+ : 1
+ : /mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data
+ : /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342
+ : ''
+ : ./api_logs
+ TIME_TAGS=0
+ NVTX_FLAG=0
+ echo

+ '[' '!' -z ']'
+ LOGBASE=rsnt50_8x8x51_211105210634377695444
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'
+ readonly _seed_override=
+ _seed_override=
+ readonly _logfile_base=/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342/rsnt50_8x8x51_211105210634377695444
+ _logfile_base=/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342/rsnt50_8x8x51_211105210634377695444
+ readonly _cont_name=image_classification
+ _cont_name=image_classification
+ _cont_mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data:/data,/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342:/results
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/bind.sh:/bm_utils/bind.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/azure.sh:/bm_utils/azure.sh
+ _cont_mounts+=,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh
+ _cont_mounts+=,/opt/microsoft:/opt/microsoft
+ '[' '' -eq 1 ']'
/var/spool/slurmd/job10873/slurm_script: line 48: [: : integer expression expected
++ srun -N1 -n1 bash
/bin/bash: line 2: /etc/dgx-release: No such file or directory
+ MLPERF_HOST_OS='Ubuntu 18.04.5 LTS / ??? ???'
+ export MLPERF_HOST_OS
+ mkdir -p /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342
+ srun --ntasks=8 mkdir -p /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342
+ srun --ntasks=8 --container-image=/mnt/resource_nvme/mlcommons/v1.1/sqsh_files/resnetv11.sqsh --container-name=image_classification true
+ echo 'RUN_NCCL_BW_TEST = 0'
RUN_NCCL_BW_TEST = 0
+ [[ 0 -eq 1 ]]
++ seq 1 1
+ for _experiment_index in $(seq 1 "${NEXP}")
+ tee /mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342/rsnt50_8x8x51_211105210634377695444_1.log
+ echo 'Beginning trial 1 of 1'
Beginning trial 1 of 1
+ srun -N1 -n1 --container-name=image_classification python -c '
import mlperf_log_utils
from mlperf_logging.mllog import constants
mlperf_log_utils.mlperf_submission_log(constants.RESNET)'
:::MLLOG {"namespace": "", "time_ms": 1636146397761, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "resnet", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 70}}
:::MLLOG {"namespace": "", "time_ms": 1636146397768, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "NVIDIA", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 75}}
:::MLLOG {"namespace": "", "time_ms": 1636146397768, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 79}}
:::MLLOG {"namespace": "", "time_ms": 1636146397768, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 83}}
:::MLLOG {"namespace": "", "time_ms": 1636146397768, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "8xSUBMISSION_PLATFORM_PLACEHOLDER", "metadata": {"file": "/workspace/image_classification/mlperf_log_utils.py", "lineno": 87}}
[1636146397.742760] [ip-0A0C0406:94248:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
+ '[' 1 -eq 1 ']'
+ srun --ntasks=8 bash -c 'echo -n '\''Clearing cache on '\'' && hostname && sync && sudo /sbin/sysctl vm.drop_caches=3'
Clearing cache on ip-0A0C0406
Clearing cache on ip-0A0C040C
Clearing cache on ip-0A0C0409
Clearing cache on ip-0A0C0408
Clearing cache on ip-0A0C040F
Clearing cache on ip-0A0C0407
Clearing cache on ip-0A0C040A
Clearing cache on ip-0A0C040D
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
vm.drop_caches = 3
+ srun --ntasks=8 --container-name=image_classification python -c '
from mlperf_logging.mllog import constants
from mlperf_log_utils import mx_resnet_print_event
mx_resnet_print_event(key=constants.CACHE_CLEAR, val=True)'
:::MLLOG {"namespace": "", "time_ms": 1636146402814, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": true, "metadata": {"file": "<string>", "lineno": 4}}
[1636146402.578880] [ip-0A0C040C:91936:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146402.619119] [ip-0A0C040F:92554:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146402.713128] [ip-0A0C040A:92297:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146402.731327] [ip-0A0C0406:94758:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146402.649310] [ip-0A0C0409:91760:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146402.791448] [ip-0A0C0407:92464:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146402.664617] [ip-0A0C040D:92543:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146402.769595] [ip-0A0C0408:92669:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
+ export SEED=20596
+ SEED=20596
+ srun --kill-on-bad-exit=0 --mpi=pmix --ntasks=64 --ntasks-per-node=8 --container-name=image_classification --container-mounts=/mnt/resource_nvme/mlcommons/v1.1/bm_data/resnet_data/prep_data:/data,/mnt/resource_nvme/mlcommons/logs/resnet/8N-m05.210342:/results,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/bind.sh:/bm_utils/bind.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/azure.sh:/bm_utils/azure.sh,/shared/data/mlcommons/training_results_v1.1/Azure-submission/benchmarks/resnet/implementations/mxnet/run_and_time.sh:/bm_utils/run_and_time.sh,/opt/microsoft:/opt/microsoft /bm_utils/run_and_time.sh
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
STARTING TIMING RUN AT 2021-11-05 09:06:44 PM
running benchmark
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 num_sockets = 2 num_nodes=4 cores_per_socket=48
--dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0num_sockets = 2 num_nodes=4 cores_per_socket=48
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=48-71 --membind=2 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=0-23 --membind=0 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
num_sockets = 2 num_nodes=4 cores_per_socket=48
num_sockets = 2 num_nodes=4 cores_per_socket=48
+ exec numactl --physcpubind=24-47 --membind=1 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
+ exec numactl --physcpubind=72-95 --membind=3 -- python train_imagenet.py --gpus 0,1,2,3,4,5,6,7 --batch-size 51 --kv-store horovod --lr 10.5 --mom 0.9 --lr-step-epochs pow2 --lars-eta 0.001 --label-smoothing 0.1 --wd 5.0e-05 --warmup-epochs 2 --eval-period 4 --eval-offset 2 --optimizer sgdwfastlars --network resnet-v1b-fl --num-layers 50 --num-epochs 37 --accuracy-threshold 0.759 --seed 20596 --dtype float16 --disp-batches 20 --image-shape 4,224,224 --fuse-bn-relu 1 --fuse-bn-add-relu 1 --bn-group 1 --min-random-area 0.05 --max-random-area 1.0 --conv-algo 1 --force-tensor-core 1 --input-layout NHWC --conv-layout NHWC --batchnorm-layout NHWC --pooling-layout NHWC --batchnorm-mom 0.9 --batchnorm-eps 1e-5 --data-train /data/train.rec --data-train-idx /data/train.idx --data-val /data/val.rec --data-val-idx /data/val.idx --dali-dont-use-mmap 0 --dali-hw-decoder-load 0.7 --dali-prefetch-queue 3 --dali-nvjpeg-memory-padding 256 --input-batch-multiplier 1 --dali-threads 6 --dali-cache-size 12288 --dali-roi-decode 0 --dali-preallocate-width 5980 --dali-preallocate-height 6430 --dali-tmp-buffer-hint 355568328 --dali-decoder-buffer-hint 1315942 --dali-crop-buffer-hint 165581 --dali-normalize-buffer-hint 441549 --profile 0 --e2e-cuda-graphs 0 --use-dali
:::MLLOG {"namespace": "", "time_ms": 1636146409596, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409596, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409596, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409596, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409596, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409596, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409596, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409596, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409601, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409601, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409601, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409601, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409601, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409602, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409601, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409599, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409602, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409600, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409597, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409597, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409597, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409597, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409597, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409597, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409597, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1636146409597, "event_type": "INTERVAL_START", "key": "init_start", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 120}}
[1636146409.539619] [ip-0A0C0407:93331:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.539743] [ip-0A0C0407:93329:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.576494] [ip-0A0C0407:93326:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.256525] [ip-0A0C040C:92791:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.509469] [ip-0A0C0407:93324:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.344515] [ip-0A0C0407:93327:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.509546] [ip-0A0C0407:93325:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.377739] [ip-0A0C0407:93328:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.576437] [ip-0A0C0407:93332:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.467813] [ip-0A0C040C:92792:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.436808] [ip-0A0C040C:92795:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.464711] [ip-0A0C040C:92793:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.353477] [ip-0A0C040C:92797:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.485583] [ip-0A0C040A:93149:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146409.238528] [ip-0A0C040C:92790:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.464110] [ip-0A0C040C:92789:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.357082] [ip-0A0C040C:92794:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.505895] [ip-0A0C040A:93150:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.408954] [ip-0A0C040A:93146:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.412850] [ip-0A0C0408:93533:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.239350] [ip-0A0C0408:93530:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.491046] [ip-0A0C040F:93424:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146409.482688] [ip-0A0C040A:93151:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.391653] [ip-0A0C040F:93420:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.354066] [ip-0A0C040A:93148:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.459428] [ip-0A0C040A:93145:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.409547] [ip-0A0C0408:93531:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.336718] [ip-0A0C0408:93529:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.530766] [ip-0A0C040F:93425:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.291023] [ip-0A0C040A:93147:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.409408] [ip-0A0C0408:93528:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146409.559202] [ip-0A0C040F:93426:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.507752] [ip-0A0C040A:93152:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.239536] [ip-0A0C0408:93535:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.428383] [ip-0A0C0408:93532:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.340801] [ip-0A0C0408:93534:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.488475] [ip-0A0C040D:93403:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.549367] [ip-0A0C040F:93423:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.504925] [ip-0A0C0406:95630:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.559337] [ip-0A0C040F:93421:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146409.361439] [ip-0A0C0406:95636:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
:::MLLOG {"namespace": "", "time_ms": 1636146422710, "event_type": "POINT_IN_TIME", "key": "seed", "value": 20596, "metadata": {"file": "train_imagenet.py", "lineno": 176}}
[1636146409.493243] [ip-0A0C0406:95634:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.334136] [ip-0A0C040F:93419:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.387190] [ip-0A0C040F:93422:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.439876] [ip-0A0C0406:95633:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.432291] [ip-0A0C040D:93399:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.277854] [ip-0A0C040D:93400:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.414264] [ip-0A0C0409:92613:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[1636146409.304004] [ip-0A0C0406:95632:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.407767] [ip-0A0C0409:92614:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.431579] [ip-0A0C0406:95635:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.490352] [ip-0A0C0406:95631:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.344879] [ip-0A0C040D:93398:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.513485] [ip-0A0C0406:95637:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.456869] [ip-0A0C040D:93401:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.491460] [ip-0A0C040D:93396:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.218017] [ip-0A0C0409:92607:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.471907] [ip-0A0C040D:93402:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.343440] [ip-0A0C040D:93397:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.387460] [ip-0A0C0409:92608:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.413816] [ip-0A0C0409:92612:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.197557] [ip-0A0C0409:92609:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.334475] [ip-0A0C0409:92611:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[1636146409.363261] [ip-0A0C0409:92610:0]          parser.c:1885 UCX  WARN  unused env variable: UCX_IB_ENABLE_CUDA_AFFINITY (set UCX_WARN_UNUSED_ENV_VARS=n to suppress this warning)
[21:07:02] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
NCCL version 2.11.4+cuda11.4

ip-0A0C040A:93150:93346 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92789:92993 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92608:92812 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93420:93622 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93535:93729 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93403:93602 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93329:93527 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95636 - context.c:584] INFO job (ID: 867530953376115587) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95636 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95636 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95636:95830 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93532:93726 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93400:93603 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93148:93350 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92792:92990 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93421:93621 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93328:93528 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92614:92814 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95631 - context.c:584] INFO job (ID: 867530787288323124) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95631 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95631 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95631:95833 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93426:93620 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92613:92813 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93534:93728 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93324:93523 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93147:93348 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93397:93601 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92790:92994 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95630 - context.c:584] INFO job (ID: 867531372231204797) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95630 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95630 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95630:95834 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92612:92817 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93331:93522 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93528:93724 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93151:93344 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93398:93599 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92794:92987 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93419:93625 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95635 - context.c:584] INFO job (ID: 867530503080443065) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95635 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95635 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95635:95831 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92611:92816 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93423:93623 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93327:93524 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93531:93730 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93152:93345 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93402:93597 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92797:92991 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95637 - context.c:584] INFO job (ID: 867531055600803296) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95637 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95637 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95637:95832 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93422:93618 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93325:93529 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93533:93731 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93396:93600 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92793:92989 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92610:92811 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93146:93347 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95632 - context.c:584] INFO job (ID: 867530607311334511) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95632 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95632 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95632:95829 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92607:92815 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93424:93619 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93326:93526 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93529:93727 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93145:93349 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93401:93596 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92795:92992 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95633 - context.c:584] INFO job (ID: 867530538679577735) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95633 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95633 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95633:95828 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93425:93624 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93530:93725 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92609:92818 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93399:93598 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92791:92988 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93332:93525 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93149:93343 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93420:93622 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0409:92608:92812 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040D:93403:93602 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0408:93535:93729 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:93329:93527 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040C:92789:92993 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040A:93150:93346 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
[ip-0A0C0406:0:95634 - context.c:584] INFO job (ID: 867530782275183241) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95634 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95634 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95634:95827 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0406:95636:95830 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0409:92608:92812 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93329:93527 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92789:92993 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93150:93346 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93403:93602 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93420:93622 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93535:93729 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95636 - context.c:584] INFO job (ID: 867530954170797226) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95636 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95636 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95636:95830 [0] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92614:92814 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93421:93621 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93328:93528 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93532:93726 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93148:93350 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92792:92990 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93400:93603 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95631 - context.c:584] INFO job (ID: 867530788102413072) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95631 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95631 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95631:95833 [1] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93534:93728 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93147:93348 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92790:92994 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92613:92813 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93426:93620 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93324:93523 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93397:93601 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95630 - context.c:584] INFO job (ID: 867531371512953903) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95630 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95630 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95630:95834 [2] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93528:93724 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93398:93599 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92612:92817 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92794:92987 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93419:93625 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93331:93522 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93151:93344 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95635 - context.c:584] INFO job (ID: 867530503265962772) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95635 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95635 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95635:95831 [3] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92611:92816 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93423:93623 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93152:93345 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92797:92991 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93327:93524 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93531:93730 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93402:93597 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95637 - context.c:584] INFO job (ID: 867531056599294071) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95637 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95637 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95637:95832 [4] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92610:92811 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93422:93618 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93325:93529 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93533:93731 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93396:93600 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92793:92989 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93146:93347 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95632 - context.c:584] INFO job (ID: 867530607622140960) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95632 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95632 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95632:95829 [5] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92607:92815 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93424:93619 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93145:93349 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93401:93596 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92795:92992 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93326:93526 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93529:93727 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)

[ip-0A0C0406:0:95633 - context.c:584] INFO job (ID: 867530539119967691) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95633 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95633 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95633:95828 [6] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0409:92609:92818 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0407:93332:93525 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0408:93530:93725 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040A:93149:93343 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040D:93399:93598 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92791:92988 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040F:93425:93624 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C040C:92789:92993 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0407:93329:93527 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0408:93535:93729 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040D:93403:93602 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C0409:92608:92812 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040A:93150:93346 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead

ip-0A0C040F:93420:93622 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
[ip-0A0C0406:0:95634 - context.c:584] INFO job (ID: 867530782388879900) resource request quota: ( osts:0 user_data_per_ost:0 max_groups:0 max_qps:1 max_group_channels:1, num_trees:1)
[ip-0A0C0406:0:95634 unique id 0] ERROR No Aggregation Manager (sharp_am) detected in sharp_create_job.

[ip-0A0C0406:0:95634 - context.c:601] ERROR sharp_create_job failed: No Aggregation Manager (sharp_am) detected(-52)

ip-0A0C0406:95634:95827 [7] sharp_plugin.c:288 NCCL WARN NET/IB :SHARP coll init error: Cannot create SHArP job(-11)


ip-0A0C0406:95636:95830 [0] transport.cc:238 NCCL WARN Cannot initialize CollNet, using point-to-point network instead
:::MLLOG {"namespace": "", "time_ms": 1636146495833, "event_type": "POINT_IN_TIME", "key": "model_bn_span", "value": 51, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 309}}
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:21] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636146502108, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "bn0_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502109, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "bn0_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502109, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "conv0_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502109, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 81, "tensor": "fc1_bias"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502110, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 72, "tensor": "fc1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502110, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502110, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502110, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502111, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502112, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502112, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502112, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502112, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502113, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502113, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502113, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502113, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502113, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502114, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502114, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502114, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502114, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502114, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502115, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502115, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502115, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502115, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage1_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502116, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage1_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502116, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502116, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502116, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage1_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502116, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502117, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502117, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502117, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502117, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502118, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502118, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502118, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502118, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502118, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502119, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502119, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502119, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502119, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502119, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502120, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502120, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502120, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502120, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502121, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502121, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502121, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502121, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502121, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502122, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502122, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502122, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502122, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502123, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502123, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502123, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502123, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502123, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502124, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502124, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage2_unit4_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502124, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage2_unit4_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502124, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502124, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502125, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage2_unit4_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502125, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502125, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502125, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502126, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502126, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502126, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502126, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502126, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502127, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502127, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502127, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502127, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502127, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502128, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502128, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502128, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502128, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502129, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502129, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502129, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502129, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502129, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502130, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502130, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502130, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502130, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502131, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502131, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502131, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502131, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit3_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502131, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502132, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502132, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502132, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502132, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit4_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502133, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit4_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502133, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502133, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502133, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit4_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502133, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502134, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502134, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502134, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502134, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit5_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502134, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit5_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502135, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502135, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502135, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit5_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502135, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502135, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502136, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502136, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502136, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage3_unit6_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502136, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage3_unit6_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502137, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502137, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502137, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage3_unit6_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502137, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502137, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502138, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502138, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502138, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502138, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502139, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit1_bn_sc_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502139, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit1_bn_sc_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502139, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502139, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv1sc_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502139, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502140, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit1_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502140, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502140, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502140, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502140, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502141, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit2_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502141, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit2_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502141, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502141, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502141, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit2_conv3_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502142, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn1_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502142, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn1_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502142, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn2_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502142, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn2_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502143, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 91, "tensor": "stage4_unit3_bn3_beta"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502143, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 86, "tensor": "stage4_unit3_bn3_gamma"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502143, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv1_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502143, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv2_weight"}}
:::MLLOG {"namespace": "", "time_ms": 1636146502143, "event_type": "POINT_IN_TIME", "key": "weights_initialization", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 76, "tensor": "stage4_unit3_conv3_weight"}}
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
[21:08:22] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for CPU
:::MLLOG {"namespace": "", "time_ms": 1636146503801, "event_type": "INTERVAL_END", "key": "init_stop", "value": null, "metadata": {"file": "train_imagenet.py", "lineno": 233}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,802 Node[0] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=22367, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,802 Node[6] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=8307, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,802 Node[2] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', 2021-11-05 21:08:23,800 Node[12] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=19423, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=39564, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,802 Node[3] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=40151, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,800 Node[15] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=31330, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,801 Node[13] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=22983, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,801 Node[9] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=37201, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,801 Node[8] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=39081, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,801 Node[11] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=61567, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,801 Node[10] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=62516, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,805 Node[17] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=13231, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:08:23,805 Node[18] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=57345, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,798 Node[51] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=36101, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,803 Node[34] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=57286, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,802 Node[14] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=31655, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:08:23,803 Node[43] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=63739, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:08:23,799 Node[54] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=36231, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,804 Node[40] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=31698, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:08:23,806 Node[22] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=28328, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,804 Node[47] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=12712, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,799 Node[55] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=20368, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:08:23,799 Node[50] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=887, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:08:23,806 Node[19] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=44377, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,804 Node[30] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=21777, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,806 Node[21] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=19454, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,804 Node[33] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=41350, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,804 Node[63] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=30763, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,804 Node[24] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=28836, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
2021-11-05 21:08:23,804 Node[59] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=27329, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,806 Node[23] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=7112, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,805 Node[57] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,804 Node[27] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=22102, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,799 Node[49] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=29400, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=55339, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,804 Node[26] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:08:23,799 Node[48] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=20647, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=65223, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,805 Node[61] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=53853, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,799 Node[52] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=17007, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,804 Node[28] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:08:23,805 Node[37] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:08:23,807 Node[16] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=34822, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=45891, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,805 Node[32] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=14557, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=17192, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,805 Node[35] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='3', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=3, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=14050, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,805 Node[45] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=57938, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,805 Node[41] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=21567, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:08:23,806 Node[60] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=59061, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:08:23,806 Node[44] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=54888, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,808 Node[20] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=15308, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,806 Node[62] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',2021-11-05 21:08:23,806 Node[31] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=33207, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=52324, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,806 Node[29] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=64783, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,806 Node[58] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=64036, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
2021-11-05 21:08:23,806 Node[42] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='2', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=2, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=62318, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,806 Node[39] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC',/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
 kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=27404, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,806 Node[46] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=17550, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,806 Node[25] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=38768, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
2021-11-05 21:08:23,802 Node[53] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=37812, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,807 Node[36] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=12707, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,809 Node[56] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='0', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=0, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=29862, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,809 Node[38] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='6', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=6, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=33644, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,802 Node[4] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='4', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=4, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=20666, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636146503802, "event_type": "POINT_IN_TIME", "key": "sgd_opt_learning_rate_decay_poly_power", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 711}}
:::MLLOG {"namespace": "", "time_ms": 1636146503803, "event_type": "POINT_IN_TIME", "key": "sgd_opt_end_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 712}}
:::MLLOG {"namespace": "", "time_ms": 1636146503803, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_decay_poly_power", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 713}}
:::MLLOG {"namespace": "", "time_ms": 1636146503803, "event_type": "POINT_IN_TIME", "key": "lars_opt_end_learning_rate", "value": 0.0001, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 714}}
:::MLLOG {"namespace": "", "time_ms": 1636146503803, "event_type": "POINT_IN_TIME", "key": "d_batch_size", "value": 51, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1164}}
:::MLLOG {"namespace": "", "time_ms": 1636146503803, "event_type": "POINT_IN_TIME", "key": "s_optimizer", "value": "sgdwfastlars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1165}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,803 Node[1] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='1', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=1, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=34505, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636146503803, "event_type": "POINT_IN_TIME", "key": "s_network", "value": "resnet-v1b-fl", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1166}}
:::MLLOG {"namespace": "", "time_ms": 1636146503803, "event_type": "POINT_IN_TIME", "key": "s_process", "value": "horovod", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1167}}
:::MLLOG {"namespace": "", "time_ms": 1636146503803, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 3264, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1168}}
:::MLLOG {"namespace": "", "time_ms": 1636146503803, "event_type": "POINT_IN_TIME", "key": "s_optimizer", "value": "sgdwfastlars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1169}}
:::MLLOG {"namespace": "", "time_ms": 1636146503803, "event_type": "POINT_IN_TIME", "key": "s_network", "value": "resnet-v1b-fl", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1170}}
:::MLLOG {"namespace": "", "time_ms": 1636146503804, "event_type": "POINT_IN_TIME", "key": "s_process", "value": "horovod", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1171}}
:::MLLOG {"namespace": "", "time_ms": 1636146503804, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1172}}
:::MLLOG {"namespace": "", "time_ms": 1636146503804, "event_type": "POINT_IN_TIME", "key": "opt_name", "value": "lars", "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1178}}
:::MLLOG {"namespace": "", "time_ms": 1636146503804, "event_type": "POINT_IN_TIME", "key": "lars_epsilon", "value": 0, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1180}}
:::MLLOG {"namespace": "", "time_ms": 1636146503804, "event_type": "POINT_IN_TIME", "key": "lars_opt_weight_decay", "value": 5e-05, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1182}}
:::MLLOG {"namespace": "", "time_ms": 1636146503804, "event_type": "POINT_IN_TIME", "key": "lars_opt_momentum", "value": 0.9, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1184}}
:::MLLOG {"namespace": "", "time_ms": 1636146503804, "event_type": "POINT_IN_TIME", "key": "lars_opt_base_learning_rate", "value": 10.5, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1185}}
:::MLLOG {"namespace": "", "time_ms": 1636146503804, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_warmup_epochs", "value": 2, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1186}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,804 Node[5] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='5', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=5, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=667, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
:::MLLOG {"namespace": "", "time_ms": 1636146503804, "event_type": "POINT_IN_TIME", "key": "lars_opt_learning_rate_decay_steps", "value": 37, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1187}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `mxnet_reader` is now deprecated. Use `readers.mxnet` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/usr/local/lib/python3.8/dist-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder` is now deprecated. Use `decoders.image` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
2021-11-05 21:08:23,804 Node[7] start with arguments Namespace(accuracy_threshold=0.759, batch_size=51, batchnorm_eps=1e-05, batchnorm_layout='NHWC', batchnorm_mom=0.9, bn_gamma_init0=False, bn_group=1, conv_algo=1, conv_layout='NHWC', custom_bn_off=0, dali_bytes_per_sample_hint=10485760, dali_cache_size=12288, dali_crop_buffer_hint=165581, dali_decoder_buffer_hint=1315942, dali_dont_use_mmap=0, dali_hw_decoder_load=0.7, dali_normalize_buffer_hint=441549, dali_nvjpeg_memory_padding=256, dali_preallocate_height=6430, dali_preallocate_width=5980, dali_prefetch_queue=3, dali_roi_decode=False, dali_threads=6, dali_tmp_buffer_hint=355568328, data_train='/data/train.rec', data_train_idx='/data/train.idx', data_val='/data/val.rec', data_val_idx='/data/val.idx', disp_batches=20, dtype='float16', e2e_cuda_graphs=0, epoch_size=0, eval_offset=2, eval_period=4, force_tensor_core=1, fuse_bn_add_relu=1, fuse_bn_relu=1, gpus='7', image_shape='4,224,224', initializer='default', input_batch_multiplier=1, input_layout='NHWC', kv_store='horovod', label_smoothing=0.1, lars_eps=0, lars_eta=0.001, lazy_init_sanity=False, local_rank=7, log='', logging_dir='logs', lr=10.5, lr_factor=0.1, lr_step_epochs='pow2', max_random_area=1.0, max_random_aspect_ratio=1.3333333333333333, min_random_area=0.05, min_random_aspect_ratio=0.75, model_prefix=None, mom=0.9, network='resnet-v1b-fl', num_classes=1000, num_epochs=37, num_examples=1281167, num_layers=50, num_val_examples=-1, optimizer='sgdwfastlars', pooling_layout='NHWC', profile=0, profile_server_suffix='', profile_worker_suffix='', resize=256, save_period=1, seed=11280, separ_val=False, top_k=0, use_dali=True, verbose=0, warmup_epochs=2, warmup_strategy='linear', wd=5e-05)
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
[21:08:45] ../src/storage/storage.cc:199: Using Pooled (Naive) StorageManager for GPU
:::MLLOG {"namespace": "", "time_ms": 1636146537957, "event_type": "INTERVAL_START", "key": "run_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1336}}
:::MLLOG {"namespace": "", "time_ms": 1636146537957, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 1281167, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 486}}
:::MLLOG {"namespace": "", "time_ms": 1636146538188, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 50000, "metadata": {"file": "/workspace/image_classification/common/dali.py", "lineno": 508}}
:::MLLOG {"namespace": "", "time_ms": 1636146538188, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 903, "first_epoch_num": 1, "epoch_count": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636146538188, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 1}}
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:08:59,088 Node[0] Epoch[0] Batch [0-20]	Speed: 119184.58 samples/sec	accuracy=nan
2021-11-05 21:08:59,592 Node[0] Epoch[0] Batch [20-40]	Speed: 129693.46 samples/sec	accuracy=nan
2021-11-05 21:09:00,097 Node[0] Epoch[0] Batch [40-60]	Speed: 129204.10 samples/sec	accuracy=nan
2021-11-05 21:09:00,577 Node[0] Epoch[0] Batch [60-80]	Speed: 135948.61 samples/sec	accuracy=nan
2021-11-05 21:09:01,067 Node[0] Epoch[0] Batch [80-100]	Speed: 133233.17 samples/sec	accuracy=nan
2021-11-05 21:09:01,556 Node[0] Epoch[0] Batch [100-120]	Speed: 133597.29 samples/sec	accuracy=nan
2021-11-05 21:09:01,997 Node[0] Epoch[0] Batch [120-140]	Speed: 147988.57 samples/sec	accuracy=nan
2021-11-05 21:09:02,501 Node[0] Epoch[0] Batch [140-160]	Speed: 129361.47 samples/sec	accuracy=nan
2021-11-05 21:09:02,979 Node[0] Epoch[0] Batch [160-180]	Speed: 136597.33 samples/sec	accuracy=nan
2021-11-05 21:09:03,460 Node[0] Epoch[0] Batch [180-200]	Speed: 135886.87 samples/sec	accuracy=nan
2021-11-05 21:09:03,961 Node[0] Epoch[0] Batch [200-220]	Speed: 130298.49 samples/sec	accuracy=nan
2021-11-05 21:09:04,467 Node[0] Epoch[0] Batch [220-240]	Speed: 128824.47 samples/sec	accuracy=nan
2021-11-05 21:09:04,946 Node[0] Epoch[0] Batch [240-260]	Speed: 136499.14 samples/sec	accuracy=nan
2021-11-05 21:09:05,414 Node[0] Epoch[0] Batch [260-280]	Speed: 139353.59 samples/sec	accuracy=nan
2021-11-05 21:09:05,886 Node[0] Epoch[0] Batch [280-300]	Speed: 138345.72 samples/sec	accuracy=nan
2021-11-05 21:09:06,378 Node[0] Epoch[0] Batch [300-320]	Speed: 132746.97 samples/sec	accuracy=nan
2021-11-05 21:09:06,851 Node[0] Epoch[0] Batch [320-340]	Speed: 137837.31 samples/sec	accuracy=nan
2021-11-05 21:09:07,331 Node[0] Epoch[0] Batch [340-360]	Speed: 136131.58 samples/sec	accuracy=nan
2021-11-05 21:09:07,793 Node[0] Epoch[0] Batch [360-380]	Speed: 141127.22 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146548035, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 1}}
2021-11-05 21:09:08,035 Node[0] Epoch[0] Time cost=9.847
:::MLLOG {"namespace": "", "time_ms": 1636146548036, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 130107.08555926915}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 1}}
:::MLLOG {"namespace": "", "time_ms": 1636146548036, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 130107.08555926915, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146548036, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 2}}
2021-11-05 21:09:08,453 Node[0] Epoch[1] Batch [0-20]	Speed: 163971.28 samples/sec	accuracy=nan
2021-11-05 21:09:08,850 Node[0] Epoch[1] Batch [20-40]	Speed: 164255.86 samples/sec	accuracy=nan
2021-11-05 21:09:09,252 Node[0] Epoch[1] Batch [40-60]	Speed: 162521.87 samples/sec	accuracy=nan
2021-11-05 21:09:09,649 Node[0] Epoch[1] Batch [60-80]	Speed: 164552.10 samples/sec	accuracy=nan
2021-11-05 21:09:10,042 Node[0] Epoch[1] Batch [80-100]	Speed: 165922.71 samples/sec	accuracy=nan
2021-11-05 21:09:10,442 Node[0] Epoch[1] Batch [100-120]	Speed: 163484.01 samples/sec	accuracy=nan
2021-11-05 21:09:10,835 Node[0] Epoch[1] Batch [120-140]	Speed: 165723.87 samples/sec	accuracy=nan
2021-11-05 21:09:11,234 Node[0] Epoch[1] Batch [140-160]	Speed: 163628.22 samples/sec	accuracy=nan
2021-11-05 21:09:11,630 Node[0] Epoch[1] Batch [160-180]	Speed: 165028.46 samples/sec	accuracy=nan
2021-11-05 21:09:12,033 Node[0] Epoch[1] Batch [180-200]	Speed: 161904.13 samples/sec	accuracy=nan
2021-11-05 21:09:12,436 Node[0] Epoch[1] Batch [200-220]	Speed: 162030.60 samples/sec	accuracy=nan
2021-11-05 21:09:12,836 Node[0] Epoch[1] Batch [220-240]	Speed: 163275.97 samples/sec	accuracy=nan
2021-11-05 21:09:13,232 Node[0] Epoch[1] Batch [240-260]	Speed: 164634.22 samples/sec	accuracy=nan
2021-11-05 21:09:13,629 Node[0] Epoch[1] Batch [260-280]	Speed: 164692.95 samples/sec	accuracy=nan
2021-11-05 21:09:14,024 Node[0] Epoch[1] Batch [280-300]	Speed: 165223.55 samples/sec	accuracy=nan
2021-11-05 21:09:14,419 Node[0] Epoch[1] Batch [300-320]	Speed: 165094.83 samples/sec	accuracy=nan
2021-11-05 21:09:14,822 Node[0] Epoch[1] Batch [320-340]	Speed: 162219.62 samples/sec	accuracy=nan
2021-11-05 21:09:15,221 Node[0] Epoch[1] Batch [340-360]	Speed: 163350.00 samples/sec	accuracy=nan
2021-11-05 21:09:15,621 Node[0] Epoch[1] Batch [360-380]	Speed: 163399.91 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146555863, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 2}}
2021-11-05 21:09:15,863 Node[0] Epoch[1] Time cost=7.827
:::MLLOG {"namespace": "", "time_ms": 1636146555863, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 163684.04690810514}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 2}}
:::MLLOG {"namespace": "", "time_ms": 1636146555863, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 163684.04690810514, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146555863, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 3}}
2021-11-05 21:09:16,277 Node[0] Epoch[2] Batch [0-20]	Speed: 165442.28 samples/sec	accuracy=nan
2021-11-05 21:09:16,682 Node[0] Epoch[2] Batch [20-40]	Speed: 161300.95 samples/sec	accuracy=nan
2021-11-05 21:09:17,078 Node[0] Epoch[2] Batch [40-60]	Speed: 164560.21 samples/sec	accuracy=nan
2021-11-05 21:09:17,480 Node[0] Epoch[2] Batch [60-80]	Speed: 162418.81 samples/sec	accuracy=nan
2021-11-05 21:09:17,873 Node[0] Epoch[2] Batch [80-100]	Speed: 165984.67 samples/sec	accuracy=nan
2021-11-05 21:09:18,269 Node[0] Epoch[2] Batch [100-120]	Speed: 164910.58 samples/sec	accuracy=nan
2021-11-05 21:09:18,661 Node[0] Epoch[2] Batch [120-140]	Speed: 166522.12 samples/sec	accuracy=nan
2021-11-05 21:09:19,059 Node[0] Epoch[2] Batch [140-160]	Speed: 164207.78 samples/sec	accuracy=nan
2021-11-05 21:09:19,452 Node[0] Epoch[2] Batch [160-180]	Speed: 166001.38 samples/sec	accuracy=nan
2021-11-05 21:09:19,848 Node[0] Epoch[2] Batch [180-200]	Speed: 164907.80 samples/sec	accuracy=nan
2021-11-05 21:09:20,245 Node[0] Epoch[2] Batch [200-220]	Speed: 164282.66 samples/sec	accuracy=nan
2021-11-05 21:09:20,645 Node[0] Epoch[2] Batch [220-240]	Speed: 163381.19 samples/sec	accuracy=nan
2021-11-05 21:09:21,038 Node[0] Epoch[2] Batch [240-260]	Speed: 166191.00 samples/sec	accuracy=nan
2021-11-05 21:09:21,434 Node[0] Epoch[2] Batch [260-280]	Speed: 164525.80 samples/sec	accuracy=nan
2021-11-05 21:09:21,828 Node[0] Epoch[2] Batch [280-300]	Speed: 166087.67 samples/sec	accuracy=nan
2021-11-05 21:09:22,225 Node[0] Epoch[2] Batch [300-320]	Speed: 164257.33 samples/sec	accuracy=nan
2021-11-05 21:09:22,622 Node[0] Epoch[2] Batch [320-340]	Speed: 164351.59 samples/sec	accuracy=nan
2021-11-05 21:09:23,020 Node[0] Epoch[2] Batch [340-360]	Speed: 164205.91 samples/sec	accuracy=nan
2021-11-05 21:09:23,420 Node[0] Epoch[2] Batch [360-380]	Speed: 162932.70 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146563660, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 3}}
2021-11-05 21:09:23,660 Node[0] Epoch[2] Time cost=7.797
:::MLLOG {"namespace": "", "time_ms": 1636146563660, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164324.32321056764}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636146563660, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164324.32321056764, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146563677, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 3}}
2021-11-05 21:09:23,677 Node[0] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,677 Node[6] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,677 Node[7] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,677 Node[4] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,677 Node[5] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,677 Node[1] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,677 Node[2] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,677 Node[3] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[57] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,678 Node[17] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[32] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,671 Node[48] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[24] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[58] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,675 Node[8] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,678 Node[18] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[33] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,671 Node[49] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[40] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[26] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[59] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,675 Node[12] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,678 Node[16] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[34] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,671 Node[51] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[41] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[28] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[61] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,675 Node[13] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,678 Node[19] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[35] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,671 Node[52] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[42] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[29] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[56] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,675 Node[14] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,678 Node[20] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[36] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,671 Node[55] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[43] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[30] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,675 Node[15] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[44] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,677 Node[60] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[62] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,677 Node[63] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[37] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,671 Node[50] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[38] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,671 Node[53] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[45] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[39] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,671 Node[54] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[46] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[47] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[31] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,678 Node[21] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[25] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,675 Node[9] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,678 Node[22] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,676 Node[27] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,675 Node[10] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,678 Node[23] DALI iterator does not support resetting while epoch is not finished. Ignoring...
/usr/local/lib/python3.8/dist-packages/nvidia/dali/plugin/mxnet.py:85: Warning: Please do not use `fill_last_batch` and use `last_batch_policy` instead.
  _DaliBaseIterator.__init__(self,
2021-11-05 21:09:23,675 Node[11] DALI iterator does not support resetting while epoch is not finished. Ignoring...
2021-11-05 21:09:24,089 Node[0] Epoch[2] Validation-accuracy=0.294494
2021-11-05 21:09:24,089 Node[0] Epoch[2] Validation-correct-count=230.000000
2021-11-05 21:09:24,090 Node[0] Epoch[2] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146564185, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636146564185, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.3284, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 3}}
:::MLLOG {"namespace": "", "time_ms": 1636146564185, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 1}}
:::MLLOG {"namespace": "", "time_ms": 1636146564185, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 4, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146564185, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 4}}
2021-11-05 21:09:24,585 Node[0] Epoch[3] Batch [0-20]	Speed: 165359.65 samples/sec	accuracy=nan
2021-11-05 21:09:24,979 Node[0] Epoch[3] Batch [20-40]	Speed: 165300.35 samples/sec	accuracy=nan
2021-11-05 21:09:25,374 Node[0] Epoch[3] Batch [40-60]	Speed: 165577.45 samples/sec	accuracy=nan
2021-11-05 21:09:25,767 Node[0] Epoch[3] Batch [60-80]	Speed: 165915.47 samples/sec	accuracy=nan
2021-11-05 21:09:26,167 Node[0] Epoch[3] Batch [80-100]	Speed: 163392.70 samples/sec	accuracy=nan
2021-11-05 21:09:26,561 Node[0] Epoch[3] Batch [100-120]	Speed: 165534.10 samples/sec	accuracy=nan
2021-11-05 21:09:26,953 Node[0] Epoch[3] Batch [120-140]	Speed: 166633.29 samples/sec	accuracy=nan
2021-11-05 21:09:27,347 Node[0] Epoch[3] Batch [140-160]	Speed: 165691.37 samples/sec	accuracy=nan
2021-11-05 21:09:27,744 Node[0] Epoch[3] Batch [160-180]	Speed: 164540.83 samples/sec	accuracy=nan
2021-11-05 21:09:28,141 Node[0] Epoch[3] Batch [180-200]	Speed: 164422.75 samples/sec	accuracy=nan
2021-11-05 21:09:28,534 Node[0] Epoch[3] Batch [200-220]	Speed: 165720.96 samples/sec	accuracy=nan
2021-11-05 21:09:28,929 Node[0] Epoch[3] Batch [220-240]	Speed: 165369.84 samples/sec	accuracy=nan
2021-11-05 21:09:29,324 Node[0] Epoch[3] Batch [240-260]	Speed: 165185.17 samples/sec	accuracy=nan
2021-11-05 21:09:29,720 Node[0] Epoch[3] Batch [260-280]	Speed: 165064.97 samples/sec	accuracy=nan
2021-11-05 21:09:30,114 Node[0] Epoch[3] Batch [280-300]	Speed: 165685.86 samples/sec	accuracy=nan
2021-11-05 21:09:30,510 Node[0] Epoch[3] Batch [300-320]	Speed: 164760.93 samples/sec	accuracy=nan
2021-11-05 21:09:30,907 Node[0] Epoch[3] Batch [320-340]	Speed: 164279.31 samples/sec	accuracy=nan
2021-11-05 21:09:31,306 Node[0] Epoch[3] Batch [340-360]	Speed: 163753.97 samples/sec	accuracy=nan
2021-11-05 21:09:31,705 Node[0] Epoch[3] Batch [360-380]	Speed: 163690.04 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146571943, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 4}}
2021-11-05 21:09:31,944 Node[0] Epoch[3] Time cost=7.758
:::MLLOG {"namespace": "", "time_ms": 1636146571944, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165138.4001994837}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146571944, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165138.4001994837, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146571944, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 5}}
2021-11-05 21:09:32,357 Node[0] Epoch[4] Batch [0-20]	Speed: 165440.88 samples/sec	accuracy=nan
2021-11-05 21:09:32,751 Node[0] Epoch[4] Batch [20-40]	Speed: 165586.26 samples/sec	accuracy=nan
2021-11-05 21:09:33,149 Node[0] Epoch[4] Batch [40-60]	Speed: 164183.76 samples/sec	accuracy=nan
2021-11-05 21:09:33,543 Node[0] Epoch[4] Batch [60-80]	Speed: 165763.30 samples/sec	accuracy=nan
2021-11-05 21:09:33,935 Node[0] Epoch[4] Batch [80-100]	Speed: 166258.62 samples/sec	accuracy=nan
2021-11-05 21:09:34,329 Node[0] Epoch[4] Batch [100-120]	Speed: 165722.76 samples/sec	accuracy=nan
2021-11-05 21:09:34,725 Node[0] Epoch[4] Batch [120-140]	Speed: 164793.46 samples/sec	accuracy=nan
2021-11-05 21:09:35,122 Node[0] Epoch[4] Batch [140-160]	Speed: 164713.36 samples/sec	accuracy=nan
2021-11-05 21:09:35,517 Node[0] Epoch[4] Batch [160-180]	Speed: 165017.52 samples/sec	accuracy=nan
2021-11-05 21:09:35,919 Node[0] Epoch[4] Batch [180-200]	Speed: 162356.50 samples/sec	accuracy=nan
2021-11-05 21:09:36,314 Node[0] Epoch[4] Batch [200-220]	Speed: 165268.22 samples/sec	accuracy=nan
2021-11-05 21:09:36,710 Node[0] Epoch[4] Batch [220-240]	Speed: 164839.29 samples/sec	accuracy=nan
2021-11-05 21:09:37,103 Node[0] Epoch[4] Batch [240-260]	Speed: 166142.60 samples/sec	accuracy=nan
2021-11-05 21:09:37,496 Node[0] Epoch[4] Batch [260-280]	Speed: 166138.36 samples/sec	accuracy=nan
2021-11-05 21:09:37,892 Node[0] Epoch[4] Batch [280-300]	Speed: 165148.80 samples/sec	accuracy=nan
2021-11-05 21:09:38,284 Node[0] Epoch[4] Batch [300-320]	Speed: 166553.32 samples/sec	accuracy=nan
2021-11-05 21:09:38,679 Node[0] Epoch[4] Batch [320-340]	Speed: 165256.55 samples/sec	accuracy=nan
2021-11-05 21:09:39,075 Node[0] Epoch[4] Batch [340-360]	Speed: 164477.87 samples/sec	accuracy=nan
2021-11-05 21:09:39,476 Node[0] Epoch[4] Batch [360-380]	Speed: 163041.07 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146579716, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 5}}
2021-11-05 21:09:39,716 Node[0] Epoch[4] Time cost=7.772
:::MLLOG {"namespace": "", "time_ms": 1636146579716, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164844.19335299463}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 5}}
:::MLLOG {"namespace": "", "time_ms": 1636146579716, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164844.19335299463, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146579716, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 6}}
2021-11-05 21:09:40,130 Node[0] Epoch[5] Batch [0-20]	Speed: 165394.21 samples/sec	accuracy=nan
2021-11-05 21:09:40,525 Node[0] Epoch[5] Batch [20-40]	Speed: 165024.48 samples/sec	accuracy=nan
2021-11-05 21:09:40,922 Node[0] Epoch[5] Batch [40-60]	Speed: 164651.15 samples/sec	accuracy=nan
2021-11-05 21:09:41,317 Node[0] Epoch[5] Batch [60-80]	Speed: 165201.42 samples/sec	accuracy=nan
2021-11-05 21:09:41,713 Node[0] Epoch[5] Batch [80-100]	Speed: 164897.17 samples/sec	accuracy=nan
2021-11-05 21:09:42,108 Node[0] Epoch[5] Batch [100-120]	Speed: 165179.69 samples/sec	accuracy=nan
2021-11-05 21:09:42,503 Node[0] Epoch[5] Batch [120-140]	Speed: 165297.96 samples/sec	accuracy=nan
2021-11-05 21:09:42,903 Node[0] Epoch[5] Batch [140-160]	Speed: 163127.52 samples/sec	accuracy=nan
2021-11-05 21:09:43,297 Node[0] Epoch[5] Batch [160-180]	Speed: 165635.04 samples/sec	accuracy=nan
2021-11-05 21:09:43,692 Node[0] Epoch[5] Batch [180-200]	Speed: 165387.52 samples/sec	accuracy=nan
2021-11-05 21:09:44,086 Node[0] Epoch[5] Batch [200-220]	Speed: 165554.42 samples/sec	accuracy=nan
2021-11-05 21:09:44,478 Node[0] Epoch[5] Batch [220-240]	Speed: 166726.04 samples/sec	accuracy=nan
2021-11-05 21:09:44,872 Node[0] Epoch[5] Batch [240-260]	Speed: 165685.46 samples/sec	accuracy=nan
2021-11-05 21:09:45,267 Node[0] Epoch[5] Batch [260-280]	Speed: 165063.08 samples/sec	accuracy=nan
2021-11-05 21:09:45,663 Node[0] Epoch[5] Batch [280-300]	Speed: 164922.50 samples/sec	accuracy=nan
2021-11-05 21:09:46,057 Node[0] Epoch[5] Batch [300-320]	Speed: 165854.67 samples/sec	accuracy=nan
2021-11-05 21:09:46,451 Node[0] Epoch[5] Batch [320-340]	Speed: 165560.83 samples/sec	accuracy=nan
2021-11-05 21:09:46,851 Node[0] Epoch[5] Batch [340-360]	Speed: 163183.82 samples/sec	accuracy=nan
2021-11-05 21:09:47,251 Node[0] Epoch[5] Batch [360-380]	Speed: 163429.76 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146587493, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 6}}
2021-11-05 21:09:47,494 Node[0] Epoch[5] Time cost=7.777
:::MLLOG {"namespace": "", "time_ms": 1636146587494, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 164727.84113915463}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 6}}
:::MLLOG {"namespace": "", "time_ms": 1636146587494, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 164727.84113915463, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146587494, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 7}}
2021-11-05 21:09:47,908 Node[0] Epoch[6] Batch [0-20]	Speed: 165146.91 samples/sec	accuracy=nan
2021-11-05 21:09:48,304 Node[0] Epoch[6] Batch [20-40]	Speed: 164858.05 samples/sec	accuracy=nan
2021-11-05 21:09:48,697 Node[0] Epoch[6] Batch [40-60]	Speed: 166150.97 samples/sec	accuracy=nan
2021-11-05 21:09:49,090 Node[0] Epoch[6] Batch [60-80]	Speed: 166030.87 samples/sec	accuracy=nan
2021-11-05 21:09:49,483 Node[0] Epoch[6] Batch [80-100]	Speed: 166025.43 samples/sec	accuracy=nan
2021-11-05 21:09:49,876 Node[0] Epoch[6] Batch [100-120]	Speed: 166485.16 samples/sec	accuracy=nan
2021-11-05 21:09:50,271 Node[0] Epoch[6] Batch [120-140]	Speed: 165209.99 samples/sec	accuracy=nan
2021-11-05 21:09:50,665 Node[0] Epoch[6] Batch [140-160]	Speed: 165594.17 samples/sec	accuracy=nan
2021-11-05 21:09:51,058 Node[0] Epoch[6] Batch [160-180]	Speed: 166205.73 samples/sec	accuracy=nan
2021-11-05 21:09:51,452 Node[0] Epoch[6] Batch [180-200]	Speed: 165717.45 samples/sec	accuracy=nan
2021-11-05 21:09:51,846 Node[0] Epoch[6] Batch [200-220]	Speed: 165618.51 samples/sec	accuracy=nan
2021-11-05 21:09:52,242 Node[0] Epoch[6] Batch [220-240]	Speed: 164766.38 samples/sec	accuracy=nan
2021-11-05 21:09:52,636 Node[0] Epoch[6] Batch [240-260]	Speed: 165839.50 samples/sec	accuracy=nan
2021-11-05 21:09:53,031 Node[0] Epoch[6] Batch [260-280]	Speed: 165139.34 samples/sec	accuracy=nan
2021-11-05 21:09:53,424 Node[0] Epoch[6] Batch [280-300]	Speed: 166033.09 samples/sec	accuracy=nan
2021-11-05 21:09:53,820 Node[0] Epoch[6] Batch [300-320]	Speed: 164849.61 samples/sec	accuracy=nan
2021-11-05 21:09:54,216 Node[0] Epoch[6] Batch [320-340]	Speed: 164969.60 samples/sec	accuracy=nan
2021-11-05 21:09:54,614 Node[0] Epoch[6] Batch [340-360]	Speed: 164064.03 samples/sec	accuracy=nan
2021-11-05 21:09:55,014 Node[0] Epoch[6] Batch [360-380]	Speed: 163108.48 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146595252, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636146595252, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165146.01802855023}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 7}}
2021-11-05 21:09:55,252 Node[0] Epoch[6] Time cost=7.758
:::MLLOG {"namespace": "", "time_ms": 1636146595252, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165146.01802855023, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146595268, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 7}}
2021-11-05 21:09:55,385 Node[0] Epoch[6] Validation-accuracy=0.387964
2021-11-05 21:09:55,385 Node[0] Epoch[6] Validation-correct-count=303.000000
2021-11-05 21:09:55,385 Node[0] Epoch[6] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146595401, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636146595401, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.41278, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 7}}
:::MLLOG {"namespace": "", "time_ms": 1636146595401, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146595401, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 8, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146595402, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 8}}
2021-11-05 21:09:55,799 Node[0] Epoch[7] Batch [0-20]	Speed: 166129.19 samples/sec	accuracy=nan
2021-11-05 21:09:56,200 Node[0] Epoch[7] Batch [20-40]	Speed: 163055.05 samples/sec	accuracy=nan
2021-11-05 21:09:56,592 Node[0] Epoch[7] Batch [40-60]	Speed: 166397.34 samples/sec	accuracy=nan
2021-11-05 21:09:56,984 Node[0] Epoch[7] Batch [60-80]	Speed: 166763.81 samples/sec	accuracy=nan
2021-11-05 21:09:57,377 Node[0] Epoch[7] Batch [80-100]	Speed: 165792.70 samples/sec	accuracy=nan
2021-11-05 21:09:57,769 Node[0] Epoch[7] Batch [100-120]	Speed: 166454.60 samples/sec	accuracy=nan
2021-11-05 21:09:58,164 Node[0] Epoch[7] Batch [120-140]	Speed: 165296.26 samples/sec	accuracy=nan
2021-11-05 21:09:58,556 Node[0] Epoch[7] Batch [140-160]	Speed: 166797.64 samples/sec	accuracy=nan
2021-11-05 21:09:58,950 Node[0] Epoch[7] Batch [160-180]	Speed: 165507.79 samples/sec	accuracy=nan
2021-11-05 21:09:59,344 Node[0] Epoch[7] Batch [180-200]	Speed: 165569.34 samples/sec	accuracy=nan
2021-11-05 21:09:59,739 Node[0] Epoch[7] Batch [200-220]	Speed: 165535.30 samples/sec	accuracy=nan
2021-11-05 21:10:00,135 Node[0] Epoch[7] Batch [220-240]	Speed: 164641.15 samples/sec	accuracy=nan
2021-11-05 21:10:00,526 Node[0] Epoch[7] Batch [240-260]	Speed: 167030.96 samples/sec	accuracy=nan
2021-11-05 21:10:00,919 Node[0] Epoch[7] Batch [260-280]	Speed: 166112.86 samples/sec	accuracy=nan
2021-11-05 21:10:01,311 Node[0] Epoch[7] Batch [280-300]	Speed: 166686.86 samples/sec	accuracy=nan
2021-11-05 21:10:01,708 Node[0] Epoch[7] Batch [300-320]	Speed: 164520.66 samples/sec	accuracy=nan
2021-11-05 21:10:02,105 Node[0] Epoch[7] Batch [320-340]	Speed: 164344.49 samples/sec	accuracy=nan
2021-11-05 21:10:02,500 Node[0] Epoch[7] Batch [340-360]	Speed: 165045.77 samples/sec	accuracy=nan
2021-11-05 21:10:02,899 Node[0] Epoch[7] Batch [360-380]	Speed: 163659.81 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146603138, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 8}}
2021-11-05 21:10:03,138 Node[0] Epoch[7] Time cost=7.736
:::MLLOG {"namespace": "", "time_ms": 1636146603138, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165601.90228693548}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 8}}
:::MLLOG {"namespace": "", "time_ms": 1636146603138, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165601.90228693548, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146603138, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 9}}
2021-11-05 21:10:03,551 Node[0] Epoch[8] Batch [0-20]	Speed: 165932.97 samples/sec	accuracy=nan
2021-11-05 21:10:03,943 Node[0] Epoch[8] Batch [20-40]	Speed: 166492.45 samples/sec	accuracy=nan
2021-11-05 21:10:04,341 Node[0] Epoch[8] Batch [40-60]	Speed: 164090.78 samples/sec	accuracy=nan
2021-11-05 21:10:04,733 Node[0] Epoch[8] Batch [60-80]	Speed: 166267.00 samples/sec	accuracy=nan
2021-11-05 21:10:05,129 Node[0] Epoch[8] Batch [80-100]	Speed: 165120.12 samples/sec	accuracy=nan
2021-11-05 21:10:05,521 Node[0] Epoch[8] Batch [100-120]	Speed: 166414.23 samples/sec	accuracy=nan
2021-11-05 21:10:05,913 Node[0] Epoch[8] Batch [120-140]	Speed: 166606.53 samples/sec	accuracy=nan
2021-11-05 21:10:06,304 Node[0] Epoch[8] Batch [140-160]	Speed: 166803.43 samples/sec	accuracy=nan
2021-11-05 21:10:06,701 Node[0] Epoch[8] Batch [160-180]	Speed: 164658.18 samples/sec	accuracy=nan
2021-11-05 21:10:07,092 Node[0] Epoch[8] Batch [180-200]	Speed: 166911.01 samples/sec	accuracy=nan
2021-11-05 21:10:07,486 Node[0] Epoch[8] Batch [200-220]	Speed: 165504.68 samples/sec	accuracy=nan
2021-11-05 21:10:07,881 Node[0] Epoch[8] Batch [220-240]	Speed: 165159.46 samples/sec	accuracy=nan
2021-11-05 21:10:08,276 Node[0] Epoch[8] Batch [240-260]	Speed: 165409.90 samples/sec	accuracy=nan
2021-11-05 21:10:08,670 Node[0] Epoch[8] Batch [260-280]	Speed: 165668.21 samples/sec	accuracy=nan
2021-11-05 21:10:09,065 Node[0] Epoch[8] Batch [280-300]	Speed: 165466.78 samples/sec	accuracy=nan
2021-11-05 21:10:09,458 Node[0] Epoch[8] Batch [300-320]	Speed: 165810.88 samples/sec	accuracy=nan
2021-11-05 21:10:09,855 Node[0] Epoch[8] Batch [320-340]	Speed: 164621.65 samples/sec	accuracy=nan
2021-11-05 21:10:10,252 Node[0] Epoch[8] Batch [340-360]	Speed: 164231.42 samples/sec	accuracy=nan
2021-11-05 21:10:10,669 Node[0] Epoch[8] Batch [360-380]	Speed: 156582.37 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146610888, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 9}}
2021-11-05 21:10:10,889 Node[0] Epoch[8] Time cost=7.750
:::MLLOG {"namespace": "", "time_ms": 1636146610889, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165308.82983323865}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 9}}
:::MLLOG {"namespace": "", "time_ms": 1636146610889, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165308.82983323865, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146610889, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 10}}
2021-11-05 21:10:11,301 Node[0] Epoch[9] Batch [0-20]	Speed: 166328.81 samples/sec	accuracy=nan
2021-11-05 21:10:11,695 Node[0] Epoch[9] Batch [20-40]	Speed: 165701.20 samples/sec	accuracy=nan
2021-11-05 21:10:12,092 Node[0] Epoch[9] Batch [40-60]	Speed: 164225.02 samples/sec	accuracy=nan
2021-11-05 21:10:12,485 Node[0] Epoch[9] Batch [60-80]	Speed: 166377.63 samples/sec	accuracy=nan
2021-11-05 21:10:12,878 Node[0] Epoch[9] Batch [80-100]	Speed: 165818.51 samples/sec	accuracy=nan
2021-11-05 21:10:13,271 Node[0] Epoch[9] Batch [100-120]	Speed: 166180.51 samples/sec	accuracy=nan
2021-11-05 21:10:13,667 Node[0] Epoch[9] Batch [120-140]	Speed: 164911.07 samples/sec	accuracy=nan
2021-11-05 21:10:14,059 Node[0] Epoch[9] Batch [140-160]	Speed: 166555.14 samples/sec	accuracy=nan
2021-11-05 21:10:14,456 Node[0] Epoch[9] Batch [160-180]	Speed: 164254.67 samples/sec	accuracy=nan
2021-11-05 21:10:14,849 Node[0] Epoch[9] Batch [180-200]	Speed: 166085.15 samples/sec	accuracy=nan
2021-11-05 21:10:15,247 Node[0] Epoch[9] Batch [200-220]	Speed: 164212.71 samples/sec	accuracy=nan
2021-11-05 21:10:15,642 Node[0] Epoch[9] Batch [220-240]	Speed: 165288.68 samples/sec	accuracy=nan
2021-11-05 21:10:16,038 Node[0] Epoch[9] Batch [240-260]	Speed: 164828.18 samples/sec	accuracy=nan
2021-11-05 21:10:16,430 Node[0] Epoch[9] Batch [260-280]	Speed: 166505.21 samples/sec	accuracy=nan
2021-11-05 21:10:16,823 Node[0] Epoch[9] Batch [280-300]	Speed: 165926.83 samples/sec	accuracy=nan
2021-11-05 21:10:17,218 Node[0] Epoch[9] Batch [300-320]	Speed: 165422.29 samples/sec	accuracy=nan
2021-11-05 21:10:17,613 Node[0] Epoch[9] Batch [320-340]	Speed: 165155.18 samples/sec	accuracy=nan
2021-11-05 21:10:18,010 Node[0] Epoch[9] Batch [340-360]	Speed: 164414.46 samples/sec	accuracy=nan
2021-11-05 21:10:18,409 Node[0] Epoch[9] Batch [360-380]	Speed: 163915.92 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146618648, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 10}}
2021-11-05 21:10:18,648 Node[0] Epoch[9] Time cost=7.759
:::MLLOG {"namespace": "", "time_ms": 1636146618648, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165122.3192960514}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 10}}
:::MLLOG {"namespace": "", "time_ms": 1636146618648, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165122.3192960514, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146618648, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 11}}
2021-11-05 21:10:19,063 Node[0] Epoch[10] Batch [0-20]	Speed: 164786.52 samples/sec	accuracy=nan
2021-11-05 21:10:19,459 Node[0] Epoch[10] Batch [20-40]	Speed: 164826.79 samples/sec	accuracy=nan
2021-11-05 21:10:19,852 Node[0] Epoch[10] Batch [40-60]	Speed: 166419.80 samples/sec	accuracy=nan
2021-11-05 21:10:20,245 Node[0] Epoch[10] Batch [60-80]	Speed: 165763.60 samples/sec	accuracy=nan
2021-11-05 21:10:20,640 Node[0] Epoch[10] Batch [80-100]	Speed: 165251.37 samples/sec	accuracy=nan
2021-11-05 21:10:21,034 Node[0] Epoch[10] Batch [100-120]	Speed: 165706.41 samples/sec	accuracy=nan
2021-11-05 21:10:21,430 Node[0] Epoch[10] Batch [120-140]	Speed: 164997.33 samples/sec	accuracy=nan
2021-11-05 21:10:21,822 Node[0] Epoch[10] Batch [140-160]	Speed: 166645.06 samples/sec	accuracy=nan
2021-11-05 21:10:22,215 Node[0] Epoch[10] Batch [160-180]	Speed: 166180.61 samples/sec	accuracy=nan
2021-11-05 21:10:22,609 Node[0] Epoch[10] Batch [180-200]	Speed: 165640.25 samples/sec	accuracy=nan
2021-11-05 21:10:23,005 Node[0] Epoch[10] Batch [200-220]	Speed: 164938.59 samples/sec	accuracy=nan
2021-11-05 21:10:23,405 Node[0] Epoch[10] Batch [220-240]	Speed: 163206.09 samples/sec	accuracy=nan
2021-11-05 21:10:23,796 Node[0] Epoch[10] Batch [240-260]	Speed: 166767.16 samples/sec	accuracy=nan
2021-11-05 21:10:24,191 Node[0] Epoch[10] Batch [260-280]	Speed: 165436.18 samples/sec	accuracy=nan
2021-11-05 21:10:24,584 Node[0] Epoch[10] Batch [280-300]	Speed: 165855.77 samples/sec	accuracy=nan
2021-11-05 21:10:24,978 Node[0] Epoch[10] Batch [300-320]	Speed: 165567.43 samples/sec	accuracy=nan
2021-11-05 21:10:25,373 Node[0] Epoch[10] Batch [320-340]	Speed: 165304.74 samples/sec	accuracy=nan
2021-11-05 21:10:25,772 Node[0] Epoch[10] Batch [340-360]	Speed: 163704.52 samples/sec	accuracy=nan
2021-11-05 21:10:26,171 Node[0] Epoch[10] Batch [360-380]	Speed: 163852.75 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146626407, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636146626407, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165126.46481468427}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 11}}
2021-11-05 21:10:26,407 Node[0] Epoch[10] Time cost=7.759
:::MLLOG {"namespace": "", "time_ms": 1636146626407, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165126.46481468427, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146626424, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 11}}
2021-11-05 21:10:26,539 Node[0] Epoch[10] Validation-accuracy=0.555698
2021-11-05 21:10:26,539 Node[0] Epoch[10] Validation-correct-count=434.000000
2021-11-05 21:10:26,539 Node[0] Epoch[10] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146626554, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636146626555, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.53828, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 11}}
:::MLLOG {"namespace": "", "time_ms": 1636146626555, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 8}}
:::MLLOG {"namespace": "", "time_ms": 1636146626555, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 12, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146626555, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 12}}
2021-11-05 21:10:26,954 Node[0] Epoch[11] Batch [0-20]	Speed: 166048.39 samples/sec	accuracy=nan
2021-11-05 21:10:27,349 Node[0] Epoch[11] Batch [20-40]	Speed: 165188.26 samples/sec	accuracy=nan
2021-11-05 21:10:27,742 Node[0] Epoch[11] Batch [40-60]	Speed: 166130.60 samples/sec	accuracy=nan
2021-11-05 21:10:28,136 Node[0] Epoch[11] Batch [60-80]	Speed: 165560.03 samples/sec	accuracy=nan
2021-11-05 21:10:28,529 Node[0] Epoch[11] Batch [80-100]	Speed: 166139.88 samples/sec	accuracy=nan
2021-11-05 21:10:28,921 Node[0] Epoch[11] Batch [100-120]	Speed: 166696.50 samples/sec	accuracy=nan
2021-11-05 21:10:29,312 Node[0] Epoch[11] Batch [120-140]	Speed: 166576.32 samples/sec	accuracy=nan
2021-11-05 21:10:29,705 Node[0] Epoch[11] Batch [140-160]	Speed: 166325.88 samples/sec	accuracy=nan
2021-11-05 21:10:30,100 Node[0] Epoch[11] Batch [160-180]	Speed: 165104.79 samples/sec	accuracy=nan
2021-11-05 21:10:30,494 Node[0] Epoch[11] Batch [180-200]	Speed: 165708.02 samples/sec	accuracy=nan
2021-11-05 21:10:30,889 Node[0] Epoch[11] Batch [200-220]	Speed: 165523.59 samples/sec	accuracy=nan
2021-11-05 21:10:31,281 Node[0] Epoch[11] Batch [220-240]	Speed: 166291.03 samples/sec	accuracy=nan
2021-11-05 21:10:31,677 Node[0] Epoch[11] Batch [240-260]	Speed: 164762.82 samples/sec	accuracy=nan
2021-11-05 21:10:32,070 Node[0] Epoch[11] Batch [260-280]	Speed: 166176.48 samples/sec	accuracy=nan
2021-11-05 21:10:32,464 Node[0] Epoch[11] Batch [280-300]	Speed: 165903.31 samples/sec	accuracy=nan
2021-11-05 21:10:32,859 Node[0] Epoch[11] Batch [300-320]	Speed: 165318.62 samples/sec	accuracy=nan
2021-11-05 21:10:33,254 Node[0] Epoch[11] Batch [320-340]	Speed: 164963.34 samples/sec	accuracy=nan
2021-11-05 21:10:33,653 Node[0] Epoch[11] Batch [340-360]	Speed: 163531.95 samples/sec	accuracy=nan
2021-11-05 21:10:34,049 Node[0] Epoch[11] Batch [360-380]	Speed: 164883.27 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146634285, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 12}}
2021-11-05 21:10:34,285 Node[0] Epoch[11] Time cost=7.730
:::MLLOG {"namespace": "", "time_ms": 1636146634285, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165731.47845868603}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 12}}
:::MLLOG {"namespace": "", "time_ms": 1636146634286, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165731.47845868603, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146634286, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 13}}
2021-11-05 21:10:34,704 Node[0] Epoch[12] Batch [0-20]	Speed: 163506.07 samples/sec	accuracy=nan
2021-11-05 21:10:35,099 Node[0] Epoch[12] Batch [20-40]	Speed: 165243.39 samples/sec	accuracy=nan
2021-11-05 21:10:35,495 Node[0] Epoch[12] Batch [40-60]	Speed: 164843.76 samples/sec	accuracy=nan
2021-11-05 21:10:35,887 Node[0] Epoch[12] Batch [60-80]	Speed: 166699.24 samples/sec	accuracy=nan
2021-11-05 21:10:36,282 Node[0] Epoch[12] Batch [80-100]	Speed: 165183.87 samples/sec	accuracy=nan
2021-11-05 21:10:36,675 Node[0] Epoch[12] Batch [100-120]	Speed: 166335.17 samples/sec	accuracy=nan
2021-11-05 21:10:37,070 Node[0] Epoch[12] Batch [120-140]	Speed: 165169.72 samples/sec	accuracy=nan
2021-11-05 21:10:37,463 Node[0] Epoch[12] Batch [140-160]	Speed: 166086.06 samples/sec	accuracy=nan
2021-11-05 21:10:37,857 Node[0] Epoch[12] Batch [160-180]	Speed: 165560.23 samples/sec	accuracy=nan
2021-11-05 21:10:38,249 Node[0] Epoch[12] Batch [180-200]	Speed: 166475.65 samples/sec	accuracy=nan
2021-11-05 21:10:38,641 Node[0] Epoch[12] Batch [200-220]	Speed: 166496.71 samples/sec	accuracy=nan
2021-11-05 21:10:39,036 Node[0] Epoch[12] Batch [220-240]	Speed: 165325.60 samples/sec	accuracy=nan
2021-11-05 21:10:39,428 Node[0] Epoch[12] Batch [240-260]	Speed: 166739.03 samples/sec	accuracy=nan
2021-11-05 21:10:39,822 Node[0] Epoch[12] Batch [260-280]	Speed: 165520.19 samples/sec	accuracy=nan
2021-11-05 21:10:40,214 Node[0] Epoch[12] Batch [280-300]	Speed: 166609.26 samples/sec	accuracy=nan
2021-11-05 21:10:40,608 Node[0] Epoch[12] Batch [300-320]	Speed: 165530.40 samples/sec	accuracy=nan
2021-11-05 21:10:41,001 Node[0] Epoch[12] Batch [320-340]	Speed: 166004.30 samples/sec	accuracy=nan
2021-11-05 21:10:41,398 Node[0] Epoch[12] Batch [340-360]	Speed: 164574.26 samples/sec	accuracy=nan
2021-11-05 21:10:41,796 Node[0] Epoch[12] Batch [360-380]	Speed: 163950.07 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146642034, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 13}}
2021-11-05 21:10:42,035 Node[0] Epoch[12] Time cost=7.749
:::MLLOG {"namespace": "", "time_ms": 1636146642035, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165339.31743636858}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 13}}
:::MLLOG {"namespace": "", "time_ms": 1636146642035, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165339.31743636858, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146642035, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 14}}
2021-11-05 21:10:42,447 Node[0] Epoch[13] Batch [0-20]	Speed: 166321.13 samples/sec	accuracy=nan
2021-11-05 21:10:42,843 Node[0] Epoch[13] Batch [20-40]	Speed: 164751.32 samples/sec	accuracy=nan
2021-11-05 21:10:43,236 Node[0] Epoch[13] Batch [40-60]	Speed: 166043.86 samples/sec	accuracy=nan
2021-11-05 21:10:43,630 Node[0] Epoch[13] Batch [60-80]	Speed: 165786.68 samples/sec	accuracy=nan
2021-11-05 21:10:44,022 Node[0] Epoch[13] Batch [80-100]	Speed: 166195.95 samples/sec	accuracy=nan
2021-11-05 21:10:44,414 Node[0] Epoch[13] Batch [100-120]	Speed: 166760.76 samples/sec	accuracy=nan
2021-11-05 21:10:44,809 Node[0] Epoch[13] Batch [120-140]	Speed: 165118.33 samples/sec	accuracy=nan
2021-11-05 21:10:45,201 Node[0] Epoch[13] Batch [140-160]	Speed: 166560.21 samples/sec	accuracy=nan
2021-11-05 21:10:45,593 Node[0] Epoch[13] Batch [160-180]	Speed: 166509.56 samples/sec	accuracy=nan
2021-11-05 21:10:45,989 Node[0] Epoch[13] Batch [180-200]	Speed: 165031.74 samples/sec	accuracy=nan
2021-11-05 21:10:46,383 Node[0] Epoch[13] Batch [200-220]	Speed: 165473.68 samples/sec	accuracy=nan
2021-11-05 21:10:46,776 Node[0] Epoch[13] Batch [220-240]	Speed: 166273.36 samples/sec	accuracy=nan
2021-11-05 21:10:47,169 Node[0] Epoch[13] Batch [240-260]	Speed: 166013.76 samples/sec	accuracy=nan
2021-11-05 21:10:47,563 Node[0] Epoch[13] Batch [260-280]	Speed: 165773.43 samples/sec	accuracy=nan
2021-11-05 21:10:47,956 Node[0] Epoch[13] Batch [280-300]	Speed: 166087.67 samples/sec	accuracy=nan
2021-11-05 21:10:48,351 Node[0] Epoch[13] Batch [300-320]	Speed: 165176.10 samples/sec	accuracy=nan
2021-11-05 21:10:48,746 Node[0] Epoch[13] Batch [320-340]	Speed: 165196.43 samples/sec	accuracy=nan
2021-11-05 21:10:49,143 Node[0] Epoch[13] Batch [340-360]	Speed: 164467.99 samples/sec	accuracy=nan
2021-11-05 21:10:49,541 Node[0] Epoch[13] Batch [360-380]	Speed: 164303.66 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146649779, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 14}}
2021-11-05 21:10:49,779 Node[0] Epoch[13] Time cost=7.744
:::MLLOG {"namespace": "", "time_ms": 1636146649779, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165442.6132515078}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 14}}
:::MLLOG {"namespace": "", "time_ms": 1636146649779, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165442.6132515078, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146649779, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 15}}
2021-11-05 21:10:50,193 Node[0] Epoch[14] Batch [0-20]	Speed: 165151.19 samples/sec	accuracy=nan
2021-11-05 21:10:50,587 Node[0] Epoch[14] Batch [20-40]	Speed: 165763.40 samples/sec	accuracy=nan
2021-11-05 21:10:50,980 Node[0] Epoch[14] Batch [40-60]	Speed: 166020.50 samples/sec	accuracy=nan
2021-11-05 21:10:51,374 Node[0] Epoch[14] Batch [60-80]	Speed: 165820.92 samples/sec	accuracy=nan
2021-11-05 21:10:51,768 Node[0] Epoch[14] Batch [80-100]	Speed: 165755.87 samples/sec	accuracy=nan
2021-11-05 21:10:52,161 Node[0] Epoch[14] Batch [100-120]	Speed: 166129.29 samples/sec	accuracy=nan
2021-11-05 21:10:52,552 Node[0] Epoch[14] Batch [120-140]	Speed: 166885.07 samples/sec	accuracy=nan
2021-11-05 21:10:52,946 Node[0] Epoch[14] Batch [140-160]	Speed: 165484.78 samples/sec	accuracy=nan
2021-11-05 21:10:53,344 Node[0] Epoch[14] Batch [160-180]	Speed: 164229.45 samples/sec	accuracy=nan
2021-11-05 21:10:53,736 Node[0] Epoch[14] Batch [180-200]	Speed: 166473.73 samples/sec	accuracy=nan
2021-11-05 21:10:54,131 Node[0] Epoch[14] Batch [200-220]	Speed: 165219.26 samples/sec	accuracy=nan
2021-11-05 21:10:54,524 Node[0] Epoch[14] Batch [220-240]	Speed: 166227.93 samples/sec	accuracy=nan
2021-11-05 21:10:54,917 Node[0] Epoch[14] Batch [240-260]	Speed: 166265.78 samples/sec	accuracy=nan
2021-11-05 21:10:55,312 Node[0] Epoch[14] Batch [260-280]	Speed: 164976.16 samples/sec	accuracy=nan
2021-11-05 21:10:55,706 Node[0] Epoch[14] Batch [280-300]	Speed: 165865.52 samples/sec	accuracy=nan
2021-11-05 21:10:56,098 Node[0] Epoch[14] Batch [300-320]	Speed: 166389.15 samples/sec	accuracy=nan
2021-11-05 21:10:56,496 Node[0] Epoch[14] Batch [320-340]	Speed: 164236.74 samples/sec	accuracy=nan
2021-11-05 21:10:56,893 Node[0] Epoch[14] Batch [340-360]	Speed: 164361.46 samples/sec	accuracy=nan
2021-11-05 21:10:57,289 Node[0] Epoch[14] Batch [360-380]	Speed: 164819.45 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146657525, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 15}}
2021-11-05 21:10:57,525 Node[0] Epoch[14] Time cost=7.746
:::MLLOG {"namespace": "", "time_ms": 1636146657525, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165398.4070893986}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636146657525, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165398.4070893986, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146657542, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 15}}
2021-11-05 21:10:57,660 Node[0] Epoch[14] Validation-accuracy=0.605634
2021-11-05 21:10:57,660 Node[0] Epoch[14] Validation-correct-count=473.000000
2021-11-05 21:10:57,660 Node[0] Epoch[14] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146657677, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636146657677, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.60632, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 15}}
:::MLLOG {"namespace": "", "time_ms": 1636146657677, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 12}}
:::MLLOG {"namespace": "", "time_ms": 1636146657678, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 16, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146657678, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 16}}
2021-11-05 21:10:58,073 Node[0] Epoch[15] Batch [0-20]	Speed: 166995.30 samples/sec	accuracy=nan
2021-11-05 21:10:58,467 Node[0] Epoch[15] Batch [20-40]	Speed: 165849.65 samples/sec	accuracy=nan
2021-11-05 21:10:58,860 Node[0] Epoch[15] Batch [40-60]	Speed: 166173.05 samples/sec	accuracy=nan
2021-11-05 21:10:59,254 Node[0] Epoch[15] Batch [60-80]	Speed: 165853.46 samples/sec	accuracy=nan
2021-11-05 21:10:59,647 Node[0] Epoch[15] Batch [80-100]	Speed: 165879.39 samples/sec	accuracy=nan
2021-11-05 21:11:00,041 Node[0] Epoch[15] Batch [100-120]	Speed: 165559.93 samples/sec	accuracy=nan
2021-11-05 21:11:00,435 Node[0] Epoch[15] Batch [120-140]	Speed: 165794.31 samples/sec	accuracy=nan
2021-11-05 21:11:00,826 Node[0] Epoch[15] Batch [140-160]	Speed: 166850.70 samples/sec	accuracy=nan
2021-11-05 21:11:01,220 Node[0] Epoch[15] Batch [160-180]	Speed: 165747.14 samples/sec	accuracy=nan
2021-11-05 21:11:01,614 Node[0] Epoch[15] Batch [180-200]	Speed: 165567.64 samples/sec	accuracy=nan
2021-11-05 21:11:02,007 Node[0] Epoch[15] Batch [200-220]	Speed: 166112.96 samples/sec	accuracy=nan
2021-11-05 21:11:02,400 Node[0] Epoch[15] Batch [220-240]	Speed: 166198.57 samples/sec	accuracy=nan
2021-11-05 21:11:02,795 Node[0] Epoch[15] Batch [240-260]	Speed: 165468.98 samples/sec	accuracy=nan
2021-11-05 21:11:03,190 Node[0] Epoch[15] Batch [260-280]	Speed: 165081.10 samples/sec	accuracy=nan
2021-11-05 21:11:03,585 Node[0] Epoch[15] Batch [280-300]	Speed: 165338.28 samples/sec	accuracy=nan
2021-11-05 21:11:03,980 Node[0] Epoch[15] Batch [300-320]	Speed: 165405.70 samples/sec	accuracy=nan
2021-11-05 21:11:04,375 Node[0] Epoch[15] Batch [320-340]	Speed: 165157.87 samples/sec	accuracy=nan
2021-11-05 21:11:04,773 Node[0] Epoch[15] Batch [340-360]	Speed: 163869.61 samples/sec	accuracy=nan
2021-11-05 21:11:05,171 Node[0] Epoch[15] Batch [360-380]	Speed: 163984.93 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146665407, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 16}}
2021-11-05 21:11:05,408 Node[0] Epoch[15] Time cost=7.730
:::MLLOG {"namespace": "", "time_ms": 1636146665408, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165742.8419975206}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 16}}
:::MLLOG {"namespace": "", "time_ms": 1636146665408, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165742.8419975206, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146665408, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 17}}
2021-11-05 21:11:05,819 Node[0] Epoch[16] Batch [0-20]	Speed: 166462.80 samples/sec	accuracy=nan
2021-11-05 21:11:06,216 Node[0] Epoch[16] Batch [20-40]	Speed: 164783.14 samples/sec	accuracy=nan
2021-11-05 21:11:06,608 Node[0] Epoch[16] Batch [40-60]	Speed: 166274.37 samples/sec	accuracy=nan
2021-11-05 21:11:07,002 Node[0] Epoch[16] Batch [60-80]	Speed: 165623.72 samples/sec	accuracy=nan
2021-11-05 21:11:07,396 Node[0] Epoch[16] Batch [80-100]	Speed: 165904.31 samples/sec	accuracy=nan
2021-11-05 21:11:07,788 Node[0] Epoch[16] Batch [100-120]	Speed: 166436.79 samples/sec	accuracy=nan
2021-11-05 21:11:08,183 Node[0] Epoch[16] Batch [120-140]	Speed: 165184.57 samples/sec	accuracy=nan
2021-11-05 21:11:08,577 Node[0] Epoch[16] Batch [140-160]	Speed: 165820.42 samples/sec	accuracy=nan
2021-11-05 21:11:08,969 Node[0] Epoch[16] Batch [160-180]	Speed: 166704.62 samples/sec	accuracy=nan
2021-11-05 21:11:09,362 Node[0] Epoch[16] Batch [180-200]	Speed: 166024.53 samples/sec	accuracy=nan
2021-11-05 21:11:09,757 Node[0] Epoch[16] Batch [200-220]	Speed: 165233.42 samples/sec	accuracy=nan
2021-11-05 21:11:10,149 Node[0] Epoch[16] Batch [220-240]	Speed: 166283.35 samples/sec	accuracy=nan
2021-11-05 21:11:10,542 Node[0] Epoch[16] Batch [240-260]	Speed: 166460.97 samples/sec	accuracy=nan
2021-11-05 21:11:10,936 Node[0] Epoch[16] Batch [260-280]	Speed: 165564.43 samples/sec	accuracy=nan
2021-11-05 21:11:11,329 Node[0] Epoch[16] Batch [280-300]	Speed: 166032.28 samples/sec	accuracy=nan
2021-11-05 21:11:11,722 Node[0] Epoch[16] Batch [300-320]	Speed: 166140.08 samples/sec	accuracy=nan
2021-11-05 21:11:12,118 Node[0] Epoch[16] Batch [320-340]	Speed: 164816.17 samples/sec	accuracy=nan
2021-11-05 21:11:12,515 Node[0] Epoch[16] Batch [340-360]	Speed: 164544.68 samples/sec	accuracy=nan
2021-11-05 21:11:12,912 Node[0] Epoch[16] Batch [360-380]	Speed: 164156.39 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146673149, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 17}}
2021-11-05 21:11:13,149 Node[0] Epoch[16] Time cost=7.741
:::MLLOG {"namespace": "", "time_ms": 1636146673149, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165506.97617648053}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 17}}
:::MLLOG {"namespace": "", "time_ms": 1636146673149, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165506.97617648053, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146673149, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 18}}
2021-11-05 21:11:13,563 Node[0] Epoch[17] Batch [0-20]	Speed: 165523.59 samples/sec	accuracy=nan
2021-11-05 21:11:13,956 Node[0] Epoch[17] Batch [20-40]	Speed: 166112.76 samples/sec	accuracy=nan
2021-11-05 21:11:14,348 Node[0] Epoch[17] Batch [40-60]	Speed: 166454.90 samples/sec	accuracy=nan
2021-11-05 21:11:14,741 Node[0] Epoch[17] Batch [60-80]	Speed: 166409.48 samples/sec	accuracy=nan
2021-11-05 21:11:15,132 Node[0] Epoch[17] Batch [80-100]	Speed: 166644.55 samples/sec	accuracy=nan
2021-11-05 21:11:15,526 Node[0] Epoch[17] Batch [100-120]	Speed: 165791.10 samples/sec	accuracy=nan
2021-11-05 21:11:15,917 Node[0] Epoch[17] Batch [120-140]	Speed: 167162.41 samples/sec	accuracy=nan
2021-11-05 21:11:16,309 Node[0] Epoch[17] Batch [140-160]	Speed: 166246.20 samples/sec	accuracy=nan
2021-11-05 21:11:16,702 Node[0] Epoch[17] Batch [160-180]	Speed: 166268.71 samples/sec	accuracy=nan
2021-11-05 21:11:17,093 Node[0] Epoch[17] Batch [180-200]	Speed: 166781.79 samples/sec	accuracy=nan
2021-11-05 21:11:17,487 Node[0] Epoch[17] Batch [200-220]	Speed: 165843.02 samples/sec	accuracy=nan
2021-11-05 21:11:17,879 Node[0] Epoch[17] Batch [220-240]	Speed: 166353.67 samples/sec	accuracy=nan
2021-11-05 21:11:18,274 Node[0] Epoch[17] Batch [240-260]	Speed: 165228.73 samples/sec	accuracy=nan
2021-11-05 21:11:18,667 Node[0] Epoch[17] Batch [260-280]	Speed: 166318.60 samples/sec	accuracy=nan
2021-11-05 21:11:19,061 Node[0] Epoch[17] Batch [280-300]	Speed: 165617.41 samples/sec	accuracy=nan
2021-11-05 21:11:19,459 Node[0] Epoch[17] Batch [300-320]	Speed: 164031.99 samples/sec	accuracy=nan
2021-11-05 21:11:19,858 Node[0] Epoch[17] Batch [320-340]	Speed: 163560.58 samples/sec	accuracy=nan
2021-11-05 21:11:20,254 Node[0] Epoch[17] Batch [340-360]	Speed: 165062.19 samples/sec	accuracy=nan
2021-11-05 21:11:20,652 Node[0] Epoch[17] Batch [360-380]	Speed: 163724.20 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146680889, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 18}}
2021-11-05 21:11:20,889 Node[0] Epoch[17] Time cost=7.740
:::MLLOG {"namespace": "", "time_ms": 1636146680889, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165533.35033665446}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 18}}
:::MLLOG {"namespace": "", "time_ms": 1636146680889, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165533.35033665446, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146680889, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 19}}
2021-11-05 21:11:21,302 Node[0] Epoch[18] Batch [0-20]	Speed: 166235.30 samples/sec	accuracy=nan
2021-11-05 21:11:21,696 Node[0] Epoch[18] Batch [20-40]	Speed: 165297.26 samples/sec	accuracy=nan
2021-11-05 21:11:22,091 Node[0] Epoch[18] Batch [40-60]	Speed: 165560.53 samples/sec	accuracy=nan
2021-11-05 21:11:22,482 Node[0] Epoch[18] Batch [60-80]	Speed: 166749.59 samples/sec	accuracy=nan
2021-11-05 21:11:22,877 Node[0] Epoch[18] Batch [80-100]	Speed: 165508.69 samples/sec	accuracy=nan
2021-11-05 21:11:23,269 Node[0] Epoch[18] Batch [100-120]	Speed: 166576.73 samples/sec	accuracy=nan
2021-11-05 21:11:23,661 Node[0] Epoch[18] Batch [120-140]	Speed: 166327.70 samples/sec	accuracy=nan
2021-11-05 21:11:24,054 Node[0] Epoch[18] Batch [140-160]	Speed: 166216.43 samples/sec	accuracy=nan
2021-11-05 21:11:24,448 Node[0] Epoch[18] Batch [160-180]	Speed: 165692.48 samples/sec	accuracy=nan
2021-11-05 21:11:24,841 Node[0] Epoch[18] Batch [180-200]	Speed: 165976.22 samples/sec	accuracy=nan
2021-11-05 21:11:25,235 Node[0] Epoch[18] Batch [200-220]	Speed: 165893.56 samples/sec	accuracy=nan
2021-11-05 21:11:25,628 Node[0] Epoch[18] Batch [220-240]	Speed: 166011.04 samples/sec	accuracy=nan
2021-11-05 21:11:26,020 Node[0] Epoch[18] Batch [240-260]	Speed: 166550.08 samples/sec	accuracy=nan
2021-11-05 21:11:26,414 Node[0] Epoch[18] Batch [260-280]	Speed: 165710.73 samples/sec	accuracy=nan
2021-11-05 21:11:26,806 Node[0] Epoch[18] Batch [280-300]	Speed: 166550.18 samples/sec	accuracy=nan
2021-11-05 21:11:27,199 Node[0] Epoch[18] Batch [300-320]	Speed: 165974.31 samples/sec	accuracy=nan
2021-11-05 21:11:27,593 Node[0] Epoch[18] Batch [320-340]	Speed: 165548.92 samples/sec	accuracy=nan
2021-11-05 21:11:27,990 Node[0] Epoch[18] Batch [340-360]	Speed: 164669.47 samples/sec	accuracy=nan
2021-11-05 21:11:28,387 Node[0] Epoch[18] Batch [360-380]	Speed: 164377.94 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146688622, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 19}}
2021-11-05 21:11:28,622 Node[0] Epoch[18] Time cost=7.733
:::MLLOG {"namespace": "", "time_ms": 1636146688622, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165675.46564952808}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636146688622, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165675.46564952808, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146688639, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 19}}
2021-11-05 21:11:28,754 Node[0] Epoch[18] Validation-accuracy=0.664533
2021-11-05 21:11:28,754 Node[0] Epoch[18] Validation-correct-count=519.000000
2021-11-05 21:11:28,754 Node[0] Epoch[18] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146688771, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636146688771, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.6573, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 19}}
:::MLLOG {"namespace": "", "time_ms": 1636146688771, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 16}}
:::MLLOG {"namespace": "", "time_ms": 1636146688771, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 20, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146688771, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 20}}
2021-11-05 21:11:29,168 Node[0] Epoch[19] Batch [0-20]	Speed: 166572.47 samples/sec	accuracy=nan
2021-11-05 21:11:29,561 Node[0] Epoch[19] Batch [20-40]	Speed: 166209.67 samples/sec	accuracy=nan
2021-11-05 21:11:29,953 Node[0] Epoch[19] Batch [40-60]	Speed: 166697.21 samples/sec	accuracy=nan
2021-11-05 21:11:30,346 Node[0] Epoch[19] Batch [60-80]	Speed: 166144.11 samples/sec	accuracy=nan
2021-11-05 21:11:30,739 Node[0] Epoch[19] Batch [80-100]	Speed: 166017.58 samples/sec	accuracy=nan
2021-11-05 21:11:31,130 Node[0] Epoch[19] Batch [100-120]	Speed: 166673.97 samples/sec	accuracy=nan
2021-11-05 21:11:31,524 Node[0] Epoch[19] Batch [120-140]	Speed: 165889.54 samples/sec	accuracy=nan
2021-11-05 21:11:31,919 Node[0] Epoch[19] Batch [140-160]	Speed: 165418.29 samples/sec	accuracy=nan
2021-11-05 21:11:32,313 Node[0] Epoch[19] Batch [160-180]	Speed: 165622.62 samples/sec	accuracy=nan
2021-11-05 21:11:32,705 Node[0] Epoch[19] Batch [180-200]	Speed: 166395.22 samples/sec	accuracy=nan
2021-11-05 21:11:33,100 Node[0] Epoch[19] Batch [200-220]	Speed: 165287.68 samples/sec	accuracy=nan
2021-11-05 21:11:33,492 Node[0] Epoch[19] Batch [220-240]	Speed: 166609.37 samples/sec	accuracy=nan
2021-11-05 21:11:33,885 Node[0] Epoch[19] Batch [240-260]	Speed: 166049.70 samples/sec	accuracy=nan
2021-11-05 21:11:34,278 Node[0] Epoch[19] Batch [260-280]	Speed: 166050.71 samples/sec	accuracy=nan
2021-11-05 21:11:34,672 Node[0] Epoch[19] Batch [280-300]	Speed: 165506.09 samples/sec	accuracy=nan
2021-11-05 21:11:35,067 Node[0] Epoch[19] Batch [300-320]	Speed: 165561.03 samples/sec	accuracy=nan
2021-11-05 21:11:35,462 Node[0] Epoch[19] Batch [320-340]	Speed: 165326.90 samples/sec	accuracy=nan
2021-11-05 21:11:35,859 Node[0] Epoch[19] Batch [340-360]	Speed: 164309.77 samples/sec	accuracy=nan
2021-11-05 21:11:36,255 Node[0] Epoch[19] Batch [360-380]	Speed: 164920.91 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146696491, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 20}}
2021-11-05 21:11:36,492 Node[0] Epoch[19] Time cost=7.720
:::MLLOG {"namespace": "", "time_ms": 1636146696492, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165946.53017308813}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 20}}
:::MLLOG {"namespace": "", "time_ms": 1636146696492, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165946.53017308813, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146696492, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 21}}
2021-11-05 21:11:36,905 Node[0] Epoch[20] Batch [0-20]	Speed: 165605.89 samples/sec	accuracy=nan
2021-11-05 21:11:37,300 Node[0] Epoch[20] Batch [20-40]	Speed: 165221.25 samples/sec	accuracy=nan
2021-11-05 21:11:37,693 Node[0] Epoch[20] Batch [40-60]	Speed: 166354.88 samples/sec	accuracy=nan
2021-11-05 21:11:38,086 Node[0] Epoch[20] Batch [60-80]	Speed: 165812.08 samples/sec	accuracy=nan
2021-11-05 21:11:38,479 Node[0] Epoch[20] Batch [80-100]	Speed: 166400.88 samples/sec	accuracy=nan
2021-11-05 21:11:38,870 Node[0] Epoch[20] Batch [100-120]	Speed: 166675.49 samples/sec	accuracy=nan
2021-11-05 21:11:39,263 Node[0] Epoch[20] Batch [120-140]	Speed: 166451.26 samples/sec	accuracy=nan
2021-11-05 21:11:39,655 Node[0] Epoch[20] Batch [140-160]	Speed: 166542.99 samples/sec	accuracy=nan
2021-11-05 21:11:40,048 Node[0] Epoch[20] Batch [160-180]	Speed: 165823.03 samples/sec	accuracy=nan
2021-11-05 21:11:40,443 Node[0] Epoch[20] Batch [180-200]	Speed: 165333.69 samples/sec	accuracy=nan
2021-11-05 21:11:40,835 Node[0] Epoch[20] Batch [200-220]	Speed: 166531.03 samples/sec	accuracy=nan
2021-11-05 21:11:41,227 Node[0] Epoch[20] Batch [220-240]	Speed: 166651.86 samples/sec	accuracy=nan
2021-11-05 21:11:41,620 Node[0] Epoch[20] Batch [240-260]	Speed: 165918.19 samples/sec	accuracy=nan
2021-11-05 21:11:42,016 Node[0] Epoch[20] Batch [260-280]	Speed: 164874.83 samples/sec	accuracy=nan
2021-11-05 21:11:42,410 Node[0] Epoch[20] Batch [280-300]	Speed: 165543.71 samples/sec	accuracy=nan
2021-11-05 21:11:42,806 Node[0] Epoch[20] Batch [300-320]	Speed: 165223.65 samples/sec	accuracy=nan
2021-11-05 21:11:43,200 Node[0] Epoch[20] Batch [320-340]	Speed: 165595.07 samples/sec	accuracy=nan
2021-11-05 21:11:43,598 Node[0] Epoch[20] Batch [340-360]	Speed: 164094.41 samples/sec	accuracy=nan
2021-11-05 21:11:43,994 Node[0] Epoch[20] Batch [360-380]	Speed: 164699.98 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146704230, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 21}}
2021-11-05 21:11:44,230 Node[0] Epoch[20] Time cost=7.738
:::MLLOG {"namespace": "", "time_ms": 1636146704230, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165576.531754922}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 21}}
:::MLLOG {"namespace": "", "time_ms": 1636146704230, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165576.531754922, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146704230, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 22}}
2021-11-05 21:11:44,643 Node[0] Epoch[21] Batch [0-20]	Speed: 165729.78 samples/sec	accuracy=nan
2021-11-05 21:11:45,037 Node[0] Epoch[21] Batch [20-40]	Speed: 165613.70 samples/sec	accuracy=nan
2021-11-05 21:11:45,431 Node[0] Epoch[21] Batch [40-60]	Speed: 165871.05 samples/sec	accuracy=nan
2021-11-05 21:11:45,823 Node[0] Epoch[21] Batch [60-80]	Speed: 166393.70 samples/sec	accuracy=nan
2021-11-05 21:11:46,216 Node[0] Epoch[21] Batch [80-100]	Speed: 166004.70 samples/sec	accuracy=nan
2021-11-05 21:11:46,610 Node[0] Epoch[21] Batch [100-120]	Speed: 166051.51 samples/sec	accuracy=nan
2021-11-05 21:11:47,002 Node[0] Epoch[21] Batch [120-140]	Speed: 166299.61 samples/sec	accuracy=nan
2021-11-05 21:11:47,395 Node[0] Epoch[21] Batch [140-160]	Speed: 166161.65 samples/sec	accuracy=nan
2021-11-05 21:11:47,790 Node[0] Epoch[21] Batch [160-180]	Speed: 165340.88 samples/sec	accuracy=nan
2021-11-05 21:11:48,182 Node[0] Epoch[21] Batch [180-200]	Speed: 166404.22 samples/sec	accuracy=nan
2021-11-05 21:11:48,578 Node[0] Epoch[21] Batch [200-220]	Speed: 164962.84 samples/sec	accuracy=nan
2021-11-05 21:11:48,971 Node[0] Epoch[21] Batch [220-240]	Speed: 165977.73 samples/sec	accuracy=nan
2021-11-05 21:11:49,364 Node[0] Epoch[21] Batch [240-260]	Speed: 166280.83 samples/sec	accuracy=nan
2021-11-05 21:11:49,759 Node[0] Epoch[21] Batch [260-280]	Speed: 165032.34 samples/sec	accuracy=nan
2021-11-05 21:11:50,153 Node[0] Epoch[21] Batch [280-300]	Speed: 165965.56 samples/sec	accuracy=nan
2021-11-05 21:11:50,546 Node[0] Epoch[21] Batch [300-320]	Speed: 165846.43 samples/sec	accuracy=nan
2021-11-05 21:11:50,944 Node[0] Epoch[21] Batch [320-340]	Speed: 164028.94 samples/sec	accuracy=nan
2021-11-05 21:11:51,344 Node[0] Epoch[21] Batch [340-360]	Speed: 163490.45 samples/sec	accuracy=nan
2021-11-05 21:11:51,741 Node[0] Epoch[21] Batch [360-380]	Speed: 164120.87 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146711978, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 22}}
2021-11-05 21:11:51,979 Node[0] Epoch[21] Time cost=7.748
:::MLLOG {"namespace": "", "time_ms": 1636146711979, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165345.1171522358}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 22}}
:::MLLOG {"namespace": "", "time_ms": 1636146711979, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165345.1171522358, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146711979, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 23}}
2021-11-05 21:11:52,390 Node[0] Epoch[22] Batch [0-20]	Speed: 166541.26 samples/sec	accuracy=nan
2021-11-05 21:11:52,784 Node[0] Epoch[22] Batch [20-40]	Speed: 165846.93 samples/sec	accuracy=nan
2021-11-05 21:11:53,177 Node[0] Epoch[22] Batch [40-60]	Speed: 166105.31 samples/sec	accuracy=nan
2021-11-05 21:11:53,571 Node[0] Epoch[22] Batch [60-80]	Speed: 165617.71 samples/sec	accuracy=nan
2021-11-05 21:11:53,965 Node[0] Epoch[22] Batch [80-100]	Speed: 165787.28 samples/sec	accuracy=nan
2021-11-05 21:11:54,357 Node[0] Epoch[22] Batch [100-120]	Speed: 166428.49 samples/sec	accuracy=nan
2021-11-05 21:11:54,749 Node[0] Epoch[22] Batch [120-140]	Speed: 166548.36 samples/sec	accuracy=nan
2021-11-05 21:11:55,142 Node[0] Epoch[22] Batch [140-160]	Speed: 166011.34 samples/sec	accuracy=nan
2021-11-05 21:11:55,537 Node[0] Epoch[22] Batch [160-180]	Speed: 165399.51 samples/sec	accuracy=nan
2021-11-05 21:11:55,929 Node[0] Epoch[22] Batch [180-200]	Speed: 166583.52 samples/sec	accuracy=nan
2021-11-05 21:11:56,322 Node[0] Epoch[22] Batch [200-220]	Speed: 166218.14 samples/sec	accuracy=nan
2021-11-05 21:11:56,716 Node[0] Epoch[22] Batch [220-240]	Speed: 165298.26 samples/sec	accuracy=nan
2021-11-05 21:11:57,110 Node[0] Epoch[22] Batch [240-260]	Speed: 165880.79 samples/sec	accuracy=nan
2021-11-05 21:11:57,504 Node[0] Epoch[22] Batch [260-280]	Speed: 165587.76 samples/sec	accuracy=nan
2021-11-05 21:11:57,898 Node[0] Epoch[22] Batch [280-300]	Speed: 165725.57 samples/sec	accuracy=nan
2021-11-05 21:11:58,291 Node[0] Epoch[22] Batch [300-320]	Speed: 166354.98 samples/sec	accuracy=nan
2021-11-05 21:11:58,686 Node[0] Epoch[22] Batch [320-340]	Speed: 165214.47 samples/sec	accuracy=nan
2021-11-05 21:11:59,083 Node[0] Epoch[22] Batch [340-360]	Speed: 164487.75 samples/sec	accuracy=nan
2021-11-05 21:11:59,481 Node[0] Epoch[22] Batch [360-380]	Speed: 163691.80 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146719716, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 23}}
2021-11-05 21:11:59,717 Node[0] Epoch[22] Time cost=7.738
:::MLLOG {"namespace": "", "time_ms": 1636146719717, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165578.3429491196}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636146719717, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165578.3429491196, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146719733, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 23}}
2021-11-05 21:11:59,846 Node[0] Epoch[22] Validation-accuracy=0.737516
2021-11-05 21:11:59,846 Node[0] Epoch[22] Validation-correct-count=576.000000
2021-11-05 21:11:59,846 Node[0] Epoch[22] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146719863, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636146719863, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.69902, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 23}}
:::MLLOG {"namespace": "", "time_ms": 1636146719863, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 20}}
:::MLLOG {"namespace": "", "time_ms": 1636146719863, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 24, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146719863, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 24}}
2021-11-05 21:12:00,262 Node[0] Epoch[23] Batch [0-20]	Speed: 165728.18 samples/sec	accuracy=nan
2021-11-05 21:12:00,656 Node[0] Epoch[23] Batch [20-40]	Speed: 165674.13 samples/sec	accuracy=nan
2021-11-05 21:12:01,048 Node[0] Epoch[23] Batch [40-60]	Speed: 166425.36 samples/sec	accuracy=nan
2021-11-05 21:12:01,442 Node[0] Epoch[23] Batch [60-80]	Speed: 165695.68 samples/sec	accuracy=nan
2021-11-05 21:12:01,836 Node[0] Epoch[23] Batch [80-100]	Speed: 165878.58 samples/sec	accuracy=nan
2021-11-05 21:12:02,229 Node[0] Epoch[23] Batch [100-120]	Speed: 166260.33 samples/sec	accuracy=nan
2021-11-05 21:12:02,623 Node[0] Epoch[23] Batch [120-140]	Speed: 165654.98 samples/sec	accuracy=nan
2021-11-05 21:12:03,017 Node[0] Epoch[23] Batch [140-160]	Speed: 165562.33 samples/sec	accuracy=nan
2021-11-05 21:12:03,410 Node[0] Epoch[23] Batch [160-180]	Speed: 165876.27 samples/sec	accuracy=nan
2021-11-05 21:12:03,804 Node[0] Epoch[23] Batch [180-200]	Speed: 165688.97 samples/sec	accuracy=nan
2021-11-05 21:12:04,198 Node[0] Epoch[23] Batch [200-220]	Speed: 165689.37 samples/sec	accuracy=nan
2021-11-05 21:12:04,591 Node[0] Epoch[23] Batch [220-240]	Speed: 166323.45 samples/sec	accuracy=nan
2021-11-05 21:12:04,984 Node[0] Epoch[23] Batch [240-260]	Speed: 166198.17 samples/sec	accuracy=nan
2021-11-05 21:12:05,379 Node[0] Epoch[23] Batch [260-280]	Speed: 165254.86 samples/sec	accuracy=nan
2021-11-05 21:12:05,773 Node[0] Epoch[23] Batch [280-300]	Speed: 165625.12 samples/sec	accuracy=nan
2021-11-05 21:12:06,166 Node[0] Epoch[23] Batch [300-320]	Speed: 165997.45 samples/sec	accuracy=nan
2021-11-05 21:12:06,561 Node[0] Epoch[23] Batch [320-340]	Speed: 165424.59 samples/sec	accuracy=nan
2021-11-05 21:12:06,959 Node[0] Epoch[23] Batch [340-360]	Speed: 163974.62 samples/sec	accuracy=nan
2021-11-05 21:12:07,353 Node[0] Epoch[23] Batch [360-380]	Speed: 165690.77 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146727589, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 24}}
2021-11-05 21:12:07,589 Node[0] Epoch[23] Time cost=7.726
:::MLLOG {"namespace": "", "time_ms": 1636146727589, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165829.9272614594}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 24}}
:::MLLOG {"namespace": "", "time_ms": 1636146727589, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165829.9272614594, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146727589, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 25}}
2021-11-05 21:12:08,012 Node[0] Epoch[24] Batch [0-20]	Speed: 172583.78 samples/sec	accuracy=nan
2021-11-05 21:12:08,406 Node[0] Epoch[24] Batch [20-40]	Speed: 165577.25 samples/sec	accuracy=nan
2021-11-05 21:12:08,798 Node[0] Epoch[24] Batch [40-60]	Speed: 166281.84 samples/sec	accuracy=nan
2021-11-05 21:12:09,192 Node[0] Epoch[24] Batch [60-80]	Speed: 166029.96 samples/sec	accuracy=nan
2021-11-05 21:12:09,586 Node[0] Epoch[24] Batch [80-100]	Speed: 165655.59 samples/sec	accuracy=nan
2021-11-05 21:12:09,977 Node[0] Epoch[24] Batch [100-120]	Speed: 166754.26 samples/sec	accuracy=nan
2021-11-05 21:12:10,370 Node[0] Epoch[24] Batch [120-140]	Speed: 166328.00 samples/sec	accuracy=nan
2021-11-05 21:12:10,761 Node[0] Epoch[24] Batch [140-160]	Speed: 166741.16 samples/sec	accuracy=nan
2021-11-05 21:12:11,155 Node[0] Epoch[24] Batch [160-180]	Speed: 165720.36 samples/sec	accuracy=nan
2021-11-05 21:12:11,549 Node[0] Epoch[24] Batch [180-200]	Speed: 165672.12 samples/sec	accuracy=nan
2021-11-05 21:12:11,941 Node[0] Epoch[24] Batch [200-220]	Speed: 166514.43 samples/sec	accuracy=nan
2021-11-05 21:12:12,334 Node[0] Epoch[24] Batch [220-240]	Speed: 165979.34 samples/sec	accuracy=nan
2021-11-05 21:12:12,729 Node[0] Epoch[24] Batch [240-260]	Speed: 165308.64 samples/sec	accuracy=nan
2021-11-05 21:12:13,122 Node[0] Epoch[24] Batch [260-280]	Speed: 166048.29 samples/sec	accuracy=nan
2021-11-05 21:12:13,516 Node[0] Epoch[24] Batch [280-300]	Speed: 165707.52 samples/sec	accuracy=nan
2021-11-05 21:12:13,909 Node[0] Epoch[24] Batch [300-320]	Speed: 166084.45 samples/sec	accuracy=nan
2021-11-05 21:12:14,304 Node[0] Epoch[24] Batch [320-340]	Speed: 165368.74 samples/sec	accuracy=nan
2021-11-05 21:12:14,701 Node[0] Epoch[24] Batch [340-360]	Speed: 164283.06 samples/sec	accuracy=nan
2021-11-05 21:12:15,099 Node[0] Epoch[24] Batch [360-380]	Speed: 164073.76 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146735335, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 25}}
2021-11-05 21:12:15,335 Node[0] Epoch[24] Time cost=7.745
:::MLLOG {"namespace": "", "time_ms": 1636146735335, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165411.4765354804}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 25}}
:::MLLOG {"namespace": "", "time_ms": 1636146735335, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165411.4765354804, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146735335, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 26}}
2021-11-05 21:12:15,748 Node[0] Epoch[25] Batch [0-20]	Speed: 165740.72 samples/sec	accuracy=nan
2021-11-05 21:12:16,141 Node[0] Epoch[25] Batch [20-40]	Speed: 166022.01 samples/sec	accuracy=nan
2021-11-05 21:12:16,535 Node[0] Epoch[25] Batch [40-60]	Speed: 165663.40 samples/sec	accuracy=nan
2021-11-05 21:12:16,929 Node[0] Epoch[25] Batch [60-80]	Speed: 166028.25 samples/sec	accuracy=nan
2021-11-05 21:12:17,320 Node[0] Epoch[25] Batch [80-100]	Speed: 166647.70 samples/sec	accuracy=nan
2021-11-05 21:12:17,712 Node[0] Epoch[25] Batch [100-120]	Speed: 166864.32 samples/sec	accuracy=nan
2021-11-05 21:12:18,104 Node[0] Epoch[25] Batch [120-140]	Speed: 166208.46 samples/sec	accuracy=nan
2021-11-05 21:12:18,497 Node[0] Epoch[25] Batch [140-160]	Speed: 166364.38 samples/sec	accuracy=nan
2021-11-05 21:12:18,890 Node[0] Epoch[25] Batch [160-180]	Speed: 165785.28 samples/sec	accuracy=nan
2021-11-05 21:12:19,285 Node[0] Epoch[25] Batch [180-200]	Speed: 165656.59 samples/sec	accuracy=nan
2021-11-05 21:12:19,678 Node[0] Epoch[25] Batch [200-220]	Speed: 166053.83 samples/sec	accuracy=nan
2021-11-05 21:12:20,071 Node[0] Epoch[25] Batch [220-240]	Speed: 165956.30 samples/sec	accuracy=nan
2021-11-05 21:12:20,465 Node[0] Epoch[25] Batch [240-260]	Speed: 165705.21 samples/sec	accuracy=nan
2021-11-05 21:12:20,858 Node[0] Epoch[25] Batch [260-280]	Speed: 166279.01 samples/sec	accuracy=nan
2021-11-05 21:12:21,251 Node[0] Epoch[25] Batch [280-300]	Speed: 165941.42 samples/sec	accuracy=nan
2021-11-05 21:12:21,643 Node[0] Epoch[25] Batch [300-320]	Speed: 166417.06 samples/sec	accuracy=nan
2021-11-05 21:12:22,038 Node[0] Epoch[25] Batch [320-340]	Speed: 165315.82 samples/sec	accuracy=nan
2021-11-05 21:12:22,440 Node[0] Epoch[25] Batch [340-360]	Speed: 162259.80 samples/sec	accuracy=nan
2021-11-05 21:12:22,835 Node[0] Epoch[25] Batch [360-380]	Speed: 165420.69 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146743072, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 26}}
2021-11-05 21:12:23,072 Node[0] Epoch[25] Time cost=7.737
:::MLLOG {"namespace": "", "time_ms": 1636146743072, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165586.7514907219}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 26}}
:::MLLOG {"namespace": "", "time_ms": 1636146743073, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165586.7514907219, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146743073, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 27}}
2021-11-05 21:12:23,484 Node[0] Epoch[26] Batch [0-20]	Speed: 166521.21 samples/sec	accuracy=nan
2021-11-05 21:12:23,878 Node[0] Epoch[26] Batch [20-40]	Speed: 165294.07 samples/sec	accuracy=nan
2021-11-05 21:12:24,271 Node[0] Epoch[26] Batch [40-60]	Speed: 166418.88 samples/sec	accuracy=nan
2021-11-05 21:12:24,665 Node[0] Epoch[26] Batch [60-80]	Speed: 165479.58 samples/sec	accuracy=nan
2021-11-05 21:12:25,058 Node[0] Epoch[26] Batch [80-100]	Speed: 166079.11 samples/sec	accuracy=nan
2021-11-05 21:12:25,450 Node[0] Epoch[26] Batch [100-120]	Speed: 166604.50 samples/sec	accuracy=nan
2021-11-05 21:12:25,842 Node[0] Epoch[26] Batch [120-140]	Speed: 166592.13 samples/sec	accuracy=nan
2021-11-05 21:12:26,235 Node[0] Epoch[26] Batch [140-160]	Speed: 166118.61 samples/sec	accuracy=nan
2021-11-05 21:12:26,627 Node[0] Epoch[26] Batch [160-180]	Speed: 166493.06 samples/sec	accuracy=nan
2021-11-05 21:12:27,025 Node[0] Epoch[26] Batch [180-200]	Speed: 164158.66 samples/sec	accuracy=nan
2021-11-05 21:12:27,419 Node[0] Epoch[26] Batch [200-220]	Speed: 165650.17 samples/sec	accuracy=nan
2021-11-05 21:12:27,812 Node[0] Epoch[26] Batch [220-240]	Speed: 166085.05 samples/sec	accuracy=nan
2021-11-05 21:12:28,206 Node[0] Epoch[26] Batch [240-260]	Speed: 165621.32 samples/sec	accuracy=nan
2021-11-05 21:12:28,600 Node[0] Epoch[26] Batch [260-280]	Speed: 165485.58 samples/sec	accuracy=nan
2021-11-05 21:12:28,992 Node[0] Epoch[26] Batch [280-300]	Speed: 166807.29 samples/sec	accuracy=nan
2021-11-05 21:12:29,387 Node[0] Epoch[26] Batch [300-320]	Speed: 165028.16 samples/sec	accuracy=nan
2021-11-05 21:12:29,783 Node[0] Epoch[26] Batch [320-340]	Speed: 165149.30 samples/sec	accuracy=nan
2021-11-05 21:12:30,180 Node[0] Epoch[26] Batch [340-360]	Speed: 164253.29 samples/sec	accuracy=nan
2021-11-05 21:12:30,576 Node[0] Epoch[26] Batch [360-380]	Speed: 164809.73 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146750813, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 27}}
2021-11-05 21:12:30,813 Node[0] Epoch[26] Time cost=7.740
:::MLLOG {"namespace": "", "time_ms": 1636146750813, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165526.32898247926}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636146750813, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165526.32898247926, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146750829, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 27}}
2021-11-05 21:12:30,944 Node[0] Epoch[26] Validation-accuracy=0.749040
2021-11-05 21:12:30,944 Node[0] Epoch[26] Validation-correct-count=585.000000
2021-11-05 21:12:30,944 Node[0] Epoch[26] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146750961, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636146750962, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.72938, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 27}}
:::MLLOG {"namespace": "", "time_ms": 1636146750962, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 24}}
:::MLLOG {"namespace": "", "time_ms": 1636146750962, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 28, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146750962, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 28}}
2021-11-05 21:12:31,358 Node[0] Epoch[27] Batch [0-20]	Speed: 167271.47 samples/sec	accuracy=nan
2021-11-05 21:12:31,752 Node[0] Epoch[27] Batch [20-40]	Speed: 165624.12 samples/sec	accuracy=nan
2021-11-05 21:12:32,145 Node[0] Epoch[27] Batch [40-60]	Speed: 165833.17 samples/sec	accuracy=nan
2021-11-05 21:12:32,538 Node[0] Epoch[27] Batch [60-80]	Speed: 166331.74 samples/sec	accuracy=nan
2021-11-05 21:12:32,931 Node[0] Epoch[27] Batch [80-100]	Speed: 166019.90 samples/sec	accuracy=nan
2021-11-05 21:12:33,323 Node[0] Epoch[27] Batch [100-120]	Speed: 166535.90 samples/sec	accuracy=nan
2021-11-05 21:12:33,714 Node[0] Epoch[27] Batch [120-140]	Speed: 167041.86 samples/sec	accuracy=nan
2021-11-05 21:12:34,109 Node[0] Epoch[27] Batch [140-160]	Speed: 165455.18 samples/sec	accuracy=nan
2021-11-05 21:12:34,501 Node[0] Epoch[27] Batch [160-180]	Speed: 166229.85 samples/sec	accuracy=nan
2021-11-05 21:12:34,894 Node[0] Epoch[27] Batch [180-200]	Speed: 166138.77 samples/sec	accuracy=nan
2021-11-05 21:12:35,287 Node[0] Epoch[27] Batch [200-220]	Speed: 166201.49 samples/sec	accuracy=nan
2021-11-05 21:12:35,679 Node[0] Epoch[27] Batch [220-240]	Speed: 166623.15 samples/sec	accuracy=nan
2021-11-05 21:12:36,070 Node[0] Epoch[27] Batch [240-260]	Speed: 166869.51 samples/sec	accuracy=nan
2021-11-05 21:12:36,462 Node[0] Epoch[27] Batch [260-280]	Speed: 166436.28 samples/sec	accuracy=nan
2021-11-05 21:12:36,855 Node[0] Epoch[27] Batch [280-300]	Speed: 166121.13 samples/sec	accuracy=nan
2021-11-05 21:12:37,249 Node[0] Epoch[27] Batch [300-320]	Speed: 165747.84 samples/sec	accuracy=nan
2021-11-05 21:12:37,646 Node[0] Epoch[27] Batch [320-340]	Speed: 164487.75 samples/sec	accuracy=nan
2021-11-05 21:12:38,045 Node[0] Epoch[27] Batch [340-360]	Speed: 163472.30 samples/sec	accuracy=nan
2021-11-05 21:12:38,442 Node[0] Epoch[27] Batch [360-380]	Speed: 164328.61 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146758678, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 28}}
2021-11-05 21:12:38,678 Node[0] Epoch[27] Time cost=7.716
:::MLLOG {"namespace": "", "time_ms": 1636146758678, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 166032.29064849814}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 28}}
:::MLLOG {"namespace": "", "time_ms": 1636146758678, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 166032.29064849814, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146758679, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 29}}
2021-11-05 21:12:39,092 Node[0] Epoch[28] Batch [0-20]	Speed: 165883.91 samples/sec	accuracy=nan
2021-11-05 21:12:39,484 Node[0] Epoch[28] Batch [20-40]	Speed: 166133.02 samples/sec	accuracy=nan
2021-11-05 21:12:39,876 Node[0] Epoch[28] Batch [40-60]	Speed: 166767.47 samples/sec	accuracy=nan
2021-11-05 21:12:40,269 Node[0] Epoch[28] Batch [60-80]	Speed: 165910.45 samples/sec	accuracy=nan
2021-11-05 21:12:40,662 Node[0] Epoch[28] Batch [80-100]	Speed: 166146.93 samples/sec	accuracy=nan
2021-11-05 21:12:41,055 Node[0] Epoch[28] Batch [100-120]	Speed: 166204.62 samples/sec	accuracy=nan
2021-11-05 21:12:41,449 Node[0] Epoch[28] Batch [120-140]	Speed: 165779.86 samples/sec	accuracy=nan
2021-11-05 21:12:41,844 Node[0] Epoch[28] Batch [140-160]	Speed: 165134.66 samples/sec	accuracy=nan
2021-11-05 21:12:42,237 Node[0] Epoch[28] Batch [160-180]	Speed: 166173.65 samples/sec	accuracy=nan
2021-11-05 21:12:42,631 Node[0] Epoch[28] Batch [180-200]	Speed: 165681.65 samples/sec	accuracy=nan
2021-11-05 21:12:43,025 Node[0] Epoch[28] Batch [200-220]	Speed: 165506.49 samples/sec	accuracy=nan
2021-11-05 21:12:43,418 Node[0] Epoch[28] Batch [220-240]	Speed: 166231.77 samples/sec	accuracy=nan
2021-11-05 21:12:43,810 Node[0] Epoch[28] Batch [240-260]	Speed: 166640.70 samples/sec	accuracy=nan
2021-11-05 21:12:44,207 Node[0] Epoch[28] Batch [260-280]	Speed: 164382.97 samples/sec	accuracy=nan
2021-11-05 21:12:44,600 Node[0] Epoch[28] Batch [280-300]	Speed: 166016.37 samples/sec	accuracy=nan
2021-11-05 21:12:44,994 Node[0] Epoch[28] Batch [300-320]	Speed: 165713.74 samples/sec	accuracy=nan
2021-11-05 21:12:45,390 Node[0] Epoch[28] Batch [320-340]	Speed: 164963.14 samples/sec	accuracy=nan
2021-11-05 21:12:45,788 Node[0] Epoch[28] Batch [340-360]	Speed: 163929.66 samples/sec	accuracy=nan
2021-11-05 21:12:46,183 Node[0] Epoch[28] Batch [360-380]	Speed: 165377.63 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146766420, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 29}}
2021-11-05 21:12:46,420 Node[0] Epoch[28] Time cost=7.741
:::MLLOG {"namespace": "", "time_ms": 1636146766420, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165494.59499797443}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 29}}
:::MLLOG {"namespace": "", "time_ms": 1636146766420, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165494.59499797443, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146766420, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 30}}
2021-11-05 21:12:46,832 Node[0] Epoch[29] Batch [0-20]	Speed: 166008.62 samples/sec	accuracy=nan
2021-11-05 21:12:47,230 Node[0] Epoch[29] Batch [20-40]	Speed: 164208.77 samples/sec	accuracy=nan
2021-11-05 21:12:47,622 Node[0] Epoch[29] Batch [40-60]	Speed: 166616.56 samples/sec	accuracy=nan
2021-11-05 21:12:48,014 Node[0] Epoch[29] Batch [60-80]	Speed: 166297.49 samples/sec	accuracy=nan
2021-11-05 21:12:48,406 Node[0] Epoch[29] Batch [80-100]	Speed: 166537.11 samples/sec	accuracy=nan
2021-11-05 21:12:48,800 Node[0] Epoch[29] Batch [100-120]	Speed: 166008.02 samples/sec	accuracy=nan
2021-11-05 21:12:49,192 Node[0] Epoch[29] Batch [120-140]	Speed: 166428.60 samples/sec	accuracy=nan
2021-11-05 21:12:49,585 Node[0] Epoch[29] Batch [140-160]	Speed: 166137.05 samples/sec	accuracy=nan
2021-11-05 21:12:49,978 Node[0] Epoch[29] Batch [160-180]	Speed: 166037.41 samples/sec	accuracy=nan
2021-11-05 21:12:50,373 Node[0] Epoch[29] Batch [180-200]	Speed: 165170.22 samples/sec	accuracy=nan
2021-11-05 21:12:50,768 Node[0] Epoch[29] Batch [200-220]	Speed: 165466.48 samples/sec	accuracy=nan
2021-11-05 21:12:51,160 Node[0] Epoch[29] Batch [220-240]	Speed: 166184.55 samples/sec	accuracy=nan
2021-11-05 21:12:51,552 Node[0] Epoch[29] Batch [240-260]	Speed: 166708.68 samples/sec	accuracy=nan
2021-11-05 21:12:51,945 Node[0] Epoch[29] Batch [260-280]	Speed: 166200.59 samples/sec	accuracy=nan
2021-11-05 21:12:52,338 Node[0] Epoch[29] Batch [280-300]	Speed: 166185.66 samples/sec	accuracy=nan
2021-11-05 21:12:52,733 Node[0] Epoch[29] Batch [300-320]	Speed: 165326.80 samples/sec	accuracy=nan
2021-11-05 21:12:53,129 Node[0] Epoch[29] Batch [320-340]	Speed: 164477.57 samples/sec	accuracy=nan
2021-11-05 21:12:53,526 Node[0] Epoch[29] Batch [340-360]	Speed: 164587.31 samples/sec	accuracy=nan
2021-11-05 21:12:53,923 Node[0] Epoch[29] Batch [360-380]	Speed: 164456.33 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146774158, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 30}}
2021-11-05 21:12:54,159 Node[0] Epoch[29] Time cost=7.738
:::MLLOG {"namespace": "", "time_ms": 1636146774159, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165562.2782743232}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 30}}
:::MLLOG {"namespace": "", "time_ms": 1636146774159, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165562.2782743232, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146774159, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 31}}
2021-11-05 21:12:54,570 Node[0] Epoch[30] Batch [0-20]	Speed: 166381.57 samples/sec	accuracy=nan
2021-11-05 21:12:54,963 Node[0] Epoch[30] Batch [20-40]	Speed: 166402.60 samples/sec	accuracy=nan
2021-11-05 21:12:55,358 Node[0] Epoch[30] Batch [40-60]	Speed: 165329.00 samples/sec	accuracy=nan
2021-11-05 21:12:55,750 Node[0] Epoch[30] Batch [60-80]	Speed: 166462.19 samples/sec	accuracy=nan
2021-11-05 21:12:56,141 Node[0] Epoch[30] Batch [80-100]	Speed: 166696.60 samples/sec	accuracy=nan
2021-11-05 21:12:56,534 Node[0] Epoch[30] Batch [100-120]	Speed: 166414.03 samples/sec	accuracy=nan
2021-11-05 21:12:56,925 Node[0] Epoch[30] Batch [120-140]	Speed: 166823.66 samples/sec	accuracy=nan
2021-11-05 21:12:57,319 Node[0] Epoch[30] Batch [140-160]	Speed: 165489.98 samples/sec	accuracy=nan
2021-11-05 21:12:57,713 Node[0] Epoch[30] Batch [160-180]	Speed: 165692.28 samples/sec	accuracy=nan
2021-11-05 21:12:58,108 Node[0] Epoch[30] Batch [180-200]	Speed: 165381.93 samples/sec	accuracy=nan
2021-11-05 21:12:58,501 Node[0] Epoch[30] Batch [200-220]	Speed: 166298.40 samples/sec	accuracy=nan
2021-11-05 21:12:58,892 Node[0] Epoch[30] Batch [220-240]	Speed: 166657.43 samples/sec	accuracy=nan
2021-11-05 21:12:59,286 Node[0] Epoch[30] Batch [240-260]	Speed: 165609.19 samples/sec	accuracy=nan
2021-11-05 21:12:59,678 Node[0] Epoch[30] Batch [260-280]	Speed: 166915.90 samples/sec	accuracy=nan
2021-11-05 21:13:00,073 Node[0] Epoch[30] Batch [280-300]	Speed: 165067.16 samples/sec	accuracy=nan
2021-11-05 21:13:00,467 Node[0] Epoch[30] Batch [300-320]	Speed: 165517.59 samples/sec	accuracy=nan
2021-11-05 21:13:00,863 Node[0] Epoch[30] Batch [320-340]	Speed: 164859.24 samples/sec	accuracy=nan
2021-11-05 21:13:01,262 Node[0] Epoch[30] Batch [340-360]	Speed: 163825.10 samples/sec	accuracy=nan
2021-11-05 21:13:01,659 Node[0] Epoch[30] Batch [360-380]	Speed: 164521.25 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146781894, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 31}}
2021-11-05 21:13:01,894 Node[0] Epoch[30] Time cost=7.735
:::MLLOG {"namespace": "", "time_ms": 1636146781894, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165628.28118641497}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636146781894, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165628.28118641497, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146781911, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 31}}
2021-11-05 21:13:02,025 Node[0] Epoch[30] Validation-accuracy=0.765685
2021-11-05 21:13:02,025 Node[0] Epoch[30] Validation-correct-count=598.000000
2021-11-05 21:13:02,025 Node[0] Epoch[30] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146782042, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636146782043, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.75254, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 31}}
:::MLLOG {"namespace": "", "time_ms": 1636146782043, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 28}}
:::MLLOG {"namespace": "", "time_ms": 1636146782043, "event_type": "INTERVAL_START", "key": "block_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1063, "first_epoch_num": 32, "epoch_count": 4}}
:::MLLOG {"namespace": "", "time_ms": 1636146782043, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 32}}
2021-11-05 21:13:02,439 Node[0] Epoch[31] Batch [0-20]	Speed: 166749.08 samples/sec	accuracy=nan
2021-11-05 21:13:02,834 Node[0] Epoch[31] Batch [20-40]	Speed: 165601.28 samples/sec	accuracy=nan
2021-11-05 21:13:03,228 Node[0] Epoch[31] Batch [40-60]	Speed: 165588.66 samples/sec	accuracy=nan
2021-11-05 21:13:03,619 Node[0] Epoch[31] Batch [60-80]	Speed: 166998.77 samples/sec	accuracy=nan
2021-11-05 21:13:04,011 Node[0] Epoch[31] Batch [80-100]	Speed: 166363.57 samples/sec	accuracy=nan
2021-11-05 21:13:04,403 Node[0] Epoch[31] Batch [100-120]	Speed: 166684.83 samples/sec	accuracy=nan
2021-11-05 21:13:04,794 Node[0] Epoch[31] Batch [120-140]	Speed: 167047.47 samples/sec	accuracy=nan
2021-11-05 21:13:05,187 Node[0] Epoch[31] Batch [140-160]	Speed: 165933.57 samples/sec	accuracy=nan
2021-11-05 21:13:05,580 Node[0] Epoch[31] Batch [160-180]	Speed: 166069.84 samples/sec	accuracy=nan
2021-11-05 21:13:05,972 Node[0] Epoch[31] Batch [180-200]	Speed: 166457.53 samples/sec	accuracy=nan
2021-11-05 21:13:06,364 Node[0] Epoch[31] Batch [200-220]	Speed: 166663.72 samples/sec	accuracy=nan
2021-11-05 21:13:06,759 Node[0] Epoch[31] Batch [220-240]	Speed: 165388.32 samples/sec	accuracy=nan
2021-11-05 21:13:07,152 Node[0] Epoch[31] Batch [240-260]	Speed: 166151.07 samples/sec	accuracy=nan
2021-11-05 21:13:07,545 Node[0] Epoch[31] Batch [260-280]	Speed: 165913.16 samples/sec	accuracy=nan
2021-11-05 21:13:07,938 Node[0] Epoch[31] Batch [280-300]	Speed: 165894.76 samples/sec	accuracy=nan
2021-11-05 21:13:08,334 Node[0] Epoch[31] Batch [300-320]	Speed: 165181.38 samples/sec	accuracy=nan
2021-11-05 21:13:08,729 Node[0] Epoch[31] Batch [320-340]	Speed: 165289.18 samples/sec	accuracy=nan
2021-11-05 21:13:09,126 Node[0] Epoch[31] Batch [340-360]	Speed: 164341.73 samples/sec	accuracy=nan
2021-11-05 21:13:09,521 Node[0] Epoch[31] Batch [360-380]	Speed: 165113.55 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146789756, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 32}}
2021-11-05 21:13:09,756 Node[0] Epoch[31] Time cost=7.713
:::MLLOG {"namespace": "", "time_ms": 1636146789757, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 166096.00948158524}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 32}}
:::MLLOG {"namespace": "", "time_ms": 1636146789757, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 166096.00948158524, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146789757, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 33}}
2021-11-05 21:13:10,170 Node[0] Epoch[32] Batch [0-20]	Speed: 165605.39 samples/sec	accuracy=nan
2021-11-05 21:13:10,564 Node[0] Epoch[32] Batch [20-40]	Speed: 165811.88 samples/sec	accuracy=nan
2021-11-05 21:13:10,956 Node[0] Epoch[32] Batch [40-60]	Speed: 166458.55 samples/sec	accuracy=nan
2021-11-05 21:13:11,349 Node[0] Epoch[32] Batch [60-80]	Speed: 166146.33 samples/sec	accuracy=nan
2021-11-05 21:13:11,742 Node[0] Epoch[32] Batch [80-100]	Speed: 166120.32 samples/sec	accuracy=nan
2021-11-05 21:13:12,135 Node[0] Epoch[32] Batch [100-120]	Speed: 166027.35 samples/sec	accuracy=nan
2021-11-05 21:13:12,529 Node[0] Epoch[32] Batch [120-140]	Speed: 165801.34 samples/sec	accuracy=nan
2021-11-05 21:13:12,924 Node[0] Epoch[32] Batch [140-160]	Speed: 165365.04 samples/sec	accuracy=nan
2021-11-05 21:13:13,314 Node[0] Epoch[32] Batch [160-180]	Speed: 167089.26 samples/sec	accuracy=nan
2021-11-05 21:13:13,708 Node[0] Epoch[32] Batch [180-200]	Speed: 165757.27 samples/sec	accuracy=nan
2021-11-05 21:13:14,105 Node[0] Epoch[32] Batch [200-220]	Speed: 164351.59 samples/sec	accuracy=nan
2021-11-05 21:13:14,500 Node[0] Epoch[32] Batch [220-240]	Speed: 165427.59 samples/sec	accuracy=nan
2021-11-05 21:13:14,894 Node[0] Epoch[32] Batch [240-260]	Speed: 165890.84 samples/sec	accuracy=nan
2021-11-05 21:13:15,287 Node[0] Epoch[32] Batch [260-280]	Speed: 166078.51 samples/sec	accuracy=nan
2021-11-05 21:13:15,681 Node[0] Epoch[32] Batch [280-300]	Speed: 165663.20 samples/sec	accuracy=nan
2021-11-05 21:13:16,076 Node[0] Epoch[32] Batch [300-320]	Speed: 165291.37 samples/sec	accuracy=nan
2021-11-05 21:13:16,472 Node[0] Epoch[32] Batch [320-340]	Speed: 164841.97 samples/sec	accuracy=nan
2021-11-05 21:13:16,868 Node[0] Epoch[32] Batch [340-360]	Speed: 164816.87 samples/sec	accuracy=nan
2021-11-05 21:13:17,264 Node[0] Epoch[32] Batch [360-380]	Speed: 164713.55 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146797500, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 33}}
2021-11-05 21:13:17,500 Node[0] Epoch[32] Time cost=7.744
:::MLLOG {"namespace": "", "time_ms": 1636146797500, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165450.350867981}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 33}}
:::MLLOG {"namespace": "", "time_ms": 1636146797501, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165450.350867981, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146797501, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 34}}
2021-11-05 21:13:17,913 Node[0] Epoch[33] Batch [0-20]	Speed: 166296.28 samples/sec	accuracy=nan
2021-11-05 21:13:18,307 Node[0] Epoch[33] Batch [20-40]	Speed: 165499.78 samples/sec	accuracy=nan
2021-11-05 21:13:18,700 Node[0] Epoch[33] Batch [40-60]	Speed: 166141.89 samples/sec	accuracy=nan
2021-11-05 21:13:19,092 Node[0] Epoch[33] Batch [60-80]	Speed: 166743.50 samples/sec	accuracy=nan
2021-11-05 21:13:19,484 Node[0] Epoch[33] Batch [80-100]	Speed: 166623.56 samples/sec	accuracy=nan
2021-11-05 21:13:19,881 Node[0] Epoch[33] Batch [100-120]	Speed: 164322.79 samples/sec	accuracy=nan
2021-11-05 21:13:20,272 Node[0] Epoch[33] Batch [120-140]	Speed: 166943.38 samples/sec	accuracy=nan
2021-11-05 21:13:20,665 Node[0] Epoch[33] Batch [140-160]	Speed: 166171.23 samples/sec	accuracy=nan
2021-11-05 21:13:21,056 Node[0] Epoch[33] Batch [160-180]	Speed: 166887.61 samples/sec	accuracy=nan
2021-11-05 21:13:21,451 Node[0] Epoch[33] Batch [180-200]	Speed: 165268.22 samples/sec	accuracy=nan
2021-11-05 21:13:21,843 Node[0] Epoch[33] Batch [200-220]	Speed: 166574.50 samples/sec	accuracy=nan
2021-11-05 21:13:22,236 Node[0] Epoch[33] Batch [220-240]	Speed: 165925.43 samples/sec	accuracy=nan
2021-11-05 21:13:22,629 Node[0] Epoch[33] Batch [240-260]	Speed: 166261.44 samples/sec	accuracy=nan
2021-11-05 21:13:23,024 Node[0] Epoch[33] Batch [260-280]	Speed: 165039.10 samples/sec	accuracy=nan
2021-11-05 21:13:23,420 Node[0] Epoch[33] Batch [280-300]	Speed: 165136.75 samples/sec	accuracy=nan
2021-11-05 21:13:23,814 Node[0] Epoch[33] Batch [300-320]	Speed: 165606.69 samples/sec	accuracy=nan
2021-11-05 21:13:24,212 Node[0] Epoch[33] Batch [320-340]	Speed: 164078.78 samples/sec	accuracy=nan
2021-11-05 21:13:24,609 Node[0] Epoch[33] Batch [340-360]	Speed: 164468.97 samples/sec	accuracy=nan
2021-11-05 21:13:25,006 Node[0] Epoch[33] Batch [360-380]	Speed: 164353.07 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146805241, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 34}}
2021-11-05 21:13:25,241 Node[0] Epoch[33] Time cost=7.740
:::MLLOG {"namespace": "", "time_ms": 1636146805241, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165523.63175786796}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 34}}
:::MLLOG {"namespace": "", "time_ms": 1636146805241, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165523.63175786796, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146805241, "event_type": "INTERVAL_START", "key": "epoch_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 913, "epoch_num": 35}}
2021-11-05 21:13:25,653 Node[0] Epoch[34] Batch [0-20]	Speed: 166292.75 samples/sec	accuracy=nan
2021-11-05 21:13:26,048 Node[0] Epoch[34] Batch [20-40]	Speed: 165329.70 samples/sec	accuracy=nan
2021-11-05 21:13:26,441 Node[0] Epoch[34] Batch [40-60]	Speed: 166352.86 samples/sec	accuracy=nan
2021-11-05 21:13:26,832 Node[0] Epoch[34] Batch [60-80]	Speed: 166587.88 samples/sec	accuracy=nan
2021-11-05 21:13:27,225 Node[0] Epoch[34] Batch [80-100]	Speed: 166158.13 samples/sec	accuracy=nan
2021-11-05 21:13:27,617 Node[0] Epoch[34] Batch [100-120]	Speed: 166555.75 samples/sec	accuracy=nan
2021-11-05 21:13:28,009 Node[0] Epoch[34] Batch [120-140]	Speed: 166567.91 samples/sec	accuracy=nan
2021-11-05 21:13:28,402 Node[0] Epoch[34] Batch [140-160]	Speed: 165997.15 samples/sec	accuracy=nan
2021-11-05 21:13:28,799 Node[0] Epoch[34] Batch [160-180]	Speed: 164516.31 samples/sec	accuracy=nan
2021-11-05 21:13:29,192 Node[0] Epoch[34] Batch [180-200]	Speed: 166109.24 samples/sec	accuracy=nan
2021-11-05 21:13:29,584 Node[0] Epoch[34] Batch [200-220]	Speed: 166468.16 samples/sec	accuracy=nan
2021-11-05 21:13:29,978 Node[0] Epoch[34] Batch [220-240]	Speed: 165907.93 samples/sec	accuracy=nan
2021-11-05 21:13:30,371 Node[0] Epoch[34] Batch [240-260]	Speed: 165995.74 samples/sec	accuracy=nan
2021-11-05 21:13:30,764 Node[0] Epoch[34] Batch [260-280]	Speed: 166132.32 samples/sec	accuracy=nan
2021-11-05 21:13:31,156 Node[0] Epoch[34] Batch [280-300]	Speed: 166509.97 samples/sec	accuracy=nan
2021-11-05 21:13:31,549 Node[0] Epoch[34] Batch [300-320]	Speed: 166156.11 samples/sec	accuracy=nan
2021-11-05 21:13:31,943 Node[0] Epoch[34] Batch [320-340]	Speed: 165779.96 samples/sec	accuracy=nan
2021-11-05 21:13:32,341 Node[0] Epoch[34] Batch [340-360]	Speed: 164093.63 samples/sec	accuracy=nan
2021-11-05 21:13:32,737 Node[0] Epoch[34] Batch [360-380]	Speed: 164751.51 samples/sec	accuracy=nan
:::MLLOG {"namespace": "", "time_ms": 1636146812972, "event_type": "INTERVAL_END", "key": "epoch_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 978, "epoch_num": 35}}
2021-11-05 21:13:32,972 Node[0] Epoch[34] Time cost=7.731
:::MLLOG {"namespace": "", "time_ms": 1636146812972, "event_type": "POINT_IN_TIME", "key": "tracked_stats", "value": {"imgs_sec": 165726.68405459158}, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 994, "step": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636146812972, "event_type": "POINT_IN_TIME", "key": "throughput", "value": 165726.68405459158, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 997}}
:::MLLOG {"namespace": "", "time_ms": 1636146812989, "event_type": "INTERVAL_START", "key": "eval_start", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1016, "epoch_num": 35}}
2021-11-05 21:13:33,101 Node[0] Epoch[34] Validation-accuracy=0.765685
2021-11-05 21:13:33,102 Node[0] Epoch[34] Validation-correct-count=598.000000
2021-11-05 21:13:33,102 Node[0] Epoch[34] Validation-total-count=781.000000
:::MLLOG {"namespace": "", "time_ms": 1636146813118, "event_type": "INTERVAL_END", "key": "eval_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1039, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636146813118, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.76054, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1044, "epoch_num": 35}}
:::MLLOG {"namespace": "", "time_ms": 1636146813118, "event_type": "INTERVAL_END", "key": "block_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1047, "first_epoch_num": 32}}
:::MLLOG {"namespace": "", "time_ms": 1636146813118, "event_type": "INTERVAL_END", "key": "run_stop", "value": null, "metadata": {"file": "/workspace/image_classification/common/fit.py", "lineno": 1051, "status": "success"}}
ENDING TIMING RUN AT 2021-11-05 09:13:52 PM
RESULT,IMAGE_CLASSIFICATION,,428,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:53 PM
RESULT,IMAGE_CLASSIFICATION,,429,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:53 PM
RESULT,IMAGE_CLASSIFICATION,,429,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:54 PM
RESULT,IMAGE_CLASSIFICATION,,430,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:55 PM
RESULT,IMAGE_CLASSIFICATION,,431,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:56 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:56 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:56 PM
RESULT,IMAGE_CLASSIFICATION,,432,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
ENDING TIMING RUN AT 2021-11-05 09:13:57 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
RESULT,IMAGE_CLASSIFICATION,,433,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:58 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:58 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:58 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:58 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:58 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:58 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:58 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:58 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:58 PM
RESULT,IMAGE_CLASSIFICATION,,434,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:59 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:59 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:59 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:13:59 PM
RESULT,IMAGE_CLASSIFICATION,,435,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:00 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:00 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:00 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:00 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:00 PM
RESULT,IMAGE_CLASSIFICATION,,436,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:01 PM
ENDING TIMING RUN AT 2021-11-05 09:14:01 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 09:06:44 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:01 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:01 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:01 PM
ENDING TIMING RUN AT 2021-11-05 09:14:01 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 09:06:44 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:01 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:01 PM
RESULT,IMAGE_CLASSIFICATION,,437,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:02 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:02 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:02 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:02 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:02 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:02 PM
RESULT,IMAGE_CLASSIFICATION,,438,root,2021-11-05 09:06:44 PM
ENDING TIMING RUN AT 2021-11-05 09:14:03 PM
RESULT,IMAGE_CLASSIFICATION,,439,root,2021-11-05 09:06:44 PM
